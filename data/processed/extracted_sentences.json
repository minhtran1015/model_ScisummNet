{
    "W11-2139": {
        "input_sentences": [
            "The CMU-ARK German-English Translation System",
            "This paper describes the German-English translation system developed by the ARK research group at Carnegie Mellon University for the Sixth Workshop on Machine Translation (WMT11).",
            "We present the results of several modeling and training improvements to our core hierarchical phrase-based translation system, including: feature engineering to improve modeling of the derivation structure of translations; better handing of OOVs; and using development set translations into other languages to create additional pseudoreferences for training.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.3763249041491011,
                0.03784999541878948,
                0.0
            ],
            [
                0.3763249041491011,
                1.0,
                0.03478782856295148,
                0.0
            ],
            [
                0.03784999541878948,
                0.03478782856295148,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "D12-1126": {
        "input_sentences": [
            "Meanwhile, our method also boosts the performance of POS tagging for pure Chinese texts.",
            "Due to the lack of specially annotated corpus, most of the English words are tagged as the oversimplified type, \u201cforeign words\u201d.",
            "In modern Chinese articles or conversations, it is very popular to involve a few English words, especially in emails and Internet literature.",
            "Experiments show that our method achieves higher performance than traditional sequence labeling methods.",
            "Therefore, it becomes an important and challenging topic to analyze Chinese-English mixed texts.",
            "Dynamic Features",
            "In this paper, we present a method using dynamic features to tag POS of mixed texts.",
            "The underlying problem is how to tag part-of-speech (POS) for the English words involved.",
            "Part-of-Speech Tagging for Chinese-English Mixed Texts with Dynamic Features",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.05836329436680251,
                0.19038521555442572,
                0.1561424773763962,
                0.0,
                0.2517886119333264,
                0.09772564569744747,
                0.3294265508132168,
                0.0
            ],
            [
                0.0,
                1.0,
                0.13956027037214888,
                0.0,
                0.04512334829605968,
                0.0,
                0.0,
                0.18471581728937633,
                0.052124226142999025,
                0.0
            ],
            [
                0.05836329436680251,
                0.13956027037214888,
                1.0,
                0.0,
                0.10215235969943612,
                0.0,
                0.0,
                0.1159065997125784,
                0.11800127648061418,
                0.0
            ],
            [
                0.19038521555442572,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.07306312974357669,
                0.0,
                0.0,
                0.0
            ],
            [
                0.1561424773763962,
                0.04512334829605968,
                0.10215235969943612,
                0.0,
                1.0,
                0.0,
                0.15652842291718255,
                0.06036132148786439,
                0.35576635883623525,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.39967130655606486,
                0.0,
                0.5053551827781617,
                0.0
            ],
            [
                0.2517886119333264,
                0.0,
                0.0,
                0.07306312974357669,
                0.15652842291718255,
                0.39967130655606486,
                1.0,
                0.199513007907777,
                0.38278974046426273,
                0.0
            ],
            [
                0.09772564569744747,
                0.18471581728937633,
                0.1159065997125784,
                0.0,
                0.06036132148786439,
                0.0,
                0.199513007907777,
                1.0,
                0.21262147699514686,
                0.0
            ],
            [
                0.3294265508132168,
                0.052124226142999025,
                0.11800127648061418,
                0.0,
                0.35576635883623525,
                0.5053551827781617,
                0.38278974046426273,
                0.21262147699514686,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "W01-0510": {
        "input_sentences": [
            "The paper presents a data-driven approach to information extraction (viewed as template filling) using the structured language model (SLM) as a statistical parser.",
            "The task of template filling is cast as constrained parsing using the SLM.",
            "The model is automatically trained from a set of sentences annotated with frame/slot labels and spans.",
            "Training proceeds in stages: first a constrained syntactic parser is trained such that the parses on training data meet the specified semantic spans, then the non-terminal labels are enriched to contain semantic information and finally a constrained syntactic+semantic parser is trained on the parse trees resulting from the previous stage.",
            "Abstract",
            "Despite the small amount of training data used, the model is shown to outperform the slot level accuracy of a simple semantic grammar authored manually for the MiPad personal information management task.",
            "Information Extraction Using The Structured Language Model"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.29704416300629644,
                0.037496860800601634,
                0.10271763287421697,
                0.0,
                0.0838178631745121,
                0.514272243870114
            ],
            [
                0.29704416300629644,
                1.0,
                0.0,
                0.09107719030596993,
                0.0,
                0.06655442482166087,
                0.11312055399751217
            ],
            [
                0.037496860800601634,
                0.0,
                1.0,
                0.1557587780460249,
                0.0,
                0.08825258888168074,
                0.07291247242593155
            ],
            [
                0.10271763287421697,
                0.09107719030596993,
                0.1557587780460249,
                1.0,
                0.0,
                0.1643547967972304,
                0.03352282262418517
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0838178631745121,
                0.06655442482166087,
                0.08825258888168074,
                0.1643547967972304,
                0.0,
                1.0,
                0.09798686896931907
            ],
            [
                0.514272243870114,
                0.11312055399751217,
                0.07291247242593155,
                0.03352282262418517,
                0.0,
                0.09798686896931907,
                1.0
            ]
        ]
    },
    "W06-2204": {
        "input_sentences": [
            "The requirement for large labelled training corpora is widely recognized as a key bottleneck in the use of learning algorithms for extraction.",
            "Compared to previous work, two novel features.",
            "Second, most bootstrapping methods identify the highest quality fragments in the unlabelled data and then assume that they are as reliable as manually labelled data in subsequent iterations. contrast, scoring mechanism prevents errors from snowballing by recording the reliability of fragments extracted from unlabelled data.",
            "Our experiments with several demonstrate that usually competitive with various fully-supervised algorithms when very little labelled training data is available.",
            "We present a semi-supervised learning algorithm for information extraction that can acquire extraction patterns from a small amount of labelled text in conjunction with a large amount of unlabelled text.",
            "Abstract",
            "First, the algorithm does not require redundancy in the fragments to be extracted, but only redundancy of the extraction patterns themselves.",
            "Transductive Pattern Learning For Information Extraction"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.021987680112525,
                0.16705073220358235,
                0.18969127194173205,
                0.0,
                0.041010181811105856,
                0.15036328741515304
            ],
            [
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.021987680112525,
                0.0,
                1.0,
                0.1323794180775436,
                0.08043159223084566,
                0.0,
                0.12264358530760344,
                0.0
            ],
            [
                0.16705073220358235,
                0.0,
                0.1323794180775436,
                1.0,
                0.0831189234485537,
                0.0,
                0.0,
                0.0
            ],
            [
                0.18969127194173205,
                0.0,
                0.08043159223084566,
                0.0831189234485537,
                1.0,
                0.0,
                0.1833987395845558,
                0.26852340054845847
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.041010181811105856,
                0.0,
                0.12264358530760344,
                0.0,
                0.1833987395845558,
                0.0,
                1.0,
                0.06955400315935216
            ],
            [
                0.15036328741515304,
                0.0,
                0.0,
                0.0,
                0.26852340054845847,
                0.0,
                0.06955400315935216,
                1.0
            ]
        ]
    },
    "D08-1094": {
        "input_sentences": [
            "This task is a crucial step towards a robust, vector-based compositional account of sentence meaning.",
            "This makes it possible to integrate syntax into the computation of word meaning in context.",
            "We argue that existing models for this task do not take syntactic structure sufficiently into account. present a novel vector space model that addresses these issues by incorporating the selectional preferences for words\u2019 argument positions.",
            "We address the task of computing vector space representations for the meaning of word occurrences, which can vary widely according to context.",
            "A Structured Vector Space Model for Word Meaning in Context",
            "Abstract",
            "In addition, the model performs at and above the state of the art for modeling the contextual adequacy of paraphrases."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.053252479013257616,
                0.12933269319136162,
                0.14320710607252835,
                0.13857038818177173,
                0.0,
                0.0
            ],
            [
                0.053252479013257616,
                1.0,
                0.0,
                0.17548424344204644,
                0.28243571343585994,
                0.0,
                0.0
            ],
            [
                0.12933269319136162,
                0.0,
                1.0,
                0.10288575640253957,
                0.16559100373895358,
                0.0,
                0.04005301246686281
            ],
            [
                0.14320710607252835,
                0.17548424344204644,
                0.10288575640253957,
                1.0,
                0.3737241642859834,
                0.0,
                0.0
            ],
            [
                0.13857038818177173,
                0.28243571343585994,
                0.16559100373895358,
                0.3737241642859834,
                1.0,
                0.0,
                0.08888299224438508
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.04005301246686281,
                0.0,
                0.08888299224438508,
                0.0,
                1.0
            ]
        ]
    },
    "W09-1210": {
        "input_sentences": [
            "Efficient Parsing of Syntactic and Semantic Dependency Structures",
            "For the subtask of syntactic dependency parsing, we could reach the second place with an accuracy in average of 85.68 which is only 0.09 points behind the first ranked system.",
            "The semantic role labeler works not as well as our parser and we reached therefore the fourth place (ranked by the macro F1 score) in the joint task for syntactic and semantic dependency parsing.",
            "Our system combines and implements efficient parsing techniques to get a high accuracy as well as very good parsing and training time.",
            "For this task, our system has the highest accuracy for English with 89.88, German with 87.48 and the out-of-domain data in average with 78.79.",
            "Abstract",
            "We think that also the development of systems can profit from this since one can perform more experiments in the given time.",
            "For the applications of syntactic and semantic parsing, the parsing time and memory footprint are very important.",
            "In this paper, we describe our system for the 2009 CoNLL shared task for joint parsing of syntactic and semantic dependency structures of multiple languages."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.1850537119381076,
                0.29054398597393205,
                0.2483060851042223,
                0.0,
                0.0,
                0.0,
                0.30291672253438734,
                0.4154287355659199
            ],
            [
                0.1850537119381076,
                1.0,
                0.1976542762393916,
                0.11079888914834941,
                0.10704252300879315,
                0.0,
                0.0,
                0.10600118132228444,
                0.10225545764668223
            ],
            [
                0.29054398597393205,
                0.1976542762393916,
                1.0,
                0.047842820495640176,
                0.039749290282465655,
                0.0,
                0.0,
                0.17933205560265086,
                0.2681754140535995
            ],
            [
                0.2483060851042223,
                0.11079888914834941,
                0.047842820495640176,
                1.0,
                0.050619744212930196,
                0.0,
                0.06593609801317635,
                0.21543484515154937,
                0.059152005189119
            ],
            [
                0.0,
                0.10704252300879315,
                0.039749290282465655,
                0.050619744212930196,
                1.0,
                0.0,
                0.0,
                0.0,
                0.049145309592825336
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.06593609801317635,
                0.0,
                0.0,
                1.0,
                0.07777915902450919,
                0.0
            ],
            [
                0.30291672253438734,
                0.10600118132228444,
                0.17933205560265086,
                0.21543484515154937,
                0.0,
                0.0,
                0.07777915902450919,
                1.0,
                0.16738323034528801
            ],
            [
                0.4154287355659199,
                0.10225545764668223,
                0.2681754140535995,
                0.059152005189119,
                0.049145309592825336,
                0.0,
                0.0,
                0.16738323034528801,
                1.0
            ]
        ]
    },
    "C08-1081": {
        "input_sentences": [
            "Parsing the SynTagRus Treebank of Russian",
            "A feature analysis shows that high parsing accuracy is crucially dependent on the use of both lexical and morphological features.",
            "We present the first results on parsing the SYNTAGRUS treebank of Russian with a data-driven dependency parser, achieving a labeled attachment score of over 82% and an unlabeled attachment score of 89%.",
            "Abstract",
            "We conjecture that the latter result can be generalized to richly inflected languages in general, provided that sufficient amounts of training data are available."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.08554239210665184,
                0.3377312534024911,
                0.0,
                0.0
            ],
            [
                0.08554239210665184,
                1.0,
                0.028890339305226883,
                0.0,
                0.0
            ],
            [
                0.3377312534024911,
                0.028890339305226883,
                1.0,
                0.0,
                0.03988554181515318
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.03988554181515318,
                0.0,
                1.0
            ]
        ]
    },
    "D11-1132": {
        "input_sentences": [
            "Relation Extraction with Relation Topics",
            "This paper describes a novel approach to the semantic relation detection problem.",
            "Instead of relying only on the training instances for a new relation, we leverage the knowledge learned from previously trained relation detectors.",
            "First, we construct a large relation repository of more than 7,000 relations from Wikipedia.",
            "Third, we integrate the relation topics in a kernel function, and use it together with SVM to construct detectors for new relations.",
            "Specifically, we detect a new semantic relation by projecting the new relation\u2019s training instances onto a lower dimension topic space constructed from existing relation detectors through a three step process.",
            "Abstract",
            "The experimental results on Wikipedia and ACE data have confirmed that backgroundknowledge-based topics generated from the Wikipedia relation repository can significantly improve the performance over the state-of-theart relation detection approaches.",
            "Similar to the topics defined over words, each relation topic is an interpretable multinomial distribution over the existing relations.",
            "Second, we construct a set of non-redundant relation topics defined at multiple scales from the relation repository to characterize the existing relations."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.09001758603323438,
                0.14486869594044133,
                0.1099503380558493,
                0.17404653568302456,
                0.1699647399010535,
                0.0,
                0.16251772200270398,
                0.17029590845100862,
                0.21627032074228214
            ],
            [
                0.09001758603323438,
                1.0,
                0.03993118536322442,
                0.030306390909063716,
                0.023118416690743798,
                0.11566401671653959,
                0.0,
                0.09332705183627801,
                0.0226202248545138,
                0.03877049406276753
            ],
            [
                0.14486869594044133,
                0.03993118536322442,
                1.0,
                0.04877321780253426,
                0.16269694518755273,
                0.3132944295285684,
                0.0,
                0.046886987011088586,
                0.03640358091076918,
                0.06239481820547934
            ],
            [
                0.1099503380558493,
                0.030306390909063716,
                0.04877321780253426,
                1.0,
                0.19876667077399204,
                0.057222350378257396,
                0.0,
                0.25241380736730135,
                0.1012920024022276,
                0.27021131404158744
            ],
            [
                0.17404653568302456,
                0.023118416690743798,
                0.16269694518755273,
                0.19876667077399204,
                1.0,
                0.19088143088460607,
                0.0,
                0.056330441886837335,
                0.12258687963414236,
                0.18403930074754635
            ],
            [
                0.1699647399010535,
                0.11566401671653959,
                0.3132944295285684,
                0.057222350378257396,
                0.19088143088460607,
                1.0,
                0.0,
                0.05500936210097474,
                0.15346539391859323,
                0.11435566283508283
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.16251772200270398,
                0.09332705183627801,
                0.046886987011088586,
                0.25241380736730135,
                0.056330441886837335,
                0.05500936210097474,
                0.0,
                1.0,
                0.05511654533610656,
                0.10838382967786536
            ],
            [
                0.17029590845100862,
                0.0226202248545138,
                0.03640358091076918,
                0.1012920024022276,
                0.12258687963414236,
                0.15346539391859323,
                0.0,
                0.05511654533610656,
                1.0,
                0.2579511645001478
            ],
            [
                0.21627032074228214,
                0.03877049406276753,
                0.06239481820547934,
                0.27021131404158744,
                0.18403930074754635,
                0.11435566283508283,
                0.0,
                0.10838382967786536,
                0.2579511645001478,
                1.0
            ]
        ]
    },
    "P14-1060": {
        "input_sentences": [
            "In this work, we present a frequencydriven paradigm for robust distributional semantics in terms of semantically cohelineal constituents, or The framework subsumes issues such as differential compositional as well as noncompositional behavior of phrasal consituents, and circumvents some problems of data sparsity by design.",
            "We design a segmentation model to optimally partition a sentence into lineal constituents, which can be used to define distributional contexts that are less noisy, semantically more interpretable, and linguistically disambiguated.",
            "Abstract",
            "Hellinger PCA embeddings learnt using the framework show competitive results on empirical tasks.",
            "Traditional models of distributional semantics suffer from computational issues such as data sparsity for individual lexemes and complexities of modeling semantic composition when dealing with structures larger than single lexical items.",
            "Vector space semantics with frequency-driven motifs"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.13625125921064496,
                0.0,
                0.04645048737663035,
                0.14676661670902477,
                0.04399029929421255
            ],
            [
                0.13625125921064496,
                1.0,
                0.0,
                0.0,
                0.02795025208710578,
                0.0
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.04645048737663035,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.14676661670902477,
                0.02795025208710578,
                0.0,
                0.0,
                1.0,
                0.04700467735299054
            ],
            [
                0.04399029929421255,
                0.0,
                0.0,
                0.0,
                0.04700467735299054,
                1.0
            ]
        ]
    },
    "W05-0104": {
        "input_sentences": [
            "Using provided scaffolding, students built realistic tools with nearly state-of-theart performance in most cases.",
            "The course work was organized around four substantial programming assignments in which the students implemented the important parts of several core tools, including language models (for speech reranking), a maximum entropy classifier, a part-of-speech tagger, a PCFG parser, and a word-alignment system.",
            "In the fall term of 2004, I taught a new statistical NLP course focusing on core tools and machine-learning algorithms.",
            "A Core-Tools Statistical NLP Course",
            "This paper briefly outlines the coverage of the course, the scope of the assignments, and some of the lessons learned in teaching the course in this way.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.06106257005348404,
                0.031220061737390656,
                0.06666815478570391,
                0.0,
                0.0
            ],
            [
                0.06106257005348404,
                1.0,
                0.0689722930667944,
                0.14728527921502757,
                0.08183534639388546,
                0.0
            ],
            [
                0.031220061737390656,
                0.0689722930667944,
                1.0,
                0.46829047298134274,
                0.06228250557618252,
                0.0
            ],
            [
                0.06666815478570391,
                0.14728527921502757,
                0.46829047298134274,
                1.0,
                0.132999728095395,
                0.0
            ],
            [
                0.0,
                0.08183534639388546,
                0.06228250557618252,
                0.132999728095395,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "W12-2802": {
        "input_sentences": [
            "Our prelimi nary evaluation demonstrates the effectivenessof the model on a corpus of ?pick up?",
            "Toward Learning Perceptually Grounded Word Meanings from Unaligned Parallel Data",
            "In this paper, we present an approach which is capable of jointly learninga policy for following natural language com mands such as ?Pick up the tire pallet,?",
            "In order for robots to effectively understand natural language commands, they must be ableto acquire a large vocabulary of meaning rep resentations that can be mapped to perceptualfeatures in the external world.",
            "We assume the action policy takes a parametric form that factors based on the structure of the language, based on the G3 framework and use stochastic gradient ascentto optimize policy parameters.",
            "and a specific object in the environment.",
            "as well as a mapping between specific phrases in the language and aspects of the external world; for example the mapping between the words ?the tire pallet?",
            "Previous ap proaches to learning these grounded meaning representations require detailed annotations at training time.",
            "com mands given to a robotic forklift by untrained users.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.07356405465935875,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.15850127058588157,
                0.0,
                0.0
            ],
            [
                0.07356405465935875,
                0.0,
                1.0,
                0.0812018605661311,
                0.11270345951155973,
                0.0,
                0.15341156973278286,
                0.0,
                0.16104863681824005,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0812018605661311,
                1.0,
                0.022898956904635694,
                0.0,
                0.13420722660520926,
                0.05351551775198901,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.11270345951155973,
                0.022898956904635694,
                1.0,
                0.0,
                0.02665493303638215,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.12616309547491664,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.15341156973278286,
                0.13420722660520926,
                0.02665493303638215,
                0.12616309547491664,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.15850127058588157,
                0.0,
                0.05351551775198901,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.16104863681824005,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "W04-0837": {
        "input_sentences": [
            "In this paper however, we examine the performance of the automatically acquired first sense in isolation since it turned out that the first sense taken from SemCor many systems in",
            "For accurate first sense heuristic should be used only as a back-off, where the evidence from the context is not strong enough.",
            "Using Automatically Acquired Predominant Senses For Word Sense Disambiguation",
            "Whilst there are hand-tagged corpora available for some languages, these are relatively small in size and many word forms either do not occur, or occur infrequently.",
            "word sense disambiguation the heuristic of choosing the most common sense is extremely powerful because the distribution of the senses of a word is often skewed.",
            "We evaluate on the and English alldata.",
            "Abstract",
            "In this paper we investigate the performance of an unsupervised first sense heuristic where predominant senses are acquired automatically from raw text.",
            "The first (or predominant) sense heuristic assumes the availability of handtagged data."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.07318959952117035,
                0.2417355764568301,
                0.0,
                0.10571376567494037,
                0.0,
                0.0,
                0.3419809003822795,
                0.07634478349104613
            ],
            [
                0.07318959952117035,
                1.0,
                0.05237453494288719,
                0.0,
                0.1220242113433204,
                0.0,
                0.0,
                0.10073532769474954,
                0.12670572375593261
            ],
            [
                0.2417355764568301,
                0.05237453494288719,
                1.0,
                0.06323859053553922,
                0.4018663916010243,
                0.0,
                0.0,
                0.3900652147961629,
                0.1636310992003208
            ],
            [
                0.0,
                0.0,
                0.06323859053553922,
                1.0,
                0.08283022203314287,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.10571376567494037,
                0.1220242113433204,
                0.4018663916010243,
                0.08283022203314287,
                1.0,
                0.0,
                0.0,
                0.15794790281925317,
                0.12728464230736486
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.3419809003822795,
                0.10073532769474954,
                0.3900652147961629,
                0.0,
                0.15794790281925317,
                0.0,
                0.0,
                1.0,
                0.18704922164797572
            ],
            [
                0.07634478349104613,
                0.12670572375593261,
                0.1636310992003208,
                0.0,
                0.12728464230736486,
                0.0,
                0.0,
                0.18704922164797572,
                1.0
            ]
        ]
    },
    "W11-0610": {
        "input_sentences": [
            "Classification of Atypical Language in Autism",
            "In this paper, we discuss previous work identifying language errors associated with atypical language in ASD and describe a procedure for reproducing those results.",
            "Our classifiers achieve results well above chance, demonstrating the potential for using NLP techniques to enhance neurodevelopmental diagnosis and atypical language analysis.",
            "We then present methods for automatically extracting lexical and syntactic features from transcripts of children\u2019s speech to 1) identify certain syntactic and semantic errors that have previously been found to distinguish ASD language from that of children with typical development; and 2) perform diagnostic classification.",
            "We expect further improvement with additional data, features, and classification techniques.",
            "Abstract",
            "We describe our data set, which consists of transcribed data from a widely used clinical diagnostic instrument (the ADOS) for children with autism, children with developmental language disorder, and typically developing children.",
            "Atypical or idiosyncratic language is a characteristic of autism spectrum disorder (ASD)."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.20555381024242456,
                0.1384327184533515,
                0.11810638061848054,
                0.16916379995296657,
                0.0,
                0.12555857791089306,
                0.38798126450327103
            ],
            [
                0.20555381024242456,
                1.0,
                0.13187487231398765,
                0.10205724774511372,
                0.0,
                0.0,
                0.03141553982299722,
                0.18212353577990814
            ],
            [
                0.1384327184533515,
                0.13187487231398765,
                1.0,
                0.013763124971565425,
                0.08192113210469175,
                0.0,
                0.01463154141199088,
                0.07762054680068463
            ],
            [
                0.11810638061848054,
                0.10205724774511372,
                0.013763124971565425,
                1.0,
                0.10285032471627177,
                0.0,
                0.21784230835256901,
                0.06622337512894727
            ],
            [
                0.16916379995296657,
                0.0,
                0.08192113210469175,
                0.10285032471627177,
                1.0,
                0.0,
                0.12534470824229235,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.12555857791089306,
                0.03141553982299722,
                0.01463154141199088,
                0.21784230835256901,
                0.12534470824229235,
                0.0,
                1.0,
                0.13439482834437586
            ],
            [
                0.38798126450327103,
                0.18212353577990814,
                0.07762054680068463,
                0.06622337512894727,
                0.0,
                0.0,
                0.13439482834437586,
                1.0
            ]
        ]
    },
    "I08-1012": {
        "input_sentences": [
            "Dependency Parsing with Short Dependency Relations in Unlabeled Data",
            "Our proposed approach achieves an unlabeled at tachment score of 86.52, an absolute 1.24% improvement over the baseline system on the data set of Chinese Treebank.",
            "We thentrain another parser which uses the informa tion on short dependency relations extractedfrom the output of the first parser.",
            "Abstract",
            "This paper presents an effective dependencyparsing approach of incorporating short de pendency information from unlabeled data.",
            "The unlabeled data is automatically parsed by a deterministic dependency parser, which can provide relatively high performance for short dependencies between words."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.08613497552914895,
                0.2881659320284415,
                0.0,
                0.16581745847419083,
                0.2791822424167421
            ],
            [
                0.08613497552914895,
                1.0,
                0.0,
                0.0,
                0.12286715403836028,
                0.055454739274520215
            ],
            [
                0.2881659320284415,
                0.0,
                1.0,
                0.0,
                0.037313444000216654,
                0.2035934555966495
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.16581745847419083,
                0.12286715403836028,
                0.037313444000216654,
                0.0,
                1.0,
                0.10675528576354017
            ],
            [
                0.2791822424167421,
                0.055454739274520215,
                0.2035934555966495,
                0.0,
                0.10675528576354017,
                1.0
            ]
        ]
    },
    "P12-2006": {
        "input_sentences": [
            "Our results show that language model based pre-sorting yields a small improvement in translation quality and a speedup by a factor of 2.",
            "Fast and Scalable Decoding with Language Model Look-Ahead for Phrase-based Statistical Machine Translation",
            "Two look-ahead methods are shown to further increase translation speed by a factor of 2 without changing the search space and a factor of 4 with the side-effect of some additional search errors.",
            "We compare our approach with Moses and observe the same performance, but a substantially better trade-off between translation quality and speed.",
            "Abstract",
            "In this work we present two extensions to the well-known dynamic programming beam search in phrase-based statistical machine translation (SMT), aiming at increased efficiency of decoding by minimizing the number of language model computations and hypothesis expansions.",
            "At a speed of roughly 70 words per second, Moses 17.2% whereas our approach yields 20.0% with identical models."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.20356753760504714,
                0.13417011548759256,
                0.10481883816331647,
                0.0,
                0.12441034594700011,
                0.06746352571140077
            ],
            [
                0.20356753760504714,
                1.0,
                0.14962016511017284,
                0.03472289717174186,
                0.0,
                0.35099580110075296,
                0.0
            ],
            [
                0.13417011548759256,
                0.14962016511017284,
                1.0,
                0.06739936640760663,
                0.0,
                0.09144039723130377,
                0.03909754823500611
            ],
            [
                0.10481883816331647,
                0.03472289717174186,
                0.06739936640760663,
                1.0,
                0.0,
                0.021220906340183636,
                0.19440153436390656
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.12441034594700011,
                0.35099580110075296,
                0.09144039723130377,
                0.021220906340183636,
                0.0,
                1.0,
                0.0
            ],
            [
                0.06746352571140077,
                0.0,
                0.03909754823500611,
                0.19440153436390656,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "W12-3706": {
        "input_sentences": [
            "We present an accuracy above 81% for Spanish opinions in the financial products domain.",
            "In order to reduce the complexity of the training corpus we first lemmatize the texts and we replace most namedentities with wildcards.",
            "The classification of opinion texts in positive and negative can be tackled by evaluating separate key words but this is a very limited approach.",
            "Opinum: statistical sentiment analysis for opinion classification",
            "We propose an approach based on the order of the words without using any syntactic and semantic information.",
            "It consists of building one probabilistic model for the positive and another one for the negative opinions.",
            "Abstract",
            "Then the test opinions are compared to both models and a decision and confidence measure are calculated."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0783189732254673,
                0.0,
                0.06952106848944942
            ],
            [
                0.0,
                1.0,
                0.07272996726972251,
                0.0,
                0.08043811576938974,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.07272996726972251,
                1.0,
                0.19187978225624547,
                0.156669186161381,
                0.18321954723350445,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.19187978225624547,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.08043811576938974,
                0.156669186161381,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0783189732254673,
                0.0,
                0.18321954723350445,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0783189732254673
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.06952106848944942,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0783189732254673,
                0.0,
                1.0
            ]
        ]
    },
    "P13-1092": {
        "input_sentences": [
            "To compensate for the lack of example annotations or question-answer pairs, GUSP adopts a novel grounded-learning approach to leverage database for indirect supervision.",
            "Grounded Unsupervised Semantic Parsing",
            "Our GUSP system produces a semantic parse by annotating the dependency-tree nodes and edges with latent states, and learns a probabilistic grammar using EM.",
            "Grounded Unsupervised Semantic",
            "Abstract",
            "We present the first unsupervised approach for semantic parsing that rivals the accuracy of supervised approaches in translating natural-language questions to database queries.",
            "On the challenging ATIS dataset, GUSP attained an accuracy of 84%, effectively tying with the best published results by supervised approaches."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.08909302640141685,
                0.033269737710445904,
                0.10900781745413776,
                0.0,
                0.1013507415747642,
                0.036200621219983395
            ],
            [
                0.08909302640141685,
                1.0,
                0.06828026344273917,
                0.8173085975132055,
                0.0,
                0.3147671861900417,
                0.0
            ],
            [
                0.033269737710445904,
                0.06828026344273917,
                1.0,
                0.08354281803775586,
                0.0,
                0.028375515018618222,
                0.03680612605796076
            ],
            [
                0.10900781745413776,
                0.8173085975132055,
                0.08354281803775586,
                1.0,
                0.0,
                0.216312161842785,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.1013507415747642,
                0.3147671861900417,
                0.028375515018618222,
                0.216312161842785,
                0.0,
                1.0,
                0.16818564379442075
            ],
            [
                0.036200621219983395,
                0.0,
                0.03680612605796076,
                0.0,
                0.0,
                0.16818564379442075,
                1.0
            ]
        ]
    },
    "W07-2214": {
        "input_sentences": [
            "We present an example from natural language which seems to require both types of context sensitivity, and introduce partially ordered multisets (pomsets) mcfgs as a formalism which succintly expresses both.",
            "Pomset mcfgs",
            "This paper identifies two orthogonal dimensions of context sensitivity, the first being context sensitivity in concurrency and the second being structural context sensitivity.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.12255132163600414,
                0.2195531574234772,
                0.0
            ],
            [
                0.12255132163600414,
                1.0,
                0.0,
                0.0
            ],
            [
                0.2195531574234772,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P05-1022": {
        "input_sentences": [
            "This paper describes a simple yet novel method for constructing sets of 50-best parses based on a coarse-to-fine generative parser (Charniak, 2000).",
            "We used these parses as the input to a MaxEnt reranker (Johnson et al., 1999; Riezler et al., 2002) that selects the best parse from the set of parses for each sentence, obtaining an f-score of 91.0% on sentences of length 100 or less.",
            "A discriminative reranker requires a source of candidate parses for each sentence.",
            "Coarse-To-Fine N-Best Parsing And MaxEnt Discriminative Reranking",
            "This method generates 50-best lists that are of substantially higher quality than previously obtainable.",
            "Abstract",
            "Discriminative reranking is one method for constructing high-performance statistical parsers (Collins, 2000)."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.07113492897701715,
                0.05833309031801102,
                0.2194117033772753,
                0.14436590946624858,
                0.0,
                0.17804451303186747
            ],
            [
                0.07113492897701715,
                1.0,
                0.19612617844537855,
                0.09467049656119805,
                0.024734087777161906,
                0.0,
                0.0
            ],
            [
                0.05833309031801102,
                0.19612617844537855,
                1.0,
                0.10072434990566387,
                0.0,
                0.0,
                0.07634952715544875
            ],
            [
                0.2194117033772753,
                0.09467049656119805,
                0.10072434990566387,
                1.0,
                0.060177310672596435,
                0.0,
                0.1948449342944911
            ],
            [
                0.14436590946624858,
                0.024734087777161906,
                0.0,
                0.060177310672596435,
                1.0,
                0.0,
                0.06051419542991648
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.17804451303186747,
                0.0,
                0.07634952715544875,
                0.1948449342944911,
                0.06051419542991648,
                0.0,
                1.0
            ]
        ]
    },
    "C08-1074": {
        "input_sentences": [
            "We findthat all of our random restart methods out perform MERT without random restarts,and we develop some refinements of ran dom restarts that are superior to the most common approach with regard to resulting model quality and training time.",
            "We compare several ways of perform ing random restarts with MERT.",
            "The use of multiple randomized start ing points in MERT is a well-established practice, although there seems to be nopublished systematic study of its benefits.",
            "Abstract",
            "Och?s (2003) minimum error rate training (MERT) procedure is the most commonly used method for training feature weights instatistical machine translation (SMT) models.",
            "Random Restarts in Minimum Error Rate Training for Statistical Machine Translation"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.3023051923658024,
                0.02250623786550378,
                0.0,
                0.07125841943517847,
                0.2206507285111092
            ],
            [
                0.3023051923658024,
                1.0,
                0.13691510529286435,
                0.0,
                0.039998894098870724,
                0.18447676097787194
            ],
            [
                0.02250623786550378,
                0.13691510529286435,
                1.0,
                0.0,
                0.024888284884630473,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.07125841943517847,
                0.039998894098870724,
                0.024888284884630473,
                0.0,
                1.0,
                0.43992467703012245
            ],
            [
                0.2206507285111092,
                0.18447676097787194,
                0.0,
                0.0,
                0.43992467703012245,
                1.0
            ]
        ]
    },
    "P09-1065": {
        "input_sentences": [
            "Therefore, one model can share translations and even derivations with other models.",
            "We instead propose a method that combines multiple translation models in one decoder.",
            "Current SMT systems usually decode with single translation models and cannot benefit from the strengths of other models in phase.",
            "Joint Decoding with Multiple Translation Models",
            "Our joint decoder draws connections among multiple models by integrating the translation hypergraphs they produce individually.",
            "Joint Decoding",
            "Abstract",
            "Comparable to the state-of-the-art system combination technique, joint decoding achieves an absolute improvement of 1.5 BLEU points over individual decoding."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.06221135703048742,
                0.09288818042721149,
                0.10306433499709082,
                0.05249914520291542,
                0.0,
                0.0,
                0.0
            ],
            [
                0.06221135703048742,
                1.0,
                0.12966390362832428,
                0.3457207211539403,
                0.27584756133555166,
                0.0,
                0.0,
                0.0
            ],
            [
                0.09288818042721149,
                0.12966390362832428,
                1.0,
                0.2148116459512539,
                0.10942124443329948,
                0.0,
                0.0,
                0.0
            ],
            [
                0.10306433499709082,
                0.3457207211539403,
                0.2148116459512539,
                1.0,
                0.386337666965412,
                0.6536445992503371,
                0.0,
                0.26790087536883
            ],
            [
                0.05249914520291542,
                0.27584756133555166,
                0.10942124443329948,
                0.386337666965412,
                1.0,
                0.1447110757863302,
                0.0,
                0.03788927265388329
            ],
            [
                0.0,
                0.0,
                0.0,
                0.6536445992503371,
                0.1447110757863302,
                1.0,
                0.0,
                0.4098570930993458
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.26790087536883,
                0.03788927265388329,
                0.4098570930993458,
                0.0,
                1.0
            ]
        ]
    },
    "D11-1094": {
        "input_sentences": [
            "We make use of a factorization model in which words, together with their window-based context words and their dependency relations, are linked to latent dimensions.",
            "Latent Vector Weighting for Word Meaning in Context",
            "This paper presents a novel method for the computation of word meaning in context.",
            "The factorization model allows us to determine which dimensions are important for a particular context, and adapt the dependency-based feature vector of the word accordingly.",
            "The evaluation on a lexical substitution task \u2013 carried out for both English and French \u2013 indicates that our approach is able to reach better results than state-of-the-art methods in lexical substitution, while at the same time providing more accurate meaning representations.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.14644020485332337,
                0.038293214547801414,
                0.29469220480175207,
                0.0,
                0.0
            ],
            [
                0.14644020485332337,
                1.0,
                0.2728679790105563,
                0.22831725938232478,
                0.048717365252502226,
                0.0
            ],
            [
                0.038293214547801414,
                0.2728679790105563,
                1.0,
                0.09606190501553863,
                0.037078097517338725,
                0.0
            ],
            [
                0.29469220480175207,
                0.22831725938232478,
                0.09606190501553863,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.048717365252502226,
                0.037078097517338725,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P14-2093": {
        "input_sentences": [
            "Effective Selection of Translation Model Training Data",
            "When the selected sentence pairs are evaluated on an end-to-end MT task, our methods can increase the translation performance by 3 BLEU points.",
            "Data selection has been demonstrated to be an effective approach to addressing the lack of high-quality bitext for statistical machine translation in the domain of interest.",
            "By contrast, we argue that the relevance between a sentence pair and target domain can be better evaluated by the combination of language model and translation model.",
            "The results show that our methods outperform previous methods.",
            "Most current data selection methods solely use language models trained on a small scale in-domain data to select domain-relevant sentence pairs from general-domain parallel corpus.",
            "In this paper, we study and experiment with novel methods that apply translation models into domain-relevant data selection.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.04543067754498493,
                0.2896383966449512,
                0.25959714809040446,
                0.0,
                0.1460186377286568,
                0.20658702054117364,
                0.0
            ],
            [
                0.04543067754498493,
                1.0,
                0.025456273846832442,
                0.11816556375185272,
                0.10140687334907186,
                0.10012218347251949,
                0.06726893593079614,
                0.0
            ],
            [
                0.2896383966449512,
                0.025456273846832442,
                1.0,
                0.06065175694442089,
                0.0,
                0.1636379041488645,
                0.1573439007708579,
                0.0
            ],
            [
                0.25959714809040446,
                0.11816556375185272,
                0.06065175694442089,
                1.0,
                0.0,
                0.15657898563432035,
                0.07041066341523416,
                0.0
            ],
            [
                0.0,
                0.10140687334907186,
                0.0,
                0.0,
                1.0,
                0.08512576985468517,
                0.1298019098381357,
                0.0
            ],
            [
                0.1460186377286568,
                0.10012218347251949,
                0.1636379041488645,
                0.15657898563432035,
                0.08512576985468517,
                1.0,
                0.3322496350185216,
                0.0
            ],
            [
                0.20658702054117364,
                0.06726893593079614,
                0.1573439007708579,
                0.07041066341523416,
                0.1298019098381357,
                0.3322496350185216,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P05-1063": {
        "input_sentences": [
            "We describe a method for discriminative training of a language model that makes use of syntactic features.",
            "The reranking model makes use of syntactic features together with a parameter estimation method that is based on the perceptron algorithm.",
            "We follow where a baseline recogniser is used to produce 1000-best output for each acoustic input, and a second \u201creranking\u201d model is then used to choose an utterance from these 1000-best lists.",
            "Discriminative Syntactic Language Modeling For Speech Recognition",
            "We describe experiments on the Switchboard speech recognition task.",
            "The syntactic features provide an additional 0.3% reduction in test\u2013set error rate beyond the model of (Roark et al., 2004a; Roark et al., 2004b) (signifiat < which makes use of a discriminatively trained n-gram model, giving a total reduction of 1.2% over the baseline Switchboard system.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.43548914033273706,
                0.03370266333720936,
                0.37412429302415245,
                0.0,
                0.194408150366836,
                0.0
            ],
            [
                0.43548914033273706,
                1.0,
                0.07454891987785289,
                0.06345641672252904,
                0.0,
                0.15272028473513072,
                0.0
            ],
            [
                0.03370266333720936,
                0.07454891987785289,
                1.0,
                0.0,
                0.0,
                0.050369474754394836,
                0.0
            ],
            [
                0.37412429302415245,
                0.06345641672252904,
                0.0,
                1.0,
                0.3360162229019465,
                0.03163850811476974,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.3360162229019465,
                1.0,
                0.057929697164129657,
                0.0
            ],
            [
                0.194408150366836,
                0.15272028473513072,
                0.050369474754394836,
                0.03163850811476974,
                0.057929697164129657,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "W11-2123": {
        "input_sentences": [
            "This paper describes the several performance techniques used and presents benchmarks against alternative implementations.",
            "Compared with the widely- SRILM, our is 2.4 times as fast while using 57% of the mem- The structure is a trie with bit-level packing, sorted records, interpolation search, and optional quantization aimed lower memory consumption. simultaneously uses less memory than the smallest lossless baseline and less CPU than the baseline.",
            "KenLM: Faster and Smaller Language Model Queries",
            "The structure uses linear probing hash tables and is designed for speed.",
            "We present KenLM, a library that implements two data structures for efficient language model queries, reducing both time and costs.",
            "Our code is thread-safe, and integrated into the Moses, cdec, and Joshua translation systems.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                1.0,
                0.0,
                0.08652933685732783,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.368590733672213,
                0.0,
                0.0
            ],
            [
                0.0,
                0.08652933685732783,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.368590733672213,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "D09-1092": {
        "input_sentences": [
            "Topic models are a useful tool for analyzing large text collections, but have previously been applied in only monolingual, or at most bilingual, contexts.",
            "We introduce a polylingual topic model that discovers topics aligned across multiple languages.",
            "Polylingual Topic Models",
            "Meanwhile, massive collections of interlinked documents in dozens of languages, such as Wikipedia, are now widely available, calling for tools that can characterize content in many languages.",
            "We explore the model\u2019s characteristics using two large corpora, each with over ten different languages, and demonstrate its usefulness in supporting machine translation and tracking topic trends across languages.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.03896540412920627,
                0.23322753292515866,
                0.054097090116774924,
                0.07688447168563078,
                0.0
            ],
            [
                0.03896540412920627,
                1.0,
                0.2935628177359412,
                0.09707033339965308,
                0.1873335637619313,
                0.0
            ],
            [
                0.23322753292515866,
                0.2935628177359412,
                1.0,
                0.0,
                0.068377968249451,
                0.0
            ],
            [
                0.054097090116774924,
                0.09707033339965308,
                0.0,
                1.0,
                0.13161452296986548,
                0.0
            ],
            [
                0.07688447168563078,
                0.1873335637619313,
                0.068377968249451,
                0.13161452296986548,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P13-1155": {
        "input_sentences": [
            "We show that the proposed approach has a very high precision of (92.43) and a reasonable recall of (56.4).",
            "When used as a preprocessing step for a state-of-the-art machine translation system, the translation quality on social media text improved by 6%.",
            "The proposed approach uses Random Walks on a contextual similarity bipartite graph constructed from n-gram sequences on large unlabeled text corpus.",
            "Social Text Normalization using Contextual Graph Random Walks",
            "The proposed approach is domain and language independent and can be deployed as a preprocessing step for any NLP application to handle social media text.",
            "The proposed system is based on unsupervised learning of the normalization equivalences from unlabeled text.",
            "We introduce a social media text normalization system that can be deployed as a preprocessing step for Machine Translation and various NLP applications to handle social media text.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.09225663607694415,
                0.0,
                0.10802648750383793,
                0.058912023043353585,
                0.0,
                0.0
            ],
            [
                0.0,
                1.0,
                0.021399820099649705,
                0.08911254188675241,
                0.2228502577411377,
                0.03144127694318666,
                0.4698464706764564,
                0.0
            ],
            [
                0.09225663607694415,
                0.021399820099649705,
                1.0,
                0.3847111610290877,
                0.10842786314698245,
                0.1568223096794174,
                0.03922188370947291,
                0.0
            ],
            [
                0.0,
                0.08911254188675241,
                0.3847111610290877,
                1.0,
                0.09597359920345579,
                0.14276993885429187,
                0.22885688026492704,
                0.0
            ],
            [
                0.10802648750383793,
                0.2228502577411377,
                0.10842786314698245,
                0.09597359920345579,
                1.0,
                0.08838312963650623,
                0.506021441080271,
                0.0
            ],
            [
                0.058912023043353585,
                0.03144127694318666,
                0.1568223096794174,
                0.14276993885429187,
                0.08838312963650623,
                1.0,
                0.1179734685020534,
                0.0
            ],
            [
                0.0,
                0.4698464706764564,
                0.03922188370947291,
                0.22885688026492704,
                0.506021441080271,
                0.1179734685020534,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P08-1043": {
        "input_sentences": [
            "These words are in turn highly ambiguous, breaking the assumption underlying most parsers that the yield of a tree for a given sentence is known in advance.",
            "A Single Generative Model for Joint Morphological Segmentation and Syntactic Parsing",
            "Using a treebank grammar, a data-driven lexicon, and a linguistically motivated unknown-tokens handling technique our model outperforms previous pipelined, integrated or factorized systems for Hebrew morphological and syntactic processing, yielding an error reduction of 12% over the best published results so far.",
            "Morphological processes in Semitic languages deliver space-delimited words which introduce multiple, distinct, syntactic units into the structure of the input sentence.",
            "Abstract",
            "Here we propose a single joint model for performing both morphological segmentation and syntactic disambiguation which bypasses the associated circularity."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0,
                0.09821935144927076,
                0.0,
                0.0
            ],
            [
                0.0,
                1.0,
                0.09604468891830535,
                0.08235276508092307,
                0.0,
                0.46268789625367185
            ],
            [
                0.0,
                0.09604468891830535,
                1.0,
                0.034764289943667565,
                0.0,
                0.07220874904808894
            ],
            [
                0.09821935144927076,
                0.08235276508092307,
                0.034764289943667565,
                1.0,
                0.0,
                0.06191482542259787
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.46268789625367185,
                0.07220874904808894,
                0.06191482542259787,
                0.0,
                1.0
            ]
        ]
    },
    "N12-1052": {
        "input_sentences": [
            "Second, and more interestingly, we provide an algorithm for inducing cross-lingual clusters and we show that features derived from these clusters significantly improve the accuracy of cross-lingual structure prediction.",
            "While previous work has focused primarily on English, we extend these results to other languages along two dimensions.",
            "It has been established that incorporating word cluster features derived from large unlabeled corpora can significantly improve prediction of linguistic structure.",
            "Specifically, we show that by augmenting direct-transfer systems with cross-lingual cluster features, the relative error of delexicalized dependency parsers, trained on English treebanks and transferred to foreign languages, can be reduced by up to 13%.",
            "Cross-lingual Word Clusters for Direct Transfer of Linguistic Structure",
            "When applying the same method to direct transfer of named-entity recognizers, we observe relative improvements of up to 26%.",
            "Abstract",
            "First, we show that these results hold true for a number of languages across families."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.28368524662337224,
                0.14914749789825887,
                0.4506554299209405,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                1.0,
                0.0,
                0.10188787230211577,
                0.0,
                0.0,
                0.0,
                0.19038705179470286
            ],
            [
                0.28368524662337224,
                0.0,
                1.0,
                0.08664432268218131,
                0.2679318402419458,
                0.0,
                0.0,
                0.0
            ],
            [
                0.14914749789825887,
                0.10188787230211577,
                0.08664432268218131,
                1.0,
                0.22538423301182645,
                0.13109854770991247,
                0.0,
                0.053564239877775595
            ],
            [
                0.4506554299209405,
                0.0,
                0.2679318402419458,
                0.22538423301182645,
                1.0,
                0.15417041554023989,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.13109854770991247,
                0.15417041554023989,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.19038705179470286,
                0.0,
                0.053564239877775595,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P07-1051": {
        "input_sentences": [
            "While U-DOP* performs worse than state-of-the-art supervised parsers on handannotated sentences, we show that the model outperforms supervised parsers when evaluated as a language model in syntax-based machine translation on Europarl.",
            "We argue that supervised parsers miss the fluidity between constituents and non-constituents and that in the field of syntax-based language modeling the end of supervised parsing has come in sight.",
            "We present a new algorithm for unsupervised parsing using an all-subtrees model, termed U-DOP*, which parses directly with packed forests of all binary trees.",
            "How far can we get with unsupervised parsing if we make our training corpus several orders of magnitude larger than has hitherto be attempted?",
            "Is the End of Supervised Parsing in Sight?",
            "Abstract",
            "We train both on Penn\u2019s WSJ data and on the (much larger) NANC corpus, showing that U-DOP* outperforms a treebank-PCFG on the standard WSJ test set."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.2860006210415143,
                0.10928267559117975,
                0.0,
                0.14687208863154474,
                0.0,
                0.06425378466671508
            ],
            [
                0.2860006210415143,
                1.0,
                0.02400237753460082,
                0.02949112089896079,
                0.4391329536631548,
                0.0,
                0.0
            ],
            [
                0.10928267559117975,
                0.02400237753460082,
                1.0,
                0.09205995694446105,
                0.06682881616569034,
                0.0,
                0.03274898474036551
            ],
            [
                0.0,
                0.02949112089896079,
                0.09205995694446105,
                1.0,
                0.08211089481596957,
                0.0,
                0.11014619833552819
            ],
            [
                0.14687208863154474,
                0.4391329536631548,
                0.06682881616569034,
                0.08211089481596957,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.06425378466671508,
                0.0,
                0.03274898474036551,
                0.11014619833552819,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P13-2112": {
        "input_sentences": [
            "The poor performance on unknown words is expected because we do not use any language-specific rules to handle this case.",
            "On individual languages, self training and revision and the method of Das and Petrov are split \u2014 each performs better on half of the cases.",
            "(Findings are similar for other languages.)",
            "We examine the impact of self-training and revision over training iterations.",
            "References Thorsten Brants.",
            "P103/12/G084).",
            "One way to improve the performance of our tagger might be to reduce the proportion of unknown words by using a larger training corpus, as Das and Petrov did.",
            "This might be because our model relies on alignments, which might be more accurate for more-related languages, whereas Das and Petrov additionally rely on label propagation.",
            "Compared to Das and Petrov, our model performs poorest on Italian, in terms of percentage point difference in accuracy.",
            "We would like to thank Prokopis Prokopidis for providing us the Greek Treebank and Antonia Marti for the Spanish CoNLL 06 dataset.",
            "Self training and revision improve the accuracy for every language over the seed model, and gives an average improvement of roughly two percentage points.",
            "Simpler unsupervised POS tagging with bilingual projections",
            "Table 2 shows results for our seed model, self training and revision, and the results reported by Das and Petrov.",
            "Seattle, Washington, USA.",
            "Using our final model with unsupervised HMM methods might improve the final performance too, i.e. use our final model as the initial state for HMM, then experiment with different inference algorithms such as Expectation Maximization (EM), Variational Bayers (VB) or Gibbs Gao and Johnson (2008) compare EM, VB and GS for unsupervised English POS tagging.",
            "Abstract",
            "The overall performance dropped slightly.",
            "2009.",
            "Interestingly, our method achieves higher accuracies on Germanic languages \u2014 the family of our source language, English \u2014 while Das and Petrov perform better on Romance languages.",
            "Our model performs poorly on unknown words as indicated by the low accuracy on unknown words, and high accuracy on known words compared to the overall accuracy.",
            "6 Conclusion We have proposed a method for unsupervised POS tagging that performs on par with the current stateof-the-art (Das and Petrov, 2011), but is substantially less-sophisticated (specifically not requiring convex optimization or a feature-based HMM). complexity of our algorithm is to that of Das and Petrov 637 where the size of training We our code are available for In future work we intend to consider using a larger training corpus to reduce the proportion of unknown tokens and improve accuracy.",
            "Pascal Denis and Benoit Sagot.",
            "We exemplify this in Figure 1 (right panel) for Dutch.",
            "2000.",
            "Figure 1 (left panel) shows accuracy, accuracy on known words, accuracy on unknown words, and proportion of known tokens for each iteration of our model for Italian; iteration 0 is the seed model, and iteration 31 is the final model.",
            "In of re-implemented label propagation from Das and Petrov (2011).",
            "7 Acknowledgements This work is funded by Erasmus Mundus European Masters Program in Language and Communication Technologies (EM-LCT) and by the Czech Science Foundation (grant no.",
            "We find that for all languages, accuracy rises quickly in the first 5\u20136 iterations, and then subsequently improves only slightly.",
            "The average accuracy of self training and revision is on par with that reported by Das and Petrov.",
            "Dipanjan Das and Slav Petrov.",
            "In of the 23rd Pacific Asia Conference on Language, Information",
            "2011.",
            "Figure 1: Overall accuracy, accuracy on known tokens, accuracy on unknown tokens, and proportion of known tokens for Italian (left) and Dutch (right).",
            "Although accuracy does not increase much in later iterations, they may still have some benefit as the vocabulary size continues to grow.",
            "Given the improvements of our model over that of Das and Petrov on languages from the same family as our source language, and the observation of Snyder et al. (2008) that a better tagger can be learned from a more-closely related language, we also plan to consider strategies for selecting an appropriate source language for a given target language.",
            "TnT: A statistical part-oftagger.",
            "It took over a day to complete this step on an eight core Intel Xeon 3.16GHz CPU with 32 Gb Ram, but only 15 minutes for our model. in fact have tried EM, but it did not help.",
            "In of the sixth conference on Applied natural language processing pages 224\u2013231.",
            "Moreover, on average for the final model, approximately 10% of the test data tokens are unknown.",
            "Finally, we thank Siva Reddy and Spandana Gella for many discussions and suggestions.",
            "In many cases, GS outperformed other methods, thus we would like to try GS first for our model.",
            "Unsupervised part-of-speech tagging with bilingual projections.",
            "Portland, Oregon, USA.",
            "This might be because selftraining with revision already found the local maximal point. the 49th Annual Meeting of the Association for Computational Linguistics: Human Language - Volume 1 (ACL pages 600\u2013609.",
            "Coupling an annotated corpus and a morphosyntactic lexicon for state-of-the-art POS tagging with less effort."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.1792963901504284,
                0.0,
                0.0,
                0.0,
                0.04440203309887948,
                0.0,
                0.0,
                0.0,
                0.07451511580279034,
                0.0,
                0.11531362755421255,
                0.0,
                0.03656768684354663,
                0.21556090984411377,
                0.024193943618503397,
                0.0,
                0.0,
                0.0,
                0.10435417395559152,
                0.0,
                0.03407650794424143,
                0.0,
                0.0,
                0.0,
                0.05950299952943608,
                0.0,
                0.03582672041097661,
                0.0,
                0.09620237343045629,
                0.0,
                0.0,
                0.04796205659778813,
                0.05708653516419446,
                0.0,
                0.0,
                0.0,
                0.0,
                0.03344498998221597,
                0.0
            ],
            [
                0.0,
                1.0,
                0.10632987570296495,
                0.28121593778916465,
                0.0,
                0.0,
                0.12080700935999836,
                0.1305605813971831,
                0.15155704220942065,
                0.0,
                0.16534871751800956,
                0.0,
                0.233080126337122,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.27845003870362306,
                0.04968548713600954,
                0.19508397166685795,
                0.0,
                0.0,
                0.0,
                0.0,
                0.111342950253068,
                0.0,
                0.06644841197060346,
                0.33211360454490607,
                0.13634484824621496,
                0.0,
                0.0,
                0.0,
                0.0,
                0.11117600049851045,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.09913777529200142,
                0.0,
                0.0,
                0.041249745188589884,
                0.0
            ],
            [
                0.0,
                0.10632987570296495,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.10336155182557294,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.16581771053765484,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.12215122766088321,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.05452921242590832,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.28121593778916465,
                0.0,
                1.0,
                0.0,
                0.0,
                0.1218599688619304,
                0.0,
                0.0,
                0.0,
                0.2662507931855355,
                0.0,
                0.26102378080556055,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.123073411279611,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.11725246958632564,
                0.37193024595279445,
                0.0,
                0.0,
                0.0,
                0.0,
                0.09927522117076713,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.051045524642274895,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.1792963901504284,
                0.12080700935999836,
                0.0,
                0.1218599688619304,
                0.0,
                0.0,
                1.0,
                0.06957170849847515,
                0.07299355109902433,
                0.0,
                0.11053612838693774,
                0.0,
                0.11213269979954354,
                0.0,
                0.0961770509361069,
                0.0,
                0.11091495090648071,
                0.0,
                0.055805186830389895,
                0.20733826729608223,
                0.3599267424697224,
                0.0,
                0.0,
                0.0,
                0.13714963084541518,
                0.10421038501258616,
                0.0,
                0.0,
                0.15977679308408305,
                0.12761067582569455,
                0.0,
                0.0,
                0.08170998206643944,
                0.0,
                0.08318463919904592,
                0.0,
                0.06054312747366323,
                0.0,
                0.054908950307551115,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.07690064187840952
            ],
            [
                0.0,
                0.1305605813971831,
                0.10336155182557294,
                0.0,
                0.0,
                0.0,
                0.06957170849847515,
                1.0,
                0.1137185177835588,
                0.0,
                0.035188874545082356,
                0.0,
                0.10349414887544764,
                0.0,
                0.033687758542280524,
                0.0,
                0.0,
                0.0,
                0.14564442856842033,
                0.025600787581628006,
                0.07026448121909032,
                0.0,
                0.0,
                0.0,
                0.060738240448787686,
                0.3823756623760705,
                0.0,
                0.06459342618638117,
                0.09831187060715597,
                0.13253862101296573,
                0.0,
                0.0,
                0.0,
                0.0,
                0.13429220439089942,
                0.0,
                0.02482634384129499,
                0.0,
                0.041447932602022876,
                0.0,
                0.038048308928746215,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.15155704220942065,
                0.0,
                0.0,
                0.0,
                0.0,
                0.07299355109902433,
                0.1137185177835588,
                1.0,
                0.0,
                0.17331811991175283,
                0.0,
                0.1085844462847365,
                0.0,
                0.035344670666258585,
                0.0,
                0.0,
                0.0,
                0.060810955755342296,
                0.23917009130028,
                0.12989965292905933,
                0.0,
                0.0,
                0.0,
                0.1835745970085889,
                0.11355813809042822,
                0.0,
                0.05203767522217858,
                0.1630569501944479,
                0.13905745329965813,
                0.0,
                0.0,
                0.15398188915341873,
                0.04405921457450316,
                0.05999311255933477,
                0.0,
                0.02604741261774867,
                0.0,
                0.043486524215529135,
                0.0,
                0.03991969209844506,
                0.0,
                0.0,
                0.07043571688490859,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.08190215034278438,
                0.08086191124963885,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.04440203309887948,
                0.16534871751800956,
                0.0,
                0.2662507931855355,
                0.0,
                0.0,
                0.11053612838693774,
                0.035188874545082356,
                0.17331811991175283,
                0.0,
                1.0,
                0.0,
                0.259559045580687,
                0.0,
                0.06376161152514,
                0.0,
                0.0,
                0.0,
                0.035580303632282435,
                0.11182873423925334,
                0.09923339498412989,
                0.0,
                0.0,
                0.0,
                0.1704150807547694,
                0.0,
                0.03315639035554596,
                0.04830736261871307,
                0.3775816210694708,
                0.0,
                0.05789632796154075,
                0.0,
                0.08829048411772127,
                0.040900836673793024,
                0.11216893479212121,
                0.0,
                0.02418020792113605,
                0.04666700805766652,
                0.12745403240708383,
                0.0,
                0.037058055218521097,
                0.0,
                0.0,
                0.07159652935799213,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.17614389477686287,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.13647311708206555,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.6821576976823215,
                0.0,
                0.0,
                0.18811489281328797
            ],
            [
                0.0,
                0.233080126337122,
                0.0,
                0.26102378080556055,
                0.0,
                0.0,
                0.11213269979954354,
                0.10349414887544764,
                0.1085844462847365,
                0.0,
                0.259559045580687,
                0.0,
                1.0,
                0.0,
                0.03216685091560607,
                0.0,
                0.0,
                0.0,
                0.05534347642641864,
                0.02444498396730018,
                0.11324928119716378,
                0.0,
                0.0,
                0.0,
                0.14866422062328372,
                0.10334818883163978,
                0.0,
                0.0,
                0.42714988543201765,
                0.12655487474280236,
                0.0,
                0.0,
                0.0,
                0.0,
                0.05459916505889383,
                0.0,
                0.023705504185451504,
                0.0,
                0.03957667492469216,
                0.0,
                0.03633053470642247,
                0.0,
                0.0,
                0.03828788841429091,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.2891473410216564,
                0.0,
                0.0
            ],
            [
                0.07451511580279034,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0961770509361069,
                0.033687758542280524,
                0.035344670666258585,
                0.0,
                0.06376161152514,
                0.17614389477686287,
                0.03216685091560607,
                0.0,
                1.0,
                0.0,
                0.05370683235338854,
                0.0,
                0.03422090907064613,
                0.023870819550911505,
                0.13470365657701647,
                0.0,
                0.0,
                0.0,
                0.11771943172971429,
                0.0,
                0.054320529195173856,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.040279362117801136,
                0.0,
                0.07308532994364708,
                0.0,
                0.1637019414434166,
                0.0,
                0.17026424536891419,
                0.14098119210199575,
                0.0,
                0.0,
                0.10526705473092242
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.11531362755421255,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.11091495090648071,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.05370683235338854,
                0.0,
                1.0,
                0.0,
                0.0,
                0.09333686040659102,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.1827729531987195,
                0.0,
                0.0,
                0.0,
                0.0,
                0.09483662830791574,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.03656768684354663,
                0.27845003870362306,
                0.16581771053765484,
                0.0,
                0.0,
                0.0,
                0.055805186830389895,
                0.14564442856842033,
                0.060810955755342296,
                0.0,
                0.035580303632282435,
                0.0,
                0.05534347642641864,
                0.0,
                0.03422090907064613,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.08675643598275241,
                0.0,
                0.0,
                0.0,
                0.0,
                0.08681771220652762,
                0.027306238358139317,
                0.1036239671022311,
                0.078858381162189,
                0.10631250356648787,
                0.04768103265844199,
                0.0,
                0.0,
                0.0,
                0.3030771575070263,
                0.0,
                0.0,
                0.03843302699175461,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.02680018943943174,
                0.0
            ],
            [
                0.21556090984411377,
                0.04968548713600954,
                0.0,
                0.0,
                0.0,
                0.0,
                0.20733826729608223,
                0.025600787581628006,
                0.23917009130028,
                0.0,
                0.11182873423925334,
                0.0,
                0.02444498396730018,
                0.0,
                0.023870819550911505,
                0.0,
                0.09333686040659102,
                0.0,
                0.0,
                1.0,
                0.10111290976477016,
                0.0,
                0.0,
                0.0,
                0.4567905789547513,
                0.0,
                0.0,
                0.10543444867319697,
                0.12138403450934353,
                0.0,
                0.0,
                0.0,
                0.36270750518780787,
                0.0892691492808457,
                0.013505900014590955,
                0.0,
                0.017591706886661788,
                0.0,
                0.11019052384188976,
                0.0,
                0.02696066333755999,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.024193943618503397,
                0.19508397166685795,
                0.0,
                0.123073411279611,
                0.0,
                0.0,
                0.3599267424697224,
                0.07026448121909032,
                0.12989965292905933,
                0.0,
                0.09923339498412989,
                0.13647311708206555,
                0.11324928119716378,
                0.0,
                0.13470365657701647,
                0.0,
                0.0,
                0.0,
                0.08675643598275241,
                0.10111290976477016,
                1.0,
                0.0,
                0.0,
                0.0,
                0.08499085958755526,
                0.16200862517602013,
                0.03325698459180168,
                0.024114807715132677,
                0.24966483075195373,
                0.12888138193568244,
                0.0,
                0.13573535688119392,
                0.15691657987070043,
                0.06493605963471127,
                0.060540776761645224,
                0.0,
                0.0,
                0.0,
                0.06574684619148857,
                0.0,
                0.0,
                0.09615100177027218,
                0.0,
                0.0,
                0.14861394974524278
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.13925613589830663,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.27553903223297016,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.10435417395559152,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.13714963084541518,
                0.060738240448787686,
                0.1835745970085889,
                0.0,
                0.1704150807547694,
                0.0,
                0.14866422062328372,
                0.0,
                0.11771943172971429,
                0.0,
                0.0,
                0.0,
                0.0,
                0.4567905789547513,
                0.08499085958755526,
                0.0,
                0.13925613589830663,
                0.0,
                1.0,
                0.0,
                0.0,
                0.083381587053122,
                0.09599512842023288,
                0.0,
                0.0,
                0.0,
                0.5080434508232073,
                0.07059745117073113,
                0.03204294398943427,
                0.0,
                0.041736580149332674,
                0.0,
                0.19556192557649058,
                0.0,
                0.06396456543511536,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.111342950253068,
                0.0,
                0.0,
                0.0,
                0.0,
                0.10421038501258616,
                0.3823756623760705,
                0.11355813809042822,
                0.0,
                0.0,
                0.0,
                0.10334818883163978,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.08681771220652762,
                0.0,
                0.16200862517602013,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.14725982886425487,
                0.19852754837982925,
                0.0,
                0.4181706810613262,
                0.0,
                0.0,
                0.0571000703832064,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.03407650794424143,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.03315639035554596,
                0.0,
                0.0,
                0.0,
                0.054320529195173856,
                0.0,
                0.0,
                0.0,
                0.027306238358139317,
                0.0,
                0.03325698459180168,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.04443275548510048,
                0.0,
                0.0,
                0.0,
                0.07183732869814709,
                0.0,
                0.04003175615700063,
                0.035814771527909676,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.024974422698578212,
                0.0
            ],
            [
                0.0,
                0.06644841197060346,
                0.12215122766088321,
                0.11725246958632564,
                0.0,
                0.0,
                0.0,
                0.06459342618638117,
                0.05203767522217858,
                0.0,
                0.04830736261871307,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.1827729531987195,
                0.0,
                0.1036239671022311,
                0.10543444867319697,
                0.024114807715132677,
                0.0,
                0.0,
                0.0,
                0.083381587053122,
                0.0,
                0.0,
                1.0,
                0.06748137365205366,
                0.0,
                0.0,
                0.0,
                0.10712860467035715,
                0.14178861394289602,
                0.034076778024562944,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.33211360454490607,
                0.0,
                0.37193024595279445,
                0.0,
                0.0,
                0.15977679308408305,
                0.09831187060715597,
                0.1630569501944479,
                0.0,
                0.3775816210694708,
                0.0,
                0.42714988543201765,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.078858381162189,
                0.12138403450934353,
                0.24966483075195373,
                0.0,
                0.0,
                0.0,
                0.09599512842023288,
                0.14725982886425487,
                0.0,
                0.06748137365205366,
                1.0,
                0.18032680985752106,
                0.0,
                0.0,
                0.12333447378807408,
                0.05713507201895294,
                0.05186521275699031,
                0.0,
                0.0,
                0.0,
                0.12165027912925375,
                0.0,
                0.0,
                0.0,
                0.0,
                0.054556039725545985,
                0.0
            ],
            [
                0.0,
                0.13634484824621496,
                0.0,
                0.0,
                0.0,
                0.0,
                0.12761067582569455,
                0.13253862101296573,
                0.13905745329965813,
                0.0,
                0.0,
                0.0,
                0.12655487474280236,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.10631250356648787,
                0.0,
                0.12888138193568244,
                0.0,
                0.0,
                0.0,
                0.0,
                0.19852754837982925,
                0.0,
                0.0,
                0.18032680985752106,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.06992180837270343,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.05950299952943608,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.05789632796154075,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.04768103265844199,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.04443275548510048,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.12543939486745864,
                0.0,
                0.0,
                0.18819656383951613,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.04360931186121037,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.13573535688119392,
                0.0,
                0.0,
                0.0,
                0.0,
                0.4181706810613262,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.03582672041097661,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.08170998206643944,
                0.0,
                0.15398188915341873,
                0.0,
                0.08829048411772127,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.09483662830791574,
                0.0,
                0.0,
                0.36270750518780787,
                0.15691657987070043,
                0.0,
                0.27553903223297016,
                0.0,
                0.5080434508232073,
                0.0,
                0.0,
                0.10712860467035715,
                0.12333447378807408,
                0.0,
                0.0,
                0.0,
                1.0,
                0.09070355583884177,
                0.0,
                0.0,
                0.0,
                0.0,
                0.20995689157753775,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.09927522117076713,
                0.0,
                0.0,
                0.0,
                0.0,
                0.04405921457450316,
                0.0,
                0.040900836673793024,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0892691492808457,
                0.06493605963471127,
                0.0,
                0.0,
                0.0,
                0.07059745117073113,
                0.0,
                0.0,
                0.14178861394289602,
                0.05713507201895294,
                0.0,
                0.0,
                0.0,
                0.09070355583884177,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.09620237343045629,
                0.11117600049851045,
                0.05452921242590832,
                0.0,
                0.0,
                0.0,
                0.08318463919904592,
                0.13429220439089942,
                0.05999311255933477,
                0.0,
                0.11216893479212121,
                0.0,
                0.05459916505889383,
                0.0,
                0.040279362117801136,
                0.0,
                0.0,
                0.0,
                0.3030771575070263,
                0.013505900014590955,
                0.060540776761645224,
                0.0,
                0.0,
                0.0,
                0.03204294398943427,
                0.0571000703832064,
                0.07183732869814709,
                0.034076778024562944,
                0.05186521275699031,
                0.06992180837270343,
                0.12543939486745864,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.013097336032310593,
                0.10110971554045894,
                0.021866187973691525,
                0.0,
                0.02007268934510007,
                0.0,
                0.0,
                0.07050601377905272,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.06054312747366323,
                0.02482634384129499,
                0.02604741261774867,
                0.0,
                0.02418020792113605,
                0.0,
                0.023705504185451504,
                0.0,
                0.07308532994364708,
                0.0,
                0.0,
                0.0,
                0.0,
                0.017591706886661788,
                0.0,
                0.0,
                0.0,
                0.0,
                0.041736580149332674,
                0.0,
                0.04003175615700063,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.013097336032310593,
                0.0,
                1.0,
                0.0,
                0.028481150396957124,
                0.0,
                0.02614508229770233,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.04796205659778813,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.04666700805766652,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.03843302699175461,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.035814771527909676,
                0.0,
                0.0,
                0.0,
                0.18819656383951613,
                0.0,
                0.0,
                0.0,
                0.10110971554045894,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.10578008238368444,
                0.0
            ],
            [
                0.05708653516419446,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.054908950307551115,
                0.041447932602022876,
                0.043486524215529135,
                0.0,
                0.12745403240708383,
                0.0,
                0.03957667492469216,
                0.0,
                0.1637019414434166,
                0.0,
                0.0,
                0.0,
                0.0,
                0.11019052384188976,
                0.06574684619148857,
                0.0,
                0.0,
                0.0,
                0.19556192557649058,
                0.0,
                0.0,
                0.0,
                0.12165027912925375,
                0.0,
                0.0,
                0.0,
                0.20995689157753775,
                0.0,
                0.021866187973691525,
                0.0,
                0.028481150396957124,
                0.0,
                1.0,
                0.0,
                0.043649585129285066,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.08190215034278438,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.09913777529200142,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.038048308928746215,
                0.03991969209844506,
                0.08086191124963885,
                0.037058055218521097,
                0.0,
                0.03633053470642247,
                0.0,
                0.17026424536891419,
                0.0,
                0.0,
                0.0,
                0.0,
                0.02696066333755999,
                0.0,
                0.0,
                0.0,
                0.0,
                0.06396456543511536,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.02007268934510007,
                0.0,
                0.02614508229770233,
                0.0,
                0.043649585129285066,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.6821576976823215,
                0.0,
                0.0,
                0.14098119210199575,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.09615100177027218,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.09542952299555654
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.2891473410216564,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.03344498998221597,
                0.041249745188589884,
                0.0,
                0.051045524642274895,
                0.0,
                0.0,
                0.0,
                0.0,
                0.07043571688490859,
                0.0,
                0.07159652935799213,
                0.0,
                0.03828788841429091,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.02680018943943174,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.024974422698578212,
                0.0,
                0.054556039725545985,
                0.0,
                0.04360931186121037,
                0.0,
                0.0,
                0.0,
                0.07050601377905272,
                0.0,
                0.0,
                0.10578008238368444,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.07690064187840952,
                0.0,
                0.0,
                0.0,
                0.0,
                0.18811489281328797,
                0.0,
                0.0,
                0.10526705473092242,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.14861394974524278,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.09542952299555654,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "W06-3120": {
        "input_sentences": [
            "Mainly we introduce two reordering approaches and add morphological information.",
            "TALP Phrase-Based Statistical Translation System For European Language Pairs",
            "This paper reports translation results for the \u201cExploiting Parallel Texts for Statistical Machine Translation\u201d (HLT-NAACL Workshop on Parallel Texts 2006).",
            "Abstract",
            "We have studied different techniques to improve the standard Phrase-Based translation system."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                1.0,
                0.13874541854273278,
                0.0,
                0.266273569273078
            ],
            [
                0.0,
                0.13874541854273278,
                1.0,
                0.0,
                0.07829590496171927
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.266273569273078,
                0.07829590496171927,
                0.0,
                1.0
            ]
        ]
    },
    "W05-1518": {
        "input_sentences": [
            "This paper explores the possibilities of improving parsing results by combining outputs of several parsers.",
            "To some extent, we are porting the ideas of Henderson and Brill (1999) to the world of dependency structures.",
            "We differ from them in exploring context features more deeply.",
            "Moreover, our experiments show that even parsers far below the state of the art can contribute to the total improvement.",
            "All our experiments were conducted on Czech but the method is language-independent.",
            "We were able to significantly improve over the best parsing result for the given setting, known so far.",
            "Abstract",
            "Improving Parsing Accuracy By Combining Diverse Dependency Parsers"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0,
                0.07279661477492956,
                0.0,
                0.06308343369529341,
                0.0,
                0.3955170755124896
            ],
            [
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.10488517001957287
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.07279661477492956,
                0.0,
                0.0,
                1.0,
                0.11174927650196473,
                0.08785781795864608,
                0.0,
                0.08753377505266656
            ],
            [
                0.0,
                0.0,
                0.0,
                0.11174927650196473,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.06308343369529341,
                0.0,
                0.0,
                0.08785781795864608,
                0.0,
                1.0,
                0.0,
                0.07585422909713817
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.3955170755124896,
                0.10488517001957287,
                0.0,
                0.08753377505266656,
                0.0,
                0.07585422909713817,
                0.0,
                1.0
            ]
        ]
    },
    "W10-1401": {
        "input_sentences": [
            "In this paper we re view the current state-of-affairs with respectto parsing MRLs and point out central challenges.",
            "Statistical Parsing of Morphologically Rich Languages (SPMRL) What How and Whither",
            "The first workshop on statistical parsing of MRLs hosts a variety of contributions which show that despite languagespecific idiosyncrasies, the problems associ ated with parsing MRLs cut across languagesand parsing frameworks.",
            "The term Morphologically Rich Languages(MRLs) refers to languages in which signif icant information concerning syntactic units and relations is expressed at word-level.",
            "The overarching analysis suggests itself as a source of directions for future investigations.",
            "We synthesize the contributions of re searchers working on parsing Arabic, Basque, French, German, Hebrew, Hindi and Korean to point out shared solutions across languages.",
            "Abstract",
            "Thereis ample evidence that the application of read ily available statistical parsing models to suchlanguages is susceptible to serious performance degradation."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.05255731553153129,
                0.15129947842325242,
                0.042305429656200294,
                0.0,
                0.08727918262112203,
                0.0,
                0.028465050396028826
            ],
            [
                0.05255731553153129,
                1.0,
                0.17756295882104614,
                0.31553331783853383,
                0.0,
                0.11442878978091929,
                0.0,
                0.12052676086688631
            ],
            [
                0.15129947842325242,
                0.17756295882104614,
                1.0,
                0.061339427938562355,
                0.0,
                0.10245772919668522,
                0.0,
                0.09616812655274914
            ],
            [
                0.042305429656200294,
                0.31553331783853383,
                0.061339427938562355,
                1.0,
                0.0,
                0.06924878322585963,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.08727918262112203,
                0.11442878978091929,
                0.10245772919668522,
                0.06924878322585963,
                0.0,
                1.0,
                0.0,
                0.023296892625919413
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.028465050396028826,
                0.12052676086688631,
                0.09616812655274914,
                0.0,
                0.0,
                0.023296892625919413,
                0.0,
                1.0
            ]
        ]
    },
    "P13-1007": {
        "input_sentences": [
            "Finally, we significantly improve the performance of the previous model using a rich set of automatically generated features.",
            "No corpusbased method, however, has yet addressed QSD when incorporating the implicit universal of plurals and/or operators such as negation.",
            "We also present a general model for learning to build partial orders from a set of pairpreferences.",
            "In this paper we report early, though promising, results for automatic QSD when handling both phenomena.",
            "Recent work on statistical quantifier scope disambiguation (QSD) has improved upon earlier work by scoping an arbitrary number and type of noun phrases.",
            "We give an algorithm for finding a guaranteed approximation of the optimal solution, which works very well in practice.",
            "Abstract",
            "Plurality, Negation, and Quantification:Towards Comprehensive Quantifier Scope Disambiguation"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.143480755608925,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                1.0,
                0.0,
                0.058981975112227074,
                0.042224829039207955,
                0.0,
                0.0,
                0.09594169584755255
            ],
            [
                0.143480755608925,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.058981975112227074,
                0.0,
                1.0,
                0.04393024758751845,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.042224829039207955,
                0.0,
                0.04393024758751845,
                1.0,
                0.0,
                0.0,
                0.21437443106287143
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.09594169584755255,
                0.0,
                0.0,
                0.21437443106287143,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P04-1013": {
        "input_sentences": [
            "Discriminative methods have shown significant improvements over traditional generative methods in many machine learning applications, but there has been difficulty in extending them to natural language parsing.",
            "We present three methods for training a neural network to estimate the probabilities for a statistical parser, one generative, one discriminative, and one where the probability model is generative but the training criteria is discriminative.",
            "We show how a parser can be trained with a discriminative learning method while still parameterizing the problem according to a generative probability model.",
            "One problem is that much of the work on discriminative methods conflates changes to the learning method with changes to the parameterization of the problem.",
            "The latter model outperforms the previous two, achieving state-ofthe-art levels of performance (90.1% F-measure on constituents).",
            "Abstract",
            "Discriminative Training Of A Neural Network Statistical Parser"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.18210153279473695,
                0.1263719841254611,
                0.1389597322183653,
                0.0,
                0.0,
                0.04084698877051038
            ],
            [
                0.18210153279473695,
                1.0,
                0.32106965935346116,
                0.0840805422889199,
                0.03938823509623923,
                0.0,
                0.6380754849050482
            ],
            [
                0.1263719841254611,
                0.32106965935346116,
                1.0,
                0.3075690772939662,
                0.05466806724710594,
                0.0,
                0.1553109194729801
            ],
            [
                0.1389597322183653,
                0.0840805422889199,
                0.3075690772939662,
                1.0,
                0.0,
                0.0,
                0.04509334888344975
            ],
            [
                0.0,
                0.03938823509623923,
                0.05466806724710594,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.04084698877051038,
                0.6380754849050482,
                0.1553109194729801,
                0.04509334888344975,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "W12-3160": {
        "input_sentences": [
            "However, these methods have not yet met with wide-spread adoption.",
            "The introduction of large-margin based dis criminative methods for optimizing statistical machine translation systems in recent years has allowed exploration into many new types of features for the translation process.",
            "Large-Margin Learning",
            "Abstract",
            "By removing the limitation on the number of parameters which can be optimized, these methods have allowed integrating millions of sparse features.",
            "Optimization Strategies for Online Large-Margin Learning in Machine Translation",
            "Thismay be partly due to the perceived complex ity of implementation, and partly due to the lack of standard methodology for applying these methods to MT. This papers aims to shedlight on large-margin learning for MT, explic itly presenting the simple passive-aggressivealgorithm which underlies many previous ap proaches, with direct application to MT, andempirically comparing several widespread op timization strategies."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0416426585340159,
                0.0,
                0.0,
                0.05805060997985027,
                0.0,
                0.027234798567015748
            ],
            [
                0.0416426585340159,
                1.0,
                0.15512525670944652,
                0.0,
                0.12921163167387764,
                0.2811269516216097,
                0.039266086962272115
            ],
            [
                0.0,
                0.15512525670944652,
                1.0,
                0.0,
                0.0,
                0.4866908078138695,
                0.16875002732283834
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.05805060997985027,
                0.12921163167387764,
                0.0,
                0.0,
                1.0,
                0.0,
                0.01824587558308581
            ],
            [
                0.0,
                0.2811269516216097,
                0.4866908078138695,
                0.0,
                0.0,
                1.0,
                0.12695701341466215
            ],
            [
                0.027234798567015748,
                0.039266086962272115,
                0.16875002732283834,
                0.0,
                0.01824587558308581,
                0.12695701341466215,
                1.0
            ]
        ]
    },
    "W04-1505": {
        "input_sentences": [
            "We present and evaluate an implemented statistical minimal parsing strategy exploiting DG charateristics to permit fast, robust, deeplinguistic analysis of unrestricted text, and compare its probability model to (Collins, 1999) and an adaptation, (Dubey and Keller, 2003).",
            "We show that DG allows for the expression of the majority of English LDDs in a context-free way and offers simple yet powerful statistical models.",
            "Abstract",
            "Fast Deep-Linguistic Statistical Dependency Parsing"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.05786375218384446,
                0.0,
                0.15535740157354963
            ],
            [
                0.05786375218384446,
                1.0,
                0.0,
                0.052338609028865876
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.15535740157354963,
                0.052338609028865876,
                0.0,
                1.0
            ]
        ]
    },
    "N06-1045": {
        "input_sentences": [
            "We also demonstrate our algorithm\u2019s effectiveness on two large-scale tasks.",
            "We introduce an algorithm that determinizes such automata while preserving proper weights, returning the sum of the weight of all multiply derived trees.",
            "Ranked lists of output trees from syntactic statistical NLP applications frequently contain multiple repeated entries.",
            "Abstract",
            "This redundancy leads to misrepresentation of tree weight and reduced information for debugging and tuning purposes. is due to nondeterminism in the weighted automata that produce the results.",
            "A Better N-Best List: Practical Determinization Of Weighted Finite Tree Automata"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.08326729380678476,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.08326729380678476,
                1.0,
                0.05570945812052302,
                0.0,
                0.09245941680110259,
                0.05053610460098273
            ],
            [
                0.0,
                0.05570945812052302,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.09245941680110259,
                0.0,
                0.0,
                1.0,
                0.1775124926525742
            ],
            [
                0.0,
                0.05053610460098273,
                0.0,
                0.0,
                0.1775124926525742,
                1.0
            ]
        ]
    },
    "E09-1034": {
        "input_sentences": [
            "Parsing Mildly Non-Projective Dependency Structures",
            "Abstract",
            "We present parsing algorithms for various mildly non-projective dependency formalisms.",
            "The third case includes all the degree in a number of dependency treebanks.",
            "In particular, algorithms are presented for: all well-nested structures of degree at most with the same complexity as the best existing parsers for constituency formalisms of equivalent generative power; all well-nested structures with degree bounded by any constant and a new class of structures with gap deup to includes some ill-nested structures."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.6292214704307451,
                0.10693767167847647,
                0.2113800349448257
            ],
            [
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.6292214704307451,
                0.0,
                1.0,
                0.0816373962851974,
                0.08068492332362451
            ],
            [
                0.10693767167847647,
                0.0,
                0.0816373962851974,
                1.0,
                0.13997323099569697
            ],
            [
                0.2113800349448257,
                0.0,
                0.08068492332362451,
                0.13997323099569697,
                1.0
            ]
        ]
    },
    "P10-1044": {
        "input_sentences": [
            "By simultaneously inferring latent topics and topic distributions over relations, the benefits of previous approaches: like traditional classbased approaches, it produces humaninterpretable classes describing each relation\u2019s preferences, but it is competitive with non-class-based methods in predictive power. compare several state-ofthe-art methods achieving an 85% increase in recall at 0.9 precision over mutual information (Erk, 2007).",
            "computation of preferthe admissible argument values for a relation, is a well-known NLP task with applicability.",
            "We also evaleffectiveness at filtering improper applications of inference rules, where we show substantial improvement Pantel system (Pantel et al.,",
            "A Latent Dirichlet Allocation Method for Selectional Preferences",
            "We present which utilizes LinkLDA (Erosheva et al., 2004) to model selectional preferences.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.03266017357834997,
                0.0,
                0.0792100098042098,
                0.024838524342442686,
                0.0
            ],
            [
                0.03266017357834997,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.12629737234531183,
                0.0
            ],
            [
                0.0792100098042098,
                0.0,
                0.0,
                1.0,
                0.1798933234052762,
                0.0
            ],
            [
                0.024838524342442686,
                0.0,
                0.12629737234531183,
                0.1798933234052762,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P06-1109": {
        "input_sentences": [
            "Unsupervised DOP models assign all possible binary trees to a set of sentences and next use (a large random subset of) all subtrees from these binary trees to compute the most probable parse trees.",
            "We investigate generalizations of the allsubtrees &quot;DOP&quot; approach to unsupervised parsing.",
            "We will test both a relative frequency estimator for unsupervised DOP and a maximum likelihood estimator which is known to be statistically consistent.",
            "To the best of our knowledge this is the first paper which tests a maximum likelihood estimator for DOP on the Wall Street Journal, leading the surprising result that unsupervised parsing model beats a widely used supervised model (a treebank PCFG).",
            "We report state-ofthe-art results on English (WSJ), German (NEGRA) and Chinese (CTB) data.",
            "Abstract",
            "An All-Subtrees Approach To Unsupervised Parsing"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.04387747133088672,
                0.0397397029074538,
                0.027096044186571824,
                0.0,
                0.0,
                0.12952586974535968
            ],
            [
                0.04387747133088672,
                1.0,
                0.06853321380136415,
                0.0818052041812729,
                0.0,
                0.0,
                0.3380963769862967
            ],
            [
                0.0397397029074538,
                0.06853321380136415,
                1.0,
                0.21624841817457072,
                0.0,
                0.0,
                0.06009776217855158
            ],
            [
                0.027096044186571824,
                0.0818052041812729,
                0.21624841817457072,
                1.0,
                0.0,
                0.0,
                0.1118223522749469
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.12952586974535968,
                0.3380963769862967,
                0.06009776217855158,
                0.1118223522749469,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P11-2121": {
        "input_sentences": [
            "Getting the Most out of Transition-based Dependency Parsing",
            "This paper suggests two ways of improving transition-based, non-projective dependency parsing.",
            "The new addition to the algorithm shows a clear advantage in parsing speed.",
            "First, we add a transition to an existing non-projective parsing algorithm, so it can perform either projective or non-projective parsing as needed.",
            "Second, we present a bootstrapping technique that narrows down discrepancies between gold-standard and automatic parses used as features.",
            "Abstract",
            "The bootstrapping technique gives a significant improvement to parsing accuracy, showing near state-of-theart performance with respect to other parsing approaches evaluated on the same data set."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.44390446181839444,
                0.0618756485254685,
                0.15576902824672947,
                0.0,
                0.0,
                0.08038586824213408
            ],
            [
                0.44390446181839444,
                1.0,
                0.04010867640945497,
                0.4213511766092257,
                0.0,
                0.0,
                0.0521072643931925
            ],
            [
                0.0618756485254685,
                0.04010867640945497,
                1.0,
                0.12296927058602616,
                0.0,
                0.0,
                0.0541950497038431
            ],
            [
                0.15576902824672947,
                0.4213511766092257,
                0.12296927058602616,
                1.0,
                0.0,
                0.0,
                0.07317608677480973
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.10044691648347362
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.08038586824213408,
                0.0521072643931925,
                0.0541950497038431,
                0.07317608677480973,
                0.10044691648347362,
                0.0,
                1.0
            ]
        ]
    },
    "N12-1090": {
        "input_sentences": [
            "To build a coreference resolver for a new language, the typical approach is to first coreference-annotate documents from this target language and then train a resolver on these annotated documents using supervised learning techniques.",
            "Experimental results on two target languages demonstrate the promise of our approach.",
            "To alleviate this corpus annotation bottleneck, we examine a translation-based projection approach to multilingual coreference resolution.",
            "Translation-Based Projection for Multilingual Coreference Resolution",
            "However, the high cost associated with manually coreference-annotating documents needed by a supervised approach makes it difficult to deploy coreference technologies across a large number of natural languages.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.08989428388126203,
                0.07344939346168314,
                0.07650331850165208,
                0.19314427420401145,
                0.0
            ],
            [
                0.08989428388126203,
                1.0,
                0.04897390032354158,
                0.0,
                0.10478221947042012,
                0.0
            ],
            [
                0.07344939346168314,
                0.04897390032354158,
                1.0,
                0.6400540952577286,
                0.08561379137117252,
                0.0
            ],
            [
                0.07650331850165208,
                0.0,
                0.6400540952577286,
                1.0,
                0.08917349539203005,
                0.0
            ],
            [
                0.19314427420401145,
                0.10478221947042012,
                0.08561379137117252,
                0.08917349539203005,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "E09-1018": {
        "input_sentences": [
            "We have compared it to several systems available on the web (all we have found so far).",
            "EM Works for Pronoun Anaphora Resolution",
            "We present an algorithm for pronounanaphora (in English) that uses Expectation Maximization (EM) to learn virtually all of its parameters in an unsupervised fashion.",
            "While EM frequently fails to find good models for the tasks to which it is set, in this case it works quite well.",
            "Abstract",
            "Our program significantly outperforms all of them.",
            "The algorithm is fast and robust, and has been made publically available for downloading."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.13721137870372932
            ],
            [
                0.0,
                1.0,
                0.07041419189977115,
                0.19208695904323586,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.07041419189977115,
                1.0,
                0.04755314207065487,
                0.0,
                0.0,
                0.08509151865760584
            ],
            [
                0.0,
                0.19208695904323586,
                0.04755314207065487,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.13721137870372932,
                0.0,
                0.08509151865760584,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P12-1099": {
        "input_sentences": [
            "In this paper, we evaluate performance on a domain adaptation setting where we translate sentences from the medical domain.",
            "Our experimental results show that ensemble decoding outperforms various strong baselines including mixture models, the current state-of-the-art for domain adaptation in machine translation.",
            "Mixing Multiple Translation Models in Statistical Machine Translation",
            "Statistical machine translation is often faced with the problem of combining training data from many diverse sources into a single translation model which then has to translate sentences in a new domain.",
            "We propose a novel approach, ensemble decoding, which combines a number of translation systems dynamically at the decoding step.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.14088836287521989,
                0.0,
                0.2031925018588875,
                0.0,
                0.0
            ],
            [
                0.14088836287521989,
                1.0,
                0.20946443823555966,
                0.11318239477858229,
                0.17873249133676067,
                0.0
            ],
            [
                0.0,
                0.20946443823555966,
                1.0,
                0.29504967912822283,
                0.08991503566526544,
                0.0
            ],
            [
                0.2031925018588875,
                0.11318239477858229,
                0.29504967912822283,
                1.0,
                0.054228771051092896,
                0.0
            ],
            [
                0.0,
                0.17873249133676067,
                0.08991503566526544,
                0.054228771051092896,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "W99-0613": {
        "input_sentences": [
            "The approach gains leverage from natural redundancy in the data: for many named-entity instances both the spelling of the name and the context in which it appears are sufficient to determine its type.",
            "Unsupervised Models for Named Entity Classification Collins",
            "The second algorithm extends ideas from boosting algorithms, designed for supervised learning tasks, to the framework suggested by (Blum and Mitchell 98).",
            "This paper discusses the use of unlabeled examples for the problem of named entity classification.",
            "We present two algorithms.",
            "The first method uses a similar algorithm to that of (Yarowsky 95), with modifications motivated by (Blum and Mitchell 98).",
            "A large number of rules is needed for coverage of the domain, suggesting that a fairly large number of labeled examples should be required to train a classi- However, we show that the use of data can reduce the requirements for supervision to just 7 simple &quot;seed&quot; rules.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.12946096103744403,
                0.0,
                0.10547843178746845,
                0.0,
                0.0,
                0.032921701835538185,
                0.0
            ],
            [
                0.12946096103744403,
                1.0,
                0.0,
                0.29999688581755607,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.14644803232993356,
                0.24403252043743348,
                0.0,
                0.0
            ],
            [
                0.10547843178746845,
                0.29999688581755607,
                0.0,
                1.0,
                0.0,
                0.0,
                0.09128298762907389,
                0.0
            ],
            [
                0.0,
                0.0,
                0.14644803232993356,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.24403252043743348,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.032921701835538185,
                0.0,
                0.0,
                0.09128298762907389,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "E03-1005": {
        "input_sentences": [
            "Two apparently opposing DOP models exist in the literature: one which computes the parse tree involving the most frequent subtrees from a treebank and one which computes the parse tree involving the fewest subtrees from a treebank.",
            "Together with a PCFGreduction of DOP we obtain improved accuracy and efficiency on the Wall Street Journal treebank Our results show an 11% relative reduction in error rate over previous models, and an average processing time of 3.6 seconds per WSJ sentence.",
            "This paper proposes an integration of the two models which outperforms each of them separately.",
            "An Efficient Implementation of a New DOP Model",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0852565832391971,
                0.03537696649082205,
                0.039151837335847796,
                0.0
            ],
            [
                0.0852565832391971,
                1.0,
                0.04046534254315847,
                0.04478316447511461,
                0.0
            ],
            [
                0.03537696649082205,
                0.04046534254315847,
                1.0,
                0.0,
                0.0
            ],
            [
                0.039151837335847796,
                0.04478316447511461,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P13-2083": {
        "input_sentences": [
            "We test our hypothesis on the problem of judging event coreferentiality, which involves compositional interactions in the predicate-argument structure of sentences, and demonstrate that our model outperforms both state-of-the-art window-based word embeddings as well as simple approaches to compositional semantics previously employed in the literature.",
            "A Structured Distributional Semantic Model for Event Co-reference",
            "In this paper we present a novel approach to modelling distributional semantics that represents meaning as distributions over relations in syntactic neighborhoods.",
            "Abstract",
            "We argue that our model approximates meaning in compositional configurations more effectively than standard distributional vectors or bag-of-words models."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0968172452833018,
                0.0356609107029053,
                0.0,
                0.09822673917852051
            ],
            [
                0.0968172452833018,
                1.0,
                0.06135399677050565,
                0.0,
                0.12569305457401644
            ],
            [
                0.0356609107029053,
                0.06135399677050565,
                1.0,
                0.0,
                0.0958418685907325
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.09822673917852051,
                0.12569305457401644,
                0.0958418685907325,
                0.0,
                1.0
            ]
        ]
    },
    "N12-1086": {
        "input_sentences": [
            "Sparse measures are desirable forhigh-dimensional multi-class learning problems such as the induction of labels on natu ral language types, which typically associate with only a few labels.",
            "Compared to standard graph-based learning methods, for two lexicon expansion problems, our approach producessignificantly smaller lexicons and obtains bet ter predictive performance.",
            "To achieve compactness, we induce sparse measures at graph vertices by incorporating sparsity-inducing penalties in Gaussian and entropic pairwise Markovnetworks constructed from labeled and unla beled data.",
            "Abstract",
            "Graph-Based Lexicon Expansion with Sparsity-Inducing Penalties",
            "We present novel methods to construct compact natural language lexicons within a graph based semi-supervised learning framework, an attractive platform suited for propagating soft labels onto new natural language types from seed data."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0739505463791809,
                0.07932604995406119,
                0.0,
                0.0,
                0.18760537572526317
            ],
            [
                0.0739505463791809,
                1.0,
                0.02203577413780586,
                0.0,
                0.2774231416195876,
                0.13765119512981028
            ],
            [
                0.07932604995406119,
                0.02203577413780586,
                1.0,
                0.0,
                0.27747188603023437,
                0.04878206211956929
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.2774231416195876,
                0.27747188603023437,
                0.0,
                1.0,
                0.08060402657942886
            ],
            [
                0.18760537572526317,
                0.13765119512981028,
                0.04878206211956929,
                0.0,
                0.08060402657942886,
                1.0
            ]
        ]
    },
    "W08-0406": {
        "input_sentences": [
            "We present a novel approach to word reordering which successfully integrates syntactic structural knowledge with phrase-based SMT.",
            "In decoding, the alternatives are scored based on the output word order, not the order of the input.",
            "Syntactic Reordering Integrated with Phrase-Based SMT",
            "On an English- Danish task, we achieve an absolute improvement in translation quality of 1.1 % BLEU.",
            "Manual evaluation supports the claim that the present approach is significantly superior to previous approaches.",
            "Abstract",
            "Unlike previous approaches, this makes it possible to successfully integrate syntactic reordering with phrase-based SMT.",
            "This is done by constructing a lattice of alternatives based on automatically learned probabilistic syntactic rules."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.1082050814940026,
                0.41815733136806116,
                0.0,
                0.15693056016884827,
                0.0,
                0.3420345967244699,
                0.08729059382979974
            ],
            [
                0.1082050814940026,
                1.0,
                0.055741134848651626,
                0.0,
                0.0,
                0.0,
                0.03487803364934749,
                0.11980566766514912
            ],
            [
                0.41815733136806116,
                0.055741134848651626,
                1.0,
                0.0,
                0.0,
                0.0,
                0.4353022831736816,
                0.14522536998578014
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.15693056016884827,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.16336490123880237,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.3420345967244699,
                0.03487803364934749,
                0.4353022831736816,
                0.0,
                0.16336490123880237,
                0.0,
                1.0,
                0.09086961280669914
            ],
            [
                0.08729059382979974,
                0.11980566766514912,
                0.14522536998578014,
                0.0,
                0.0,
                0.0,
                0.09086961280669914,
                1.0
            ]
        ]
    },
    "P09-2003": {
        "input_sentences": [
            "We present a CYK and an Earley-style algorithm for parsing Range Concatenation Grammar (RCG), using the deductive parsing framework.",
            "Experiments show that, compared to previous approaches, the constraint propagation helps to considerably decrease the number of items in the chart.",
            "Abstract",
            "An Earley Parsing Algorithm for Range Concatenation Grammars",
            "The characteristic property of the Earley parser is that we use a technique of range boundary constraint propagation to compute the yields of non-terminals as late as possible."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0,
                0.49864143077017503,
                0.06653209209897797
            ],
            [
                0.0,
                1.0,
                0.0,
                0.0,
                0.10276703756906368
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.49864143077017503,
                0.0,
                0.0,
                1.0,
                0.12132806386411743
            ],
            [
                0.06653209209897797,
                0.10276703756906368,
                0.0,
                0.12132806386411743,
                1.0
            ]
        ]
    },
    "N12-1049": {
        "input_sentences": [
            "We achieve an accuracy of 72% on an adapted TempEval-2 task \u2013 comparable to state of the art systems.",
            "While most approaches to the task have used regular expressions and similar linear pattern interpretation rules, the possibility of phrasal embedding and modification in time expressions motivates our use of a comof time This is used to construct a parse which evaluates to the time the phrase would represent, as a logical parse might evaluate to a concrete entity.",
            "We present a probabilistic approach for learning to interpret temporal phrases given only a corpus of utterances and the times they reference.",
            "In this way, we can employ a loosely supervised EM-style bootstrapping approach to learn these latent parses while capturing both syntactic uncertainty and pragmatic ambiguity in a probabilistic framework.",
            "Parsing Time: Learning to Interpret Time Expressions",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.03443898511151448,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.03443898511151448,
                1.0,
                0.0,
                0.0,
                0.35867855172004304,
                0.0
            ],
            [
                0.0,
                0.0,
                1.0,
                0.09876543571051094,
                0.17218195895375613,
                0.0
            ],
            [
                0.0,
                0.0,
                0.09876543571051094,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.35867855172004304,
                0.17218195895375613,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "D07-1013": {
        "input_sentences": [
            "We show that, in spite of similar performance overall, the two models produce different types of errors, in a way that can be explained by theoretical properties of the two models.",
            "This analysisleads to new directions for parser develop ment.",
            "We present a comparative error analysisof the two dominant approaches in datadriven dependency parsing: global, exhaus tive, graph-based models, and local, greedy, transition-based models.",
            "Characterizing the Errors of Data-Driven Dependency Parsing Models",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.10652630837470763,
                0.18164671435914218,
                0.0
            ],
            [
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.10652630837470763,
                0.0,
                1.0,
                0.2059922956891051,
                0.0
            ],
            [
                0.18164671435914218,
                0.0,
                0.2059922956891051,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "C10-1045": {
        "input_sentences": [
            "In this paper, we offer broad insightinto the underperformance of Arabic constituency parsing by analyzing the inter play of linguistic phenomena, annotationchoices, and model design.",
            "Better Arabic Parsing: Baselines Evaluations and Analysis",
            "Second, we show that although the PennArabic Treebank is similar to other tree banks in gross statistical terms, annotation consistency remains problematic.",
            "First, we identify sources of syntactic ambiguity under studied in the existing parsing literature.",
            "Fourth, we show how to build better models for three different parsers.Finally, we show that in application set tings, the absence of gold segmentation lowers parsing performance by 2?5% F1.",
            "Abstract",
            "Third,we develop a human interpretable grammar that is competitive with a latent vari able PCFG."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.1261990130060454,
                0.0,
                0.03598657969943479,
                0.02438739859798149,
                0.0,
                0.0
            ],
            [
                0.1261990130060454,
                1.0,
                0.0,
                0.06404475072342918,
                0.12220903679007672,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.03598657969943479,
                0.06404475072342918,
                0.0,
                1.0,
                0.03484880854200166,
                0.0,
                0.0
            ],
            [
                0.02438739859798149,
                0.12220903679007672,
                0.0,
                0.03484880854200166,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "H05-1094": {
        "input_sentences": [
            "On two standard text data sets, we show that joint decoding outperforms cascaded decoding.",
            "Specifically, we perform joint decoding ofseparately-trained sequence models, preserv ing uncertainty between the tasks and allowinginformation from the new task to affect predic tions on the old task.",
            "Therefore, we wantto transfer learning from the old, general purpose subtask to a more specific new task, for which there is often less data.",
            "While work in transfer learning often considers how the old task should affect learning on the new task, in this paper we show that it helps to take into account how the new task affects the old.",
            "Composition Of Conditional Random Fields For Transfer Learning",
            "Many learning tasks have subtasks for which much training data exists.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.16389370522638824,
                0.0598882306781799,
                0.0,
                0.0,
                0.07870671042336533,
                0.0
            ],
            [
                0.16389370522638824,
                1.0,
                0.16996274817715826,
                0.32665922732624403,
                0.0,
                0.07643085021558825,
                0.0
            ],
            [
                0.0598882306781799,
                0.16996274817715826,
                1.0,
                0.4098823301831909,
                0.14218604311112398,
                0.14694183616355166,
                0.0
            ],
            [
                0.0,
                0.32665922732624403,
                0.4098823301831909,
                1.0,
                0.13747523492032995,
                0.08541562943612103,
                0.0
            ],
            [
                0.0,
                0.0,
                0.14218604311112398,
                0.13747523492032995,
                1.0,
                0.08031530805255507,
                0.0
            ],
            [
                0.07870671042336533,
                0.07643085021558825,
                0.14694183616355166,
                0.08541562943612103,
                0.08031530805255507,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "E09-1038": {
        "input_sentences": [
            "Enhancing Unlexicalized Parsing Performance Using a Wide Coverage Lexicon Fuzzy Tag-Set Mapping and EM-HMM-Based Lexical Probabilities",
            "We show that this solution greatly enhances the performance of an unlexicalized Hebrew PCFG parser, resulting in state-of-the-art Hebrew parsing results both when a segmentation oracle is assumed, and in a real-word parsing scenario of parsing unsegmented tokens.",
            "We present a framework for interfacing a PCFG parser with lexical information from an external resource following a different tagging scheme than the treebank.",
            "Lexical probabilities for rare events are estimated in a semi-supervised manner from a lexicon and large unannotated corpora.",
            "This is achieved by defining a stochastic mapping layer between the two resources.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.1675547438929288,
                0.03513168186144273,
                0.14553621826234303,
                0.07410839552271431,
                0.0
            ],
            [
                0.1675547438929288,
                1.0,
                0.07130067824641996,
                0.0,
                0.0,
                0.0
            ],
            [
                0.03513168186144273,
                0.07130067824641996,
                1.0,
                0.04068115708228679,
                0.0,
                0.0
            ],
            [
                0.14553621826234303,
                0.0,
                0.04068115708228679,
                1.0,
                0.0,
                0.0
            ],
            [
                0.07410839552271431,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "C10-2096": {
        "input_sentences": [
            "The main advantage of our model is that we can make global decision to search for the best segmentation, parse-tree and translation in one step.",
            "More importantly,our model takes into account all the probabilities of different steps, such as segmen tation, parsing, and translation.",
            "Machine Translation with Lattices and Forests",
            "Medium-scale experiments show an improvement of +0.9 BLEU points over a state-of-the-art forest-based baseline.",
            "Traditional 1-best translation pipelinessuffer a major drawback: the errors of 1 best outputs, inevitably introduced by each module, will propagate and accumulate along the pipeline.",
            "We integrate both lat tice and forest into a single tree-to-stringsystem, and explore the algorithms of lattice parsing, lattice-forest-based rule ex traction and decoding.",
            "In order to alleviate this problem, we use compact structures, lattice and forest, in each module insteadof 1-best results.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.10477654927162382,
                0.06475995349920069,
                0.0,
                0.11417972813044201,
                0.04917188864698301,
                0.048064285053167476,
                0.0
            ],
            [
                0.10477654927162382,
                1.0,
                0.06960719161947129,
                0.0,
                0.03407492410719467,
                0.052852370800175096,
                0.0,
                0.0
            ],
            [
                0.06475995349920069,
                0.06960719161947129,
                1.0,
                0.0,
                0.057853263790342946,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.12884212387253305,
                0.05059342988670058,
                0.0
            ],
            [
                0.11417972813044201,
                0.03407492410719467,
                0.057853263790342946,
                0.0,
                1.0,
                0.0,
                0.14354040450072186,
                0.0
            ],
            [
                0.04917188864698301,
                0.052852370800175096,
                0.0,
                0.12884212387253305,
                0.0,
                1.0,
                0.17864338991728462,
                0.0
            ],
            [
                0.048064285053167476,
                0.0,
                0.0,
                0.05059342988670058,
                0.14354040450072186,
                0.17864338991728462,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "E12-1047": {
        "input_sentences": [
            "Instead, we introduce a technique which removes this length restriction, while maintaining a respectable accuracy.",
            "There have been some results on an a manner that minimizes parsing complexity, but the present work shows that parsing long sentences with such an optimally binarized grammar remains infeasible.",
            "Efficient parsing with Linear Context-Free Rewriting Systems",
            "Abstract",
            "The resulting parser has been applied to a discontinuous treebank with favorable results.",
            "Previous work on treebank parsing with discontinuous constituents using Linear Rewriting systems has been limited to sentences of up to 30 words, for reasons of computational complexity.",
            "Linear Context-Free Rewriting Systems"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                1.0,
                0.12501454347317423,
                0.0,
                0.0727889899304163,
                0.21802615859352312,
                0.0
            ],
            [
                0.0,
                0.12501454347317423,
                1.0,
                0.0,
                0.0,
                0.2619231234634759,
                0.8109710326710888
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0727889899304163,
                0.0,
                0.0,
                1.0,
                0.1525032133594692,
                0.0
            ],
            [
                0.0,
                0.21802615859352312,
                0.2619231234634759,
                0.0,
                0.1525032133594692,
                1.0,
                0.24223102266746363
            ],
            [
                0.0,
                0.0,
                0.8109710326710888,
                0.0,
                0.0,
                0.24223102266746363,
                1.0
            ]
        ]
    },
    "P05-1039": {
        "input_sentences": [
            "In addition to the high accuracy of the model, the use of smoothing in an unlexicalized parser allows us to better examine the interplay between smoothing and parsing results.",
            "What To Do When Lexicalization Fails: Parsing German With Suffix Analysis And Smoothing",
            "In this paper, we present an unlexicalized parser for German which employs smoothing and suffix analysis to achieve labelled bracket of 76.2, higher than previously reported results on the NEGRA corpus.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.17929008377668199,
                0.1841865488459004,
                0.0
            ],
            [
                0.17929008377668199,
                1.0,
                0.25568845451102185,
                0.0
            ],
            [
                0.1841865488459004,
                0.25568845451102185,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "A00-2005": {
        "input_sentences": [
            "Bagging And Boosting A Treebank Parser",
            "Error analysis of the result of the boosting technique reveals some inconsistent annotations in the Penn Treebank, suggesting a semi-automatic method for finding inconsistent treebank annotations.",
            "Experiments using these techniques with a trainable statistical parser are described.",
            "Bagging and boosting, two effective machine learning techniques, are applied to natural language parsing.",
            "The best resulting system provides roughly as large of a gain in F-measure as doubling the corpus size.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.24519658672093742,
                0.16895096685987407,
                0.24537991376743748,
                0.0,
                0.0
            ],
            [
                0.24519658672093742,
                1.0,
                0.0,
                0.034268493532312705,
                0.0,
                0.0
            ],
            [
                0.16895096685987407,
                0.0,
                1.0,
                0.08986612269954042,
                0.0,
                0.0
            ],
            [
                0.24537991376743748,
                0.034268493532312705,
                0.08986612269954042,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "D07-1091": {
        "input_sentences": [
            "We present an extension of phrase-based statistical machine translation models that enables the straight-forward integration of additional annotation at the word-level ?may it be linguistic markup or automatically generated word classes.",
            "Factored Translation Models",
            "In a num ber of experiments we show that factoredtranslation models lead to better translation performance, both in terms of auto matic scores, as well as more grammatical coherence.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.12663001672534585,
                0.04589664083340155,
                0.0
            ],
            [
                0.12663001672534585,
                1.0,
                0.1627318523151344,
                0.0
            ],
            [
                0.04589664083340155,
                0.1627318523151344,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "E06-1010": {
        "input_sentences": [
            "In particular, we define a new measure the non-projectivity in an acyclic dependency graph obeying the single-head constraint.",
            "We investigate a series of graph-theoretic constraints on non-projective dependency and their effect on i.e. whether they allow naturally occurring syntactic constructions to be adequately and i.e. whether they reduce the search space for the parser.",
            "The constraints are evaluated experimentally using data from the Prague Dependency Treebank and the Danish Dependency Treebank.",
            "The results indicate that, whereas complete linguistic coverage in principle requires unrestricted non-projective dependency graphs, limiting the degree of non-projectivity to at most 2 can reduce average running time from quadratic to linear, while excluding less than 0.5% of the dependency graphs found in the two treebanks.",
            "This is a substantial improvement over the commonly used projective approximation (degree 0), which excludes 15\u201325% of the graphs.",
            "Abstract",
            "Constraints On Non-Projective Dependency Parsing"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.102484553057344,
                0.05129100981074695,
                0.12498347321662312,
                0.0,
                0.0,
                0.1262625585338991
            ],
            [
                0.102484553057344,
                1.0,
                0.07963776422979703,
                0.12353594111367149,
                0.030435994975001514,
                0.0,
                0.24357229018595836
            ],
            [
                0.05129100981074695,
                0.07963776422979703,
                1.0,
                0.06976879402634241,
                0.0,
                0.0,
                0.19891845469741057
            ],
            [
                0.12498347321662312,
                0.12353594111367149,
                0.06976879402634241,
                1.0,
                0.16026068232914603,
                0.0,
                0.22033921561666306
            ],
            [
                0.0,
                0.030435994975001514,
                0.0,
                0.16026068232914603,
                1.0,
                0.0,
                0.07602274054474525
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.1262625585338991,
                0.24357229018595836,
                0.19891845469741057,
                0.22033921561666306,
                0.07602274054474525,
                0.0,
                1.0
            ]
        ]
    },
    "W12-3117": {
        "input_sentences": [
            "In this paper, we focus on a subset of our feature set that we consider to be relatively novel: features based on a topic model built using the Latent Dirichlet Allocation approach, and features based on source and target language syntax extracted using part-of-speech (POS) taggers and parsers.",
            "We evaluate nine feature combinations using four classification-based and four regression-based machine learning techniques.",
            "DCU-Symantec Submission for the WMT 2012 Quality Estimation Task",
            "Two sets features are proposed: one i.e. respecting the data limitation suggested by the organisers, and one i.e. using data or tools trained on data that was not provided by the workshop organisers.",
            "This paper describes the features and the machine learning methods used by Dublin City (DCU) and the WMT 2012 quality estimation task.",
            "Abstract",
            "In total, more than 300 features were extracted and used to train classifiers in order to predict the translation quality of unseen data."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.2557058695268642,
                0.0,
                0.07272416348566986,
                0.0802739372163283,
                0.0,
                0.0807645462152195
            ],
            [
                0.2557058695268642,
                1.0,
                0.0,
                0.03495679968365924,
                0.12880732829201122,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.4862784798342898,
                0.0,
                0.06237700103028172
            ],
            [
                0.07272416348566986,
                0.03495679968365924,
                0.0,
                1.0,
                0.025433517597516324,
                0.0,
                0.16497880754310057
            ],
            [
                0.0802739372163283,
                0.12880732829201122,
                0.4862784798342898,
                0.025433517597516324,
                1.0,
                0.0,
                0.14268497348725223
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0807645462152195,
                0.0,
                0.06237700103028172,
                0.16497880754310057,
                0.14268497348725223,
                0.0,
                1.0
            ]
        ]
    },
    "N01-1023": {
        "input_sentences": [
            "The algorithm takes as input a small corpus (9695 sentences) annotated with parse trees, a dictionary of possible lexicalized structures for each word in the training set and a large pool of unlabeled text.",
            "We propose a novel Co-Training method for statistical parsing.",
            "Applying Co-Training Methods To Statistical Parsing",
            "Using empirical results based on parsing the Wall Street Journal corpus we show that training a statistical parser on the combined labeled and unlabeled data strongly outperforms training only on the labeled data.",
            "The algorithm iteratively labels the entire data set with parse trees.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.03953421072961048,
                0.045111716240822254,
                0.10328206497924951,
                0.24868667338512895,
                0.0
            ],
            [
                0.03953421072961048,
                1.0,
                0.34692615700469626,
                0.17309329184377167,
                0.0,
                0.0
            ],
            [
                0.045111716240822254,
                0.34692615700469626,
                1.0,
                0.1975133769142783,
                0.0,
                0.0
            ],
            [
                0.10328206497924951,
                0.17309329184377167,
                0.1975133769142783,
                1.0,
                0.11525383770882917,
                0.0
            ],
            [
                0.24868667338512895,
                0.0,
                0.0,
                0.11525383770882917,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "W09-1207": {
        "input_sentences": [
            "Multilingual Dependency-based Syntactic and Semantic Parsing",
            "2000.",
            "In Jason Eisner.",
            "2008.",
            "dependency parser.",
            "In in Probabilistic",
            "In EMNLP/CoNLL- Chang and Chih-Jen Lin, 2001. a for support vector Wanxiang Che, Zhenghua Li, Yuxuan Hu, Yongqiang Li, Bing Qin, Ting Liu, and Sheng Li.",
            "Abstract",
            "Bilexical grammars and their cubicparsing algorithms.",
            "A cascaded syntactic and semantic dependency parsing system."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0,
                0.0,
                0.20426973400040402,
                0.0,
                0.0,
                0.0,
                0.0,
                0.6492129958573976
            ],
            [
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.20426973400040402,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.2300858752242662
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.6492129958573976,
                0.0,
                0.0,
                0.0,
                0.2300858752242662,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "N09-1061": {
        "input_sentences": [
            "The parsing complexity of an is exponential in both the of a production, defined as the number of nonterminals on its right-hand side, and a measure for the discontinuity of a phrase, In this paper, we present an algorithm that transforms an LCFRS into a strongly equivalent form in which productions have rank at most and has minimal fan-out.",
            "Linear Context-free Rewriting Systems (LCFRS) is an expressive grammar formalism with applications in syntax-based machine translation.",
            "Our results generalize previous work on Synchronous Context-Free Grammar, and are particularly relevant for machine translation from or to languages that require syntactic analyses with discontinuous constituents.",
            "Optimal Reduction of Rule Length in Linear Context-Free Rewriting Systems",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.04139724142839572,
                0.0,
                0.0,
                0.0
            ],
            [
                0.04139724142839572,
                1.0,
                0.2213958601220332,
                0.3367773551240035,
                0.0
            ],
            [
                0.0,
                0.2213958601220332,
                1.0,
                0.08609064791129394,
                0.0
            ],
            [
                0.0,
                0.3367773551240035,
                0.08609064791129394,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "E09-1055": {
        "input_sentences": [
            "Treebank Grammar Techniques for Non-Projective Dependency Parsing",
            "In this paper, we provide two key tools for this approach.",
            "For efficient parsing, the extracted grammars need to be transformed in order to minimize the number of nonterminal symbols per production.",
            "Abstract",
            "Our second contribution is an algorithm that computes this transformation for a large, empirically relevant class of grammars.",
            "We propose to attack this problem using chart-parsing algorithms developed for mildly contextsensitive grammar formalisms.",
            "An open problem in dependency parsing is the accurate and efficient treatment of non-projective structures.",
            "First, we show how to reduce nonprojective dependency parsing to parsing with Linear Context-Free Rewriting Systems (LCFRS), by presenting a technique for extracting LCFRS from dependency treebanks."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.04326749888472311,
                0.0,
                0.0,
                0.13973612149588507,
                0.3647005103512609,
                0.1759371170160512
            ],
            [
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.04326749888472311,
                0.0,
                1.0,
                0.0,
                0.06887110984006725,
                0.02938725336276652,
                0.11236681622949254,
                0.04491988007591836
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.06887110984006725,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.13973612149588507,
                0.0,
                0.02938725336276652,
                0.0,
                0.0,
                1.0,
                0.11236681622949254,
                0.04491988007591836
            ],
            [
                0.3647005103512609,
                0.0,
                0.11236681622949254,
                0.0,
                0.0,
                0.11236681622949254,
                1.0,
                0.14147733230359855
            ],
            [
                0.1759371170160512,
                0.0,
                0.04491988007591836,
                0.0,
                0.0,
                0.04491988007591836,
                0.14147733230359855,
                1.0
            ]
        ]
    },
    "W11-2138": {
        "input_sentences": [
            "This method called \u201creverse self-training\u201d improves the decoder\u2019s ability to produce grammatically correct translations into languages with morphology richer than the source language esp. in small-data setting.",
            "We use target-side monolingual data to extend the vocabulary of the translation model in statistical machine translation.",
            "We empirically evaluate the gains for several pairs of European languages and discuss some approaches of the underlying back-off techniques needed to translate unseen forms of known words.",
            "Improving Translation Model by Monolingual Data",
            "Abstract",
            "We also provide a description of the systems we"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.03292816764221489,
                0.037837176350990764,
                0.057098837973667944,
                0.0,
                0.0
            ],
            [
                0.03292816764221489,
                1.0,
                0.0,
                0.5226601274035401,
                0.0,
                0.0
            ],
            [
                0.037837176350990764,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.057098837973667944,
                0.5226601274035401,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "D12-1127": {
        "input_sentences": [
            "Across eight languages for which we have labeled data to evaluate results, we achieve accuracy that significantly exceeds best unsupervised and parallel text methods.",
            "Wiki-ly Supervised Part-of-Speech Tagging",
            "However, parallel text is not always available and techniques for using it require multiple complex algorithmic steps.",
            "In this paper we show that we can build POS-taggers exceeding state-of-the-art bilingual methods by using simple hidden Markov models and a freely available and naturally growing resource, the Wiktionary.",
            "Use of parallel text between resource-rich and resource-poor languages is one source of weak supervision that significantly improves accuracy.",
            "Despite significant recent work, purely unsupervised techniques for part-of-speech (POS) tagging have not achieved useful accuracies required by many language processing tasks.",
            "Abstract",
            "We achieve highest accuracy reported for several languages and show that our approach yields better out-of-domain taggers than those trained using fully supervised Penn"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.1121921071112247,
                0.05009202240207654,
                0.23839276674527995,
                0.05401235067445396,
                0.0,
                0.14873080551465812
            ],
            [
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.17599399827275003,
                0.0,
                0.09734336694632958
            ],
            [
                0.1121921071112247,
                0.0,
                1.0,
                0.10218403657558967,
                0.10434063435502434,
                0.06315458426570209,
                0.0,
                0.052021442357392166
            ],
            [
                0.05009202240207654,
                0.0,
                0.10218403657558967,
                1.0,
                0.09317292505037257,
                0.04199331357036109,
                0.0,
                0.08104408679335676
            ],
            [
                0.23839276674527995,
                0.0,
                0.10434063435502434,
                0.09317292505037257,
                1.0,
                0.0,
                0.0,
                0.0827545251697618
            ],
            [
                0.05401235067445396,
                0.17599399827275003,
                0.06315458426570209,
                0.04199331357036109,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.14873080551465812,
                0.09734336694632958,
                0.052021442357392166,
                0.08104408679335676,
                0.0827545251697618,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "W11-2133": {
        "input_sentences": [
            "Bilingual Latent Semantic Models",
            "This work presents a simplified approach to bilingual topic modeling for language model adaptation by combining text in the source and target language into very short documents and performing Probabilistic Latent Semantic Analysis (PLSA) during model training.",
            "Our topic modeling approach is simpler to construct than its counterparts.",
            "During inference, documents containing only the source language can be used to infer a full topic-word distribution on all words in the target language\u2019s vocabulary, from which we perform Minimum Discrimination Information (MDI) adaptation on a background language model (LM).",
            "Abstract",
            "We apply our approach on the English-French IWSLT 2010 TED Talk exercise, and report a 15% reduction in perplexity and relative BLEU and NIST improvements of 3% and 2.4%, respectively over a baseline only using a 5-gram background LM over the entire translation task.",
            "Topic Adaptation for Lecture Translation through Bilingual Latent Semantic Models"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.2163122070433179,
                0.0,
                0.0,
                0.0,
                0.0,
                0.6789348096346639
            ],
            [
                0.2163122070433179,
                1.0,
                0.1561542436012336,
                0.3652440159532255,
                0.0,
                0.021572401062125202,
                0.23271660346612996
            ],
            [
                0.0,
                0.1561542436012336,
                1.0,
                0.03606315555431805,
                0.0,
                0.04749882677116277,
                0.08124930165289804
            ],
            [
                0.0,
                0.3652440159532255,
                0.03606315555431805,
                1.0,
                0.0,
                0.05649297405274419,
                0.08213446946217975
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.021572401062125202,
                0.04749882677116277,
                0.05649297405274419,
                0.0,
                1.0,
                0.06363856156690602
            ],
            [
                0.6789348096346639,
                0.23271660346612996,
                0.08124930165289804,
                0.08213446946217975,
                0.0,
                0.06363856156690602,
                1.0
            ]
        ]
    },
    "D12-1069": {
        "input_sentences": [
            "On this task, the trained semantic parser achieves 80% precision and 56% recall, despite never having seen an annotated logical form.",
            "Weakly Supervised Training of Semantic Parsers",
            "We demonstrate recovery of this richer structure by extracting logical forms from natural language queries against Freebase.",
            "This semantic parser extracts instances of binary relations with state-of-theart accuracy, while simultaneously recovering much richer semantic structures, such as conjunctions of multiple relations with partially shared arguments.",
            "Our key observation is that multiple forms of weak supervision can be combined to train an accurate semantic parser: supervision a knowledge base, supervision dependencyparsed sentences.",
            "We apply our approach to train a semantic parser that uses 77 relations from Freebase in its knowledge representation.",
            "We present a method for training a semantic parser using only a knowledge base and an unlabeled text corpus, without any individually annotated sentences.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.034878906853246454,
                0.06227075616125336,
                0.052539448240923006,
                0.035420931779491495,
                0.05477883691435853,
                0.10658467759327597,
                0.0
            ],
            [
                0.034878906853246454,
                1.0,
                0.0,
                0.05836313171701002,
                0.028372685232761752,
                0.04387865081764366,
                0.14507899673589514,
                0.0
            ],
            [
                0.06227075616125336,
                0.0,
                1.0,
                0.05209905745109052,
                0.050654929387640844,
                0.07833837159079275,
                0.0,
                0.0
            ],
            [
                0.052539448240923006,
                0.05836313171701002,
                0.05209905745109052,
                1.0,
                0.07959668160203912,
                0.18009806961717942,
                0.05731767584550558,
                0.0
            ],
            [
                0.035420931779491495,
                0.028372685232761752,
                0.050654929387640844,
                0.07959668160203912,
                1.0,
                0.14124948508242505,
                0.17055002943874842,
                0.0
            ],
            [
                0.05477883691435853,
                0.04387865081764366,
                0.07833837159079275,
                0.18009806961717942,
                0.14124948508242505,
                1.0,
                0.11510576125132296,
                0.0
            ],
            [
                0.10658467759327597,
                0.14507899673589514,
                0.0,
                0.05731767584550558,
                0.17055002943874842,
                0.11510576125132296,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P08-1028": {
        "input_sentences": [
            "This paper proposes a framework for representing the meaning of phrases and sentences in vector space.",
            "Experimental results demonstrate that the multiplicative models are superior to the additive alternatives when compared against human judgments.",
            "Under this framework, we introduce a wide range of composition models which we evaluate empirically on a sentence similarity task.",
            "Central to our approach is vector composition which we operationalize in terms of additive and multiplicative functions.",
            "Abstract",
            "Vector-based Models of Semantic Composition"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.07588958357228515,
                0.06211777527427815,
                0.0,
                0.09053857780810368
            ],
            [
                0.0,
                1.0,
                0.04927434272346614,
                0.15876756217170362,
                0.0,
                0.08247283944278769
            ],
            [
                0.07588958357228515,
                0.04927434272346614,
                1.0,
                0.05714845012173264,
                0.0,
                0.1665912655471916
            ],
            [
                0.06211777527427815,
                0.15876756217170362,
                0.05714845012173264,
                1.0,
                0.0,
                0.1913042240967014
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.09053857780810368,
                0.08247283944278769,
                0.1665912655471916,
                0.1913042240967014,
                0.0,
                1.0
            ]
        ]
    },
    "W05-0636": {
        "input_sentences": [
            "Joint Parsing And Semantic Role Labeling",
            "A striking feature of human syntactic prois that it is that is, it seems to take into account semantic information from the discourse context and world knowledge.",
            "To do this, we jointly perform parsing and semantic role labeling, using a probabilistic SRL system to rerank the results of a probabilistic parser.",
            "In this paper, we attempt to use this insight to bridge the gap between SRL results from gold parses and from automatically-generated parses.",
            "Our current results are negative, because a locallytrained SRL model can return inaccurate probability estimates.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.07565291959538456,
                0.3783098344643069,
                0.0,
                0.0,
                0.0
            ],
            [
                0.07565291959538456,
                1.0,
                0.040084083614452,
                0.0,
                0.0,
                0.0
            ],
            [
                0.3783098344643069,
                0.040084083614452,
                1.0,
                0.0727007296634865,
                0.09074854881118093,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0727007296634865,
                1.0,
                0.08572224173087356,
                0.0
            ],
            [
                0.0,
                0.0,
                0.09074854881118093,
                0.08572224173087356,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "A00-2018": {
        "input_sentences": [
            "The major technical innovation is the use of a &quot;maximum-entropy-inspired&quot; model for conditioning and smoothing that let us successfully to test and combine many different conditioning events.",
            "We also present some partial results showing the effects of different conditioning information, including a surprising 2% improvement due to guessing the lexical head's pre-terminal before guessing the lexical head.",
            "A Maximum-Entropy-Inspired Parser *",
            "This represents a 13% decrease in error rate over the best single-parser results on this corpus [9].",
            "Abstract",
            "We present a new parser for parsing down to Penn tree-bank style parse trees that achieves 90.1% average precision/recall for sentences of 40 and less, and for of length 100 and less when trained and tested on the previously established [5,9,10,15,17] &quot;standard&quot; sections of the Wall Street Journal treebank."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.09491164494923993,
                0.2923665094141451,
                0.0,
                0.0,
                0.10587994618584398
            ],
            [
                0.09491164494923993,
                1.0,
                0.0,
                0.045667976875145996,
                0.0,
                0.023748647662372096
            ],
            [
                0.2923665094141451,
                0.0,
                1.0,
                0.10027237144034327,
                0.0,
                0.05214448684945389
            ],
            [
                0.0,
                0.045667976875145996,
                0.10027237144034327,
                1.0,
                0.0,
                0.027235078959552114
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.10587994618584398,
                0.023748647662372096,
                0.05214448684945389,
                0.027235078959552114,
                0.0,
                1.0
            ]
        ]
    },
    "N06-1039": {
        "input_sentences": [
            "surface text patterns for a question answering system. of the 40th Annual Meeting of the As",
            "Preemptive Information Extraction Using Unrestricted Relation Discovery",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "W06-2920": {
        "input_sentences": [
            "We also give an overview of the parsing approaches that participants took and the results that they achieved.",
            "In this paper, we describe how treebanks for 13 languages were converted into the same dependency format and how parsing performance was measured.",
            "Finally, we try to draw general conclusions about multi-lingual parsing: What makes a particular language, treebank or annotation scheme easier or harder to parse and which phenomena are challenging for any dependency parser?",
            "His work was made possible by the MITRE Cor",
            "The tenth CoNLL (CoNLL-X) saw a shared task on Multilingual Dependency Parsing.",
            "Each year the Conference on Computational Natural Language Learning features a shared task, in which participants train and test their systems on exactly the same data sets, in order to better compare systems.",
            "Abstract",
            "Acknowledgement Many thanks to Amit Dubey and Yuval Krymolowski, the other two organizers of the shared task, for discussions, converting treebanks, writing and helping with the also to Alexander Yeh for additional help with the paper reviews.",
            "CoNLL-X Shared Task On Multilingual Dependency Parsing"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.04764873163002084,
                0.030890765201905864,
                0.0,
                0.05092076200497288,
                0.06442839585029339,
                0.0,
                0.0,
                0.07836886788727618
            ],
            [
                0.04764873163002084,
                1.0,
                0.05991328307306114,
                0.0,
                0.09876187942769672,
                0.0,
                0.0,
                0.11669111607428324,
                0.15199805298303262
            ],
            [
                0.030890765201905864,
                0.05991328307306114,
                1.0,
                0.0,
                0.06402751812973247,
                0.03591088317420022,
                0.0,
                0.0,
                0.09854063277704198
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.05092076200497288,
                0.09876187942769672,
                0.06402751812973247,
                0.0,
                1.0,
                0.0698713718565137,
                0.0,
                0.07359669365621221,
                0.8029870165477709
            ],
            [
                0.06442839585029339,
                0.0,
                0.03591088317420022,
                0.0,
                0.0698713718565137,
                1.0,
                0.0,
                0.04375794817131517,
                0.1075345319771749
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.11669111607428324,
                0.0,
                0.0,
                0.07359669365621221,
                0.04375794817131517,
                0.0,
                1.0,
                0.11326793502266844
            ],
            [
                0.07836886788727618,
                0.15199805298303262,
                0.09854063277704198,
                0.0,
                0.8029870165477709,
                0.1075345319771749,
                0.0,
                0.11326793502266844,
                1.0
            ]
        ]
    },
    "P05-1065": {
        "input_sentences": [
            "Existing measures of reading level are not well suited to this task, but previous work and our own pilot experiments have shown the benefit of using statistical language models.",
            "Reading proficiency is a fundamental component of language competency.",
            "In this paper, we also use support vector machines to combine features from traditional reading level measures, statistical language models, and other language processing tools to produce a better method of assessing reading level.",
            "However, finding topical texts at an appropriate reading level for foreign and second language learners is a challenge for teachers.",
            "Abstract",
            "Reading Level Assessment Using Support Vector Machines And Statistical Language Models",
            "This task can be addressed with natural language processing technology to assess reading level."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0622246902262749,
                0.221692151006504,
                0.06919897884743072,
                0.0,
                0.30231413411703223,
                0.16832769575642767
            ],
            [
                0.0622246902262749,
                1.0,
                0.1024915497551787,
                0.06852861613531792,
                0.0,
                0.09116075750908677,
                0.08645918070734643
            ],
            [
                0.221692151006504,
                0.1024915497551787,
                1.0,
                0.11397904204518185,
                0.0,
                0.46549599768529965,
                0.21052885402508212
            ],
            [
                0.06919897884743072,
                0.06852861613531792,
                0.11397904204518185,
                1.0,
                0.0,
                0.10137826813838202,
                0.0961497276270494
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.30231413411703223,
                0.09116075750908677,
                0.46549599768529965,
                0.10137826813838202,
                0.0,
                1.0,
                0.12790396916036495
            ],
            [
                0.16832769575642767,
                0.08645918070734643,
                0.21052885402508212,
                0.0961497276270494,
                0.0,
                0.12790396916036495,
                1.0
            ]
        ]
    },
    "C04-1074": {
        "input_sentences": [
            "A commonformat for pronoun resolution algorithms with sev eral open parameters is proposed, and the parameter settings optimal on the evaluation data are given.",
            "Optimizing Algorithms For Pronoun Resolution",
            "It describes and discusses factorsand strategies of factor interaction used in the algo rithms.",
            "The factors used in the algorithms and the algorithms themselves are evaluated on a Germancorpus annotated with syntactic and coreference in formation (Negra) (Skut et al, 1997).",
            "The paper aims at a deeper understanding of sev eral well-known algorithms and proposes ways to optimize them.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.28611497988431295,
                0.0,
                0.051945440948322166,
                0.15088669328836155,
                0.0
            ],
            [
                0.28611497988431295,
                1.0,
                0.0,
                0.11423234007106052,
                0.06882559164676821,
                0.0
            ],
            [
                0.0,
                0.0,
                1.0,
                0.06085096225481543,
                0.0,
                0.0
            ],
            [
                0.051945440948322166,
                0.11423234007106052,
                0.06085096225481543,
                1.0,
                0.0602420050389642,
                0.0
            ],
            [
                0.15088669328836155,
                0.06882559164676821,
                0.0,
                0.0602420050389642,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "I05-6010": {
        "input_sentences": [
            "The information gained from cor pus research and the analyses that are proposed are realized in the framework of SILVA, a parsing and extraction tool for German text corpora.",
            "This article is devoted to the problem of quantifying noun groups in German.After a thorough description of the phenom ena, the results of corpus-based in vestigations are described.",
            "We argue that a more sophisticatedand fine-grained annotation in the tree bank would have very positve effects onstochastic parsers trained on the tree bank and on grammars induced from the treebank, and it would make the treebank more valuable as a source ofdata for theoretical linguistic investigations.",
            "Abstract",
            "Moreover,some examples are given that under line the necessity of integrating somekind of information other than gram mar sensu stricto into the treebank.",
            "Some remarks on the Annotation of Quantifying Noun Groups in Treebanks"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.04478733333808305,
                0.0,
                0.0,
                0.05096385333466977,
                0.0
            ],
            [
                0.04478733333808305,
                1.0,
                0.0,
                0.0,
                0.0,
                0.24304433017845503
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.07368512903032723,
                0.05730294295912977
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.05096385333466977,
                0.0,
                0.07368512903032723,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.24304433017845503,
                0.05730294295912977,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "W04-0305": {
        "input_sentences": [
            "Experiments with an incremental statistical parser show that performance is severely degraded when the search for the most probable parse is pruned to only the most probable analysis after each prefix.",
            "One method which has been extensively used to address the difficulty of deterministic parsing is lookahead, where information about a bounded number of subsequent words is used to decide which analyses to pursue.",
            "We simulate the effects of lookahead by summing probabilities over possible parses for the lookahead words and using this sum to choose which parse to pursue.",
            "We find that a large improvement is achieved with one word lookahead, but that more lookahead results in relatively small additional improvements.",
            "To support incremental interpretation, any model of human sentence processing must not only process the sentence incrementally, it must to some degree restrict the number of analyses which it produces for any sentence prefix.",
            "Lookahead In Deterministic Left-Corner Parsing",
            "This suggests that one word lookahead is sufficient, but that other modifications to our left-corner parsing model could make deterministic parsing more effective.",
            "Abstract",
            "Deterministic parsing takes the extreme position that there can only be one analysis for any sentence prefix."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.052703431583432055,
                0.0,
                0.07537934873748957,
                0.0,
                0.0,
                0.0,
                0.13566487340495403
            ],
            [
                0.0,
                1.0,
                0.1482646753327967,
                0.052809551313124,
                0.0821562041619137,
                0.18220948108590512,
                0.12441807299380131,
                0.0,
                0.08726344605981
            ],
            [
                0.052703431583432055,
                0.1482646753327967,
                1.0,
                0.11970005610921715,
                0.0,
                0.11760316533335397,
                0.05914961724092664,
                0.0,
                0.0
            ],
            [
                0.0,
                0.052809551313124,
                0.11970005610921715,
                1.0,
                0.0,
                0.1310294178321339,
                0.136024675337129,
                0.0,
                0.0
            ],
            [
                0.07537934873748957,
                0.0821562041619137,
                0.0,
                0.0,
                1.0,
                0.0,
                0.051262482165017616,
                0.0,
                0.256327068069446
            ],
            [
                0.0,
                0.18220948108590512,
                0.11760316533335397,
                0.1310294178321339,
                0.0,
                1.0,
                0.5842774817332688,
                0.0,
                0.21651535093427643
            ],
            [
                0.0,
                0.12441807299380131,
                0.05914961724092664,
                0.136024675337129,
                0.051262482165017616,
                0.5842774817332688,
                1.0,
                0.0,
                0.16334764585092973
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.13566487340495403,
                0.08726344605981,
                0.0,
                0.0,
                0.256327068069446,
                0.21651535093427643,
                0.16334764585092973,
                0.0,
                1.0
            ]
        ]
    },
    "D11-1006": {
        "input_sentences": [
            "We first demonstrate that delexicalized parsers can be directly transferred between languages, producing significantly higher accuracies than unsupervised parsers.",
            "Multi-Source Transfer of Delexicalized Dependency Parsers",
            "We then use a constraint driven learning algorithm where constraints are drawn from parallel corpora to project the final parser.",
            "The projected parsers from our system result in state-of-theart performance when compared to previously studied unsupervised and projected parsing systems across eight different languages.",
            "We present a simple method for transferring dependency parsers from source languages with labeled training data to target languages without labeled training data.",
            "Abstract",
            "Unlike previous work on projecting syntactic resources, we show that simple methods for introducing multiple source languages can significantly improve the overall quality of the resulting parsers.",
            "Multi-Source Transfer"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.22700437353621838,
                0.0,
                0.14132012903003177,
                0.10330081403048082,
                0.0,
                0.1408439798515656,
                0.0
            ],
            [
                0.22700437353621838,
                1.0,
                0.0,
                0.0427201821099227,
                0.17016928708362053,
                0.0,
                0.09691523025959263,
                0.7157790301227551
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.14132012903003177,
                0.0427201821099227,
                0.0,
                1.0,
                0.06416319246089684,
                0.0,
                0.046348371507212036,
                0.0
            ],
            [
                0.10330081403048082,
                0.17016928708362053,
                0.0,
                0.06416319246089684,
                1.0,
                0.0,
                0.12705360935929172,
                0.06733929748781982
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.1408439798515656,
                0.09691523025959263,
                0.0,
                0.046348371507212036,
                0.12705360935929172,
                0.0,
                1.0,
                0.07591586614177816
            ],
            [
                0.0,
                0.7157790301227551,
                0.0,
                0.0,
                0.06733929748781982,
                0.0,
                0.07591586614177816,
                1.0
            ]
        ]
    },
    "P03-1013": {
        "input_sentences": [
            "We observe that existing lexicalized parsing models using head-head dependencies, while successful for English, fail to outperform an unlexicalized baseline model for German.",
            "We propose an alternative model that uses sister-head dependencies instead of head-head dependencies.",
            "This indicates that sister-head dependencies are more appropriate for treebanks with very flat structures such as Negra.",
            "We present a probabilistic parsing model for German trained on the Negra treebank.",
            "Probabilistic Parsing For German Using Sister-Head Dependencies",
            "Learning curves show that this effect is not due to lack of training data.",
            "This model outperforms the baseline, achieving a labeled precision and recall of up to 74%.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.3050204505106588,
                0.12218489015733434,
                0.16075978798961865,
                0.4082615448952272,
                0.0,
                0.11128695042394539,
                0.0
            ],
            [
                0.3050204505106588,
                1.0,
                0.29988319703078664,
                0.052159587419998855,
                0.409062571132213,
                0.0,
                0.04734260216917138,
                0.0
            ],
            [
                0.12218489015733434,
                0.29988319703078664,
                1.0,
                0.10950250885650678,
                0.25752812935430786,
                0.0,
                0.0,
                0.0
            ],
            [
                0.16075978798961865,
                0.052159587419998855,
                0.10950250885650678,
                1.0,
                0.3718185312635713,
                0.0,
                0.062350710967762096,
                0.0
            ],
            [
                0.4082615448952272,
                0.409062571132213,
                0.25752812935430786,
                0.3718185312635713,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.11128695042394539,
                0.04734260216917138,
                0.0,
                0.062350710967762096,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "W08-1007": {
        "input_sentences": [
            "Moreover, the parser is able to recover both constituent labels and grammatical functions with an F-Score over 75% for T\u00a8uBa-D/Z and over 65% for TIGER.",
            "Constituency representations are automatically transformed into dependency representations with complex arc labels, which makes it possible to recover the constituent structure with both constituent labels and grammatical functions.",
            "We report a labeled attachment score close to 90% for dependency versions of the TIGER and T\u00a8uBa- D/Z treebanks.",
            "Abstract",
            "We present a dependency-driven parser that parses both dependency structures and constituent structures.",
            "A Dependency-Driven Parser for German Dependency and Constituency Representations"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.35249632719959545,
                0.22387932532515836,
                0.0,
                0.10831275381291736,
                0.07352133607704489
            ],
            [
                0.35249632719959545,
                1.0,
                0.027614342441923078,
                0.0,
                0.13280195503447123,
                0.29509569118635515
            ],
            [
                0.22387932532515836,
                0.027614342441923078,
                1.0,
                0.0,
                0.07649104698908321,
                0.10384232280314777
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.10831275381291736,
                0.13280195503447123,
                0.07649104698908321,
                0.0,
                1.0,
                0.3844269818890756
            ],
            [
                0.07352133607704489,
                0.29509569118635515,
                0.10384232280314777,
                0.0,
                0.3844269818890756,
                1.0
            ]
        ]
    },
    "P11-1086": {
        "input_sentences": [
            "Large-scale experiments on a state-of-the-art tree-to-string translation system show that our approach leads to a slimmer model, a faster decoder, yet the same translation quality (measured using B ) as composed rules.",
            "Rule Markov Models for Fast Tree-to-String Translation",
            "Though this practice improves translation by weakening independence assumptions in the translation model, it nevertheless results in huge, redundant grammars, making both trainand decoding Here, we take the approach, where we only use minrules that cannot be formed out other rules), and instead rely on a model the derivation history to capture dependencies between minimal rules.",
            "Abstract",
            "Most statistical machine translation systems on rules that can be formed out of smaller rules in the grammar)."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.1962964218962779,
                0.18715243666164455,
                0.0,
                0.13210411877103462
            ],
            [
                0.1962964218962779,
                1.0,
                0.05063591513359127,
                0.0,
                0.04805860017349097
            ],
            [
                0.18715243666164455,
                0.05063591513359127,
                1.0,
                0.0,
                0.2090169704736544
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.13210411877103462,
                0.04805860017349097,
                0.2090169704736544,
                0.0,
                1.0
            ]
        ]
    },
    "N06-2033": {
        "input_sentences": [
            "We apply this idea to dependency and constituent parsing, generating results that surpass state-of-theart accuracy levels for individual parsers.",
            "Parser Combination By Reparsing",
            "We present a novel parser combination scheme that works by reparsing input sentences once they have already been parsed by several different parsers.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.05200909993820064,
                0.0
            ],
            [
                0.0,
                1.0,
                0.421697442660751,
                0.0
            ],
            [
                0.05200909993820064,
                0.421697442660751,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "W10-2924": {
        "input_sentences": [
            "Experimental results show improved results for our joint extraction method compared to a pipelined approach.",
            "Joint Entity and Relation Extraction Using Card-Pyramid Parsing",
            "Both entity and relation extraction can benefit from being performed jointly, allowing each task to correct the errors of the other.",
            "Abstract",
            "We present a new method for joint entity and relation extraction using a graph we call a \u201ccard-pyramid.\u201d This graph compactly encodes all possible entities and relations in a sentence, reducing the task of their joint extraction to jointly labeling its nodes.",
            "We give an efficient labeling algorithm that is analogous to parsing using dynamic programming."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.12388408452469882,
                0.0392495227366451,
                0.0,
                0.1508898425400733,
                0.0
            ],
            [
                0.12388408452469882,
                1.0,
                0.22878237316672978,
                0.0,
                0.4496818676792591,
                0.21294910693470254
            ],
            [
                0.0392495227366451,
                0.22878237316672978,
                1.0,
                0.0,
                0.2276446623217787,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.1508898425400733,
                0.4496818676792591,
                0.2276446623217787,
                0.0,
                1.0,
                0.09233785020701715
            ],
            [
                0.0,
                0.21294910693470254,
                0.0,
                0.0,
                0.09233785020701715,
                1.0
            ]
        ]
    },
    "P11-1141": {
        "input_sentences": [
            "2007.",
            "annotation of a large corpus.",
            "Chinese segmentawith a word-based perceptron algorithm.",
            "2003.",
            "Chinese word segmentation as tagging.",
            "Linguistics and Language 8(1):29\u201348.",
            "Lan- 11(2):207\u2013238.",
            "Abstract",
            "Parsing the Internal Structure of Words: A New Paradigm for Chinese Word Segmentation",
            "Yue Zhang and Stephen Clark.",
            "In Pro",
            "Nianwen Xue."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.2984039655299266,
                0.0,
                0.0,
                0.0,
                0.18057147447676078,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.2984039655299266,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.39563845723309354,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.18057147447676078,
                0.0,
                0.39563845723309354,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P12-1051": {
        "input_sentences": [
            "Semantic Parsing with Bayesian Tree Transducers",
            "However, while tree transformations are central to several state-of-the-art approaches, little use has been made of the rich literature on tree automata.",
            "Many semantic parsing models use tree transformations to map between natural language and meaning representation.",
            "This paper makes the connection concrete with a tree transducer based semantic parsing model and suggests that other models can be interpreted in a similar framework, increasing the generality of their contributions.",
            "Abstract",
            "In particular, this paper further introduces a variational Bayesian inference algorithm that is applicable to a wide class of tree transducers, producing state-of-the-art semantic parsing results while remaining applicable to any domain employing probabilistic tree transducers."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.11064477150438193,
                0.2249726175586886,
                0.1624521897473319,
                0.0,
                0.43464766803989113
            ],
            [
                0.11064477150438193,
                1.0,
                0.21204318984740228,
                0.04298808623367017,
                0.0,
                0.1562010489902421
            ],
            [
                0.2249726175586886,
                0.21204318984740228,
                1.0,
                0.14822576276796848,
                0.0,
                0.0885314027338105
            ],
            [
                0.1624521897473319,
                0.04298808623367017,
                0.14822576276796848,
                1.0,
                0.0,
                0.09890914402958462
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.43464766803989113,
                0.1562010489902421,
                0.0885314027338105,
                0.09890914402958462,
                0.0,
                1.0
            ]
        ]
    },
    "E12-1083": {
        "input_sentences": [
            "We study multitask learning techniques that exploit commonalities between tasks by mixtures of translation models or by multi-task metaparameter tuning.",
            "We find small but significant gains over task-specific training by techniques that model commonalities through shared parameters.",
            "In this paper we analyze patents along the orthogonal dimensions of topic and textual structure.",
            "A by-product of our work is a parallel patent corpus of 23 million German-English sentence pairs.",
            "We view different patent classes and different patent text sections such as title, abstract, and claims, as separate translation tasks, and investigate the influence of such tasks on machine translation performance.",
            "Structural and Topical Dimensions in Multi-Task Patent Translation",
            "Patent translation is a complex problem due to the highly specialized technical vocabulary and the peculiar textual structure of patent documents.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.17860485219305589,
                0.0,
                0.0,
                0.13833197386044702,
                0.21840121435715656,
                0.034738942161562855,
                0.0
            ],
            [
                0.17860485219305589,
                1.0,
                0.0,
                0.0,
                0.0,
                0.07630725086791272,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.12111708590308116,
                0.15596000601430007,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.05348671194312779,
                0.05730765165229773,
                0.07379389645743116,
                0.0
            ],
            [
                0.13833197386044702,
                0.0,
                0.0,
                0.05348671194312779,
                1.0,
                0.1586057687388173,
                0.1531750648265433,
                0.17979234701731572
            ],
            [
                0.21840121435715656,
                0.07630725086791272,
                0.12111708590308116,
                0.05730765165229773,
                0.1586057687388173,
                1.0,
                0.16411745904723757,
                0.0
            ],
            [
                0.034738942161562855,
                0.0,
                0.15596000601430007,
                0.07379389645743116,
                0.1531750648265433,
                0.16411745904723757,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.17979234701731572,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P07-1108": {
        "input_sentences": [
            "Pivot Language Approach for Phrase-Based Statistical Machine Translation",
            "This paper proposes a novel method for phrase-based statistical machine translation by using pivot language.",
            "Using only bilingual corpora, we can build a model for The advantage of this method lies in that we can perform between even if there is no bilingual corpus available for this language pair.",
            "Moreover, with small bilingual corpus available, our method can further improve the translaquality by using the additional bilingual corpora.",
            "Using BLEU as a metric, our pivot language method achieves an absolute improvement of 0.06 (22.13% relative) as compared with the model directly with 5,000 sentence pairs for French-Spanish translation.",
            "To conduct transbetween languages with a small bilingual corpus, we bring in a third which is named the lan- For and there exist bilingual corpora.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.6498636478019028,
                0.051551344701645026,
                0.0,
                0.14086668678521924,
                0.0,
                0.0
            ],
            [
                0.6498636478019028,
                1.0,
                0.12476563003651418,
                0.0945327718706238,
                0.17585700429068854,
                0.0,
                0.0
            ],
            [
                0.051551344701645026,
                0.12476563003651418,
                1.0,
                0.48197892679958304,
                0.1297229761806556,
                0.28434412269465,
                0.0
            ],
            [
                0.0,
                0.0945327718706238,
                0.48197892679958304,
                1.0,
                0.061229568020325184,
                0.3968824529869927,
                0.0
            ],
            [
                0.14086668678521924,
                0.17585700429068854,
                0.1297229761806556,
                0.061229568020325184,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.28434412269465,
                0.3968824529869927,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "W03-1509": {
        "input_sentences": [
            "In this paper, we present a hybrid algorithm which can combine a class-based statistical model with various types of human knowledge very well.",
            "In order to avoid data sparseness problem, we employ a back-off model and YI CI CI LIN a Chinese thesaurus, to smooth the parameters in the model.",
            "Named Entity Recognition is one of the key techniques in the fields of natural language processing, information retrieval, question answering and so on.",
            "Unfortunately, Chinese Named Entity Recognition (NER) is more difficult for the lack of capitalization information and the uncertainty in word segmentation.",
            "The F-measure of person names, location names, and organization names on the newswire test data for the 1999 IEER evaluation in Mandarin is 86.84%, 84.40% and 76.22% respectively.",
            "Abstract",
            "Chinese Named Entity Recognition Combining Statistical Model Wih Human Knowledge"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.07135947315663534,
                0.0,
                0.0,
                0.0,
                0.0,
                0.29450732537649804
            ],
            [
                0.07135947315663534,
                1.0,
                0.0,
                0.037098015096972484,
                0.031013120517974693,
                0.0,
                0.141894506093931
            ],
            [
                0.0,
                0.0,
                1.0,
                0.20088527213385274,
                0.0,
                0.0,
                0.17587815969144008
            ],
            [
                0.0,
                0.037098015096972484,
                0.20088527213385274,
                1.0,
                0.0,
                0.0,
                0.2398825811051145
            ],
            [
                0.0,
                0.031013120517974693,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.29450732537649804,
                0.141894506093931,
                0.17587815969144008,
                0.2398825811051145,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P05-1053": {
        "input_sentences": [
            "This suggests that most of useful information in full parse trees for relation extraction is shallow and can be captured by chunking.",
            "We also demonstrate how semantic information such as WordNet and Name List, can be used in feature-based relation extraction to further improve the performance.",
            "Evaluation on the ACE corpus shows that effective incorporation of diverse features enables our system outperform previously best-reported systems on the 24 ACE relation subtypes and significantly outperforms tree kernel-based systems by over 20 in F-measure on the 5 ACE relation types.",
            "This paper investigates the incorporation of diverse lexical, syntactic and semantic knowledge in feature-based relation extraction using SVM.",
            "Exploring Various Knowledge In Relation Extraction",
            "Extracting semantic relationships between entities is challenging.",
            "Our study illustrates that the base phrase chunking information is very effective for relation extraction and contributes to most of the performance improvement from syntactic aspect while additional information from full parsing gives limited further enhancement.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.1333715905241887,
                0.030407139610294884,
                0.06359552574448078,
                0.11194152654762883,
                0.0,
                0.19830202329854696,
                0.0
            ],
            [
                0.1333715905241887,
                1.0,
                0.05945966277921798,
                0.24880644527048654,
                0.10692327484989803,
                0.08415952793235285,
                0.18941229760181924,
                0.0
            ],
            [
                0.030407139610294884,
                0.05945966277921798,
                1.0,
                0.12963891536350372,
                0.04695325228467944,
                0.0,
                0.04886648426737964,
                0.0
            ],
            [
                0.06359552574448078,
                0.24880644527048654,
                0.12963891536350372,
                1.0,
                0.22033626247104932,
                0.07729434342639083,
                0.09529450552994968,
                0.0
            ],
            [
                0.11194152654762883,
                0.10692327484989803,
                0.04695325228467944,
                0.22033626247104932,
                1.0,
                0.0,
                0.07475895451529736,
                0.0
            ],
            [
                0.0,
                0.08415952793235285,
                0.0,
                0.07729434342639083,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.19830202329854696,
                0.18941229760181924,
                0.04886648426737964,
                0.09529450552994968,
                0.07475895451529736,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "E12-3010": {
        "input_sentences": [
            "Then we add a rule-based preprocessor and a statistical post-editor to the Its-2 translation pipeline.",
            "We use the Europarl corpus to evaluate two MT systems on their performance regarding null subject translation: Its-2, a rule-based system developed at LATL, and a statistical system built using the Moses toolkit.",
            "Improving machine translation of null subjects in Italian and Spanish",
            "In this study we quantify and compare the occurrence of this phenomenon in these two languages.",
            "Next, we evaluate null subjects\u2019 translation into French, a \u201cnon prodrop\u201d language.",
            "Abstract",
            "A second evaluation of the improved Its-2 system shows an average increase of 15.46% in correct pro-drop translations for Italian-French and 12.80% for",
            "Null subjects are non overtly expressed pronouns found in languages such as Italian and Spanish."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.2181783574726478,
                0.06876496230542277,
                0.0,
                0.06293942078944206,
                0.0,
                0.0,
                0.0
            ],
            [
                0.2181783574726478,
                1.0,
                0.08979854096029045,
                0.0,
                0.15398291999224553,
                0.0,
                0.0,
                0.03741723203110001
            ],
            [
                0.06876496230542277,
                0.08979854096029045,
                1.0,
                0.0,
                0.26681878839908746,
                0.0,
                0.06282009167907142,
                0.39365047158282557
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.11488098614209637
            ],
            [
                0.06293942078944206,
                0.15398291999224553,
                0.26681878839908746,
                0.0,
                1.0,
                0.0,
                0.07721738524252585,
                0.2726732116124826
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.06282009167907142,
                0.0,
                0.07721738524252585,
                0.0,
                1.0,
                0.052351717999743946
            ],
            [
                0.0,
                0.03741723203110001,
                0.39365047158282557,
                0.11488098614209637,
                0.2726732116124826,
                0.0,
                0.052351717999743946,
                1.0
            ]
        ]
    },
    "W11-0314": {
        "input_sentences": [
            "ULISSE: an Unsupervised Algorithm for Detecting Reliable Dependency Parses",
            "In this paper we present ULISSE, an unsupervised linguistically\u2013driven algorithm to select reliable parses from the output of a dependency parser.",
            "Abstract",
            "In all cases, ULISSE appears to outperform the baseline algorithms.",
            "Different experiments were devised to show that the algorithm is robust enough to deal with the output of different parsers and with different languages, as well as to be used across different domains."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.5179010824951867,
                0.0,
                0.09057264623870495,
                0.04219919367163024
            ],
            [
                0.5179010824951867,
                1.0,
                0.0,
                0.06030721518669817,
                0.06887603746201743
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.09057264623870495,
                0.06030721518669817,
                0.0,
                1.0,
                0.0
            ],
            [
                0.04219919367163024,
                0.06887603746201743,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "D07-1015": {
        "input_sentences": [
            "To demonstrate an application of the method, we perform experiments which use the algorithm in training both log-linear and max-margin dependency parsers.",
            "This paper provides an algorithmic framework for learning statistical models involv ing directed spanning trees, or equivalently non-projective dependency structures.",
            "Structured Prediction Models via the Matrix-Tree Theorem",
            "The new training methods give improvements in accuracy over perceptron-trained models.",
            "We show how partition functions and marginals for directed spanning trees can be computed by an adaptation of Kirchhoff?s Matrix-Tree Theorem.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.04726152402073329,
                0.0,
                0.06883048177005709,
                0.0,
                0.0
            ],
            [
                0.04726152402073329,
                1.0,
                0.05803438456390597,
                0.04601725000037768,
                0.16350725371004118,
                0.0
            ],
            [
                0.0,
                0.05803438456390597,
                1.0,
                0.08451980192196172,
                0.30031348453597717,
                0.0
            ],
            [
                0.06883048177005709,
                0.04601725000037768,
                0.08451980192196172,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.16350725371004118,
                0.30031348453597717,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P13-1109": {
        "input_sentences": [
            "Out-of-vocabulary (oov) words or phrases still remain a challenge in statistical machine translation especially when a limited amount of parallel text is available for training or when there is a domain shift from training data to test data.",
            "In this paper, we propose a novel approach to finding translations for oov words.",
            "Our method differs from previous approaches by adopting a graph propagation approach that takes into account not only one-step (from oov directly to a source language phrase that has a translation) but multi-step paraphrases from oov source language words to other source language phrases and eventually to target language translations.",
            "Experimental results show that our graph propagation method significantly improves performance over two strong baselines under intrinsic and extrinsic evaluation metrics.",
            "Abstract",
            "We induce a lexicon by constructing a graph on source language monolingual text and employ a graph propagation technique in order to find translations for all the source language phrases.",
            "Graph Propagation for Paraphrasing Out-of-Vocabulary Words in Statistical Machine Translation"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.07699143100647733,
                0.08208822392113525,
                0.0,
                0.0,
                0.06386632992358397,
                0.2921966878345477
            ],
            [
                0.07699143100647733,
                1.0,
                0.16696381525185527,
                0.0,
                0.0,
                0.050893848160870545,
                0.07094755479364064
            ],
            [
                0.08208822392113525,
                0.16696381525185527,
                1.0,
                0.06549493218457127,
                0.0,
                0.46890296171264906,
                0.12074337252373657
            ],
            [
                0.0,
                0.0,
                0.06549493218457127,
                1.0,
                0.0,
                0.08040278761449855,
                0.09912988426080624
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.06386632992358397,
                0.050893848160870545,
                0.46890296171264906,
                0.08040278761449855,
                0.0,
                1.0,
                0.13072437929836148
            ],
            [
                0.2921966878345477,
                0.07094755479364064,
                0.12074337252373657,
                0.09912988426080624,
                0.0,
                0.13072437929836148,
                1.0
            ]
        ]
    },
    "P05-1013": {
        "input_sentences": [
            "In order to realize the full potential of dependency-based syntactic parsing, it is desirable to allow non-projective dependency structures.",
            "Experiments using data from the Prague Dependency Treebank show that the combined system can handle nonprojective constructions with a precision sufficient to yield a significant improvement in overall parsing accuracy.",
            "This leads to the best reported performance for robust non-projective parsing of Czech.",
            "Pseudo-Projective Dependency Parsing",
            "Abstract",
            "We show how a datadriven deterministic dependency parser, in itself restricted to projective structures, can be combined with graph transformation techniques to produce non-projective structures."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.08144321369095367,
                0.13780197977899936,
                0.30648150243898925,
                0.0,
                0.27354689199844323
            ],
            [
                0.08144321369095367,
                1.0,
                0.032450489372445726,
                0.12131451390225402,
                0.0,
                0.06863792038585721
            ],
            [
                0.13780197977899936,
                0.032450489372445726,
                1.0,
                0.18317317589198318,
                0.0,
                0.11970540867827119
            ],
            [
                0.30648150243898925,
                0.12131451390225402,
                0.18317317589198318,
                1.0,
                0.0,
                0.19967507121792194
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.27354689199844323,
                0.06863792038585721,
                0.11970540867827119,
                0.19967507121792194,
                0.0,
                1.0
            ]
        ]
    },
    "W05-1505": {
        "input_sentences": [
            "Analysis of the types of dependency errors made by these parsers on a Czech corpus show that the correct governor is likely to be found within a local neighborhood of the governor proposed by the parser.",
            "The continuity constraint of these constituencybased parsers makes it impossible for them to posit non-projective dependency trees.",
            "Our model, based on a MaxEnt classifier, improves overall dependency accuracy by .7% (a 4.5% reduction in error) with over 50% accuracy for non-projective structures.",
            "We present a corrective model for recovering non-projective dependency structures from trees generated by state-of-theart constituency-based parsers.",
            "Abstract",
            "Corrective Modeling",
            "Corrective Modeling For Non-Projective Dependency Parsing"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.06964197987329572,
                0.019500210770886643,
                0.06080328261400608,
                0.0,
                0.0,
                0.04068803006005379
            ],
            [
                0.06964197987329572,
                1.0,
                0.09735117967117567,
                0.23754525591804326,
                0.0,
                0.0,
                0.20312743135865047
            ],
            [
                0.019500210770886643,
                0.09735117967117567,
                1.0,
                0.2523031455935222,
                0.0,
                0.0,
                0.15521218761793484
            ],
            [
                0.06080328261400608,
                0.23754525591804326,
                0.2523031455935222,
                1.0,
                0.0,
                0.1401974069492356,
                0.26236638753320074
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.1401974069492356,
                0.0,
                1.0,
                0.6064243627418964
            ],
            [
                0.04068803006005379,
                0.20312743135865047,
                0.15521218761793484,
                0.26236638753320074,
                0.0,
                0.6064243627418964,
                1.0
            ]
        ]
    },
    "C10-1151": {
        "input_sentences": [
            "There often exist multiple corpora for the same natural language processing (NLP)tasks.",
            "For the purpose of full use of readily available human annotations, it is significant to simultaneously utilize multiple corpora of different annotation standards.",
            "Experimental results show the effectiveness of the proposed approach, which outperforms state of-the-art baselines, especially on long sentences.",
            "Abstract",
            "Heterogeneous Parsing via Collaborative Decoding",
            "However, such corpora are generally used independently due to distinctions in annotation standards.",
            "In this paper, we focus on the challenge of con stituent syntactic parsing with treebanksof different annotations and propose a collaborative decoding (or co-decoding) ap proach to improve parsing accuracy byleveraging bracket structure consensus be tween multiple parsing decoders trainedon individual treebanks."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.11090466082549637,
                0.0,
                0.0,
                0.0,
                0.07842143773490254,
                0.03387119458171573
            ],
            [
                0.11090466082549637,
                1.0,
                0.0,
                0.0,
                0.0,
                0.22620589470418923,
                0.09770114010096344
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.4204190427688554
            ],
            [
                0.07842143773490254,
                0.22620589470418923,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.03387119458171573,
                0.09770114010096344,
                0.0,
                0.0,
                0.4204190427688554,
                0.0,
                1.0
            ]
        ]
    },
    "D07-1111": {
        "input_sentences": [
            "We present a data-driven variant of the LR algorithm for dependency parsing, and extend it with a best-first search for probabil istic generalized LR dependency parsing.",
            "We apply this pars ing framework to both tracks of the CoNLL 2007 shared task, in each case taking ad vantage of multiple models trained with different learners.",
            "In the domain adaptation track, we use two models to parse unlabeled data in the target domain to supplement the labeled out-of domain training set, in a scheme similar to one iteration of co-training.",
            "Parser actions are determined by a classifier, based on features that represent the current state of the parser.",
            "Dependency Parsing and Domain Adaptation with LR Models and Parser Ensembles",
            "Abstract",
            "In the multilingual track, we train three LR models for each of the ten languages, and combine the analyses obtained with each individual model with a maximum spanning tree voting scheme."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.03415996070482917,
                0.0,
                0.38197519747963804,
                0.0,
                0.06247129230653034
            ],
            [
                0.0,
                1.0,
                0.019260060654471813,
                0.0,
                0.03943512092845111,
                0.0,
                0.024104350904694784
            ],
            [
                0.03415996070482917,
                0.019260060654471813,
                1.0,
                0.0,
                0.28742705179141836,
                0.0,
                0.09847448192609816
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.18203713615279954,
                0.0,
                0.0
            ],
            [
                0.38197519747963804,
                0.03943512092845111,
                0.28742705179141836,
                0.18203713615279954,
                1.0,
                0.0,
                0.10128742431762353
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.06247129230653034,
                0.024104350904694784,
                0.09847448192609816,
                0.0,
                0.10128742431762353,
                0.0,
                1.0
            ]
        ]
    },
    "W99-0623": {
        "input_sentences": [
            "The resulting parsers surpass the best previously published performance results for the Penn Treebank.",
            "Exploiting Diversity in Natural Language Processing: Combining Parsers",
            "Both parametric and non-parametric models are explored.",
            "Two general approaches are presented and two combination techniques are described for each approach.",
            "Abstract",
            "Three state-of-the-art statistical parsers are combined to produce more accurate parses, as well as new bounds on achievable Treebank parsing accuracy."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.06224277704893783,
                0.0,
                0.0,
                0.0,
                0.10497944026737055
            ],
            [
                0.06224277704893783,
                1.0,
                0.0,
                0.0,
                0.0,
                0.05192171700553539
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.10497944026737055,
                0.05192171700553539,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P09-1111": {
        "input_sentences": [
            "An Optimal-Time Binarization Algorithm for Linear Context-Free Rewriting Systems with Fan-Out Two",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0
            ],
            [
                0.0,
                1.0
            ]
        ]
    },
    "W11-0115": {
        "input_sentences": [
            "These representations are then used as feature vectors in a supervised learning model using multivariate multiple regression.",
            "In brief, distributional semantic spaces containing representations for complex constructions such as Adjective-Noun and Verb-Noun pairs, as well as for their constituent parts, are built.",
            "In a second experimental setting based on Verb-Noun pairs, a comparatively much lower performance was obtained by all the models; however, the proposed approach gives the best results in combination with a Random Indexing semantic space.",
            "This article introduces and evaluates an approach to semantic compositionality in computational linguistics based on the combination of Distributional Semantics and supervised Machine Learning.",
            "In particular, the distributional semantic representations of the constituents are used to predict those of the complex structures.",
            "Abstract",
            "Computing Semantic Compositionality in Distributional Semantics",
            "This approach outperforms the rivals in a series of experiments with Adjective-Noun pairs extracted from the BNC."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.046811394527632604,
                0.0,
                0.13375122988269425,
                0.1531839387811031,
                0.0,
                0.0,
                0.0
            ],
            [
                0.046811394527632604,
                1.0,
                0.16484784926581136,
                0.0588496735236837,
                0.20930072640699543,
                0.0,
                0.11272604851262649,
                0.2193630318473366
            ],
            [
                0.0,
                0.16484784926581136,
                1.0,
                0.1520639037976498,
                0.028043130806923333,
                0.0,
                0.04091324873540788,
                0.12518833573055527
            ],
            [
                0.13375122988269425,
                0.0588496735236837,
                0.1520639037976498,
                1.0,
                0.08219436255268095,
                0.0,
                0.35483076659697455,
                0.05373205761719901
            ],
            [
                0.1531839387811031,
                0.20930072640699543,
                0.028043130806923333,
                0.08219436255268095,
                1.0,
                0.0,
                0.15744260156089224,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.11272604851262649,
                0.04091324873540788,
                0.35483076659697455,
                0.15744260156089224,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.2193630318473366,
                0.12518833573055527,
                0.05373205761719901,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P07-1021": {
        "input_sentences": [
            "Mildly Context-Sensitive Dependency Languages",
            "In this paper, we show how two empirically relevant relaxations of projectivity can be lexicalized, and how combining the resulting lexicons with a regular means of syntactic composition gives rise to a hierarchy of mildly context-sensitive dependency languages.",
            "In previous work, several constraints have been proposed to identify classes of dependency structures that are wellbalanced in this sense; the best-known but also most restrictive of these is projectivity.",
            "Most constraints are formulated on fully specified structures, which makes them hard to integrate into models where structures are composed from lexical information.",
            "Abstract",
            "Dependency-based representations of natural language syntax require a fine balance between structural flexibility and computational complexity."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.4031535327849477,
                0.05738032074855085,
                0.0,
                0.0,
                0.05742042103240571
            ],
            [
                0.4031535327849477,
                1.0,
                0.06732953170523144,
                0.0,
                0.0,
                0.023149245593213477
            ],
            [
                0.05738032074855085,
                0.06732953170523144,
                1.0,
                0.15691165239375132,
                0.0,
                0.028474082175941422
            ],
            [
                0.0,
                0.0,
                0.15691165239375132,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.05742042103240571,
                0.023149245593213477,
                0.028474082175941422,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P10-1074": {
        "input_sentences": [
            "Hierarchical Joint Learning: Improving Joint Parsing and Named Entity Recognition with Non-Jointly Labeled Data",
            "One of the main obstacles to producing high quality joint models is the lack of jointly annotated data.",
            "Our model utilizes a hierarchical prior to link the feature weights for shared features in several single-task models and the joint model.",
            "Abstract",
            "Joint modeling of multiple natural language processing tasks outperforms single-task models learned from the same data, but still underperforms compared to single-task models learned on the more abundant quantities of available single-task annotated data.",
            "Experiments on joint parsing and named entity recognition, using the OntoNotes corpus, show that our hierarchical joint model can produce substantial gains over a joint model trained on only the jointly annotated data.",
            "In this paper we present a novel model which makes use of additional single-task annotated data to improve the performance of a joint model."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.14808350237781193,
                0.09509590756584678,
                0.0,
                0.06430736307180661,
                0.44515497710369684,
                0.07186543956174153
            ],
            [
                0.14808350237781193,
                1.0,
                0.07730985870855739,
                0.0,
                0.1453344125881527,
                0.1622019251253515,
                0.09235793205459515
            ],
            [
                0.09509590756584678,
                0.07730985870855739,
                1.0,
                0.0,
                0.23606500225390256,
                0.23456098457007094,
                0.2803254044019043
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.06430736307180661,
                0.1453344125881527,
                0.23606500225390256,
                0.0,
                1.0,
                0.07516682640580102,
                0.2269681723689039
            ],
            [
                0.44515497710369684,
                0.1622019251253515,
                0.23456098457007094,
                0.0,
                0.07516682640580102,
                1.0,
                0.23986852343246853
            ],
            [
                0.07186543956174153,
                0.09235793205459515,
                0.2803254044019043,
                0.0,
                0.2269681723689039,
                0.23986852343246853,
                1.0
            ]
        ]
    },
    "N06-1022": {
        "input_sentences": [
            "We define a sequence of PCFGs corresponding to each partition, where the nonterminals of each PCFG are clusters of nonterminals of the original source PCFG.",
            "We present a PCFG parsing algorithm that uses a multilevel coarse-to-fine (mlctf) scheme to improve the efficiency of search for the best parse.",
            "We suggest that the search space over mlctf algorithms is almost totally unexplored so that future work should be able to improve significantly on these results.",
            "Abstract",
            "Our approach requires the user to specify a sequence of nested partitions or equivalence classes of the PCFG nonterminals.",
            "Multilevel Coarse-To-Fine PCFG Parsing",
            "We use the results of parsing at a coarser level (i.e., grammar defined in terms of a coarser partition) to prune the next finer level.",
            "We present experiments showing that with our algorithm the work load (as measured by the total number of constituents processed) is decreased by a factor of ten with no decrease in parsing accuracy compared to standard CKY parsing with the original PCFG."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.05597394609332713,
                0.0,
                0.0,
                0.26261350735121736,
                0.11214221239329034,
                0.05284326055021944,
                0.08972044505605271
            ],
            [
                0.05597394609332713,
                1.0,
                0.1844529865655483,
                0.0,
                0.03001131834895696,
                0.4991335991929846,
                0.030035526107417953,
                0.16875053582416993
            ],
            [
                0.0,
                0.1844529865655483,
                1.0,
                0.0,
                0.0,
                0.0,
                0.05206835143420443,
                0.04660172965171926
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.26261350735121736,
                0.03001131834895696,
                0.0,
                0.0,
                1.0,
                0.060126824556552064,
                0.0,
                0.02274692381344717
            ],
            [
                0.11214221239329034,
                0.4991335991929846,
                0.0,
                0.0,
                0.060126824556552064,
                1.0,
                0.06017532411358476,
                0.1499141447041733
            ],
            [
                0.05284326055021944,
                0.030035526107417953,
                0.05206835143420443,
                0.0,
                0.0,
                0.06017532411358476,
                1.0,
                0.04553054391800718
            ],
            [
                0.08972044505605271,
                0.16875053582416993,
                0.04660172965171926,
                0.0,
                0.02274692381344717,
                0.1499141447041733,
                0.04553054391800718,
                1.0
            ]
        ]
    },
    "W12-2429": {
        "input_sentences": [
            "The system is evaluated on two widely used data sets and found to outperform a state-of-the-art unsupervised approach which also uses information from the UMLS Metathesaurus.",
            "Scaling up WSD with Automatically Generated Examples",
            "However, these require manually labeled training examples which are expensive to create and consequently supervised WSD systems are normally limited to disambiguating a small set of ambiguous terms.",
            "The labeled examples are generated without any use of labeled training data whatsoever and is therefore completely unsupervised (unlike some previous approaches).",
            "An alternative approach is to create labeled training examples automatically and use them as a substitute for manually labeled ones.",
            "The most accurate approaches to Word Sense Disambiguation (WSD) for biomedical documents are based on supervised learning.",
            "Abstract",
            "This paper describes a large scale WSD system based on automatically labeled examples generated using information from the UMLS Metathesaurus."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0,
                0.12853558981288749,
                0.06782950941096842,
                0.0,
                0.0,
                0.19090084647085712
            ],
            [
                0.0,
                1.0,
                0.11232744384808081,
                0.16122056945568372,
                0.1701553966345833,
                0.0784366577463478,
                0.0,
                0.33583761630469
            ],
            [
                0.0,
                0.11232744384808081,
                1.0,
                0.13673665672153462,
                0.267766195330611,
                0.09325721424447787,
                0.0,
                0.09226787492992683
            ],
            [
                0.12853558981288749,
                0.16122056945568372,
                0.13673665672153462,
                1.0,
                0.3398317188921987,
                0.07283752657322835,
                0.0,
                0.1662728405739593
            ],
            [
                0.06782950941096842,
                0.1701553966345833,
                0.267766195330611,
                0.3398317188921987,
                1.0,
                0.0,
                0.0,
                0.17548766409237776
            ],
            [
                0.0,
                0.0784366577463478,
                0.09325721424447787,
                0.07283752657322835,
                0.0,
                1.0,
                0.0,
                0.11340149955561682
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.19090084647085712,
                0.33583761630469,
                0.09226787492992683,
                0.1662728405739593,
                0.17548766409237776,
                0.11340149955561682,
                0.0,
                1.0
            ]
        ]
    },
    "E09-1053": {
        "input_sentences": [
            "Unlike earlier proposals, our dependency structures are always tree-shaped.",
            "We propose a novel algorithm for extracting dependencies from the derivations of a large fragment of CCG.",
            "Abstract",
            "Dependency Trees and the Strong Generative Capacity of CCG",
            "We then use these dependency trees to compare the strong generative capacities of CCG and TAG and obtain surprising results: Both formalisms generate the same languages of derivation trees \u2013 but the mechanisms they use to bring the words in these trees into a linear order are incomparable."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0,
                0.09001775755656882,
                0.03334452052572089
            ],
            [
                0.0,
                1.0,
                0.0,
                0.07864440790235185,
                0.029131586308236992
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.09001775755656882,
                0.07864440790235185,
                0.0,
                1.0,
                0.3994635764964098
            ],
            [
                0.03334452052572089,
                0.029131586308236992,
                0.0,
                0.3994635764964098,
                1.0
            ]
        ]
    },
    "W10-1407": {
        "input_sentences": [
            "Generally, due to the longdistance dependencies they induce, they lie beyond the expressivity of Probabilistic CFG, i.e., they cannot be directly reconstructed by a PCFG parser.",
            "Direct Parsing of Discontinuous Constituents in German",
            "Discontinuities occur especially frequently in languages with a relatively free word order, such as German.",
            "In both treebanks, discontinuities are annotated with crossing branches.",
            "In this paper, we use a parser for Probabilistic Linear Context-Free Rewriting Systems (PLCFRS), a formalism with high expressivity, to directly parse the German NeGra and TIGER treebanks.",
            "Based on an evaluation using different metrics, we show that an output quality can be achieved which is comparable to the output quality of PCFG-based systems.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0,
                0.0,
                0.21105603877269427,
                0.04843195225897241,
                0.0
            ],
            [
                0.0,
                1.0,
                0.07960236323907142,
                0.0,
                0.05871106288279993,
                0.0,
                0.0
            ],
            [
                0.0,
                0.07960236323907142,
                1.0,
                0.11049951088374246,
                0.09902757845247039,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.11049951088374246,
                1.0,
                0.08149938604875165,
                0.0,
                0.0
            ],
            [
                0.21105603877269427,
                0.05871106288279993,
                0.09902757845247039,
                0.08149938604875165,
                1.0,
                0.03873834017542323,
                0.0
            ],
            [
                0.04843195225897241,
                0.0,
                0.0,
                0.0,
                0.03873834017542323,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P04-1042": {
        "input_sentences": [
            "We use an algorithm based on loglinear classifiers to augment and reshape context-free trees so as to reintroduce underlying nonlocal dependencies lost in the context-free approximation.",
            "By this new evaluation metric our algorithm achieves 60% error reduction on gold-standard input trees and 5% error reduction on state-ofthe-art machine-parsed input trees, when compared with the best previous work.",
            "We present a linguistically-motivated algorithm for reconstructing nonlocal dependency in broad-coverage context-free parse trees derived from treebanks.",
            "Deep Dependencies From Context-Free Statistical Parsers: Correcting The Surface Dependency Approximation",
            "Our new evaluation metric quantitatively corroborates the intuition that in a language with freer word order, the surface dependencies in context-free parse trees are a poorer approximation to underlying dependency structure.",
            "We also present the first results on nonlocal dependency reconstruction for a language other than English, comparing performance on English and German.",
            "We find that our algorithm compares favorably with prior work on English using an existing evaluation metric, and also introduce and argue for a new dependency-based evaluation metric.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.06062908074373801,
                0.23820408696022763,
                0.2707476404896288,
                0.25989643544934443,
                0.04409600128635275,
                0.07744815235354037,
                0.0
            ],
            [
                0.06062908074373801,
                1.0,
                0.06885289899943273,
                0.0,
                0.11542817157079112,
                0.0,
                0.18347487358167153,
                0.0
            ],
            [
                0.23820408696022763,
                0.06885289899943273,
                1.0,
                0.12964306680131063,
                0.1746054242121496,
                0.14749184907934007,
                0.05710607189676787,
                0.0
            ],
            [
                0.2707476404896288,
                0.0,
                0.12964306680131063,
                1.0,
                0.2830408547013117,
                0.03791508393755931,
                0.0315349737815744,
                0.0
            ],
            [
                0.25989643544934443,
                0.11542817157079112,
                0.1746054242121496,
                0.2830408547013117,
                1.0,
                0.08300429610920237,
                0.19882287446759264,
                0.0
            ],
            [
                0.04409600128635275,
                0.0,
                0.14749184907934007,
                0.03791508393755931,
                0.08300429610920237,
                1.0,
                0.14229423111856104,
                0.0
            ],
            [
                0.07744815235354037,
                0.18347487358167153,
                0.05710607189676787,
                0.0315349737815744,
                0.19882287446759264,
                0.14229423111856104,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "W12-3131": {
        "input_sentences": [
            "This paper describes the French-English translation system developed by the Avenue research group at Carnegie Mellon University for the Seventh Workshop on Statistical Machine Translation (NAACL WMT12).",
            "The CMU-Avenue French-English Translation System",
            "Translation System",
            "We present a method for training data selection, a description of our hierarchical phrase-based translation system, and a discussion of the impact of data size on best practice for system building.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.34479307212858923,
                0.2715108651291912,
                0.03574034137969838,
                0.0
            ],
            [
                0.34479307212858923,
                1.0,
                0.3115442086992723,
                0.0410101318357254,
                0.0
            ],
            [
                0.2715108651291912,
                0.3115442086992723,
                1.0,
                0.13163503185293263,
                0.0
            ],
            [
                0.03574034137969838,
                0.0410101318357254,
                0.13163503185293263,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P04-1015": {
        "input_sentences": [
            "This paper describes an incremental parsing approach where parameters are estimated using a variant of the perceptron algorithm.",
            "The perceptron approach was implemented with the same feature set as that of an existing generative model (Roark, 2001a), and experimental results show that it gives competitive performance to the generative model on parsing the Penn treebank.",
            "We demonstrate that training a perceptron model to combine with the generative model during search provides a 2.1 percent F-measure improvement over the generative model alone, to 88.8 percent.",
            "Abstract",
            "Incremental Parsing With The Perceptron Algorithm",
            "A beam-search algorithm is used during both training and decoding phases of the method."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.11462233171550767,
                0.0264620163388264,
                0.0,
                0.4786465198477012,
                0.06236439263199073
            ],
            [
                0.11462233171550767,
                1.0,
                0.3510228752135376,
                0.0,
                0.13238327957158225,
                0.0
            ],
            [
                0.0264620163388264,
                0.3510228752135376,
                1.0,
                0.0,
                0.0552850908583776,
                0.11387445392016877
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.4786465198477012,
                0.13238327957158225,
                0.0552850908583776,
                0.0,
                1.0,
                0.13029321231006596
            ],
            [
                0.06236439263199073,
                0.0,
                0.11387445392016877,
                0.0,
                0.13029321231006596,
                1.0
            ]
        ]
    },
    "E99-1016": {
        "input_sentences": [
            "The approach is based on Markov Mod- els.",
            "Cascaded Markov Models",
            "Each layer of the resulting structure is represented byits own Markov Model, and output of a lower layer is passed as input to the next higher layer.",
            "An em- pirical evaluation of the method yields very good results for NP/PP chunking of German ewspaper texts.",
            "This paper presents a new approach to partial parsing of context-free structures.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.1493915352834391,
                0.053297101285115965,
                0.0,
                0.1120620580524022,
                0.0
            ],
            [
                0.1493915352834391,
                1.0,
                0.06896891312617925,
                0.0,
                0.0,
                0.0
            ],
            [
                0.053297101285115965,
                0.06896891312617925,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.1120620580524022,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "C08-1049": {
        "input_sentences": [
            "With aperceptron classifier trained with local features as the baseline, word lattice reranking performs reranking with non-local fea tures that can?t be easily incorporated intothe perceptron baseline.",
            "As a derivation of the forest reranking for parsing (Huang, 2008), this strategy reranks on the pruned word lattice, which potentially contains much more candidates while using less storage, compared with the traditional n-best list reranking.",
            "In this paper, we describe a new rerank ing strategy named word lattice reranking,for the task of joint Chinese word segmen tation and part-of-speech (POS) tagging.",
            "Word Lattice Reranking for Chinese Word Segmentation and Part-of-Speech Tagging",
            "Experimental results show that, this strategy achieves im provement on both segmentation and POS tagging, above the perceptron baseline and the n-best list reranking.",
            "Abstract",
            "Word Lattice"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.09260151655061258,
                0.0871514769443199,
                0.15592700051306066,
                0.18254935260333868,
                0.0,
                0.1698268991544983
            ],
            [
                0.09260151655061258,
                1.0,
                0.12552588273825754,
                0.1668803528294515,
                0.18168604310254896,
                0.0,
                0.18175667304304033
            ],
            [
                0.0871514769443199,
                0.12552588273825754,
                1.0,
                0.46972793425351816,
                0.16548425737122036,
                0.0,
                0.30790697131566214
            ],
            [
                0.15592700051306066,
                0.1668803528294515,
                0.46972793425351816,
                1.0,
                0.22106478015073647,
                0.0,
                0.5508915299850384
            ],
            [
                0.18254935260333868,
                0.18168604310254896,
                0.16548425737122036,
                0.22106478015073647,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.1698268991544983,
                0.18175667304304033,
                0.30790697131566214,
                0.5508915299850384,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P04-1054": {
        "input_sentences": [
            "Dependency Tree Kernels For Relation Extraction",
            "Using this kernel within a Support Vector Machine, we detect and classify relations between entities in the Automatic Content Extraction (ACE) corpus of news articles.",
            "We examine the utility of different features such as Wordnet hypernyms, parts of speech, and entity types, and find that the dependency tree kernel achieves a 20% F1 improvement over a \u201cbag-of-words\u201d kernel.",
            "Abstract",
            "We extend previous work on tree kernels to estimate the similarity between the dependency trees of sentences."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.09303699966763025,
                0.11357509635691121,
                0.0,
                0.2960238424768766
            ],
            [
                0.09303699966763025,
                1.0,
                0.07536301602683898,
                0.0,
                0.0
            ],
            [
                0.11357509635691121,
                0.07536301602683898,
                1.0,
                0.0,
                0.06947841138762685
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.2960238424768766,
                0.0,
                0.06947841138762685,
                0.0,
                1.0
            ]
        ]
    },
    "P08-1013": {
        "input_sentences": [
            "We propose a language model based on a precise, linguistically motivated grammar (a hand-crafted Head-driven Phrase Structure Grammar) and a statistical model estimating the probability of a parse tree.",
            "To demonstrate that our approach is feasible and beneficial for non-trivial broad-domain speech recognition tasks, we applied it to a simplified German broadcast-news transcription task.",
            "Applying a Grammar-Based Language Model to a Simplified Broadcast-News Transcription Task",
            "The language model is applied by means of an N-best rescoring step, which allows to directly measure the performance gains relative to the baseline system without rescoring.",
            "Language Model",
            "Abstract",
            "We report a significant reduction in word error rate compared to a state-of-the-art baseline system."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.2770219041763821,
                0.06487630795959635,
                0.28973254889637867,
                0.0,
                0.0
            ],
            [
                0.0,
                1.0,
                0.3343136810551131,
                0.04409111059093178,
                0.0,
                0.0,
                0.0
            ],
            [
                0.2770219041763821,
                0.3343136810551131,
                1.0,
                0.07603451606036322,
                0.3395642390129739,
                0.0,
                0.0
            ],
            [
                0.06487630795959635,
                0.04409111059093178,
                0.07603451606036322,
                1.0,
                0.22391791397520558,
                0.0,
                0.05689643691732357
            ],
            [
                0.28973254889637867,
                0.0,
                0.3395642390129739,
                0.22391791397520558,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.05689643691732357,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P10-1097": {
        "input_sentences": [
            "We present a syntactically enriched vector model that supports the computation of contextualized semantic representations in a quasi compositional fashion.",
            "Contextualizing Semantic Representations Using Syntactically Enriched Vector Models",
            "It employs a systematic combination of firstand second-order context vectors.",
            "We apply our model to two different tasks and show that (i) it substantially outperforms previous work on a paraphrase ranking task, and (ii) achieves promising results on a wordsense similarity task; to our knowledge, it is the first time that an unsupervised method has been applied to this task.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.39406983670324713,
                0.0,
                0.03619788713249855,
                0.0
            ],
            [
                0.39406983670324713,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.03619788713249855,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P07-1083": {
        "input_sentences": [
            "A character-based measure of similarity is an important component of many natural language processing systems, including approaches to transliteration, coreference, word alignment, spelling correction, and the identification of cognates in related vocabu- We propose an alignment-based disfor string similarity.",
            "We gather features from substring pairs consistent with a character-based alignment of the two strings.",
            "This approach achieves exceptional performance; on nine separate cognate identification experiments using six language pairs, we more than double the precision of traditional orthographic measures like Longest Common Subsequence Ratio and Dice\u2019s Coefficient.",
            "Alignment-Based Discriminative String Similarity",
            "We also show strong improvements over other recent discriminative and heuristic similarity functions.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.18635005752899697,
                0.05573783683258382,
                0.4136483976843177,
                0.07516141728962629,
                0.0
            ],
            [
                0.18635005752899697,
                1.0,
                0.05302704053741744,
                0.2126348673906855,
                0.0,
                0.0
            ],
            [
                0.05573783683258382,
                0.05302704053741744,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.4136483976843177,
                0.2126348673906855,
                0.0,
                1.0,
                0.27836368556384866,
                0.0
            ],
            [
                0.07516141728962629,
                0.0,
                0.0,
                0.27836368556384866,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "W10-3504": {
        "input_sentences": [
            "We report empirical evidence that our method successfully expands existing textual entailment corpora.",
            "In this paper we propose a novel method to automatically extract large textual entailment datasets homogeneous to existing ones.",
            "Abstract",
            "Expanding textual entailment corpora fromWikipedia using co-training",
            "The key idea is the combination of two intuitions: (1) the use of Wikipedia to extract a large set of textual entailment pairs; (2) the application of semisupervised machine learning methods to make the extracted dataset homogeneous to the existing ones."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.20883466568052536,
                0.0,
                0.20578493144452462,
                0.08984317689613555
            ],
            [
                0.20883466568052536,
                1.0,
                0.0,
                0.09035671070062311,
                0.27192963037853823
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.20578493144452462,
                0.09035671070062311,
                0.0,
                1.0,
                0.06222936284553251
            ],
            [
                0.08984317689613555,
                0.27192963037853823,
                0.0,
                0.06222936284553251,
                1.0
            ]
        ]
    },
    "P11-2074": {
        "input_sentences": [
            "Discriminative Feature-Tied Mixture Modeling for Statistical Machine Translation",
            "All features within the same mixture component are tied and share the same mixture weights, where the mixture weights are trained discriminatively to maximize the translation performance.",
            "Each component contains a large set of features trained in a maximumentropy framework.",
            "The proposed approach improves the translation performance significantly on a large-scale Arabic-to-English MT task.",
            "This approach aims at bridging the gap between the maximum-likelihood training and the discriminative training for SMT.",
            "We model the feature space with a log-linear combination of multiple mixture components.",
            "Abstract",
            "In this paper we present a novel discriminative mixture model for statistical machine translation (SMT).",
            "It is shown that the feature space can be partitioned in a variety of ways, such as based on feature types, word alignments, or domains, for various applications."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.2772329409999135,
                0.0,
                0.05758808161740652,
                0.07239295348653435,
                0.15706107523130716,
                0.0,
                0.46407408096488423,
                0.12873726471627112
            ],
            [
                0.2772329409999135,
                1.0,
                0.21266212759802341,
                0.09080574206408071,
                0.0,
                0.12088921333872393,
                0.0,
                0.16287261958233684,
                0.0
            ],
            [
                0.0,
                0.21266212759802341,
                1.0,
                0.08385071328379402,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.05758808161740652,
                0.09080574206408071,
                0.08385071328379402,
                1.0,
                0.06628846906494912,
                0.0,
                0.0,
                0.04816437750564215,
                0.0
            ],
            [
                0.07239295348653435,
                0.0,
                0.0,
                0.06628846906494912,
                1.0,
                0.0,
                0.0,
                0.14063676814676937,
                0.0
            ],
            [
                0.15706107523130716,
                0.12088921333872393,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.1551715153983802,
                0.17703055472465407
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.46407408096488423,
                0.16287261958233684,
                0.0,
                0.04816437750564215,
                0.14063676814676937,
                0.1551715153983802,
                0.0,
                1.0,
                0.0
            ],
            [
                0.12873726471627112,
                0.0,
                0.0,
                0.0,
                0.0,
                0.17703055472465407,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "W10-1404": {
        "input_sentences": [
            "Application of Different Techniques to Dependency Parsing of Basque",
            "We present a set of experiments on dependency parsing of the Basque Dependency Treebank (BDT).",
            "Abstract",
            "All the tests were conducted using MaltParser (Vivre et al., 2007a), a freely available and state of the art dependency parser generator.",
            "The present work has examined several directions that try to explore the rich set of morphosyntactic features in the BDT: i) experimenting the impact of morphological features, ii) application of dependency tree transformations, iii) application of a two-stage parsing scheme (stacking), and iv) combinations of the individual experiments."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.35183947906595825,
                0.0,
                0.04159085171668782,
                0.18726360402015385
            ],
            [
                0.35183947906595825,
                1.0,
                0.0,
                0.06864668793598691,
                0.27556150119873174
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.04159085171668782,
                0.06864668793598691,
                0.0,
                1.0,
                0.015321731700269922
            ],
            [
                0.18726360402015385,
                0.27556150119873174,
                0.0,
                0.015321731700269922,
                1.0
            ]
        ]
    },
    "E06-2025": {
        "input_sentences": [
            "Theoretical Evaluation Of Estimation Methods For Data-Oriented Parsing",
            "We analyze estimation methods for Data- Oriented Parsing, as well as the theoretical criteria used to evaluate them.",
            "We show that all current estimation methods are inconsistent in the \u201cweight-distribution test\u201d, and argue that these results force us to rethink both the methods proposed and the criteria used.",
            "Abstract",
            "Estimation Methods"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.6150863983548802,
                0.1288300025089341,
                0.0,
                0.387002827584368
            ],
            [
                0.6150863983548802,
                1.0,
                0.24550173492892394,
                0.0,
                0.3115442086992723
            ],
            [
                0.1288300025089341,
                0.24550173492892394,
                1.0,
                0.0,
                0.33289163108465586
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.387002827584368,
                0.3115442086992723,
                0.33289163108465586,
                0.0,
                1.0
            ]
        ]
    },
    "P08-1006": {
        "input_sentences": [
            "This paper presents a comparative evaluation of several state-of-the-art English parsers based on different frameworks.",
            "Our experiments show that the levels of accuracy obtained with these different parsers are similar, but that accuracy improvements vary when the parsers are retrained with domain-specific data.",
            "We run a PPI system with several combinations of parser and parse representation, and examine their impact on PPI identification accuracy.",
            "Syntactic Parsers and Their Representations",
            "Task-oriented Evaluation of Syntactic Parsers and Their Representations",
            "Abstract",
            "Our approach is to measure the impact of each parser when it is used as a component of an information extraction system that performs protein-protein interaction (PPI) identification in biomedical papers.",
            "We evaluate eight parsers (based on dependency parsing, phrase structure parsing, or deep parsing) using five different parse representations."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.09928485148381049,
                0.0,
                0.08348828488197338,
                0.1624668763457072,
                0.0,
                0.0,
                0.12021035857532351
            ],
            [
                0.09928485148381049,
                1.0,
                0.11446263964175288,
                0.13288943762383904,
                0.08007240283472407,
                0.0,
                0.0,
                0.07161303630194604
            ],
            [
                0.0,
                0.11446263964175288,
                1.0,
                0.0,
                0.0,
                0.0,
                0.26662004723806987,
                0.05186900654724611
            ],
            [
                0.08348828488197338,
                0.13288943762383904,
                0.0,
                1.0,
                0.6025490382567462,
                0.0,
                0.0,
                0.16019565245640235
            ],
            [
                0.1624668763457072,
                0.08007240283472407,
                0.0,
                0.6025490382567462,
                1.0,
                0.0,
                0.0,
                0.0965257363205172
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.26662004723806987,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.12021035857532351,
                0.07161303630194604,
                0.05186900654724611,
                0.16019565245640235,
                0.0965257363205172,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "D08-1008": {
        "input_sentences": [
            "We present a PropBank semantic role label ing system for English that is integrated with a dependency parser.",
            "To tackle the problemof joint syntactic?semantic analysis, the system relies on a syntactic and a semantic subcomponent.",
            "Our system is the first dependency-based semantic role labeler for PropBank that rivals constituent-based systems in terms of performance.",
            "The syntactic model is a projective parser using pseudo-projective transfor mations, and the semantic model uses global inference mechanisms on top of a pipeline of classifiers.",
            "Dependency-based Semantic Role Labeling of PropBank",
            "Using a dependency-based metric, the F1 figure of our system is 84.29 on the test set from CoNLL-2008.",
            "Abstract",
            "The complete syntactic?semanticoutput is selected from a candidate pool gen erated by the subsystems.We evaluate the system on the CoNLL 2005 test sets using segment-based and dependency-based metrics.",
            "Using the segment-based CoNLL-2005 metric, our system achieves a near state-of-the-art F1 figure of 77.97 on the WSJ+Brown test set, or 78.84 if punctuation is treated consistently."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.07963552264622632,
                0.21236372055051597,
                0.0880422861948853,
                0.3645732437144538,
                0.04411744865414601,
                0.0,
                0.03054353016080625,
                0.0
            ],
            [
                0.07963552264622632,
                1.0,
                0.07215496098259537,
                0.13016791215768073,
                0.12387129076153648,
                0.0,
                0.0,
                0.08710941533850224,
                0.0
            ],
            [
                0.21236372055051597,
                0.07215496098259537,
                1.0,
                0.025502083254127117,
                0.4569487982097001,
                0.11991983026593747,
                0.0,
                0.13837212049289754,
                0.05124798703259167
            ],
            [
                0.0880422861948853,
                0.13016791215768073,
                0.025502083254127117,
                1.0,
                0.043780440412945036,
                0.03471621309591904,
                0.0,
                0.05482234704302216,
                0.022254068004618845
            ],
            [
                0.3645732437144538,
                0.12387129076153648,
                0.4569487982097001,
                0.043780440412945036,
                1.0,
                0.13724742748715646,
                0.0,
                0.14252935297131286,
                0.04398972860777282
            ],
            [
                0.04411744865414601,
                0.0,
                0.11991983026593747,
                0.03471621309591904,
                0.13724742748715646,
                1.0,
                0.0,
                0.22417961144476903,
                0.44754790509721454
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.03054353016080625,
                0.08710941533850224,
                0.13837212049289754,
                0.05482234704302216,
                0.14252935297131286,
                0.22417961144476903,
                0.0,
                1.0,
                0.20631660958207398
            ],
            [
                0.0,
                0.0,
                0.05124798703259167,
                0.022254068004618845,
                0.04398972860777282,
                0.44754790509721454,
                0.0,
                0.20631660958207398,
                1.0
            ]
        ]
    },
    "W08-2107": {
        "input_sentences": [
            "In a second stage we also study whether the combination of statistical and linguistic properties can provide some indication of the degree of idiomaticity of a given VPC.",
            "Picking them up and Figuring them out: Verb-Particle Constructions Noise and Idiomaticity",
            "Given the limited coverage provided by lexical resources, such as dictionaries, and the constantly growing number of VPCs, possible ways of automatically identifying them are crucial for any NLP task that requires some degree of semantic interpretation.",
            "This paper investigates, in a first stage, some methods for the automatic acquisition of verb-particle constructions (VPCs) taking into account their statistical properties and some regular patterns found in productive combinations of verbs and particles.",
            "The results obtained show that such combination can successfully be used to detect VPCs and distinguish idiomatic from compositional cases.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.08615197395747062,
                0.09006501057624192,
                0.14731273122136723,
                0.06449705241635614,
                0.0
            ],
            [
                0.08615197395747062,
                1.0,
                0.0,
                0.20208264067387743,
                0.0,
                0.0
            ],
            [
                0.09006501057624192,
                0.0,
                1.0,
                0.025097474459120035,
                0.03296483159915582,
                0.0
            ],
            [
                0.14731273122136723,
                0.20208264067387743,
                0.025097474459120035,
                1.0,
                0.03594543797533339,
                0.0
            ],
            [
                0.06449705241635614,
                0.0,
                0.03296483159915582,
                0.03594543797533339,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P07-1055": {
        "input_sentences": [
            "Structured Models for Fine-to-Coarse Sentiment Analysis",
            "The primary advantage of such a model is that it allows classification decisions from one level in the text to influence decisions at another.",
            "In this paper we investigate a structured model for jointly classifying the sentiment of text at varying levels of granularity.",
            "Inference in the model is based on standard sequence classification techniques using constrained Viterbi to ensure consistent solutions.",
            "Experiments show that this method can significantly reduce classification error relative to models trained in isolation.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.19482997948646316,
                0.0,
                0.09923337072177647,
                0.0
            ],
            [
                0.0,
                1.0,
                0.11462416363037559,
                0.08501720189677946,
                0.04859208037710931,
                0.0
            ],
            [
                0.19482997948646316,
                0.11462416363037559,
                1.0,
                0.04497600651017466,
                0.0,
                0.0
            ],
            [
                0.0,
                0.08501720189677946,
                0.04497600651017466,
                1.0,
                0.04581554378205222,
                0.0
            ],
            [
                0.09923337072177647,
                0.04859208037710931,
                0.0,
                0.04581554378205222,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P08-1102": {
        "input_sentences": [
            "Experiments show that the cascaded model achieves improved accuracies on both segmentation only and joint segmentation and part-of-speech tagging.",
            "Cascaded Linear Model",
            "We propose a cascaded linear model for joint Chinese word segmentation and partof-speech tagging.",
            "A Cascaded Linear Model for Joint Chinese Word Segmentation and Part-of-Speech Tagging",
            "With a character-based perceptron as the core, combined with realvalued features such as language models, the cascaded model is able to efficiently utilize knowledge sources that are inconvenient to incorporate into the perceptron directly.",
            "On the Penn Chinese Treebank 5.0, we obtain an error reduction of segmentation and joint segmentation and part-of-speech tagging over the perceptron-only baseline.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.20772681383199543,
                0.38283232435002323,
                0.47304862096359174,
                0.0492216576771535,
                0.3146032628102604,
                0.0
            ],
            [
                0.20772681383199543,
                1.0,
                0.4328166132287353,
                0.5348119502855482,
                0.12709014970295665,
                0.0,
                0.0
            ],
            [
                0.38283232435002323,
                0.4328166132287353,
                1.0,
                0.8092874757148654,
                0.05500672816916665,
                0.3177589435778502,
                0.0
            ],
            [
                0.47304862096359174,
                0.5348119502855482,
                0.8092874757148654,
                1.0,
                0.06796933082472051,
                0.39264038195718426,
                0.0
            ],
            [
                0.0492216576771535,
                0.12709014970295665,
                0.05500672816916665,
                0.06796933082472051,
                1.0,
                0.09985545105671101,
                0.0
            ],
            [
                0.3146032628102604,
                0.0,
                0.3177589435778502,
                0.39264038195718426,
                0.09985545105671101,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P11-2124": {
        "input_sentences": [
            "We show that the methodology is very effective: using a small training set of about 5500 trees, we construct a parser which parses and segments unsegmented Hebrew text with an F-score of almost 80%, an error reduction of over 20% over the best previous result for this task.",
            "Abstract",
            "This result indicates that lattice parsing with the Berkeley parser is an effective methodology for parsing over uncertain inputs.",
            "We experiment with extending a lattice parsing methodology for parsing Hebrew (Goldberg and Tsarfaty, 2008; Golderg et al., 2009) to make use of a stronger syntactic model: the PCFG-LA Berkeley Parser.",
            "Joint Hebrew Segmentation and Parsing using a PCFGLA Lattice Parser"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.15928526025185913,
                0.05886492310232547,
                0.13359224766237238
            ],
            [
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.15928526025185913,
                0.0,
                1.0,
                0.28922517126187297,
                0.25567120167430624
            ],
            [
                0.05886492310232547,
                0.0,
                0.28922517126187297,
                1.0,
                0.20426471284871922
            ],
            [
                0.13359224766237238,
                0.0,
                0.25567120167430624,
                0.20426471284871922,
                1.0
            ]
        ]
    },
    "S12-1097": {
        "input_sentences": [
            "This approach also makes use of information from WordNet.",
            "Two approaches were developed.",
            "Resultsfrom the formal evaluation show that both approaches are useful for determining the simi larity in meaning between pairs of sentences with the best performance being obtained bythe supervised approach.",
            "Abstract",
            "Incorporating information from WordNet alo improves perfor mance for both approaches.",
            "The first is an unsupervised technique based on the widely used vector space model and information from WordNet.The second method relies on supervised ma chine learning and represents each sentence as a set of n-grams.",
            "University_Of_Sheffield: Two Approaches to Semantic Text Similarity",
            "This paper describes the University of Sheffield?s submission to SemEval-2012 Task 6: Semantic Text Similarity."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.09124823345672212,
                0.0,
                0.21276519024653573,
                0.12157651979442317,
                0.0,
                0.0
            ],
            [
                0.0,
                1.0,
                0.08540508230095656,
                0.0,
                0.1337182928292661,
                0.0,
                0.1812603532706148,
                0.0
            ],
            [
                0.09124823345672212,
                0.08540508230095656,
                1.0,
                0.0,
                0.039824629307683775,
                0.03975401489100061,
                0.05398383590193536,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.21276519024653573,
                0.1337182928292661,
                0.039824629307683775,
                0.0,
                1.0,
                0.09269517031646436,
                0.08452221088839335,
                0.0
            ],
            [
                0.12157651979442317,
                0.0,
                0.03975401489100061,
                0.0,
                0.09269517031646436,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.1812603532706148,
                0.05398383590193536,
                0.0,
                0.08452221088839335,
                0.0,
                1.0,
                0.35381268327851667
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.35381268327851667,
                1.0
            ]
        ]
    },
    "W09-1218": {
        "input_sentences": [
            "In the closed challenge of the CoNLL-2009 Shared Task (Haji\u02c7c et al., 2009), our system achieved the 3rd best performances for English and Czech, and the 4th best performance for Japanese.",
            "This paper describes a system for syntacticsemantic dependency parsing for multiple languages.",
            "Multilingual Syntactic-Semantic Dependency Parsing with Three-Stage Approximate Max-Margin Linear Models",
            "The system consists of three parts: a state-of-the-art higher-order projective dependency parser for syntactic dependency parsing, a predicate classifier, and an argument classifier for semantic dependency parsing.",
            "All components are trained with an approximate max-margin learning algorithm.",
            "For semantic dependency parsing, we explore use of global features.",
            "Abstract",
            "Dependency Parsing"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                1.0,
                0.09410057476232843,
                0.1510243828034167,
                0.0,
                0.11697311615679264,
                0.0,
                0.33452702897418884
            ],
            [
                0.0,
                0.09410057476232843,
                1.0,
                0.22578691724725558,
                0.30216596281051555,
                0.1800080959066055,
                0.0,
                0.2812943846447426
            ],
            [
                0.0,
                0.1510243828034167,
                0.22578691724725558,
                1.0,
                0.0,
                0.21027550649101298,
                0.0,
                0.4514564436438089
            ],
            [
                0.0,
                0.0,
                0.30216596281051555,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.11697311615679264,
                0.1800080959066055,
                0.21027550649101298,
                0.0,
                1.0,
                0.0,
                0.349667159976535
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.33452702897418884,
                0.2812943846447426,
                0.4514564436438089,
                0.0,
                0.349667159976535,
                0.0,
                1.0
            ]
        ]
    },
    "W09-2208": {
        "input_sentences": [
            "We present a simple semi-supervised learning algorithm for named entity recognition (NER) using conditional random fields (CRFs).",
            "Such independent evidence is used to automatically extract highaccuracy and non-redundant data, leading to a much improved classifier at the next iteration.",
            "We show that our algorithm achieves an averimprovement of recall and precision compared to the supervised algorithm.",
            "We also show that our algorithm achieves high accuracy when the training and test sets are from different domains.",
            "A Simple Semi-supervised Algorithm For Named Entity Recognition",
            "Named Entity Recognition",
            "Abstract",
            "The algorithm is based on exploiting evidence that is independent from the features used for a classifier, which provides high-precision labels to unlabeled data."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.13487223088626113,
                0.03299014420935342,
                0.5680769674823902,
                0.36446553866706705,
                0.0,
                0.027350468323393592
            ],
            [
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.3088475547253388
            ],
            [
                0.13487223088626113,
                0.0,
                1.0,
                0.19278361846597786,
                0.23741893899340683,
                0.0,
                0.0,
                0.15982719616690833
            ],
            [
                0.03299014420935342,
                0.0,
                0.19278361846597786,
                1.0,
                0.05807337050744992,
                0.0,
                0.0,
                0.10926158135945875
            ],
            [
                0.5680769674823902,
                0.0,
                0.23741893899340683,
                0.05807337050744992,
                1.0,
                0.6415777430342045,
                0.0,
                0.048145708924981954
            ],
            [
                0.36446553866706705,
                0.0,
                0.0,
                0.0,
                0.6415777430342045,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.027350468323393592,
                0.3088475547253388,
                0.15982719616690833,
                0.10926158135945875,
                0.048145708924981954,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "D11-1086": {
        "input_sentences": [
            "In theory, sucha covariance matrix should represent seman tic equivalence, and should be highly sparse.",
            "In this paper, we explore techniques to recover the desired sparsity in covariance matrices in two ways.",
            "Many existing approaches are based on word co-occurrencesextracted from aligned training data, repre sented as a covariance matrix.",
            "Unfortunately, the presence of noise leads to dense covariance matrices which in turn leads to suboptimal document representations.",
            "Mapping documents into an interlingual representation can help bridge the language bar rier of cross-lingual corpora.",
            "First, we explore word association measures and bilingual dictionaries to weigh the word pairs.",
            "Abstract",
            "Our experimental results on the task of aligning compa rable documents shows the efficacy of sparse covariance matrices on two data sets from two different language pairs.",
            "Later, we explore different selection strategies to remove the noisy pairsbased on the association scores.",
            "Improving Bilingual Projections via Sparse Covariance Matrices"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.03650151135123299,
                0.10682152981292312,
                0.027605598862702387,
                0.0,
                0.0,
                0.0,
                0.07713349831752664,
                0.0,
                0.1437234422312281
            ],
            [
                0.03650151135123299,
                1.0,
                0.03303410837006869,
                0.07537448304009194,
                0.0,
                0.069865511926016,
                0.0,
                0.07214075108150873,
                0.06834773112169427,
                0.13442041780470743
            ],
            [
                0.10682152981292312,
                0.03303410837006869,
                1.0,
                0.024983248931152863,
                0.0,
                0.152310665850639,
                0.0,
                0.08387198129854358,
                0.0,
                0.044554318968374335
            ],
            [
                0.027605598862702387,
                0.07537448304009194,
                0.024983248931152863,
                1.0,
                0.0,
                0.0,
                0.0,
                0.05455907337225703,
                0.0,
                0.10166034214767561
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.11462196823100847,
                0.0,
                0.0
            ],
            [
                0.0,
                0.069865511926016,
                0.152310665850639,
                0.0,
                0.0,
                1.0,
                0.0,
                0.06607036223653279,
                0.1449272745451155,
                0.12310941545796504
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.07713349831752664,
                0.07214075108150873,
                0.08387198129854358,
                0.05455907337225703,
                0.11462196823100847,
                0.06607036223653279,
                0.0,
                1.0,
                0.06463502848211351,
                0.17149061740743282
            ],
            [
                0.0,
                0.06834773112169427,
                0.0,
                0.0,
                0.0,
                0.1449272745451155,
                0.0,
                0.06463502848211351,
                1.0,
                0.0
            ],
            [
                0.1437234422312281,
                0.13442041780470743,
                0.044554318968374335,
                0.10166034214767561,
                0.0,
                0.12310941545796504,
                0.0,
                0.17149061740743282,
                0.0,
                1.0
            ]
        ]
    },
    "P12-1065": {
        "input_sentences": [
            "This paper introduces a novel variant of the Yarowsky algorithm based on this view.",
            "It is a bootstrapping learning method which uses a graph propagation algorithm with a well defined objective function.",
            "The experimental results show that our proposed bootstrapping algorithm achieves state of the art performance or better on several different natural language data sets.",
            "Abstract",
            "Bootstrapping via Graph Propagation",
            "Bootstrapping a classifier from a small set of seed rules can be viewed as the propagation of labels between examples via features shared between them."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.06202853837870771,
                0.04712410475653965,
                0.0,
                0.0,
                0.0
            ],
            [
                0.06202853837870771,
                1.0,
                0.0791079424249923,
                0.0,
                0.4340051276607553,
                0.08939464452404132
            ],
            [
                0.04712410475653965,
                0.0791079424249923,
                1.0,
                0.0,
                0.07717576400681965,
                0.02875535781961868
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.4340051276607553,
                0.07717576400681965,
                0.0,
                1.0,
                0.205976010020595
            ],
            [
                0.0,
                0.08939464452404132,
                0.02875535781961868,
                0.0,
                0.205976010020595,
                1.0
            ]
        ]
    },
    "N03-2024": {
        "input_sentences": [
            "The interpretation of the probabilistic data helps us gain insight on how extractive summaries can be rewritten in an efficient manner to produce more fluent and easy-to-read text.",
            "References To Named Entities: A Corpus Study",
            "References included in multi-document summaries are often problematic.",
            "In this paper, we present a corpus study performed to derive a statistical model for the syntactic realization of referential expressions.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.07145656434696325,
                0.0,
                0.0
            ],
            [
                0.0,
                1.0,
                0.14218783310364055,
                0.19477400403431264,
                0.0
            ],
            [
                0.07145656434696325,
                0.14218783310364055,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.19477400403431264,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "W07-0738": {
        "input_sentences": [
            "This happens, for instance, when the systems under evaluation are based on different paradigms, and therefore, do not share the same lexicon.",
            "Evaluation results recently reported by Callison-Burch et al. (2006) and Koehn and Monz (2006), revealed that, in certain cases, may not be a reliable MT quality indicator.",
            "The reason is that, while MT quality aspects are its scope to the lexical dimension.",
            "We provide experimental results showing that metrics based on deeper linguistic information (syntactic/shallow-semantic) are able to produce more reliable system rankings than metrics based on lexical matching alone, specially when the systems under evaluation are of a different nature.",
            "Abstract",
            "Linguistic Features for Automatic Evaluation of Heterogenous MT Systems",
            "In this work, we suggest using metrics which take into account linguistic features at more abstract levels."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.03235084027724377,
                0.0,
                0.22509696558712622,
                0.0,
                0.15312381600554087,
                0.0
            ],
            [
                0.03235084027724377,
                1.0,
                0.11295347379310383,
                0.08301301392464877,
                0.0,
                0.09478417291776964,
                0.0
            ],
            [
                0.0,
                0.11295347379310383,
                1.0,
                0.058417260878013307,
                0.0,
                0.09701075341553611,
                0.0
            ],
            [
                0.22509696558712622,
                0.08301301392464877,
                0.058417260878013307,
                1.0,
                0.0,
                0.13320926534069458,
                0.14059962537777904
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.30168867846139075
            ],
            [
                0.15312381600554087,
                0.09478417291776964,
                0.09701075341553611,
                0.13320926534069458,
                0.0,
                1.0,
                0.2025389465639417
            ],
            [
                0.0,
                0.0,
                0.0,
                0.14059962537777904,
                0.30168867846139075,
                0.2025389465639417,
                1.0
            ]
        ]
    },
    "P12-1045": {
        "input_sentences": [
            "It is especially important in language grounding where the training data usually consist of language paired with an ambiguous perceptual context.",
            "We show that by changing the grammar of the formal meaning representation language and training on additional data collected from Amazon\u2019s Mechanical Turk we can further improve the results.",
            "Recent work by Chen and Mooney (2011) introduced a lexicon learning method that deals with ambiguous relational data by taking intersections of graphs.",
            "In this paper we introduce a new online algorithm that is an order of magnitude faster and surpasses the stateof-the-art results.",
            "Learning a semantic lexicon is often an important first step in building a system that learns to interpret the meaning of natural language.",
            "We also include experimental results on a Chinese translation of the training data to demonstrate the generality of our approach.",
            "Abstract",
            "While the algorithm produced good lexicons for the task of learning to interpret navigation instructions, it only works in batch settings and does not scale well to large datasets.",
            "Fast Online Lexicon Learning for Grounded Language Acquisition"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.15239471782726993,
                0.09081099159419102,
                0.0,
                0.1601364399912852,
                0.09899579911530638,
                0.0,
                0.0,
                0.11211674720707095
            ],
            [
                0.15239471782726993,
                1.0,
                0.03154984018244059,
                0.04581770626716288,
                0.10932885751468788,
                0.14471321421626757,
                0.0,
                0.0,
                0.05247661000028495
            ],
            [
                0.09081099159419102,
                0.03154984018244059,
                1.0,
                0.0,
                0.08762483227557673,
                0.03846520854302776,
                0.0,
                0.029102950738360035,
                0.11332473028308848
            ],
            [
                0.0,
                0.04581770626716288,
                0.0,
                1.0,
                0.0,
                0.05586042960402971,
                0.0,
                0.05590657263004891,
                0.09544080659259756
            ],
            [
                0.1601364399912852,
                0.10932885751468788,
                0.08762483227557673,
                0.0,
                1.0,
                0.0,
                0.0,
                0.1008497138537648,
                0.20964255772223236
            ],
            [
                0.09899579911530638,
                0.14471321421626757,
                0.03846520854302776,
                0.05586042960402971,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.029102950738360035,
                0.05590657263004891,
                0.1008497138537648,
                0.0,
                0.0,
                1.0,
                0.04840671733749123
            ],
            [
                0.11211674720707095,
                0.05247661000028495,
                0.11332473028308848,
                0.09544080659259756,
                0.20964255772223236,
                0.0,
                0.0,
                0.04840671733749123,
                1.0
            ]
        ]
    },
    "P12-2002": {
        "input_sentences": [
            "The protocol uses distance-based metrics defined for the space of trees over lattices.",
            "Our metrics allow us to precisely quantify the performance gap between non-realistic parsing scenarios (assuming gold segmented and tagged input) and realistic ones (not assuming gold segmentation and tags).",
            "Our evaluation of segmentation and parsing for Modern Hebrew sheds new light on the performance of the best parsing systems to date in the different scenarios.",
            "We present novel metrics for parse evaluation in joint segmentation and parsing scenarios where the gold sequence of terminals is not known in advance.",
            "Joint Evaluation of Morphological Segmentation and Syntactic Parsing",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0343026816783137,
                0.0,
                0.05082834483312084,
                0.0,
                0.0
            ],
            [
                0.0343026816783137,
                1.0,
                0.13069902491299487,
                0.19353955310786689,
                0.074709320131906,
                0.0
            ],
            [
                0.0,
                0.13069902491299487,
                1.0,
                0.1767222002895234,
                0.22210472056362057,
                0.0
            ],
            [
                0.05082834483312084,
                0.19353955310786689,
                0.1767222002895234,
                1.0,
                0.2918272438750859,
                0.0
            ],
            [
                0.0,
                0.074709320131906,
                0.22210472056362057,
                0.2918272438750859,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "W07-0718": {
        "input_sentences": [
            "We carried out an extensive human evaluation which allowed us not only to rank the different MT systems, but also to perform higher-level analysis of the evaluation process.",
            "We measured the correlation of automatic evaluation metrics with human judgments.",
            "This meta-evaluation reveals surprising facts about the most commonly used methodologies.",
            "j schroeder ed ac uk Abstract This paper evaluates the translation quality of machine translation systems for 8 language pairs: translating French, German, Spanish, and Czech to English and back.",
            "We measured timing and intraand inter-annotator agreement for three types of subjective evaluation.",
            "Abstract",
            "(Meta-) Evaluation of Machine Translation"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.14510032787430022,
                0.05989765512164341,
                0.04205362625273956,
                0.056019209281393846,
                0.0,
                0.10304902942897998
            ],
            [
                0.14510032787430022,
                1.0,
                0.04628826363199768,
                0.0,
                0.1457322824055158,
                0.0,
                0.07963518157001334
            ],
            [
                0.05989765512164341,
                0.04628826363199768,
                1.0,
                0.0,
                0.03901457041881044,
                0.0,
                0.2415969704624687
            ],
            [
                0.04205362625273956,
                0.0,
                0.0,
                1.0,
                0.0,
                0.18643827309403618,
                0.3023281877399862
            ],
            [
                0.056019209281393846,
                0.1457322824055158,
                0.03901457041881044,
                0.0,
                1.0,
                0.0,
                0.06712138575512071
            ],
            [
                0.0,
                0.0,
                0.0,
                0.18643827309403618,
                0.0,
                1.0,
                0.0
            ],
            [
                0.10304902942897998,
                0.07963518157001334,
                0.2415969704624687,
                0.3023281877399862,
                0.06712138575512071,
                0.0,
                1.0
            ]
        ]
    },
    "W10-2009": {
        "input_sentences": [
            "Modeling the Noun Phrase versus Sentence Coordination Ambiguity in Dutch: Evidence from Surprisal Theory",
            "Surprisal Theory",
            "We find that our lexicalized surprisal model can account for the reading time data from a classic experiment on this ambiguity by Frazier (1987).",
            "This paper investigates whether surprisal theory can account for differential processing difficulty in the NP-/S-coordination ambiguity in Dutch.",
            "We argue that syntactic and lexical probabilities, as specified in a PCFG, are sufficient to account for what is commonly referred to as an NP-coordination preference.",
            "Surprisal is estimated using a Probabilistic Context-Free Grammar (PCFG), which is induced from an automatically annotated corpus.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.3059228145265822,
                0.08497937157663564,
                0.29006065251390634,
                0.05120454707740541,
                0.03015756710426531,
                0.0
            ],
            [
                0.3059228145265822,
                1.0,
                0.10179175492608217,
                0.30251313253882783,
                0.0,
                0.098579006442963,
                0.0
            ],
            [
                0.08497937157663564,
                0.10179175492608217,
                1.0,
                0.1372711146329025,
                0.04649414993561018,
                0.02738331899546577,
                0.0
            ],
            [
                0.29006065251390634,
                0.30251313253882783,
                0.1372711146329025,
                1.0,
                0.1705696530065279,
                0.029821444041626018,
                0.0
            ],
            [
                0.05120454707740541,
                0.0,
                0.04649414993561018,
                0.1705696530065279,
                1.0,
                0.0616275361755965,
                0.0
            ],
            [
                0.03015756710426531,
                0.098579006442963,
                0.02738331899546577,
                0.029821444041626018,
                0.0616275361755965,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P06-1012": {
        "input_sentences": [
            "Estimating Class Priors In Domain Adaptation For Word Sense Disambiguation",
            "This paper presents a method to estimate the sense priors of words drawn from a new domain, and highlights the importance of using well calibrated probabilities when performing these estimations.",
            "Instances of a word drawn from different domains may have different sense priors (the proportions of the different senses of a word).",
            "Abstract",
            "This in turn affects the accuracy of word sense disambiguation (WSD) systems trained and applied on different domains.",
            "By using well calibrated probabilities, we are able to estimate the sense priors effectively to achieve significant improvements in WSD accuracy."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.14936129809255017,
                0.1875959301142697,
                0.0,
                0.2009806056637076,
                0.08481891254557651
            ],
            [
                0.14936129809255017,
                1.0,
                0.09687471108506998,
                0.0,
                0.023546720785366973,
                0.2879163602518612
            ],
            [
                0.1875959301142697,
                0.09687471108506998,
                1.0,
                0.0,
                0.36047724524475894,
                0.055012963547699516
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.2009806056637076,
                0.023546720785366973,
                0.36047724524475894,
                0.0,
                1.0,
                0.1714943006580119
            ],
            [
                0.08481891254557651,
                0.2879163602518612,
                0.055012963547699516,
                0.0,
                0.1714943006580119,
                1.0
            ]
        ]
    },
    "J01-2004": {
        "input_sentences": [
            "This paper describes the functioning of a broad-coverage probabilistic top-down parser, and its application to the problem of language modeling for speech recognition",
            " A small recognition experiment also demonstrates the utility of the model",
            " A new language model that utilizes probabilistic top-down parsing is then outlined, and empirical results show that it improves upon previous work in test corpus perplexity",
            " A lexicalized probabilistic topdown parser is then presented, which performs very well, in terms of both the accuracy of returned parses and the efficiency with which they are found, relative to the best broad-coverage statistical parsers",
            " Interpolation with a trigram model yields an exceptional improvement relative to the improvement observed by other models, demonstrating the degree to which the information captured by our parsing model is orthogonal to that captured by a trigram model",
            " The paper first introduces key notions in language modeling and probabilistic parsing, and briefly reviews some previous approaches to using syntactic structure for language modeling"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.09431933278829903,
                0.07496673478971268,
                0.19448803060610512,
                0.0,
                0.266685428162317
            ],
            [
                0.09431933278829903,
                1.0,
                0.059817679129922065,
                0.0,
                0.1231431460008623,
                0.0
            ],
            [
                0.07496673478971268,
                0.059817679129922065,
                1.0,
                0.025706477820388058,
                0.1055666008163696,
                0.17556684056262953
            ],
            [
                0.19448803060610512,
                0.0,
                0.025706477820388058,
                1.0,
                0.033702023615509155,
                0.022842658362148653
            ],
            [
                0.0,
                0.1231431460008623,
                0.1055666008163696,
                0.033702023615509155,
                1.0,
                0.0234514994017299
            ],
            [
                0.266685428162317,
                0.0,
                0.17556684056262953,
                0.022842658362148653,
                0.0234514994017299,
                1.0
            ]
        ]
    },
    "N07-1050": {
        "input_sentences": [
            "Moreover, by restricting the class of permissible structures to limited degrees of non-projectivity, the parsing time can be reduced by up to 50% without a significant decrease in accuracy.",
            "Incremental Non-Projective Dependency Parsing",
            "An open issue in data-driven dependency parsing is how to handle non-projective dependencies, which seem to be required by linguistically adequate representations, but which pose problems in parsing with respect to both accuracy and efficiency.",
            "Using data from five different languages, we evaluate an incremental deterministic parser that derives non-projective depenstructures in supported by SVM classifiers for predicting the next parser action.",
            "Abstract",
            "The experiments show that unrestricted non-projective parsing gives a significant improvement in accuracy, compared to a strictly projective baseline, with up to 35% error reduction, leading to state-of-the-art results for the given data sets."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.11311588004763545,
                0.09915044379040928,
                0.01742879032958039,
                0.0,
                0.11150164598030597
            ],
            [
                0.11311588004763545,
                1.0,
                0.32088480980881284,
                0.2008221971370781,
                0.0,
                0.19560960416167852
            ],
            [
                0.09915044379040928,
                0.32088480980881284,
                1.0,
                0.06358639054604527,
                0.0,
                0.14531360531602286
            ],
            [
                0.01742879032958039,
                0.2008221971370781,
                0.06358639054604527,
                1.0,
                0.0,
                0.07736782028398499
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.11150164598030597,
                0.19560960416167852,
                0.14531360531602286,
                0.07736782028398499,
                0.0,
                1.0
            ]
        ]
    },
    "P12-1053": {
        "input_sentences": [
            "Strong Lexicalization of Tree Adjoining Grammars",
            "A more powerful model, the simple context-free tree grammar, admits such a normal form.",
            "Linguist., 2012) that finitely ambiguous tree adjoining grammars cannot be transformed into a normal form (preserving the generated tree language), in which each production contains a lexical symbol.",
            "Abstract",
            "it was shown Tree-adjoining grammars are not closed unstrong Comput.",
            "It can be effectively constructed and the maximal rank of the nononly increases by Thus, simple context-free tree grammars strongly lexicalize tree adjoining grammars and themselves."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.05519139536088405,
                0.18362100553732805,
                0.0,
                0.2517783560447331,
                0.2562760422343445
            ],
            [
                0.05519139536088405,
                1.0,
                0.17426826981755877,
                0.0,
                0.04265452719365379,
                0.2570656466468799
            ],
            [
                0.18362100553732805,
                0.17426826981755877,
                1.0,
                0.0,
                0.14191101933199168,
                0.15131514869205756
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.2517783560447331,
                0.04265452719365379,
                0.14191101933199168,
                0.0,
                1.0,
                0.19806227657571074
            ],
            [
                0.2562760422343445,
                0.2570656466468799,
                0.15131514869205756,
                0.0,
                0.19806227657571074,
                1.0
            ]
        ]
    },
    "W05-0602": {
        "input_sentences": [
            "It first usesan integrated statistical parser to pro duce a semantically augmented parse tree, in which each non-terminal node has both a syntactic and a semantic label.",
            "We present experimentalresults demonstrating that SCISSOR produces more accurate semantic representa tions than several previous approaches.",
            "A compositional-semantics procedure is then used to map the augmented parse tree into a final meaning representation.",
            "A Statistical Semantic Parser That Integrates Syntax And Semantics",
            "Abstract",
            "We introduce a learning semantic parser,SCISSOR, that maps natural-language sentences to a detailed, formal, meaning representation language.",
            "We evaluate the system in two domains, a natural-language database interface and an interpreter for coaching instructions in robotic soccer."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.03238272028101808,
                0.1851987912940994,
                0.20620154470123164,
                0.0,
                0.06790432215118136,
                0.0
            ],
            [
                0.03238272028101808,
                1.0,
                0.0,
                0.0579362340329072,
                0.0,
                0.09564738235256108,
                0.0
            ],
            [
                0.1851987912940994,
                0.0,
                1.0,
                0.11044697523775734,
                0.0,
                0.12951252565990962,
                0.0
            ],
            [
                0.20620154470123164,
                0.0579362340329072,
                0.11044697523775734,
                1.0,
                0.0,
                0.12148827108582502,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.06790432215118136,
                0.09564738235256108,
                0.12951252565990962,
                0.12148827108582502,
                0.0,
                1.0,
                0.1822556467099789
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.1822556467099789,
                1.0
            ]
        ]
    },
    "P13-1126": {
        "input_sentences": [
            "Experiments on large scale NIST evaluation data show improvements over strong baselines: +1.8 BLEU on Arabic to English and +1.4 BLEU on Chinese to English over a non-adapted baseline, and significant improvements in most circumstances over baselines with linear mixture model adaptation.",
            "The general idea is first to create a vector profile for the in-domain development (\u201cdev\u201d) set.",
            "An informal analysis suggests that VSM adaptation may help in making a good choice among words with the same meaning, on the basis of style and genre.",
            "Vector Space Model for Adaptation in Statistical Machine Translation",
            "Then, for each phrase pair extracted from the training data, we create a vector with features defined in the same way, and calculate its similarity score with the vector representing the dev set.",
            "This is a simple, computationally cheap form of instance weighting for phrase pairs.",
            "Abstract",
            "Thus, we obtain a decoding feature whose value represents the phrase pair\u2019s closeness to the dev.",
            "This profile might, for instance, be a vector with a dimensionality equal to the number of training subcorpora; each entry in the vector reflects the contribution of a particular subcorpus to all the phrase pairs that can be extracted from the dev set.",
            "This paper proposes a new approach to domain adaptation in statistical machine translation (SMT) based on a vector space model (VSM)."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.021072560990227845,
                0.08415434681393984,
                0.034449902594650764,
                0.0,
                0.0,
                0.0,
                0.0,
                0.050667601739392644
            ],
            [
                0.0,
                1.0,
                0.0,
                0.0671635794852781,
                0.25840313958025823,
                0.0,
                0.0,
                0.06216665349451435,
                0.241100164943486,
                0.12330983538159684
            ],
            [
                0.021072560990227845,
                0.0,
                1.0,
                0.05857638918075465,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.09355898246472097
            ],
            [
                0.08415434681393984,
                0.0671635794852781,
                0.05857638918075465,
                1.0,
                0.09345508731604048,
                0.0,
                0.0,
                0.0,
                0.0871972260217332,
                0.602079436863976
            ],
            [
                0.034449902594650764,
                0.25840313958025823,
                0.0,
                0.09345508731604048,
                1.0,
                0.04544084608653521,
                0.0,
                0.15798863050399087,
                0.2971124592169028,
                0.056267386343315365
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.04544084608653521,
                1.0,
                0.0,
                0.060465180825283425,
                0.1825515253287597,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.06216665349451435,
                0.0,
                0.0,
                0.15798863050399087,
                0.060465180825283425,
                0.0,
                1.0,
                0.08070980994936608,
                0.0
            ],
            [
                0.0,
                0.241100164943486,
                0.0,
                0.0871972260217332,
                0.2971124592169028,
                0.1825515253287597,
                0.0,
                0.08070980994936608,
                1.0,
                0.05249965673926596
            ],
            [
                0.050667601739392644,
                0.12330983538159684,
                0.09355898246472097,
                0.602079436863976,
                0.056267386343315365,
                0.0,
                0.0,
                0.0,
                0.05249965673926596,
                1.0
            ]
        ]
    },
    "P13-2073": {
        "input_sentences": [
            "Although pivoting is a robust technique, it introduces some low quality translations.",
            "Language Independent Connectivity Strength Features for Phrase Pivot Statistical Machine Translation",
            "An important challenge to statistical machine translation (SMT) is the lack of parallel data for many language pairs.",
            "We show positive results (0.6 BLEU points) on Persian-Arabic SMT as a case study.",
            "In this paper, we present two language-independent features to improve the quality of phrase-pivot based SMT.",
            "The features, source connectivity strength and target connectivity strength reflect the quality of projected alignments between the source and target phrases in the pivot phrase table.",
            "Abstract",
            "One common solution is to pivot through a third language for which there exist parallel corpora with the source and target languages."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0,
                0.0,
                0.07428813551794945,
                0.047988814491602215,
                0.0,
                0.0
            ],
            [
                0.0,
                1.0,
                0.3447612208851409,
                0.0,
                0.3760183457789695,
                0.4051584109751667,
                0.0,
                0.11609226842955357
            ],
            [
                0.0,
                0.3447612208851409,
                1.0,
                0.0606165007200394,
                0.11355005877486495,
                0.0,
                0.0,
                0.13286065876893433
            ],
            [
                0.0,
                0.0,
                0.0606165007200394,
                1.0,
                0.06499006365859616,
                0.0,
                0.0,
                0.0
            ],
            [
                0.07428813551794945,
                0.3760183457789695,
                0.11355005877486495,
                0.06499006365859616,
                1.0,
                0.16756985182876785,
                0.0,
                0.10371270638964286
            ],
            [
                0.047988814491602215,
                0.4051584109751667,
                0.0,
                0.0,
                0.16756985182876785,
                1.0,
                0.0,
                0.2675773871890108
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.11609226842955357,
                0.13286065876893433,
                0.0,
                0.10371270638964286,
                0.2675773871890108,
                0.0,
                1.0
            ]
        ]
    },
    "N06-1037": {
        "input_sentences": [
            "It also shows that our method significantly outperforms the previous two dependency tree kernels on the 5 ACE relation major types.",
            "Our study reveals that the syntactic structure features embedded in a parse tree are very effective for relation extraction and these features can be well captured by the convolution tree kernel.",
            "This paper proposes to use a convolution kernel over parse trees to model syntactic structure information for relation extraction.",
            "Abstract",
            "Exploring Syntactic Features For Relation Extraction Using A Convolution Tree Kernel",
            "Evaluation on the ACE 2003 corpus shows that the convolution kernel over parse trees can achieve comparable performance with the previous best-reported feature-based methods on the 24 ACE relation subtypes."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.10975301996478112,
                0.028405861902009347,
                0.0,
                0.1053847275547428,
                0.21593527758551817
            ],
            [
                0.10975301996478112,
                1.0,
                0.2920669372368839,
                0.0,
                0.5269466286923327,
                0.09275538126828375
            ],
            [
                0.028405861902009347,
                0.2920669372368839,
                1.0,
                0.0,
                0.28883772217176423,
                0.16362586876355223
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.1053847275547428,
                0.5269466286923327,
                0.28883772217176423,
                0.0,
                1.0,
                0.09800488039611684
            ],
            [
                0.21593527758551817,
                0.09275538126828375,
                0.16362586876355223,
                0.0,
                0.09800488039611684,
                1.0
            ]
        ]
    },
    "W12-3407": {
        "input_sentences": [
            "For example the non-clausal modifier (ncmod) relation\u2019s f-score increases 3.25 points, while the dependency relation for clausal subordinate sentences functioning as indirect object decreases 0.46 points, which is surprising in principle.",
            "In the following experiments we will make use of the second order non-projective algorithm.",
            "The erroneous assignment of incorrect part of speech or morphological features can difficult the work of the parser.",
            "Looking with more detail at the errors made by the different versions of the parsers, we observe significant differences in the results for different dependency relations, seeing that the statistical parsers behave in a different manner regarding to each relation, as shown in table 2.",
            "As table 1 shows, the parser type is relevant, as MaltParser seems to be sensitive when using the stacked features, while the partial parsers do not seem to give any significant improvement to MST.",
            "Regarding the data-driven parsers, they are trained using two kinds of tags as input: syntactic analyzers (two last lines of the example in figure 1).",
            "McDonald and Nivre (2007) examined the types of errors made by the two data-driven parsers used in this work, showing how the greedy algorithm of MaltParser performed better with local dependency relations, while the graph-based algorithm of MST was more accurate for global relations.",
            "We have performed three experiments for each statistical parser, trying with the chunks provided by the chunker, the partial dependency parser, and both.",
            "This means that the result of this analysis is on the one hand a partial analysis and, on the other hand, it does not define a dependency tree, and can also be seen as a set of constraints on the shape of the tree.",
            "We performed an additional test using the partial dependency analyzer\u2019s gold dependency relations as input to MaltParser.",
            "To determine the best action at each step, the parser uses history-based feature models and discriminative machine learning.",
            "In the last years, many attempts have been performed trying to combine different parsers (Surdeanu and Manning, 2010), with significant improvements over the best individual parser\u2019s baseline.",
            "Several variants of the parser have been implemented, and we will use one of its standard versions (MaltParser version 1.4).",
            "We must take into account that this evaluation was performed on the gold POS tags, rather than on automatically assigned POS tasks, as in the present experiment.",
            "The two most successful approaches have been stacking (Martins et al., 2008) and voting (Sagae and Lavie, 2006, Nivre and McDonald, 2008, McDonald and Nivre, 2011).",
            "The learning configuration can include any kind of information (such as word-form, lemma, category, subcategory or morphological features).",
            "However, when examining the scores for the output dependency relations, we noticed that the gold partial dependency tags are beneficial for some relations, although negative for some others.",
            "The evaluation of the chunker on the BDT gave a result of 87% precision and 85% recall over all chunks.",
            "Each word contains its form, lemma, category or coarse part of speech (CPOS), POS, morphosyntactic features such as case, number of subordinate relations, and the dependency relation (headword + dependency).",
            "As it was successfully done on part of speech (POS) tagging, where the use of rule-based POS taggers (Tapanainen and Voutilainen, 1994) or a combination of a rulebased POS tagger with a statistical one (Aduriz et al., 1997, Ezeiza et al., 1998) outperformed purely statistical taggers, we think that exploring the combination of knowledge-based and data-driven systems in syntactic processing can be an interesting line of research.",
            "2 f-score = 2 * precision * recall / (precision + recall) (ncmod = non-clausal modifier, ncobj = non-clausal object, ncpred = non-clausal predicate, ncsubj = non-clausal subject, nciobj = non-clausal indirect object) Table 2 shows how the addition of the rule-based parsers\u2019 tags performs in accord with this behavior, as MaltParser gets f-score improvements for the local relations.",
            "For example, this analyzer assigns tags of the form &NCSUBJ> (see figure 1), meaning that the corresponding wordform is a non-clausal syntactic subject and that its head is situated to its right (the \u201c>\u201d or \u201c<\u201d symbols mark the direction of the head).",
            "This algorithm finds the highest scoring directed spanning tree in a dependency graph forming a valid dependency tree.",
            "The learning procedure is global since model parameters are set relative to classifying the entire dependency graph, and not just over single arc attachments.",
            "Morphologically rich languages present new challenges, as the use of state of the art parsers for more configurational and non-inflected languages like English does not reach similar performance levels in languages like Basque, Greek or Turkish (Nivre et al., 2007a).",
            "The MST Parser can be considered a representative of global, exhaustive graph-based parsing (McDonald et al., 2005, 2006).",
            "The general idea will be to apply a stacked scheme where the output of the rule-based partial parsers will be given as input to MaltParser and MST, two state of the art statistical parsers.",
            "We can point out some avenues for further research: schemes, such as voting, trying to get the best from each type of parser.",
            "The table shows modest gains, suggesting that the rule-based analyzers help the statistical ones, giving slight increases over the baseline, which are statistically significant when applying MaltParser to the output of the rule-based dependency parser and a combination of the chunker and rule-based parsers.",
            "To learn arc scores, it uses large-margin structured learning algorithms, which optimize the parameters of the model to maximize the score margin between the correct dependency graph and all incorrect dependency graphs for every sentence in a training set.",
            "As each type of syntactic information can have an important influence on the results on specific relations, their study can shed light on novel schemes of parser combination.",
            "The system was evaluated on the BDT, obtaining f-scores between 90% for the auxmod dependency relation between the auxiliary and the main verb and 52% for the subject dependency relation, giving a (macro) average of 65%.",
            "The chunker delimits the chunks with three tags, using a standard IOB marking style (see figure 1).",
            "Regarding the data-driven parsers, we have made use of MaltParser (Nivre et al., 2007b) and MST Parser (McDonald et al., 2006), two state of the art dependency parsers representing two dominant approaches in data-driven dependency parsing, and that have been successfully applied to typologically different languages and treebanks (McDonald and Nivre, 2007).",
            "Although not shown in Table 2, we also inspected the results on the long distance relations, where we did not observe noticeable improvements with respect to the baseline on any parser.",
            "The first one is to mark the beginning of the phrase (B-VP if it is a verb phrase and B-NP whether it's a noun phrase) and the other one to mark the continuation of the phrase (I-NP or I-VP, meaning that the word is inside an NP or VP).",
            "Our work will make use the second version of the Basque dependency Treebank (BDT II, Aduriz et al., 2003), containing 150,000 tokens (11,225 sentences).",
            "This paper presents the results of a set of preliminary experiments combining two knowledge-based partial dependency analyzers with two statistical parsers, applied to the Basque Dependency Treebank.",
            "The first step consisted in applying the complete set of text processing tools for Basque, including: properties, such as case, number, tense, or different types of subordination for verbs.",
            "Yeh (2000) used the output of several baseline diverse parsers to increase the performance of a second transformation-based parser.",
            "For all those reasons, the relation between the input dependency tags and the obtained results seems to be intricate, and we think that it deserves new experiments in order to determine their nature.",
            "In this paper we present a set of preliminary experiments on the combination of two knowledge-based partial syntactic analyzers with two state of the art data-driven statistical parsers.",
            "In this paper we will experiment the use of the stacking technique, giving the tags obtained by the rulebased syntactic partial parsers as input to the statistical parsers.",
            "The experiments have been performed on the Basque Dependency Treebank (Aduriz et al., 2003).",
            "Consequently, the morphological analyzer for Basque (Aduriz et al. 2000) gives a high ambiguity.",
            "Although the potential gain is in theory high, the experiments have shown very modest improvements, which seem to happen in the set of local dependency relations.",
            "The last two lines of the sentence in figure 1 do not properly correspond to the treebank, but are the result of the rule-based partial syntactic analyzers (see subsection 2.2).",
            "MaltParser (Nivre, 2006) is a representative of local, greedy, transition-based dependency parsing models, where the parser obtains deterministically a dependency tree in a single pass over the input using two data structures: a stack of partially analyzed items and the remaining input sequence.",
            "For evaluation, we divided the treebank in three sets, corresponding to training, development, and test (80%, 10%, and 10%, respectively).",
            "First, subsection 2.1 will describe the Basque Dependency Treebank, and then subsection 2.2 will explain the main details of the analyzers that have been employed.",
            "Abstract",
            "The analyzers are a rulebased chunker, a rule-based shallow dependency parser and two state of the art data-driven dependency parsers, MaltParser and MST.",
            "For that reason, the results can serve as an upper bound on the real results.",
            "As both the chunker and the partial dependency analyzer are based on a set of local rules in the CG formalism, we could expect that the stacked parsers could benefit mostly on the local dependency relations.",
            "This section will describe the main resources that have been used in the experiments.",
            "The last tag marks words that are outside a chunk.",
            "We use the freely available version of MSTParser1.",
            "The rule-based analyzers are based on the Contraint Grammar (CG) formalism (Karlsson et al., 1995), based on the assignment of morphosyntactic tags to words using a formalism that has the capabilities of finite state automata or regular expressions, by means of a set of rules that examine mainly local contexts of words to determine the correct tag assignment.",
            "In the rest of this paper, section 2 will first present the corpus and the different parsers we will combine, followed by the experimental results in section 3, and the main conclusions of the work.",
            "As could be expected, the gold tags gave a noticeable improvement to the parser\u2019s results, reaching 95% LAS.",
            "If only categorial (POS) ambiguity is taken into account, there is an average of 1.55 interpretations per wordform, which rises to 2.65 when the full morphosyntactic information is taken into account, giving an overall 64% of ambiguous word-forms. can pose an important problem, as determining the correct interpretation for each word-form requires in many cases the inspection of local contexts, and in some others, as the agreement of verbs with subject, object or indirect object, it could also suppose the examination of elements which can be far from each other, added to the free constituent order of the main sentence elements in Basque.",
            "This means that there is room for improvement in the first-stage knowledge-based parsers, which will have, at least in theory, a positive effect on the second-phase statistical parsers, allowing us to test whether knowledge-based and machine learningbased systems can be successfully combined.",
            "Table 1 shows the results of using the output of the knowledge-based analyzers as input to the statistical parsers.",
            "In our work we will study the use of two partial rule-based syntactic analyzers together with two data-driven parsers: set of predefined tags to each word, where each tag gives both the name of a dependency relation (e.g. subject) together with the direction of its head (left or right).",
            "Figure 1 presents an example of a syntactically annotated sentence.",
            "These tags contain errors of the CG-based syntactic taggers.",
            "In our experiments, we will use the StackLazy algorithm with the liblinear classifier.",
            "This subsection will present the four types of analyzers that have been used.",
            "For that reason, MaltParser, seems to mostly benefit of the local nature of the stacked features, while MST does not get a significant improvement, except for some local dependency relations, such as ncobj and ncsubj.",
            "For that reason, we performed a matching process trying to link the multiword units given by the morphological analysis module and the treebank, obtaining a correct match for 99% of the sentences.",
            "Most of the experiments on combined parsers have relied on different types of statistical parsers (Sagae and Lavie, 2006, Martins et al., 2008, McDonald and Nivre, 2011), trained on an automatically annotated treebank.",
            "The experiments were performed on the development set, leaving the best system for the final test.",
            "The rule-based dependency analyzer (RBDA, Aranzabe et al., 2004) uses a set of 505 CG rules that try to assign dependency relations to wordforms.",
            "Finally, we must also take into account that the rule-based analyzers were developed mainly having linguistic principles in mind, such as coverage of diverse linguistic phenomena or the treatment of specific syntactic constructions (Aranzabe et al., 2004), instead of performanceoriented measures, such as precision and recall.",
            "The information in figure 1 has been simplified due to space reasons, as typically each word contains many morphosyntactic features (case, number, type of subordinated sentence, ...), which are relevant for parsing.",
            "Combining Rule-Based and Statistical Syntactic Analyzers",
            "We have presented a preliminary effort to integrate different syntactic analyzers, with the objective of getting the best from each system.",
            "The table shows the differences in f-score2 corresponding to five local dependency relations, (determination of verbal modifiers, such as subject, object and indirect object).",
            "The rule-based chunker (RBC henceforth, Aranzabe et al., 2009) uses 560 rules, where 479 of the rules deal with noun phrases and the rest with verb phrases.",
            "When performing this task, we found the problem of matching the treebank tokens with those obtained from the analyzers, as there were divergences on the treatment of multiword units, mostly coming from Named Entities, verb compounds and complex postpositions (formed with morphemes appearing at two different words).",
            "We will experiment the effect of using the output of the knowledge-based analyzers as input to the data-driven parsers in a stacked learning scheme.",
            "Figure 1 shows how the two last lines of the example sentence contain the tags assigned by the rule-based chunker (B-NP, I-NP, B-VP and I-VP) and the rule-based partial dependency analyzer (&NCSUBJ, &<NCMOD, &<AUXMOD, &CCOMP_OBJ and &MAINV) .",
            "This is in contrast to the local but richer contexts used by transition-based parsers.",
            "The results show a modest improvement over the baseline, although they also present interesting lines for further research.",
            "As the CG formalism only allows the assignment of tags, the rules only aim at marking the name of the dependency relation together with the direction of the head (left or right).",
            "As the analyzers are applied after morphological processing, the errors can be propagated and augmented."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.05009811996264711,
                0.0,
                0.06187337273150777,
                0.0,
                0.046152110910846075,
                0.009350618933167309,
                0.01639774363648867,
                0.009504634516703211,
                0.032086028091160394,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.02676260525387232,
                0.0,
                0.12929958606690042,
                0.0,
                0.41455739125180197,
                0.13942917561219328,
                0.022951019191831613,
                0.011521492333565845,
                0.022687342531579443,
                0.0,
                0.0,
                0.0,
                0.04879980097152704,
                0.05128159616625581,
                0.0,
                0.13045262504797064,
                0.0,
                0.015298620750852913,
                0.0,
                0.0,
                0.050476865656133144,
                0.027000289779039767,
                0.0,
                0.0,
                0.08058154556533521,
                0.0,
                0.0,
                0.019454123005826697,
                0.0,
                0.013587893813395131,
                0.0,
                0.01706532629139019,
                0.0,
                0.014092401780238746,
                0.0,
                0.029385087974879636,
                0.0,
                0.026025014244587048,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.05796206289158036,
                0.0,
                0.0,
                0.07112152764399013,
                0.060391028018345574,
                0.0,
                0.0,
                0.0,
                0.01250690249378372,
                0.04090948974590364,
                0.0,
                0.0,
                0.023184338446115803,
                0.0,
                0.0,
                0.0,
                0.0,
                0.1346756229057693,
                0.0,
                0.0,
                0.0,
                0.07231594629042616,
                0.0,
                0.0,
                0.0818410622259356,
                0.0
            ],
            [
                0.05009811996264711,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.12309499730505728,
                0.06449091820961751,
                0.0,
                0.0,
                0.0,
                0.0,
                0.070285388962023,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.026647772848641678,
                0.1519007967289927,
                0.058906698034624054,
                0.07553392095644607,
                0.0,
                0.07265124331481519,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.031865938849925994,
                0.0,
                0.0,
                0.197513502147482,
                0.05309491105536313,
                0.0,
                0.08873461797748766,
                0.14270199084993535,
                0.05597850373290252,
                0.056404980084154926,
                0.07651139592259563,
                0.0,
                0.05344002004096941,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.08433677581065835,
                0.0,
                0.08106830856982448,
                0.0,
                0.0,
                0.0,
                0.040793337061553483,
                0.06173795630134331,
                0.0,
                0.04643714847170894,
                0.0,
                0.0,
                0.2754988942974337,
                0.0,
                0.0,
                0.0,
                0.04133520720555199,
                0.06760182080007537,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.11838718762354715,
                0.0,
                0.05558979741400192,
                0.10010514465440658,
                0.0,
                0.0,
                0.03904300662326613,
                0.03582369935090507,
                0.05149948982365258,
                0.0,
                0.0,
                0.14847887653462627,
                0.0,
                0.0,
                0.13946346013391914,
                0.046885209864025335,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.04096032831216309,
                0.0,
                0.04703903158088074,
                0.02721113971421758,
                0.07295837934154609,
                0.036887110617405454,
                0.0,
                0.0,
                0.023348801475789178,
                0.037819196153090956,
                0.0,
                0.061191176947192935,
                0.0,
                0.0,
                0.04114957408552755,
                0.0,
                0.0,
                0.0,
                0.0,
                0.08710931133032972,
                0.0,
                0.0,
                0.026045152840004922,
                0.0,
                0.0,
                0.0,
                0.04484761055573021,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.10540544180766166,
                0.06656358109736414,
                0.04282729962462285,
                0.0,
                0.0,
                0.0,
                0.066269827632426,
                0.0,
                0.0,
                0.0,
                0.0,
                0.06824579175336307,
                0.062295852388900966,
                0.0,
                0.0,
                0.0,
                0.0,
                0.06060814683806853,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.09401792700408025,
                0.10534311847851176
            ],
            [
                0.06187337273150777,
                0.0,
                0.0,
                1.0,
                0.13375082239266092,
                0.10719695514792806,
                0.11563797167390595,
                0.05640045654919198,
                0.010992117173916181,
                0.07188668765046403,
                0.0,
                0.17836306077375688,
                0.08729981722108124,
                0.0,
                0.0,
                0.0,
                0.08896882686505654,
                0.0,
                0.08280856233511524,
                0.029207681454473056,
                0.04128466260914045,
                0.0,
                0.02654287145645221,
                0.013324614799903023,
                0.020347114427177255,
                0.0,
                0.09731495644200325,
                0.0,
                0.11636153371327856,
                0.02009021539622082,
                0.05705630109855534,
                0.08725731077110613,
                0.0,
                0.16219236595131378,
                0.2170963116692882,
                0.0,
                0.011903645954619154,
                0.13486016177150906,
                0.08995253296361445,
                0.03828575784136009,
                0.08615005775529203,
                0.07291736693316771,
                0.1078172207575075,
                0.022498708311195426,
                0.0,
                0.10652164666860112,
                0.0,
                0.019736063062332145,
                0.0,
                0.016297873564529226,
                0.0,
                0.07571030540091968,
                0.08007395875111498,
                0.09526254399516909,
                0.0,
                0.0,
                0.0,
                0.0,
                0.15774744434154933,
                0.0358278069079142,
                0.0,
                0.0746891157545421,
                0.19960389423418115,
                0.07922925971644147,
                0.0,
                0.08166685275988227,
                0.0,
                0.0,
                0.08738024357690326,
                0.0,
                0.17508169827848918,
                0.0,
                0.05194302303555382,
                0.0,
                0.0,
                0.058077710465484246,
                0.12617680160183803,
                0.13636447157381157,
                0.0,
                0.07638249112002939,
                0.04177533187292635,
                0.010362599241843368,
                0.05026102926141349,
                0.04481954610327172,
                0.05474194940776308,
                0.07149223826595646
            ],
            [
                0.0,
                0.0,
                0.11838718762354715,
                0.13375082239266092,
                1.0,
                0.09029996279967142,
                0.09312736379396522,
                0.13947201884690044,
                0.029561616228169958,
                0.17209953278677617,
                0.03450554965203611,
                0.11723350737144916,
                0.10386856022443597,
                0.0,
                0.0,
                0.06280110281683064,
                0.04161895254313242,
                0.0,
                0.05260046189755393,
                0.0,
                0.07516560843037699,
                0.0,
                0.0,
                0.0,
                0.014595948373574294,
                0.09609657972964743,
                0.24883159000308736,
                0.13077602959499074,
                0.20266367995591178,
                0.0,
                0.10255206596847186,
                0.0,
                0.061475065120503346,
                0.11240201556319773,
                0.0887272038138787,
                0.0,
                0.0,
                0.06949171029806189,
                0.0,
                0.06383148486328492,
                0.0,
                0.07326581563098605,
                0.0972799236505798,
                0.0,
                0.0,
                0.0,
                0.04601373206284602,
                0.0880128392282774,
                0.0,
                0.0,
                0.0,
                0.18596575523480294,
                0.0,
                0.1353509485099125,
                0.0,
                0.0,
                0.0,
                0.02990104660269151,
                0.02281001916957183,
                0.11156893781442442,
                0.0,
                0.08749829270886474,
                0.2864580427918123,
                0.05737935724892242,
                0.0,
                0.0,
                0.0,
                0.0,
                0.3565356544084206,
                0.0,
                0.04282322304571056,
                0.0,
                0.0,
                0.0,
                0.2003136810844977,
                0.0,
                0.0,
                0.10907018667976667,
                0.0,
                0.0,
                0.16842435798925898,
                0.07107965060467264,
                0.03605461555386118,
                0.09222019573068417,
                0.0,
                0.0
            ],
            [
                0.046152110910846075,
                0.0,
                0.0,
                0.10719695514792806,
                0.09029996279967142,
                1.0,
                0.09883764752633056,
                0.0,
                0.0,
                0.13977256695287038,
                0.0,
                0.02504638623229811,
                0.0,
                0.039902311226314956,
                0.0,
                0.0,
                0.041495633366904955,
                0.0,
                0.0,
                0.07591125922857209,
                0.02662034700686726,
                0.1647734670410053,
                0.0,
                0.0,
                0.015289932416694678,
                0.0,
                0.10539827998240892,
                0.0,
                0.04313501196227776,
                0.0,
                0.04146442698165689,
                0.0,
                0.17936329060768852,
                0.21361541191122008,
                0.0,
                0.0,
                0.0,
                0.06532267028920259,
                0.0,
                0.028770008249152237,
                0.09418273073882419,
                0.23778080917729869,
                0.20521766517505732,
                0.0,
                0.0,
                0.0,
                0.249657590963697,
                0.146321727682257,
                0.0,
                0.03811365661675679,
                0.0,
                0.19503948591364834,
                0.0,
                0.027770131209193468,
                0.0,
                0.0,
                0.0,
                0.07306715817141998,
                0.023894552282583692,
                0.04350932917857552,
                0.0,
                0.04003401496642667,
                0.2507338878161528,
                0.22078931724742626,
                0.1941391469986114,
                0.13222010088725733,
                0.0,
                0.06389874556632737,
                0.0,
                0.0,
                0.1265911181741167,
                0.0,
                0.0,
                0.04958476394009215,
                0.05193482937790413,
                0.15608648103611256,
                0.08903308454047115,
                0.0,
                0.0,
                0.023757181523374884,
                0.32342487793342967,
                0.17333232401129195,
                0.03776888085782185,
                0.10643042629061492,
                0.039777299413508854,
                0.04792333555107574
            ],
            [
                0.009350618933167309,
                0.12309499730505728,
                0.05558979741400192,
                0.11563797167390595,
                0.09312736379396522,
                0.09883764752633056,
                1.0,
                0.06411380170896841,
                0.010598829011922644,
                0.18497825549186275,
                0.015756253678318555,
                0.04886930776363939,
                0.03921832391543736,
                0.03596199952119993,
                0.1339250125749039,
                0.0,
                0.14172762754979343,
                0.0,
                0.06992520653624074,
                0.050380387885975805,
                0.05882415991945388,
                0.0,
                0.15540159418629768,
                0.10369134264886026,
                0.033030372127850885,
                0.20997463835345134,
                0.11358780230063295,
                0.0,
                0.07581285624799938,
                0.050042279092978655,
                0.050521021972950705,
                0.02280002476522079,
                0.0,
                0.3033045376877189,
                0.051797617321321994,
                0.0,
                0.047823319755149,
                0.06522269098715057,
                0.040244161902271564,
                0.08266802538279285,
                0.014083742920725468,
                0.11405651640432546,
                0.03707692979689154,
                0.07606398858694066,
                0.0,
                0.10541359665934807,
                0.018224126681920305,
                0.16294421285454128,
                0.0,
                0.01571475016462526,
                0.0,
                0.2287321995100864,
                0.0,
                0.18134508227402674,
                0.07572163869551385,
                0.0,
                0.0,
                0.0442761901570429,
                0.05486662882006975,
                0.0,
                0.013635762544877842,
                0.048792707242292024,
                0.048126416093878334,
                0.14111776714189708,
                0.0,
                0.10367879521868426,
                0.1460089577166157,
                0.17534225747008292,
                0.19441239679359035,
                0.029285603907317,
                0.14084444620727654,
                0.04803897250607029,
                0.08859534791153502,
                0.009954830318041303,
                0.0,
                0.03133652981653753,
                0.0,
                0.09112125002353051,
                0.01156304933827042,
                0.0,
                0.11787426035619741,
                0.03206704195469646,
                0.1521002888746637,
                0.0,
                0.014303876559610362,
                0.06893430965770411
            ],
            [
                0.01639774363648867,
                0.06449091820961751,
                0.10010514465440658,
                0.05640045654919198,
                0.13947201884690044,
                0.0,
                0.06411380170896841,
                1.0,
                0.05342753871440818,
                0.2001822647444484,
                0.08133542291131243,
                0.21221666546309453,
                0.10728509781384266,
                0.06306487870150207,
                0.0,
                0.0,
                0.10138674312548984,
                0.17907284423696418,
                0.042659321496998054,
                0.049387535390929015,
                0.0,
                0.0,
                0.04488158382156195,
                0.022530712888883753,
                0.0,
                0.08532963810913831,
                0.09197548310687544,
                0.2031270988690062,
                0.1522255151944839,
                0.03397072874267087,
                0.07684420339326963,
                0.03998333839480332,
                0.18531670739343742,
                0.0785578701034523,
                0.07878594860684959,
                0.0,
                0.02012798368748331,
                0.20943437023995104,
                0.0,
                0.08572387990407233,
                0.0761814673004347,
                0.1651411168248263,
                0.10190150958267497,
                0.21269180213082556,
                0.0,
                0.08196073658468274,
                0.0542310786931423,
                0.08762983983358885,
                0.0,
                0.02755822329546134,
                0.0,
                0.2229009950081997,
                0.0,
                0.16236806489997538,
                0.08741272752697264,
                0.0,
                0.0,
                0.0,
                0.0,
                0.08921896207251652,
                0.0,
                0.03620871194908723,
                0.0714285243010549,
                0.0626600669126588,
                0.0,
                0.0,
                0.07649581182115923,
                0.0,
                0.024457719630274044,
                0.1228446275845207,
                0.08341573958948426,
                0.15431111318902094,
                0.04533784842492507,
                0.0,
                0.0,
                0.09820413118066786,
                0.0,
                0.022968962559080063,
                0.046005936689142074,
                0.0,
                0.0,
                0.09428309100845281,
                0.0,
                0.0,
                0.025084040159149272,
                0.0
            ],
            [
                0.009504634516703211,
                0.0,
                0.0,
                0.010992117173916181,
                0.029561616228169958,
                0.0,
                0.010598829011922644,
                0.05342753871440818,
                1.0,
                0.07045633893775129,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.05876686205182084,
                0.06321477688957719,
                0.024726649504219864,
                0.0,
                0.0,
                0.0,
                0.22914244595652672,
                0.03883996787253569,
                0.031704857425377424,
                0.0,
                0.0259662563751412,
                0.0,
                0.010104665700071288,
                0.039125758255192995,
                0.0,
                0.02317556772595388,
                0.0,
                0.01734082702070053,
                0.0,
                0.0,
                0.011666795917091128,
                0.08949669028783026,
                0.02314734047357215,
                0.0,
                0.014315718568520415,
                0.062090584750866845,
                0.028768543892974122,
                0.022051045475106883,
                0.0,
                0.04580598970067243,
                0.09690241995274572,
                0.09486159659314346,
                0.0,
                0.015973590401194056,
                0.0,
                0.03330769066433956,
                0.0,
                0.08626398674403453,
                0.0,
                0.0,
                0.0,
                0.04790856867145094,
                0.0,
                0.0,
                0.0,
                0.04150681317891562,
                0.0,
                0.061262385607661195,
                0.0,
                0.0,
                0.0,
                0.0,
                0.06952253468447697,
                0.10628175380464995,
                0.0,
                0.03846149227677422,
                0.052217828787877035,
                0.0,
                0.0,
                0.0,
                0.0,
                0.013313514297546625,
                0.0,
                0.0,
                0.0,
                0.029194688810233318,
                0.0,
                0.0,
                0.01453947806480481,
                0.0
            ],
            [
                0.032086028091160394,
                0.0,
                0.0,
                0.07188668765046403,
                0.17209953278677617,
                0.13977256695287038,
                0.18497825549186275,
                0.2001822647444484,
                0.07045633893775129,
                1.0,
                0.0,
                0.056276037650823105,
                0.06728753742575573,
                0.14758685769328506,
                0.0,
                0.0,
                0.3356929970787832,
                0.0,
                0.12259064549961267,
                0.0,
                0.03851617157831185,
                0.05482714205860478,
                0.08782133634958916,
                0.044086619640639556,
                0.0,
                0.0,
                0.15116834464974355,
                0.0,
                0.06966481025403111,
                0.066471691525233,
                0.04333988321533345,
                0.07823677131158921,
                0.07088619294510488,
                0.08904645506448436,
                0.04443502126185342,
                0.0,
                0.03938511689973596,
                0.15173228970508018,
                0.0,
                0.0,
                0.10888814666569031,
                0.051046059929070756,
                0.11348332208141833,
                0.16772455132675942,
                0.08147874114979549,
                0.10072488850405684,
                0.05305790701868484,
                0.22207393588222,
                0.0756134934382899,
                0.05392412190376143,
                0.0,
                0.17103750452635796,
                0.0,
                0.2652787585741322,
                0.0,
                0.0,
                0.0,
                0.034478554102938846,
                0.0,
                0.09365004284627113,
                0.0,
                0.06260540049629539,
                0.17744598906472317,
                0.08263152333966477,
                0.0,
                0.0,
                0.0,
                0.0,
                0.1425913664300189,
                0.05024580278337159,
                0.0,
                0.19715035574719514,
                0.19474928024198038,
                0.0,
                0.0,
                0.0,
                0.0,
                0.08706825343063063,
                0.0,
                0.0,
                0.1410688353337396,
                0.1162474477013555,
                0.0,
                0.0,
                0.049082802794604787,
                0.0
            ],
            [
                0.0,
                0.0,
                0.03904300662326613,
                0.0,
                0.03450554965203611,
                0.0,
                0.015756253678318555,
                0.08133542291131243,
                0.0,
                0.0,
                1.0,
                0.08579671785120528,
                0.04184333181860327,
                0.0,
                0.0,
                0.06290331403773,
                0.0,
                0.0,
                0.0,
                0.02155753420625651,
                0.008568387898266746,
                0.0,
                0.0,
                0.055652771838512576,
                0.0,
                0.05589199042178536,
                0.02059287961688988,
                0.1126571122933678,
                0.06717393575774841,
                0.08817777126616948,
                0.029970774752893455,
                0.0,
                0.0,
                0.018970899538298523,
                0.030728094184339486,
                0.0,
                0.0,
                0.022748409393396153,
                0.07060065574300625,
                0.05615022377557197,
                0.07521393982588964,
                0.023983878960038164,
                0.0,
                0.0,
                0.0,
                0.0,
                0.02492914088917542,
                0.09377335023771353,
                0.0,
                0.0,
                0.0,
                0.061196341018499516,
                0.0,
                0.021926715726007566,
                0.0,
                0.0,
                0.0,
                0.0791695425612248,
                0.0,
                0.034797177898737056,
                0.0,
                0.09562359107869096,
                0.031178370083339572,
                0.018783378676820745,
                0.0,
                0.03410758490432718,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.08302750546671794,
                0.08122259816289232,
                0.013617407948139714,
                0.0,
                0.04286585472154953,
                0.07009113238410651,
                0.0,
                0.06577070915113496,
                0.0,
                0.0958398959847448,
                0.030197109696619484,
                0.029821519661554403,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.03582369935090507,
                0.17836306077375688,
                0.11723350737144916,
                0.02504638623229811,
                0.04886930776363939,
                0.21221666546309453,
                0.0,
                0.056276037650823105,
                0.08579671785120528,
                1.0,
                0.038393122573110026,
                0.04513688606121917,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.033567407755783894,
                0.0,
                0.0,
                0.0,
                0.012312241681167466,
                0.030536125909376453,
                0.04200325897088646,
                0.17861468592462063,
                0.11462631215056308,
                0.0,
                0.027499522114711926,
                0.0,
                0.0,
                0.07052968347818017,
                0.1436055041054798,
                0.0,
                0.0,
                0.023199944561004385,
                0.03628744932997851,
                0.11359297779959404,
                0.0,
                0.024459937071127907,
                0.04653626544751912,
                0.06824160071350566,
                0.0,
                0.06634739878425136,
                0.0,
                0.01941678934773518,
                0.0,
                0.0,
                0.0,
                0.05868319151517582,
                0.0,
                0.022361941024147097,
                0.0,
                0.0,
                0.0,
                0.0,
                0.12862949023571235,
                0.03192796219135118,
                0.0,
                0.03223745235105988,
                0.03179723227796049,
                0.019156211602957083,
                0.0,
                0.0,
                0.0,
                0.0,
                0.05543129253646971,
                0.08792253426443754,
                0.07299048775469665,
                0.13647646225470297,
                0.0,
                0.0,
                0.0,
                0.0,
                0.11521229897775749,
                0.0,
                0.0,
                0.030813204307840396,
                0.025278669571123197,
                0.0,
                0.030413449613484196,
                0.07779126841640799,
                0.0,
                0.0
            ],
            [
                0.0,
                0.070285388962023,
                0.05149948982365258,
                0.08729981722108124,
                0.10386856022443597,
                0.0,
                0.03921832391543736,
                0.10728509781384266,
                0.0,
                0.06728753742575573,
                0.04184333181860327,
                0.038393122573110026,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.028418105374505443,
                0.021327265915358086,
                0.0,
                0.0,
                0.0,
                0.03182931206870887,
                0.04389817171363615,
                0.05125699545432685,
                0.05041286460996164,
                0.06655263049762918,
                0.0,
                0.039532806074259776,
                0.0,
                0.13308091415185197,
                0.09108911469629587,
                0.04053174462244443,
                0.0,
                0.12658005992932592,
                0.0,
                0.0,
                0.04410099097308936,
                0.0,
                0.0,
                0.06015221897840899,
                0.0,
                0.0,
                0.0,
                0.0,
                0.06370087586994574,
                0.0,
                0.0,
                0.0,
                0.10968766782148391,
                0.0,
                0.0,
                0.0,
                0.0,
                0.23931939696676083,
                0.0,
                0.0,
                0.04589904989591514,
                0.0,
                0.0,
                0.0,
                0.049522179059997735,
                0.0,
                0.0,
                0.08336891514461477,
                0.0,
                0.05245639424361138,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.039902311226314956,
                0.03596199952119993,
                0.06306487870150207,
                0.0,
                0.14758685769328506,
                0.0,
                0.04513688606121917,
                0.0,
                1.0,
                0.0,
                0.0,
                0.10827209430260162,
                0.08558097588832127,
                0.11678455934761471,
                0.2054685772068824,
                0.013921563383818124,
                0.026993713926450034,
                0.0,
                0.0,
                0.031954436260204576,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.04047322009186438,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.03457778109054249,
                0.0634818191770468,
                0.11818574097007659,
                0.07481955656853269,
                0.0,
                0.0,
                0.0,
                0.0,
                0.06786807336201589,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.01968589439890159,
                0.049937234977327986,
                0.11352631131599557,
                0.12565347262372736,
                0.0,
                0.0,
                0.030518459238349147,
                0.0,
                0.05541659770218853,
                0.0,
                0.1053754101195176,
                0.0,
                0.04030026224233221,
                0.0721586821192029,
                0.06610699222641316,
                0.0,
                0.04841474597651399,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.08812548310105732,
                0.08605000648241065,
                0.0,
                0.07828312558008348,
                0.03511824343914339,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.1339250125749039,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.05655690853817135,
                0.0,
                0.0,
                0.0,
                0.0,
                0.08078254940534842,
                0.20964347260809882,
                0.0,
                0.0813026501661613,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.3556665944875053,
                0.0,
                0.0,
                0.0455022904268985,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.07143345475298839,
                0.08600245367755001,
                0.06477524017000641,
                0.0,
                0.0,
                0.09034862191474659,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.031787241376494316,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.5689333770841705,
                0.0,
                0.051246463093183925,
                0.03572572301086211,
                0.0,
                0.0,
                0.0,
                0.0,
                0.04149727163820328,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.14847887653462627,
                0.0,
                0.06280110281683064,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.06290331403773,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.30913963787668514,
                0.0,
                0.0,
                0.053419552038597454,
                0.0,
                0.056660619292255424,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.04271508269315827,
                0.06547438460370054,
                0.0,
                0.0,
                0.0,
                0.0,
                0.02816966697215738,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.07205803738799565,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.1100068714029169,
                0.0,
                0.0,
                0.05031587965393618,
                0.0,
                0.0,
                0.0,
                0.0,
                0.056453870873675156,
                0.05153199803788982,
                0.0,
                0.0,
                0.0,
                0.0,
                0.16045067347317063,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0723399621752234,
                0.0,
                0.0,
                0.0,
                0.0,
                0.08714129699759991
            ],
            [
                0.02676260525387232,
                0.0,
                0.0,
                0.08896882686505654,
                0.04161895254313242,
                0.041495633366904955,
                0.14172762754979343,
                0.10138674312548984,
                0.05876686205182084,
                0.3356929970787832,
                0.0,
                0.0,
                0.0,
                0.10827209430260162,
                0.0,
                0.0,
                1.0,
                0.0,
                0.13487915157508734,
                0.0,
                0.0448992200974276,
                0.02807158838369203,
                0.07325081655211513,
                0.03677216747014886,
                0.0,
                0.0,
                0.09323995774655582,
                0.0,
                0.06979983468684052,
                0.10955721074532629,
                0.07229864556282935,
                0.12894816193091654,
                0.042089338950433444,
                0.048827307090569164,
                0.07412553090708206,
                0.0,
                0.032850695432621535,
                0.12655824404647895,
                0.0,
                0.06252733615898161,
                0.0762678717437782,
                0.04257696053141566,
                0.07905191824939693,
                0.06209007031762972,
                0.0,
                0.12465973129674045,
                0.044255020194566265,
                0.054465950950775596,
                0.0,
                0.04497752056040993,
                0.0,
                0.09378588683250076,
                0.0,
                0.19983687792333626,
                0.0,
                0.0,
                0.0,
                0.020471963436987817,
                0.0,
                0.11805948194697392,
                0.0,
                0.0,
                0.08581983868327134,
                0.10065912905222481,
                0.0,
                0.057629414187285656,
                0.0,
                0.0,
                0.11474236740742134,
                0.0,
                0.0,
                0.0,
                0.1433480495048222,
                0.0,
                0.0,
                0.0,
                0.0,
                0.10775792595393896,
                0.0,
                0.0,
                0.06822642064432727,
                0.08091235379573074,
                0.0,
                0.0,
                0.07745996423165356,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.17907284423696418,
                0.06321477688957719,
                0.0,
                0.0,
                0.0,
                0.0,
                0.08558097588832127,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.13527878453851802,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.03806232101762229,
                0.0,
                0.0,
                0.06799328855050626,
                0.16144028002007083,
                0.0,
                0.0,
                0.0,
                0.06845690518832764,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0983961020181901,
                0.0,
                0.07534473215322043,
                0.0,
                0.0,
                0.06273181380027293,
                0.0,
                0.05555866802701218,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.10694209725471276,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.10749667368363035,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0400784764965221,
                0.0,
                0.0,
                0.03825723865749299,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.12929958606690042,
                0.0,
                0.13946346013391914,
                0.08280856233511524,
                0.05260046189755393,
                0.0,
                0.06992520653624074,
                0.042659321496998054,
                0.024726649504219864,
                0.12259064549961267,
                0.0,
                0.0,
                0.0,
                0.11678455934761471,
                0.0,
                0.30913963787668514,
                0.13487915157508734,
                0.0,
                1.0,
                0.11956863692690235,
                0.012398630215202345,
                0.04474273516798173,
                0.059707904214910096,
                0.02997357785793697,
                0.0,
                0.0,
                0.0,
                0.0,
                0.02319179021969359,
                0.04519272372254479,
                0.02946588725780219,
                0.1247379702929152,
                0.0,
                0.03979991366733129,
                0.030210448890563357,
                0.023594131755257063,
                0.02677712370467103,
                0.07024222769485934,
                0.10506750245347038,
                0.0,
                0.0770515613096307,
                0.0,
                0.0,
                0.05061060266249031,
                0.0,
                0.06848076156479324,
                0.0,
                0.04439606185180467,
                0.0,
                0.03666189150989827,
                0.0,
                0.076446366215199,
                0.0,
                0.0994334133946449,
                0.0,
                0.0,
                0.0,
                0.03262984715755797,
                0.0,
                0.0,
                0.11727043724876424,
                0.0,
                0.0,
                0.11014913760673808,
                0.0,
                0.0,
                0.0,
                0.0,
                0.11031693865183652,
                0.0,
                0.0,
                0.0,
                0.08858008250556372,
                0.0,
                0.3118423189132016,
                0.0,
                0.0,
                0.0591958987654363,
                0.0,
                0.0,
                0.0,
                0.023310555678371387,
                0.0,
                0.0,
                0.07825590312901247,
                0.0
            ],
            [
                0.0,
                0.026647772848641678,
                0.046885209864025335,
                0.029207681454473056,
                0.0,
                0.07591125922857209,
                0.050380387885975805,
                0.049387535390929015,
                0.0,
                0.0,
                0.02155753420625651,
                0.0,
                0.028418105374505443,
                0.2054685772068824,
                0.05655690853817135,
                0.0,
                0.0,
                0.0,
                0.11956863692690235,
                1.0,
                0.015841381893940208,
                0.014847878707223601,
                0.0,
                0.0,
                0.05304790472671509,
                0.09937124423406445,
                0.07488008753517159,
                0.04589594470116847,
                0.1576161400525209,
                0.0,
                0.08252092975207975,
                0.0,
                0.0,
                0.17981539919433778,
                0.0,
                0.0,
                0.10360296299061457,
                0.09334582317622438,
                0.030808967612943425,
                0.022720672090684346,
                0.04310632533541221,
                0.2483087528079542,
                0.12430049398423146,
                0.16304899953813873,
                0.12280507884299088,
                0.0,
                0.06836853835332737,
                0.029659681163616378,
                0.0,
                0.0,
                0.0,
                0.14392987913399155,
                0.0,
                0.021931034557070614,
                0.0,
                0.0,
                0.03277790404937506,
                0.087765979717738,
                0.0,
                0.0,
                0.04421630241559503,
                0.16140631960365942,
                0.12793732389778328,
                0.11156186853304693,
                0.0,
                0.20276616775440431,
                0.03160821824023429,
                0.0,
                0.0,
                0.0,
                0.09177095849400595,
                0.0,
                0.10241930416326182,
                0.08356996822071526,
                0.0,
                0.1941784769027003,
                0.021851853381531866,
                0.0,
                0.08293492719937447,
                0.0,
                0.11186952809685248,
                0.055828932172190746,
                0.029827393505456563,
                0.11217986677308436,
                0.0,
                0.05277274549342628
            ],
            [
                0.41455739125180197,
                0.1519007967289927,
                0.0,
                0.04128466260914045,
                0.07516560843037699,
                0.02662034700686726,
                0.05882415991945388,
                0.0,
                0.0,
                0.03851617157831185,
                0.008568387898266746,
                0.033567407755783894,
                0.021327265915358086,
                0.013921563383818124,
                0.0,
                0.0,
                0.0448992200974276,
                0.13527878453851802,
                0.012398630215202345,
                0.015841381893940208,
                1.0,
                0.26028328221255825,
                0.0,
                0.0,
                0.07412403778514753,
                0.008989163790726812,
                0.05572542738526803,
                0.0,
                0.09647738574720398,
                0.04112699205954333,
                0.013736885750854922,
                0.018018468352358947,
                0.01599411540811404,
                0.02106027052612263,
                0.06050820388746659,
                0.0,
                0.0,
                0.019095335975480163,
                0.0,
                0.019068297074021513,
                0.013664369181976898,
                0.020132406570374538,
                0.034811723368721355,
                0.0,
                0.0,
                0.06238555813946591,
                0.026727521572407046,
                0.02792665859021938,
                0.0,
                0.0,
                0.0,
                0.056055884182811495,
                0.0,
                0.06804346228845805,
                0.0,
                0.0,
                0.0,
                0.04003073384212867,
                0.008336597903897047,
                0.015180020037222429,
                0.07575788210893404,
                0.0265338989073158,
                0.08896798336671316,
                0.06014542332240631,
                0.0,
                0.0354586826466981,
                0.0,
                0.0,
                0.12391152271464789,
                0.0,
                0.015651016723265986,
                0.0,
                0.034119633369343136,
                0.0911294820889565,
                0.0,
                0.0459581845151896,
                0.0,
                0.21388711704992108,
                0.016958379187411596,
                0.0,
                0.02080628629109306,
                0.09803228685343102,
                0.04872896783928347,
                0.0,
                0.01387794786826978,
                0.0
            ],
            [
                0.13942917561219328,
                0.058906698034624054,
                0.0,
                0.0,
                0.0,
                0.1647734670410053,
                0.0,
                0.0,
                0.0,
                0.05482714205860478,
                0.0,
                0.0,
                0.0,
                0.026993713926450034,
                0.0,
                0.053419552038597454,
                0.02807158838369203,
                0.0,
                0.04474273516798173,
                0.014847878707223601,
                0.26028328221255825,
                1.0,
                0.0,
                0.0,
                0.02667637900808001,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.02805047742018701,
                0.03493755454661981,
                0.07777345751273111,
                0.0,
                0.0,
                0.09849383471629984,
                0.0,
                0.0,
                0.0,
                0.0,
                0.026495018017331555,
                0.03303807590610499,
                0.05983244157554917,
                0.0,
                0.050074830972771205,
                0.0,
                0.08113665728350763,
                0.0,
                0.05200350542504922,
                0.0,
                0.0,
                0.0,
                0.0,
                0.04447035790816026,
                0.0,
                0.0,
                0.0,
                0.015084198879633805,
                0.0,
                0.02943384352642868,
                0.070779029973997,
                0.0,
                0.0,
                0.292038211376339,
                0.13133416173019807,
                0.0894462367965095,
                0.0,
                0.0,
                0.05130439181069048,
                0.0,
                0.0,
                0.0,
                0.03961634060496744,
                0.01875813992326458,
                0.03513365226126542,
                0.059048220032726896,
                0.03368161759583641,
                0.09405922580852698,
                0.0,
                0.0,
                0.0,
                0.14788037021381117,
                0.0,
                0.0,
                0.26244346235007354,
                0.0
            ],
            [
                0.022951019191831613,
                0.07553392095644607,
                0.0,
                0.02654287145645221,
                0.0,
                0.0,
                0.15540159418629768,
                0.04488158382156195,
                0.22914244595652672,
                0.08782133634958916,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.07325081655211513,
                0.0,
                0.059707904214910096,
                0.0,
                0.0,
                0.0,
                1.0,
                0.08146456975481445,
                0.0,
                0.05815274497981286,
                0.0,
                0.0,
                0.02439992574168124,
                0.08518766597049136,
                0.0,
                0.05596247796011595,
                0.0,
                0.04187322017010889,
                0.0,
                0.0,
                0.028172030868707027,
                0.07390137300523915,
                0.0,
                0.0,
                0.034568434065883155,
                0.0,
                0.0,
                0.05324707299473037,
                0.0,
                0.03719086044175807,
                0.0,
                0.1378864363416293,
                0.0,
                0.0385717282675089,
                0.0,
                0.08042870521001415,
                0.0,
                0.07123198680070938,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.030510209524744942,
                0.0,
                0.0,
                0.08959445397905559,
                0.0,
                0.03423212394745406,
                0.0,
                0.0,
                0.0,
                0.06345689092256268,
                0.0,
                0.0,
                0.0,
                0.0,
                0.032148392620119766,
                0.0,
                0.0,
                0.0,
                0.024524878078045258,
                0.0,
                0.0,
                0.03510875031734477,
                0.0
            ],
            [
                0.011521492333565845,
                0.0,
                0.0,
                0.013324614799903023,
                0.0,
                0.0,
                0.10369134264886026,
                0.022530712888883753,
                0.03883996787253569,
                0.044086619640639556,
                0.055652771838512576,
                0.0,
                0.0,
                0.0,
                0.0,
                0.056660619292255424,
                0.03677216747014886,
                0.0,
                0.02997357785793697,
                0.0,
                0.0,
                0.0,
                0.08146456975481445,
                1.0,
                0.0,
                0.13036904349838266,
                0.0,
                0.0,
                0.012248848516165664,
                0.2831983131345959,
                0.0,
                0.028093360708543215,
                0.0,
                0.021020503757991187,
                0.0,
                0.0,
                0.014142458553226666,
                0.07371669243562144,
                0.028059143709315917,
                0.0,
                0.0173534754489334,
                0.0386066693987075,
                0.0,
                0.02673021786814372,
                0.0,
                0.055525897207328964,
                0.0,
                0.07590241728503368,
                0.0,
                0.01936314321433945,
                0.0,
                0.04037549281495995,
                0.0,
                0.07105397706472757,
                0.0,
                0.0,
                0.0,
                0.019503348183231742,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.04555169570486479,
                0.0,
                0.0,
                0.0,
                0.0,
                0.017184646586964582,
                0.0,
                0.0,
                0.04662291723323012,
                0.06329831126043763,
                0.0,
                0.0,
                0.0,
                0.0,
                0.016138606133927206,
                0.0,
                0.0,
                0.06400170597259078,
                0.012311575028371777,
                0.0,
                0.0,
                0.017624716107001066,
                0.0
            ],
            [
                0.022687342531579443,
                0.07265124331481519,
                0.0,
                0.020347114427177255,
                0.014595948373574294,
                0.015289932416694678,
                0.033030372127850885,
                0.0,
                0.031704857425377424,
                0.0,
                0.0,
                0.012312241681167466,
                0.03182931206870887,
                0.031954436260204576,
                0.08078254940534842,
                0.0,
                0.0,
                0.0,
                0.0,
                0.05304790472671509,
                0.07412403778514753,
                0.02667637900808001,
                0.0,
                0.0,
                1.0,
                0.04298423222517713,
                0.08905543568283611,
                0.0,
                0.009352192393636662,
                0.0,
                0.0,
                0.0,
                0.0,
                0.24489347863960953,
                0.0,
                0.0,
                0.07442911368860274,
                0.04307197148515565,
                0.02215220362265793,
                0.06567748476078214,
                0.04828065288500974,
                0.12413443570411074,
                0.05395219877723876,
                0.10397510276165749,
                0.07831186163989134,
                0.0,
                0.0,
                0.021189549056388386,
                0.0,
                0.03017748597621128,
                0.0,
                0.09165267184084748,
                0.0,
                0.013651173618189046,
                0.0,
                0.0,
                0.03671244522450545,
                0.040888804421297345,
                0.03955078010869907,
                0.0,
                0.01185930096383193,
                0.019679823794240603,
                0.019411085018764783,
                0.03272363096623739,
                0.0,
                0.0,
                0.035402354556924136,
                0.05867239894995629,
                0.04171960107478714,
                0.0,
                0.0818181361836679,
                0.0,
                0.037132378335313285,
                0.025886295035225222,
                0.0,
                0.0,
                0.0,
                0.0,
                0.03006826807834817,
                0.0,
                0.015431733174665098,
                0.0,
                0.018566334673425448,
                0.04358757673991212,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.04096032831216309,
                0.0,
                0.09609657972964743,
                0.0,
                0.20997463835345134,
                0.08532963810913831,
                0.0,
                0.0,
                0.05589199042178536,
                0.030536125909376453,
                0.04389817171363615,
                0.0,
                0.20964347260809882,
                0.0,
                0.0,
                0.0,
                0.0,
                0.09937124423406445,
                0.008989163790726812,
                0.0,
                0.05815274497981286,
                0.13036904349838266,
                0.04298423222517713,
                1.0,
                0.07421591653027436,
                0.040096076536903495,
                0.07047270947155744,
                0.04401562861963607,
                0.031442577808975844,
                0.0,
                0.0,
                0.30361409489266733,
                0.032237087638829084,
                0.0,
                0.061752512636435435,
                0.02386553695323614,
                0.0,
                0.058907645685214734,
                0.0,
                0.025161677887197573,
                0.0,
                0.11671648960219948,
                0.08790840635929519,
                0.0,
                0.026153359683941627,
                0.18925562623870315,
                0.0,
                0.0,
                0.0,
                0.12745373011797295,
                0.0,
                0.023003491601221535,
                0.0,
                0.0,
                0.0,
                0.08127300115810059,
                0.0,
                0.036505995678613075,
                0.0,
                0.03316232538139742,
                0.0327094756603783,
                0.019705791739814005,
                0.0,
                0.0357825381917103,
                0.0,
                0.0,
                0.05384286293945443,
                0.0,
                0.16957663902878078,
                0.0,
                0.09004072060847834,
                0.06277057283558696,
                0.062011130155261746,
                0.04497090861157849,
                0.0,
                0.0,
                0.07291126091561549,
                0.0,
                0.02600389932794601,
                0.031680027595898975,
                0.03128599310732875,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.09731495644200325,
                0.24883159000308736,
                0.10539827998240892,
                0.11358780230063295,
                0.09197548310687544,
                0.0259662563751412,
                0.15116834464974355,
                0.02059287961688988,
                0.04200325897088646,
                0.05125699545432685,
                0.0,
                0.0,
                0.0,
                0.09323995774655582,
                0.0,
                0.0,
                0.07488008753517159,
                0.05572542738526803,
                0.0,
                0.0,
                0.0,
                0.08905543568283611,
                0.07421591653027436,
                1.0,
                0.0,
                0.2385185478212493,
                0.0,
                0.0,
                0.0,
                0.0,
                0.17568691122677274,
                0.0,
                0.0,
                0.0,
                0.14577376072733106,
                0.0,
                0.12705705866848893,
                0.04613276927220659,
                0.2796711288157397,
                0.2223187545035729,
                0.0,
                0.0,
                0.0,
                0.10465315150940796,
                0.10199429666266605,
                0.0,
                0.0,
                0.0,
                0.3486637269733553,
                0.0,
                0.16312439955011043,
                0.0,
                0.0,
                0.0,
                0.08483116309724126,
                0.0400716118569038,
                0.0,
                0.0,
                0.12432496624662183,
                0.29520803201573936,
                0.11874786016094618,
                0.0,
                0.032587759219034104,
                0.0,
                0.0,
                0.144752656071594,
                0.0683278522695935,
                0.10546817270006272,
                0.0,
                0.05033228609003731,
                0.035088417869667696,
                0.0,
                0.18364357095442282,
                0.0,
                0.0,
                0.04075700881545991,
                0.0,
                0.3561729505167161,
                0.10228904483582789,
                0.09183180082230767,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.04703903158088074,
                0.0,
                0.13077602959499074,
                0.0,
                0.0,
                0.2031270988690062,
                0.0,
                0.0,
                0.1126571122933678,
                0.17861468592462063,
                0.05041286460996164,
                0.0,
                0.0813026501661613,
                0.0,
                0.0,
                0.0,
                0.0,
                0.04589594470116847,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.040096076536903495,
                0.0,
                1.0,
                0.026636992074930567,
                0.0,
                0.21295511396874642,
                0.0,
                0.0,
                0.022856148121747518,
                0.03702122141116258,
                0.0,
                0.0,
                0.0,
                0.0,
                0.04028132927597526,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.025495607206304578,
                0.0,
                0.0,
                0.0,
                0.04390133818350825,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.04192365526298419,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.06718372764644816,
                0.0,
                0.10003157516571344,
                0.0,
                0.0,
                0.07121387034569453,
                0.0,
                0.08444582717640786,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.1259341289646825,
                0.0,
                0.0
            ],
            [
                0.04879980097152704,
                0.0,
                0.02721113971421758,
                0.11636153371327856,
                0.20266367995591178,
                0.04313501196227776,
                0.07581285624799938,
                0.1522255151944839,
                0.010104665700071288,
                0.06966481025403111,
                0.06717393575774841,
                0.11462631215056308,
                0.06655263049762918,
                0.0,
                0.0,
                0.0,
                0.06979983468684052,
                0.03806232101762229,
                0.02319179021969359,
                0.1576161400525209,
                0.09647738574720398,
                0.0,
                0.02439992574168124,
                0.012248848516165664,
                0.009352192393636662,
                0.07047270947155744,
                0.2385185478212493,
                0.026636992074930567,
                1.0,
                0.018468226567212958,
                0.06570910137216415,
                0.05965372233512473,
                0.03938946765933924,
                0.06640796749295926,
                0.09856206272477241,
                0.0,
                0.01094260196469315,
                0.1445564132738006,
                0.049205337229164696,
                0.17543571710254138,
                0.013427097829353597,
                0.1749338926570225,
                0.11398251820118398,
                0.020682269172631985,
                0.0,
                0.0708430056769719,
                0.16504530350914517,
                0.08186301845066338,
                0.0,
                0.03829454083359239,
                0.0,
                0.31143354401884366,
                0.0,
                0.1251711200341275,
                0.0,
                0.0,
                0.0,
                0.13088271636030097,
                0.014615267354781473,
                0.024251996742965177,
                0.020540409971460217,
                0.1102640869301415,
                0.3260477355240834,
                0.1507583773665076,
                0.0,
                0.07131414855687244,
                0.0,
                0.03908410750042522,
                0.08311798454983373,
                0.0,
                0.049496035175894716,
                0.0,
                0.13479375360226417,
                0.09015510152555864,
                0.0,
                0.33718549461155817,
                0.024004268673367503,
                0.08237261854877763,
                0.11420268932376847,
                0.014531243584475075,
                0.14081308391322897,
                0.23136455919369053,
                0.08545418667562267,
                0.13193944672072444,
                0.01363696788459931,
                0.029312638015921044
            ],
            [
                0.05128159616625581,
                0.0,
                0.07295837934154609,
                0.02009021539622082,
                0.0,
                0.0,
                0.050042279092978655,
                0.03397072874267087,
                0.039125758255192995,
                0.066471691525233,
                0.08817777126616948,
                0.0,
                0.0,
                0.0,
                0.0,
                0.04271508269315827,
                0.10955721074532629,
                0.0,
                0.04519272372254479,
                0.0,
                0.04112699205954333,
                0.0,
                0.08518766597049136,
                0.2831983131345959,
                0.0,
                0.04401562861963607,
                0.0,
                0.0,
                0.018468226567212958,
                1.0,
                0.0,
                0.0836999951713175,
                0.0,
                0.03169370781646804,
                0.0,
                0.0,
                0.021323320999006818,
                0.08354110505450918,
                0.021153115846837614,
                0.0,
                0.026164738334097222,
                0.029104642633135093,
                0.0,
                0.04030254102076004,
                0.0,
                0.05593446519230646,
                0.044540170495286024,
                0.03535374031948972,
                0.052500963098769476,
                0.029194819044733835,
                0.0,
                0.06087623241363909,
                0.0,
                0.08052352277863091,
                0.0,
                0.0,
                0.0,
                0.04068710380257355,
                0.0,
                0.0,
                0.03668622499886484,
                0.0,
                0.0,
                0.04588687200029596,
                0.057416217417583425,
                0.0,
                0.0,
                0.0,
                0.02591018626989218,
                0.0378666341594286,
                0.0,
                0.03514789972099553,
                0.11362488152176414,
                0.0,
                0.03343967605423698,
                0.0,
                0.0,
                0.024333016623319412,
                0.03392131370428358,
                0.0,
                0.04824935197092149,
                0.04553895111808621,
                0.0,
                0.0,
                0.026573701994707637,
                0.0
            ],
            [
                0.0,
                0.0,
                0.036887110617405454,
                0.05705630109855534,
                0.10255206596847186,
                0.04146442698165689,
                0.050521021972950705,
                0.07684420339326963,
                0.0,
                0.04333988321533345,
                0.029970774752893455,
                0.027499522114711926,
                0.039532806074259776,
                0.0,
                0.0,
                0.06547438460370054,
                0.07229864556282935,
                0.0,
                0.02946588725780219,
                0.08252092975207975,
                0.013736885750854922,
                0.02805047742018701,
                0.0,
                0.0,
                0.0,
                0.031442577808975844,
                0.0,
                0.21295511396874642,
                0.06570910137216415,
                0.0,
                1.0,
                0.0,
                0.0,
                0.01792335504622476,
                0.10192835523790449,
                0.0,
                0.0,
                0.04295846739319645,
                0.0,
                0.03158784947058665,
                0.04018888654606796,
                0.11205560851466372,
                0.03852051874372558,
                0.0,
                0.0,
                0.03670742476081895,
                0.04208950501002392,
                0.019993168474563817,
                0.0,
                0.0,
                0.0,
                0.03442659135196579,
                0.09978374664742752,
                0.03515302906402837,
                0.0,
                0.0,
                0.0,
                0.0,
                0.03562806986501691,
                0.0775223651343809,
                0.0635537225485412,
                0.0,
                0.05887774267799902,
                0.10358895173432868,
                0.0,
                0.05758607454995932,
                0.0,
                0.0,
                0.033787148220784706,
                0.0,
                0.0,
                0.0,
                0.031316014491561364,
                0.07509900316428414,
                0.11168911538573896,
                0.07237323640964403,
                0.041282322677493974,
                0.031730502851160414,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.05585164394234836,
                0.0,
                0.0
            ],
            [
                0.13045262504797064,
                0.0,
                0.0,
                0.08725731077110613,
                0.0,
                0.0,
                0.02280002476522079,
                0.03998333839480332,
                0.02317556772595388,
                0.07823677131158921,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.12894816193091654,
                0.06799328855050626,
                0.1247379702929152,
                0.0,
                0.018018468352358947,
                0.03493755454661981,
                0.05596247796011595,
                0.028093360708543215,
                0.0,
                0.0,
                0.0,
                0.0,
                0.05965372233512473,
                0.0836999951713175,
                0.0,
                1.0,
                0.0,
                0.03730329879618098,
                0.0,
                0.026543870156487827,
                0.07408868778654391,
                0.06583599225144786,
                0.0,
                0.0,
                0.11364062848686347,
                0.0,
                0.057588996108684655,
                0.047435842428053716,
                0.0,
                0.033131958180190775,
                0.0,
                0.04161113449828871,
                0.0,
                0.08876789633248987,
                0.0,
                0.07165095041772884,
                0.0,
                0.06345793508781324,
                0.08278706845510998,
                0.0,
                0.0,
                0.0,
                0.043225688979738296,
                0.0,
                0.12497762377142682,
                0.0,
                0.0,
                0.13979915800980006,
                0.0,
                0.0,
                0.0,
                0.0,
                0.03049612957523015,
                0.05715788546336642,
                0.0,
                0.0,
                0.05653139054375393,
                0.0,
                0.0,
                0.0,
                0.0,
                0.07026023840828007,
                0.039925177199128144,
                0.037361629453577384,
                0.0,
                0.07072417743153053,
                0.0,
                0.0,
                0.11541686973287249,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.061475065120503346,
                0.17936329060768852,
                0.0,
                0.18531670739343742,
                0.0,
                0.07088619294510488,
                0.0,
                0.0,
                0.13308091415185197,
                0.04047322009186438,
                0.0,
                0.0,
                0.042089338950433444,
                0.16144028002007083,
                0.0,
                0.0,
                0.01599411540811404,
                0.07777345751273111,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.03938946765933924,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.039725496775848676,
                0.0,
                0.042587949167121296,
                0.0,
                0.0,
                0.0,
                0.07016462844381442,
                0.03770164411518182,
                0.0,
                0.0,
                0.0,
                0.06491912959678728,
                0.0,
                0.05749587253054675,
                0.0,
                0.0,
                0.0,
                0.054387489927227965,
                0.0,
                0.04413184604536232,
                0.0,
                0.0,
                0.08175540807945282,
                0.03506184942585879,
                0.09044840908681252,
                0.06366666118864758,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.052677895471356095,
                0.0,
                0.0,
                0.0,
                0.041475921898311056,
                0.0,
                0.06499521494282025,
                0.11027061128779957,
                0.0,
                0.0,
                0.14152450283718776,
                0.0
            ],
            [
                0.015298620750852913,
                0.031865938849925994,
                0.023348801475789178,
                0.16219236595131378,
                0.11240201556319773,
                0.21361541191122008,
                0.3033045376877189,
                0.0785578701034523,
                0.01734082702070053,
                0.08904645506448436,
                0.018970899538298523,
                0.07052968347818017,
                0.09108911469629587,
                0.0,
                0.3556665944875053,
                0.0,
                0.048827307090569164,
                0.0,
                0.03979991366733129,
                0.17981539919433778,
                0.02106027052612263,
                0.0,
                0.04187322017010889,
                0.021020503757991187,
                0.24489347863960953,
                0.30361409489266733,
                0.17568691122677274,
                0.022856148121747518,
                0.06640796749295926,
                0.03169370781646804,
                0.01792335504622476,
                0.03730329879618098,
                0.0,
                1.0,
                0.018376253083233356,
                0.0,
                0.10991263014737164,
                0.1275827755144144,
                0.023651059656601914,
                0.05019369425331707,
                0.02304252191610868,
                0.2367761576801271,
                0.08793362431872583,
                0.16855813085185287,
                0.10022165410850399,
                0.024790570934595087,
                0.0,
                0.19360698813017943,
                0.0,
                0.02571102562101421,
                0.0,
                0.38381312074514484,
                0.0,
                0.07663127248613097,
                0.0,
                0.0,
                0.03919647214042388,
                0.0682463650112147,
                0.050680013505205034,
                0.02080967806898277,
                0.0,
                0.0754273869111088,
                0.04144894454731392,
                0.16646956063829066,
                0.0,
                0.0,
                0.03779773849467359,
                0.0,
                0.07729327848794544,
                0.0,
                0.28981796398908005,
                0.0,
                0.12158853914368115,
                0.055275612177950025,
                0.03534848539909245,
                0.0,
                0.033175442243204005,
                0.02142937803040025,
                0.06420547718009688,
                0.020083112667104285,
                0.16320875801555723,
                0.016347718832915942,
                0.039645129346543524,
                0.0,
                0.02340268428395575,
                0.06310670277729977
            ],
            [
                0.0,
                0.0,
                0.037819196153090956,
                0.2170963116692882,
                0.0887272038138787,
                0.0,
                0.051797617321321994,
                0.07878594860684959,
                0.0,
                0.04443502126185342,
                0.030728094184339486,
                0.1436055041054798,
                0.04053174462244443,
                0.0,
                0.0,
                0.0,
                0.07412553090708206,
                0.0,
                0.030210448890563357,
                0.0,
                0.06050820388746659,
                0.0,
                0.0,
                0.0,
                0.0,
                0.032237087638829084,
                0.0,
                0.03702122141116258,
                0.09856206272477241,
                0.0,
                0.10192835523790449,
                0.0,
                0.0,
                0.018376253083233356,
                1.0,
                0.0,
                0.0,
                0.044043967596986394,
                0.0,
                0.09546290069320655,
                0.04120440332734766,
                0.0,
                0.0,
                0.0,
                0.0,
                0.18606149880592354,
                0.0,
                0.020498367793126634,
                0.0,
                0.0,
                0.0,
                0.03529650301772207,
                0.10230514193672645,
                0.03604129679163543,
                0.0,
                0.0,
                0.0,
                0.0,
                0.03652834120722134,
                0.17223623202267607,
                0.0,
                0.0,
                0.1339130229498377,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.03464090205570274,
                0.0,
                0.0,
                0.0,
                0.03210732624394159,
                0.0,
                0.0,
                0.0,
                0.0,
                0.07921998243631617,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.13938743221602357,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.02816966697215738,
                0.0,
                0.0,
                0.023594131755257063,
                0.0,
                0.0,
                0.09849383471629984,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.026543870156487827,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.023959474948896633,
                0.0,
                0.0,
                0.02411278415722953,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.024026534986732077,
                0.0,
                0.0,
                0.0,
                0.05562957281777155,
                0.022807658481081232,
                0.0,
                0.3580392737965248,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.050476865656133144,
                0.197513502147482,
                0.061191176947192935,
                0.011903645954619154,
                0.0,
                0.0,
                0.047823319755149,
                0.02012798368748331,
                0.011666795917091128,
                0.03938511689973596,
                0.0,
                0.0,
                0.12658005992932592,
                0.0,
                0.0455022904268985,
                0.0,
                0.032850695432621535,
                0.06845690518832764,
                0.02677712370467103,
                0.10360296299061457,
                0.0,
                0.0,
                0.028172030868707027,
                0.014142458553226666,
                0.07442911368860274,
                0.061752512636435435,
                0.0,
                0.0,
                0.01094260196469315,
                0.021323320999006818,
                0.0,
                0.07408868778654391,
                0.0,
                0.10991263014737164,
                0.0,
                0.0,
                1.0,
                0.11357200280610233,
                0.03182455899100191,
                0.05772989172125203,
                0.01550285925171978,
                0.0,
                0.03669653926524782,
                0.41945496433797064,
                0.17525152480958048,
                0.016678935290504262,
                0.0426264865999298,
                0.02094743135575908,
                0.03264032974508299,
                0.10125624189643684,
                0.0,
                0.03606975352983943,
                0.0,
                0.03194531356228346,
                0.0,
                0.0,
                0.14599949589355038,
                0.03308926870265894,
                0.04352042613717719,
                0.0,
                0.01703744826223436,
                0.04016612246273683,
                0.0,
                0.08722280133637006,
                0.0,
                0.0,
                0.05086014647611904,
                0.0,
                0.015352034704070365,
                0.08040759908513956,
                0.07864830121424841,
                0.0,
                0.08180398030343006,
                0.0371890732606113,
                0.0,
                0.0,
                0.0,
                0.014417546511041551,
                0.04319702849958888,
                0.07355119851262912,
                0.0,
                0.010998639171357849,
                0.0,
                0.0,
                0.01574517415617457,
                0.0
            ],
            [
                0.027000289779039767,
                0.05309491105536313,
                0.0,
                0.13486016177150906,
                0.06949171029806189,
                0.06532267028920259,
                0.06522269098715057,
                0.20943437023995104,
                0.08949669028783026,
                0.15173228970508018,
                0.022748409393396153,
                0.023199944561004385,
                0.0,
                0.0,
                0.0,
                0.0,
                0.12655824404647895,
                0.0,
                0.07024222769485934,
                0.09334582317622438,
                0.019095335975480163,
                0.0,
                0.07390137300523915,
                0.07371669243562144,
                0.04307197148515565,
                0.02386553695323614,
                0.14577376072733106,
                0.0,
                0.1445564132738006,
                0.08354110505450918,
                0.04295846739319645,
                0.06583599225144786,
                0.0,
                0.1275827755144144,
                0.044043967596986394,
                0.0,
                0.11357200280610233,
                1.0,
                0.07461927774942952,
                0.05062485889119061,
                0.1279498021192038,
                0.5063145404114048,
                0.213474624138537,
                0.27994760255185686,
                0.05912316882722407,
                0.1325393682743851,
                0.16393107290879175,
                0.07012488428097471,
                0.04281134709008092,
                0.19080096046583864,
                0.0,
                0.1866005849280276,
                0.11147202938048739,
                0.21329239976359432,
                0.07196627249228975,
                0.0,
                0.0,
                0.07923008053325162,
                0.1248218828055438,
                0.04987636937860063,
                0.02234646882492628,
                0.18803654663837713,
                0.32699960063206907,
                0.17474774139258692,
                0.13737405998109198,
                0.03599883560335056,
                0.0629784539824795,
                0.0591880737167926,
                0.04027173079364692,
                0.0395998542843512,
                0.14994650686922326,
                0.11231573834180927,
                0.13211171602859423,
                0.0346175588390564,
                0.0,
                0.37306489506742657,
                0.12755789073722315,
                0.037820364726221335,
                0.016694385959587107,
                0.05520199120078586,
                0.1609219223622877,
                0.08776484431619765,
                0.06645963558115293,
                0.06239388982344334,
                0.0413030212046375,
                0.15576639005890974
            ],
            [
                0.0,
                0.0,
                0.0,
                0.08995253296361445,
                0.0,
                0.0,
                0.040244161902271564,
                0.0,
                0.02314734047357215,
                0.0,
                0.07060065574300625,
                0.03628744932997851,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.10506750245347038,
                0.030808967612943425,
                0.0,
                0.0,
                0.0,
                0.028059143709315917,
                0.02215220362265793,
                0.0,
                0.0,
                0.0,
                0.049205337229164696,
                0.021153115846837614,
                0.0,
                0.0,
                0.0,
                0.023651059656601914,
                0.0,
                0.0,
                0.03182455899100191,
                0.07461927774942952,
                1.0,
                0.0,
                0.0,
                0.03466350673643413,
                0.0,
                0.06015060197528294,
                0.04530416892438609,
                0.033091604297321026,
                0.0,
                0.0,
                0.0,
                0.04357258613534137,
                0.0,
                0.0,
                0.0,
                0.03169032246796871,
                0.0,
                0.0,
                0.0,
                0.017511338109759536,
                0.03461866103855976,
                0.0,
                0.04769150292941624,
                0.0,
                0.0,
                0.027147309006263144,
                0.0,
                0.0,
                0.0,
                0.10168555446099041,
                0.0,
                0.0,
                0.07773063605983335,
                0.04186100046331343,
                0.028231268373532164,
                0.0,
                0.10699304597654435,
                0.0,
                0.04486558475338539,
                0.0,
                0.0,
                0.027159866833797317,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.08534382454363935
            ],
            [
                0.0,
                0.08873461797748766,
                0.04114957408552755,
                0.03828575784136009,
                0.06383148486328492,
                0.028770008249152237,
                0.08266802538279285,
                0.08572387990407233,
                0.0,
                0.0,
                0.05615022377557197,
                0.11359297779959404,
                0.04410099097308936,
                0.0,
                0.0,
                0.0,
                0.06252733615898161,
                0.0,
                0.0,
                0.022720672090684346,
                0.019068297074021513,
                0.0,
                0.0,
                0.0,
                0.06567748476078214,
                0.058907645685214734,
                0.12705705866848893,
                0.04028132927597526,
                0.17543571710254138,
                0.0,
                0.03158784947058665,
                0.0,
                0.0,
                0.05019369425331707,
                0.09546290069320655,
                0.0,
                0.05772989172125203,
                0.05062485889119061,
                0.0,
                1.0,
                0.0,
                0.05337430266081826,
                0.05345476702277214,
                0.0,
                0.1053954294299423,
                0.0,
                0.02627419398833847,
                0.037457185978186584,
                0.0,
                0.0,
                0.0,
                0.09350102634553882,
                0.0,
                0.04879624198686287,
                0.10916984165691547,
                0.0,
                0.0,
                0.038309775409417005,
                0.022101684571526427,
                0.03667466145033218,
                0.0,
                0.12295335189324877,
                0.15584452035876867,
                0.04180098390922647,
                0.0,
                0.035947861429879345,
                0.0,
                0.12028096024009033,
                0.0,
                0.0,
                0.04149340520305149,
                0.0,
                0.020587300717855615,
                0.07248125914055037,
                0.0,
                0.04517868415268845,
                0.0,
                0.0,
                0.01667074679149634,
                0.0,
                0.12389575608912659,
                0.03182639632802687,
                0.156463978980435,
                0.08935642105390958,
                0.0,
                0.0
            ],
            [
                0.08058154556533521,
                0.14270199084993535,
                0.0,
                0.08615005775529203,
                0.0,
                0.09418273073882419,
                0.014083742920725468,
                0.0761814673004347,
                0.014315718568520415,
                0.10888814666569031,
                0.07521393982588964,
                0.0,
                0.0,
                0.03457778109054249,
                0.0,
                0.0,
                0.0762678717437782,
                0.0,
                0.0770515613096307,
                0.04310632533541221,
                0.013664369181976898,
                0.026495018017331555,
                0.034568434065883155,
                0.0173534754489334,
                0.04828065288500974,
                0.0,
                0.04613276927220659,
                0.0,
                0.013427097829353597,
                0.026164738334097222,
                0.04018888654606796,
                0.11364062848686347,
                0.039725496775848676,
                0.02304252191610868,
                0.04120440332734766,
                0.0,
                0.01550285925171978,
                0.1279498021192038,
                0.0,
                0.0,
                1.0,
                0.04468795653806222,
                0.16711375008158272,
                0.09038094926238144,
                0.0,
                0.0631273247816552,
                0.0,
                0.09012334447421859,
                0.0,
                0.021225735454201422,
                0.0,
                0.04425931884285688,
                0.10428530191330504,
                0.0391984330394297,
                0.0673265257315512,
                0.0,
                0.0,
                0.06160377145235959,
                0.03723536294532794,
                0.08436426525305805,
                0.032565551990231846,
                0.0,
                0.13138059445422404,
                0.09191043272956714,
                0.0,
                0.05439280265691814,
                0.05891816201872889,
                0.0,
                0.10311957694401044,
                0.0,
                0.03299812999481409,
                0.05396691637600865,
                0.034919855551378436,
                0.0,
                0.07484958773097639,
                0.0,
                0.0,
                0.017691021576735112,
                0.0,
                0.05165313782354007,
                0.055527835668240974,
                0.0375741597157234,
                0.0,
                0.05837128537037522,
                0.10576329971265452,
                0.0
            ],
            [
                0.0,
                0.05597850373290252,
                0.0,
                0.07291736693316771,
                0.07326581563098605,
                0.23778080917729869,
                0.11405651640432546,
                0.1651411168248263,
                0.062090584750866845,
                0.051046059929070756,
                0.023983878960038164,
                0.024459937071127907,
                0.0,
                0.0634818191770468,
                0.0,
                0.0,
                0.04257696053141566,
                0.0,
                0.0,
                0.2483087528079542,
                0.020132406570374538,
                0.03303807590610499,
                0.0,
                0.0386066693987075,
                0.12413443570411074,
                0.025161677887197573,
                0.2796711288157397,
                0.0,
                0.1749338926570225,
                0.029104642633135093,
                0.11205560851466372,
                0.0,
                0.0,
                0.2367761576801271,
                0.0,
                0.0,
                0.0,
                0.5063145404114048,
                0.03466350673643413,
                0.05337430266081826,
                0.04468795653806222,
                1.0,
                0.27043823741166984,
                0.06883455811832549,
                0.0,
                0.0936089176107577,
                0.1634618280965841,
                0.049996501115745356,
                0.0,
                0.03722124356583917,
                0.0,
                0.36948145602737686,
                0.0,
                0.13652566261478782,
                0.07587477167354245,
                0.0,
                0.0,
                0.11900698109347707,
                0.14487586669613967,
                0.0,
                0.0,
                0.19824884002428814,
                0.2754123239084038,
                0.27558347497958147,
                0.0,
                0.10577927547304103,
                0.06639882337639876,
                0.17896326076557528,
                0.0,
                0.0,
                0.11621431377158661,
                0.11841562313711787,
                0.06057967476391525,
                0.0635768196362703,
                0.0,
                0.2853734536023934,
                0.18310822786843803,
                0.0,
                0.017601060594730305,
                0.023200918474209523,
                0.2908485136168356,
                0.062112593160000416,
                0.07006906847602905,
                0.08659262965670726,
                0.0,
                0.04680123355704976
            ],
            [
                0.0,
                0.056404980084154926,
                0.0,
                0.1078172207575075,
                0.0972799236505798,
                0.20521766517505732,
                0.03707692979689154,
                0.10190150958267497,
                0.028768543892974122,
                0.11348332208141833,
                0.0,
                0.04653626544751912,
                0.06015221897840899,
                0.11818574097007659,
                0.07143345475298839,
                0.0,
                0.07905191824939693,
                0.0,
                0.0,
                0.12430049398423146,
                0.034811723368721355,
                0.05983244157554917,
                0.0,
                0.0,
                0.05395219877723876,
                0.0,
                0.2223187545035729,
                0.0,
                0.11398251820118398,
                0.0,
                0.03852051874372558,
                0.057588996108684655,
                0.042587949167121296,
                0.08793362431872583,
                0.0,
                0.0,
                0.03669653926524782,
                0.213474624138537,
                0.0,
                0.05345476702277214,
                0.16711375008158272,
                0.27043823741166984,
                1.0,
                0.0,
                0.0,
                0.0,
                0.09193719124410715,
                0.06906166384086909,
                0.0,
                0.0,
                0.0,
                0.15088014279204495,
                0.0,
                0.09098313404030212,
                0.0,
                0.0,
                0.06938054581921967,
                0.020714483998723488,
                0.1074684436821206,
                0.040420236143421856,
                0.031197349603567806,
                0.1042813178294416,
                0.20722656919158586,
                0.1853274867633516,
                0.0,
                0.12283268443039175,
                0.06690468769989219,
                0.0,
                0.0,
                0.0,
                0.11685033498083647,
                0.0,
                0.0,
                0.025759749814152112,
                0.0,
                0.16217678098536437,
                0.04625352226574559,
                0.0,
                0.0,
                0.055375045914809434,
                0.2105859128192589,
                0.05293425379149796,
                0.07017470101091114,
                0.0,
                0.03695317454430729,
                0.0
            ],
            [
                0.019454123005826697,
                0.07651139592259563,
                0.0,
                0.022498708311195426,
                0.0,
                0.0,
                0.07606398858694066,
                0.21269180213082556,
                0.022051045475106883,
                0.16772455132675942,
                0.0,
                0.06824160071350566,
                0.0,
                0.07481955656853269,
                0.08600245367755001,
                0.0,
                0.06209007031762972,
                0.0,
                0.05061060266249031,
                0.16304899953813873,
                0.0,
                0.0,
                0.05324707299473037,
                0.02673021786814372,
                0.10397510276165749,
                0.11671648960219948,
                0.0,
                0.0,
                0.020682269172631985,
                0.04030254102076004,
                0.0,
                0.047435842428053716,
                0.0,
                0.16855813085185287,
                0.0,
                0.0,
                0.41945496433797064,
                0.27994760255185686,
                0.06015060197528294,
                0.0,
                0.09038094926238144,
                0.06883455811832549,
                0.0,
                1.0,
                0.3312374169069555,
                0.09723741793465498,
                0.08056698695501355,
                0.039592083781619075,
                0.061692464721776356,
                0.19138125073618797,
                0.0,
                0.06817431118317673,
                0.0,
                0.06037883640756232,
                0.10370560677631642,
                0.0,
                0.0,
                0.06254099018150022,
                0.0,
                0.0,
                0.03220194722528256,
                0.0,
                0.0,
                0.025861569112328602,
                0.0,
                0.0,
                0.0907538845337181,
                0.0,
                0.02901639985824657,
                0.11799380607940874,
                0.1994789642399768,
                0.1830731985872228,
                0.1546151404836984,
                0.0702899023411807,
                0.0,
                0.0,
                0.0,
                0.027250152999480342,
                0.08164535032609178,
                0.04783675721649899,
                0.0,
                0.02078818334146141,
                0.0,
                0.0,
                0.02975946042071931,
                0.0
            ],
            [
                0.0,
                0.0,
                0.08710931133032972,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.08147874114979549,
                0.0,
                0.0,
                0.0,
                0.0,
                0.06477524017000641,
                0.07205803738799565,
                0.0,
                0.0,
                0.0,
                0.12280507884299088,
                0.0,
                0.050074830972771205,
                0.0,
                0.0,
                0.07831186163989134,
                0.08790840635929519,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.10022165410850399,
                0.0,
                0.0,
                0.17525152480958048,
                0.05912316882722407,
                0.04530416892438609,
                0.1053954294299423,
                0.0,
                0.0,
                0.0,
                0.3312374169069555,
                1.0,
                0.10623090640642974,
                0.0,
                0.0,
                0.0,
                0.06171692648135421,
                0.0,
                0.0,
                0.0,
                0.06608750054789847,
                0.0,
                0.0,
                0.0,
                0.04710455907066971,
                0.0,
                0.0,
                0.06755102786273971,
                0.0,
                0.0,
                0.0871484868584699,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.05798175637807719,
                0.06885174292389211,
                0.0,
                0.13481453010467684,
                0.052940876812039114,
                0.0,
                0.0,
                0.0,
                0.0,
                0.06149356152052946,
                0.0,
                0.0,
                0.045507305529875176,
                0.0,
                0.0,
                0.0,
                0.09804792450060813
            ],
            [
                0.013587893813395131,
                0.05344002004096941,
                0.0,
                0.10652164666860112,
                0.0,
                0.0,
                0.10541359665934807,
                0.08196073658468274,
                0.04580598970067243,
                0.10072488850405684,
                0.0,
                0.06634739878425136,
                0.0,
                0.0,
                0.0,
                0.0,
                0.12465973129674045,
                0.0,
                0.06848076156479324,
                0.0,
                0.06238555813946591,
                0.0,
                0.03719086044175807,
                0.055525897207328964,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0708430056769719,
                0.05593446519230646,
                0.03670742476081895,
                0.033131958180190775,
                0.0,
                0.024790570934595087,
                0.18606149880592354,
                0.0,
                0.016678935290504262,
                0.1325393682743851,
                0.033091604297321026,
                0.0,
                0.0631273247816552,
                0.0936089176107577,
                0.0,
                0.09723741793465498,
                0.10623090640642974,
                1.0,
                0.0,
                0.058182573530743235,
                0.0,
                0.02283595963723368,
                0.0,
                0.047616913950883945,
                0.0,
                0.21643893559252625,
                0.07243404250647778,
                0.0,
                0.0,
                0.04872799511959162,
                0.0,
                0.0,
                0.019814869459310845,
                0.06800224328837066,
                0.0,
                0.053721478636459534,
                0.0,
                0.0,
                0.0633878045197896,
                0.0,
                0.14775422383192752,
                0.0,
                0.03550143015264087,
                0.11304577385286503,
                0.10986262721353655,
                0.0,
                0.0,
                0.0,
                0.0,
                0.09673555937601727,
                0.0,
                0.0,
                0.0,
                0.014519679336486433,
                0.06332093657264655,
                0.11104001822836912,
                0.02078574233439138,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.04601373206284602,
                0.249657590963697,
                0.018224126681920305,
                0.0542310786931423,
                0.09690241995274572,
                0.05305790701868484,
                0.02492914088917542,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.044255020194566265,
                0.0983961020181901,
                0.0,
                0.06836853835332737,
                0.026727521572407046,
                0.08113665728350763,
                0.0,
                0.0,
                0.0,
                0.026153359683941627,
                0.10465315150940796,
                0.0,
                0.16504530350914517,
                0.044540170495286024,
                0.04208950501002392,
                0.0,
                0.07016462844381442,
                0.0,
                0.0,
                0.0,
                0.0426264865999298,
                0.16393107290879175,
                0.0,
                0.02627419398833847,
                0.0,
                0.1634618280965841,
                0.09193719124410715,
                0.08056698695501355,
                0.0,
                0.0,
                1.0,
                0.01662995093829878,
                0.046915372622660774,
                0.29118868234038625,
                0.0,
                0.11756280890192651,
                0.0,
                0.06839638617404942,
                0.0,
                0.0,
                0.0,
                0.08556213542045683,
                0.0,
                0.0,
                0.028399079009424167,
                0.03656104184088773,
                0.08685837003287654,
                0.16488381872591645,
                0.18831273069604404,
                0.10994828925779991,
                0.0,
                0.22760160795157844,
                0.0,
                0.04339601637958865,
                0.04352623631493549,
                0.0,
                0.06093080106114496,
                0.09280927413154065,
                0.10967487923431231,
                0.2921516985380887,
                0.09037526213691091,
                0.0,
                0.0493392489969509,
                0.06049382144524374,
                0.06905204881839068,
                0.26745603421429365,
                0.03449240937948276,
                0.10803486956565231,
                0.0,
                0.04864578190520694
            ],
            [
                0.01706532629139019,
                0.0,
                0.026045152840004922,
                0.019736063062332145,
                0.0880128392282774,
                0.146321727682257,
                0.16294421285454128,
                0.08762983983358885,
                0.09486159659314346,
                0.22207393588222,
                0.09377335023771353,
                0.01941678934773518,
                0.06370087586994574,
                0.0,
                0.09034862191474659,
                0.0,
                0.054465950950775596,
                0.0,
                0.04439606185180467,
                0.029659681163616378,
                0.02792665859021938,
                0.0,
                0.1378864363416293,
                0.07590241728503368,
                0.021189549056388386,
                0.18925562623870315,
                0.10199429666266605,
                0.025495607206304578,
                0.08186301845066338,
                0.03535374031948972,
                0.019993168474563817,
                0.04161113449828871,
                0.03770164411518182,
                0.19360698813017943,
                0.020498367793126634,
                0.0,
                0.02094743135575908,
                0.07012488428097471,
                0.0,
                0.037457185978186584,
                0.09012334447421859,
                0.049996501115745356,
                0.06906166384086909,
                0.039592083781619075,
                0.0,
                0.058182573530743235,
                0.01662995093829878,
                1.0,
                0.0,
                0.028680169843705607,
                0.0,
                0.1668856339871395,
                0.0,
                0.1260646688647765,
                0.0,
                0.0,
                0.0,
                0.05874090020350566,
                0.0,
                0.023212808007295617,
                0.012442959055622429,
                0.02108669214040433,
                0.1623638037343891,
                0.06184159562245124,
                0.0,
                0.022752788237043114,
                0.0,
                0.0,
                0.10818331782040433,
                0.0,
                0.0649504028463785,
                0.0,
                0.06021413340263207,
                0.009084020467897231,
                0.039430576590267045,
                0.028595332029959536,
                0.0,
                0.05029397532881875,
                0.010551558741266554,
                0.0,
                0.1642136484481718,
                0.03837972963034619,
                0.14022987000137502,
                0.0,
                0.026105258108174784,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0756134934382899,
                0.0,
                0.0,
                0.0,
                0.06786807336201589,
                0.0,
                0.0,
                0.0,
                0.07534473215322043,
                0.0,
                0.0,
                0.0,
                0.05200350542504922,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.052500963098769476,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.03264032974508299,
                0.04281134709008092,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.061692464721776356,
                0.0,
                0.0,
                0.046915372622660774,
                0.0,
                1.0,
                0.04468949843753353,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.04420745767374191,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.03322958088352345,
                0.03332929404236285,
                0.18491036054767845,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.06195076244926812,
                0.0,
                0.027856065799319926,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.014092401780238746,
                0.0,
                0.0,
                0.016297873564529226,
                0.0,
                0.03811365661675679,
                0.01571475016462526,
                0.02755822329546134,
                0.015973590401194056,
                0.05392412190376143,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.04497752056040993,
                0.0,
                0.03666189150989827,
                0.0,
                0.0,
                0.0,
                0.0385717282675089,
                0.01936314321433945,
                0.03017748597621128,
                0.0,
                0.0,
                0.0,
                0.03829454083359239,
                0.029194819044733835,
                0.0,
                0.08876789633248987,
                0.0,
                0.02571102562101421,
                0.0,
                0.0,
                0.10125624189643684,
                0.19080096046583864,
                0.04357258613534137,
                0.0,
                0.021225735454201422,
                0.03722124356583917,
                0.0,
                0.19138125073618797,
                0.06171692648135421,
                0.02283595963723368,
                0.29118868234038625,
                0.028680169843705607,
                0.04468949843753353,
                1.0,
                0.0,
                0.08780698975745406,
                0.0,
                0.04373791722319365,
                0.11412076180007465,
                0.0,
                0.0,
                0.018803457650810432,
                0.05958597940179076,
                0.0,
                0.05279973902601382,
                0.0,
                0.04838657286385875,
                0.04788434509417075,
                0.0,
                0.0,
                0.0,
                0.3718216696063581,
                0.0210192340665267,
                0.04133711612585755,
                0.0414611578476195,
                0.0,
                0.038963847101126124,
                0.02113323115154247,
                0.0,
                0.06652470277669102,
                0.037946268293257965,
                0.019739779815653336,
                0.0,
                0.05762372518494832,
                0.03846712746607064,
                0.015058783777680305,
                0.0,
                0.0,
                0.021557500838577014,
                0.04633780939843355
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.029385087974879636,
                0.0,
                0.04484761055573021,
                0.07571030540091968,
                0.18596575523480294,
                0.19503948591364834,
                0.2287321995100864,
                0.2229009950081997,
                0.03330769066433956,
                0.17103750452635796,
                0.061196341018499516,
                0.05868319151517582,
                0.10968766782148391,
                0.0,
                0.0,
                0.0,
                0.09378588683250076,
                0.06273181380027293,
                0.076446366215199,
                0.14392987913399155,
                0.056055884182811495,
                0.0,
                0.08042870521001415,
                0.04037549281495995,
                0.09165267184084748,
                0.12745373011797295,
                0.3486637269733553,
                0.04390133818350825,
                0.31143354401884366,
                0.06087623241363909,
                0.03442659135196579,
                0.07165095041772884,
                0.06491912959678728,
                0.38381312074514484,
                0.03529650301772207,
                0.0,
                0.03606975352983943,
                0.1866005849280276,
                0.0,
                0.09350102634553882,
                0.04425931884285688,
                0.36948145602737686,
                0.15088014279204495,
                0.06817431118317673,
                0.0,
                0.047616913950883945,
                0.11756280890192651,
                0.1668856339871395,
                0.0,
                0.08780698975745406,
                0.0,
                1.0,
                0.0,
                0.2015261453443397,
                0.0,
                0.0,
                0.0,
                0.12159196083733373,
                0.024087922276649253,
                0.03997054575994314,
                0.0,
                0.07666754495585237,
                0.1260677820188321,
                0.24642362839350385,
                0.0,
                0.039178429559629184,
                0.0,
                0.06441585506914754,
                0.14846238920645985,
                0.0,
                0.04522234114282219,
                0.0,
                0.1417580165299906,
                0.06421804648076974,
                0.0,
                0.20215017875868574,
                0.03956225665093406,
                0.04116084508044019,
                0.09022164289219037,
                0.023949439825428853,
                0.22532006941113913,
                0.16429518806215496,
                0.0723296769891213,
                0.0,
                0.044951106882888996,
                0.04831116182216548
            ],
            [
                0.0,
                0.0,
                0.0,
                0.08007395875111498,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.09978374664742752,
                0.0,
                0.0,
                0.0,
                0.10230514193672645,
                0.0,
                0.0,
                0.11147202938048739,
                0.0,
                0.0,
                0.10428530191330504,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.09245053401025695,
                0.11585262016484336,
                0.0,
                0.0,
                0.15278062416859253,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.09130004559525354,
                0.0764936932958258,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.14492826379266974,
                0.0,
                0.0
            ],
            [
                0.026025014244587048,
                0.0,
                0.0,
                0.09526254399516909,
                0.1353509485099125,
                0.027770131209193468,
                0.18134508227402674,
                0.16236806489997538,
                0.08626398674403453,
                0.2652787585741322,
                0.021926715726007566,
                0.022361941024147097,
                0.0,
                0.0,
                0.0,
                0.0,
                0.19983687792333626,
                0.05555866802701218,
                0.0994334133946449,
                0.021931034557070614,
                0.06804346228845805,
                0.04447035790816026,
                0.07123198680070938,
                0.07105397706472757,
                0.013651173618189046,
                0.023003491601221535,
                0.16312439955011043,
                0.0,
                0.1251711200341275,
                0.08052352277863091,
                0.03515302906402837,
                0.06345793508781324,
                0.05749587253054675,
                0.07663127248613097,
                0.03604129679163543,
                0.0,
                0.03194531356228346,
                0.21329239976359432,
                0.03169032246796871,
                0.04879624198686287,
                0.0391984330394297,
                0.13652566261478782,
                0.09098313404030212,
                0.06037883640756232,
                0.06608750054789847,
                0.21643893559252625,
                0.06839638617404942,
                0.1260646688647765,
                0.0,
                0.04373791722319365,
                0.0,
                0.2015261453443397,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.26607376114944936,
                0.02133355941994148,
                0.0,
                0.03795159625289616,
                0.06790090100391297,
                0.06697367700128565,
                0.14151903296007398,
                0.0,
                0.13416493867896476,
                0.0,
                0.0,
                0.3949088195432376,
                0.0,
                0.04005133737974944,
                0.05265646367632861,
                0.32727356682625797,
                0.013853339692333945,
                0.0,
                0.04360853761019819,
                0.0,
                0.15111157755396218,
                0.14485428836034162,
                0.0,
                0.1255280685311244,
                0.15985796506210614,
                0.18533820657395997,
                0.0,
                0.24359059253753806,
                0.0
            ],
            [
                0.0,
                0.08433677581065835,
                0.0,
                0.0,
                0.0,
                0.0,
                0.07572163869551385,
                0.08741272752697264,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.08278706845510998,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.07196627249228975,
                0.0,
                0.10916984165691547,
                0.0673265257315512,
                0.07587477167354245,
                0.0,
                0.10370560677631642,
                0.0,
                0.07243404250647778,
                0.0,
                0.0,
                0.0,
                0.11412076180007465,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.3468838759853325,
                0.0,
                0.04484775376834671,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.10003594786859957,
                0.19132705096819275,
                0.0,
                0.0,
                0.05602685316071424,
                0.09162932868651534,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.14331670353027498,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.1883632571174377,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.09733799352057808,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.07670445653929217,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.08106830856982448,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.23931939696676083,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.03277790404937506,
                0.0,
                0.0,
                0.0,
                0.0,
                0.03671244522450545,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.03919647214042388,
                0.0,
                0.0,
                0.14599949589355038,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.06938054581921967,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.05711968522014201,
                0.0,
                0.0,
                0.09615906005339142,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.10540544180766166,
                0.0,
                0.02990104660269151,
                0.07306715817141998,
                0.0442761901570429,
                0.0,
                0.04790856867145094,
                0.034478554102938846,
                0.0791695425612248,
                0.0,
                0.0,
                0.01968589439890159,
                0.031787241376494316,
                0.0,
                0.020471963436987817,
                0.0,
                0.03262984715755797,
                0.087765979717738,
                0.04003073384212867,
                0.015084198879633805,
                0.0,
                0.019503348183231742,
                0.040888804421297345,
                0.08127300115810059,
                0.08483116309724126,
                0.0,
                0.13088271636030097,
                0.04068710380257355,
                0.0,
                0.0,
                0.054387489927227965,
                0.0682463650112147,
                0.0,
                0.0,
                0.03308926870265894,
                0.07923008053325162,
                0.017511338109759536,
                0.038309775409417005,
                0.06160377145235959,
                0.11900698109347707,
                0.020714483998723488,
                0.06254099018150022,
                0.04710455907066971,
                0.04872799511959162,
                0.08556213542045683,
                0.05874090020350566,
                0.0,
                0.018803457650810432,
                0.0,
                0.12159196083733373,
                0.0,
                0.26607376114944936,
                0.0,
                0.1883632571174377,
                0.0,
                1.0,
                0.0,
                0.021465424764960075,
                0.062160978248908545,
                0.08470935951956451,
                0.11703451902425523,
                0.13770980120999182,
                0.0,
                0.14345066249644362,
                0.0,
                0.031524588896781336,
                0.047359971866375486,
                0.03134741182554705,
                0.0337877090964073,
                0.029096742074255257,
                0.17141904805597158,
                0.1037220762249517,
                0.033227845486117784,
                0.1471247678732248,
                0.01936144254253636,
                0.022238570010659556,
                0.12291818660688243,
                0.07053520275280464,
                0.09304196380890921,
                0.09343981256957903,
                0.14304843410927126,
                0.0,
                0.2610553556342015,
                0.02364308467123169
            ],
            [
                0.0,
                0.0,
                0.06656358109736414,
                0.15774744434154933,
                0.02281001916957183,
                0.023894552282583692,
                0.05486662882006975,
                0.0,
                0.0,
                0.0,
                0.0,
                0.12862949023571235,
                0.0,
                0.049937234977327986,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.008336597903897047,
                0.0,
                0.0,
                0.0,
                0.03955078010869907,
                0.0,
                0.0400716118569038,
                0.0,
                0.014615267354781473,
                0.0,
                0.03562806986501691,
                0.043225688979738296,
                0.0,
                0.050680013505205034,
                0.03652834120722134,
                0.0,
                0.04352042613717719,
                0.1248218828055438,
                0.03461866103855976,
                0.022101684571526427,
                0.03723536294532794,
                0.14487586669613967,
                0.1074684436821206,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.05958597940179076,
                0.0,
                0.024087922276649253,
                0.09245053401025695,
                0.02133355941994148,
                0.3468838759853325,
                0.0,
                0.0,
                0.0,
                1.0,
                0.041365506747934065,
                0.023416399348427267,
                0.030754915440311118,
                0.08488569557724056,
                0.06540772234875038,
                0.0,
                0.0,
                0.0,
                0.09169109882549814,
                0.0,
                0.0,
                0.06963379904829718,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.04855974347437785,
                0.0,
                0.05607783010009917,
                0.029396165758163742,
                0.024116153368363157,
                0.0,
                0.02901479499449704,
                0.11986413314473537,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.04282729962462285,
                0.0358278069079142,
                0.11156893781442442,
                0.04350932917857552,
                0.0,
                0.08921896207251652,
                0.0,
                0.09365004284627113,
                0.034797177898737056,
                0.03192796219135118,
                0.04589904989591514,
                0.11352631131599557,
                0.0,
                0.0,
                0.11805948194697392,
                0.10694209725471276,
                0.0,
                0.0,
                0.015180020037222429,
                0.02943384352642868,
                0.0,
                0.0,
                0.0,
                0.036505995678613075,
                0.0,
                0.04192365526298419,
                0.024251996742965177,
                0.0,
                0.0775223651343809,
                0.0,
                0.04413184604536232,
                0.02080967806898277,
                0.17223623202267607,
                0.0,
                0.0,
                0.04987636937860063,
                0.0,
                0.03667466145033218,
                0.08436426525305805,
                0.0,
                0.040420236143421856,
                0.0,
                0.0,
                0.0,
                0.0,
                0.023212808007295617,
                0.0,
                0.0,
                0.0,
                0.03997054575994314,
                0.11585262016484336,
                0.0,
                0.0,
                0.0,
                0.0,
                0.021465424764960075,
                0.041365506747934065,
                1.0,
                0.0,
                0.04969786155458737,
                0.06835923672759246,
                0.03327721247757157,
                0.0,
                0.060426048448820276,
                0.0,
                0.0,
                0.06626821397716791,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.026749065034369728,
                0.0,
                0.15784543117356964,
                0.038292799765427286,
                0.0
            ],
            [
                0.05796206289158036,
                0.040793337061553483,
                0.0,
                0.0,
                0.0,
                0.0,
                0.013635762544877842,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.12565347262372736,
                0.0,
                0.1100068714029169,
                0.0,
                0.0,
                0.11727043724876424,
                0.04421630241559503,
                0.07575788210893404,
                0.070779029973997,
                0.0,
                0.0,
                0.01185930096383193,
                0.0,
                0.0,
                0.0,
                0.020540409971460217,
                0.03668622499886484,
                0.0635537225485412,
                0.12497762377142682,
                0.0,
                0.0,
                0.0,
                0.023959474948896633,
                0.01703744826223436,
                0.02234646882492628,
                0.04769150292941624,
                0.0,
                0.032565551990231846,
                0.0,
                0.031197349603567806,
                0.03220194722528256,
                0.06755102786273971,
                0.019814869459310845,
                0.028399079009424167,
                0.012442959055622429,
                0.0,
                0.05279973902601382,
                0.0,
                0.0,
                0.0,
                0.03795159625289616,
                0.04484775376834671,
                0.0,
                0.0,
                0.062160978248908545,
                0.023416399348427267,
                0.0,
                1.0,
                0.0,
                0.0,
                0.06419362674530697,
                0.036608923511794844,
                0.0,
                0.0,
                0.0,
                0.03647697629346305,
                0.024143992341214476,
                0.0,
                0.0,
                0.0,
                0.04167490871008084,
                0.11514864273278815,
                0.0,
                0.0,
                0.1749913144692058,
                0.0,
                0.025956687082853667,
                0.0,
                0.017200153586177422,
                0.07144121325912926,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.06173795630134331,
                0.0,
                0.0746891157545421,
                0.08749829270886474,
                0.04003401496642667,
                0.048792707242292024,
                0.03620871194908723,
                0.04150681317891562,
                0.06260540049629539,
                0.09562359107869096,
                0.03223745235105988,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.16140631960365942,
                0.0265338989073158,
                0.0,
                0.0,
                0.0,
                0.019679823794240603,
                0.03316232538139742,
                0.12432496624662183,
                0.0,
                0.1102640869301415,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0754273869111088,
                0.0,
                0.0,
                0.04016612246273683,
                0.18803654663837713,
                0.0,
                0.12295335189324877,
                0.0,
                0.19824884002428814,
                0.1042813178294416,
                0.0,
                0.0,
                0.06800224328837066,
                0.03656104184088773,
                0.02108669214040433,
                0.04420745767374191,
                0.0,
                0.0,
                0.07666754495585237,
                0.0,
                0.06790090100391297,
                0.0,
                0.0,
                0.0,
                0.08470935951956451,
                0.030754915440311118,
                0.04969786155458737,
                0.0,
                1.0,
                0.2577179326650589,
                0.05816686602732012,
                0.0,
                0.0500221345100667,
                0.0,
                0.0,
                0.04430054648266494,
                0.0,
                0.13354560996783033,
                0.06707640215070425,
                0.02864762143685672,
                0.019971270729692646,
                0.0,
                0.11904003223716858,
                0.0,
                0.0,
                0.02319766198092557,
                0.0,
                0.2460200821121824,
                0.04428703724689406,
                0.09234889892441484,
                0.06217058171896685,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.19960389423418115,
                0.2864580427918123,
                0.2507338878161528,
                0.048126416093878334,
                0.0714285243010549,
                0.0,
                0.17744598906472317,
                0.031178370083339572,
                0.03179723227796049,
                0.0,
                0.0,
                0.0,
                0.0,
                0.08581983868327134,
                0.0,
                0.0,
                0.12793732389778328,
                0.08896798336671316,
                0.0,
                0.0,
                0.0,
                0.019411085018764783,
                0.0327094756603783,
                0.29520803201573936,
                0.0,
                0.3260477355240834,
                0.0,
                0.05887774267799902,
                0.0,
                0.08175540807945282,
                0.04144894454731392,
                0.1339130229498377,
                0.0,
                0.0,
                0.32699960063206907,
                0.0,
                0.15584452035876867,
                0.13138059445422404,
                0.2754123239084038,
                0.20722656919158586,
                0.0,
                0.0,
                0.0,
                0.08685837003287654,
                0.1623638037343891,
                0.0,
                0.04838657286385875,
                0.0,
                0.1260677820188321,
                0.15278062416859253,
                0.06697367700128565,
                0.0,
                0.0,
                0.0,
                0.11703451902425523,
                0.08488569557724056,
                0.06835923672759246,
                0.0,
                0.2577179326650589,
                1.0,
                0.09564631019909875,
                0.0,
                0.04933905485877145,
                0.0,
                0.08112161316201115,
                0.0,
                0.0,
                0.10273224784648194,
                0.0,
                0.02825642247157489,
                0.04744591334720787,
                0.0,
                0.26016557033349974,
                0.04982242456314796,
                0.1450519426669525,
                0.022880885197767573,
                0.030160543407826784,
                0.47759454134137413,
                0.10114842006633724,
                0.0910878241163797,
                0.08551542018665982,
                0.0,
                0.06084029120684765
            ],
            [
                0.07112152764399013,
                0.04643714847170894,
                0.066269827632426,
                0.07922925971644147,
                0.05737935724892242,
                0.22078931724742626,
                0.14111776714189708,
                0.0626600669126588,
                0.061262385607661195,
                0.08263152333966477,
                0.018783378676820745,
                0.019156211602957083,
                0.049522179059997735,
                0.030518459238349147,
                0.0,
                0.05031587965393618,
                0.10065912905222481,
                0.0,
                0.11014913760673808,
                0.11156186853304693,
                0.06014542332240631,
                0.292038211376339,
                0.030510209524744942,
                0.04555169570486479,
                0.03272363096623739,
                0.019705791739814005,
                0.11874786016094618,
                0.0,
                0.1507583773665076,
                0.04588687200029596,
                0.10358895173432868,
                0.13979915800980006,
                0.03506184942585879,
                0.16646956063829066,
                0.0,
                0.02411278415722953,
                0.08722280133637006,
                0.17474774139258692,
                0.027147309006263144,
                0.04180098390922647,
                0.09191043272956714,
                0.27558347497958147,
                0.1853274867633516,
                0.025861569112328602,
                0.0871484868584699,
                0.053721478636459534,
                0.16488381872591645,
                0.06184159562245124,
                0.0,
                0.04788434509417075,
                0.0,
                0.24642362839350385,
                0.0,
                0.14151903296007398,
                0.0,
                0.09733799352057808,
                0.05711968522014201,
                0.13770980120999182,
                0.06540772234875038,
                0.03327721247757157,
                0.06419362674530697,
                0.05816686602732012,
                0.09564631019909875,
                1.0,
                0.0,
                0.13085008093202452,
                0.05508135826903661,
                0.04887163680537758,
                0.016626199141810034,
                0.0,
                0.03430971815011161,
                0.04510781775866199,
                0.10715089030972987,
                0.06992907410983203,
                0.04291553194748021,
                0.22012776168713016,
                0.06809511724776841,
                0.06099627271428401,
                0.03717568133052223,
                0.018170189987918046,
                0.1709479845513659,
                0.1264639560911616,
                0.054875770883862175,
                0.0,
                0.3693566044425419,
                0.03665317415540348
            ],
            [
                0.060391028018345574,
                0.0,
                0.0,
                0.0,
                0.0,
                0.1941391469986114,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.13133416173019807,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.057416217417583425,
                0.0,
                0.0,
                0.09044840908681252,
                0.0,
                0.0,
                0.0,
                0.0,
                0.13737405998109198,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.18831273069604404,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.036608923511794844,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.10694782458652954,
                0.0,
                0.0,
                0.0,
                0.14138061532635907,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.1785855959352988,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.08166685275988227,
                0.0,
                0.13222010088725733,
                0.10367879521868426,
                0.0,
                0.0,
                0.0,
                0.03410758490432718,
                0.0,
                0.0,
                0.05541659770218853,
                0.0,
                0.0,
                0.057629414187285656,
                0.0,
                0.0,
                0.20276616775440431,
                0.0354586826466981,
                0.0894462367965095,
                0.0,
                0.0,
                0.0,
                0.0357825381917103,
                0.032587759219034104,
                0.0,
                0.07131414855687244,
                0.0,
                0.05758607454995932,
                0.0,
                0.06366666118864758,
                0.0,
                0.0,
                0.0,
                0.0,
                0.03599883560335056,
                0.0,
                0.035947861429879345,
                0.05439280265691814,
                0.10577927547304103,
                0.12283268443039175,
                0.0,
                0.0,
                0.0,
                0.10994828925779991,
                0.022752788237043114,
                0.0,
                0.0,
                0.0,
                0.039178429559629184,
                0.0,
                0.13416493867896476,
                0.0,
                0.0,
                0.0,
                0.14345066249644362,
                0.0,
                0.060426048448820276,
                0.0,
                0.0500221345100667,
                0.04933905485877145,
                0.13085008093202452,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.11952060109179194,
                0.06005865644064929,
                0.0,
                0.18905695206906303,
                0.0691464930447564,
                0.0,
                0.02503054946371427,
                0.0,
                0.03922434675520138,
                0.1831477532464159,
                0.04719187021709005,
                0.0,
                0.1532927939293228,
                0.14922219884709503
            ],
            [
                0.0,
                0.2754988942974337,
                0.0,
                0.0,
                0.0,
                0.0,
                0.1460089577166157,
                0.07649581182115923,
                0.0,
                0.0,
                0.0,
                0.0,
                0.08336891514461477,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.03160821824023429,
                0.0,
                0.0,
                0.08959445397905559,
                0.0,
                0.035402354556924136,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.03779773849467359,
                0.0,
                0.0,
                0.05086014647611904,
                0.0629784539824795,
                0.0,
                0.0,
                0.05891816201872889,
                0.06639882337639876,
                0.06690468769989219,
                0.0907538845337181,
                0.0,
                0.0633878045197896,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.10003594786859957,
                0.0,
                0.09615906005339142,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.05508135826903661,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.04902969782050625,
                0.08018580454819926,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.06389874556632737,
                0.17534225747008292,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.1053754101195176,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.05867239894995629,
                0.0,
                0.0,
                0.0,
                0.03908410750042522,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0591880737167926,
                0.10168555446099041,
                0.12028096024009033,
                0.0,
                0.17896326076557528,
                0.0,
                0.0,
                0.0,
                0.0,
                0.22760160795157844,
                0.0,
                0.0,
                0.3718216696063581,
                0.0,
                0.06441585506914754,
                0.0,
                0.0,
                0.19132705096819275,
                0.0,
                0.0,
                0.031524588896781336,
                0.09169109882549814,
                0.0,
                0.0,
                0.0,
                0.08112161316201115,
                0.04887163680537758,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.10331086965789617,
                0.0,
                0.0,
                0.03543052753833895,
                0.0,
                0.11153075915404126,
                0.06361811377070682,
                0.0,
                0.0,
                0.038511913033728765,
                0.06449135057645619,
                0.0,
                0.1579032309421129,
                0.1437377501415755,
                0.0,
                0.07768679669401486
            ],
            [
                0.01250690249378372,
                0.0,
                0.06824579175336307,
                0.08738024357690326,
                0.3565356544084206,
                0.0,
                0.19441239679359035,
                0.024457719630274044,
                0.06952253468447697,
                0.1425913664300189,
                0.0,
                0.05543129253646971,
                0.05245639424361138,
                0.0,
                0.0,
                0.056453870873675156,
                0.11474236740742134,
                0.0,
                0.11031693865183652,
                0.0,
                0.12391152271464789,
                0.05130439181069048,
                0.03423212394745406,
                0.017184646586964582,
                0.04171960107478714,
                0.05384286293945443,
                0.144752656071594,
                0.0,
                0.08311798454983373,
                0.02591018626989218,
                0.033787148220784706,
                0.03049612957523015,
                0.0,
                0.07729327848794544,
                0.03464090205570274,
                0.0,
                0.015352034704070365,
                0.04027173079364692,
                0.0,
                0.0,
                0.10311957694401044,
                0.0,
                0.0,
                0.02901639985824657,
                0.0,
                0.14775422383192752,
                0.0,
                0.10818331782040433,
                0.0,
                0.0210192340665267,
                0.0,
                0.14846238920645985,
                0.09130004559525354,
                0.3949088195432376,
                0.0,
                0.0,
                0.0,
                0.047359971866375486,
                0.0,
                0.06626821397716791,
                0.03647697629346305,
                0.04430054648266494,
                0.0,
                0.016626199141810034,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.06101771393696061,
                0.0,
                0.0,
                0.06699049142726805,
                0.0,
                0.048150761065917265,
                0.0,
                0.0,
                0.12772118586685002,
                0.0,
                0.0,
                0.06947564368054991,
                0.059989272589012765,
                0.11656681902362821,
                0.08289961144328568,
                0.019132122770996938,
                0.0
            ],
            [
                0.04090948974590364,
                0.0,
                0.062295852388900966,
                0.0,
                0.0,
                0.0,
                0.029285603907317,
                0.1228446275845207,
                0.10628175380464995,
                0.05024580278337159,
                0.0,
                0.08792253426443754,
                0.0,
                0.04030026224233221,
                0.0,
                0.05153199803788982,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0683278522695935,
                0.06718372764644816,
                0.0,
                0.0378666341594286,
                0.0,
                0.05715788546336642,
                0.0,
                0.0,
                0.0,
                0.0,
                0.08040759908513956,
                0.0395998542843512,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.11799380607940874,
                0.05798175637807719,
                0.0,
                0.04339601637958865,
                0.0,
                0.03322958088352345,
                0.04133711612585755,
                0.0,
                0.0,
                0.0764936932958258,
                0.0,
                0.0,
                0.0,
                0.0,
                0.03134741182554705,
                0.0,
                0.0,
                0.024143992341214476,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.06101771393696061,
                1.0,
                0.03082909735824827,
                0.053834136466898615,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.17310413633014576,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.07011855493341863
            ],
            [
                0.0,
                0.04133520720555199,
                0.0,
                0.17508169827848918,
                0.04282322304571056,
                0.1265911181741167,
                0.14084444620727654,
                0.08341573958948426,
                0.0,
                0.0,
                0.0,
                0.07299048775469665,
                0.0,
                0.0721586821192029,
                0.5689333770841705,
                0.0,
                0.0,
                0.0,
                0.0,
                0.09177095849400595,
                0.015651016723265986,
                0.0,
                0.0,
                0.0,
                0.0818181361836679,
                0.16957663902878078,
                0.10546817270006272,
                0.0,
                0.049496035175894716,
                0.0,
                0.0,
                0.0,
                0.0,
                0.28981796398908005,
                0.0,
                0.0,
                0.07864830121424841,
                0.14994650686922326,
                0.07773063605983335,
                0.04149340520305149,
                0.03299812999481409,
                0.11621431377158661,
                0.11685033498083647,
                0.1994789642399768,
                0.06885174292389211,
                0.03550143015264087,
                0.04352623631493549,
                0.0649504028463785,
                0.03332929404236285,
                0.0414611578476195,
                0.0,
                0.04522234114282219,
                0.0,
                0.04005133737974944,
                0.05602685316071424,
                0.0,
                0.0,
                0.0337877090964073,
                0.06963379904829718,
                0.0,
                0.0,
                0.13354560996783033,
                0.10273224784648194,
                0.03430971815011161,
                0.10694782458652954,
                0.0,
                0.04902969782050625,
                0.10331086965789617,
                0.0,
                0.03082909735824827,
                1.0,
                0.044909438983842205,
                0.05447155878372832,
                0.03797405135138399,
                0.0,
                0.06294356203147926,
                0.045582704477069594,
                0.0,
                0.044108821076968736,
                0.05343774455581727,
                0.04527534181451392,
                0.0,
                0.054471985684799246,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.06760182080007537,
                0.0,
                0.0,
                0.0,
                0.0,
                0.04803897250607029,
                0.15431111318902094,
                0.03846149227677422,
                0.19715035574719514,
                0.08302750546671794,
                0.13647646225470297,
                0.0,
                0.06610699222641316,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.04662291723323012,
                0.0,
                0.0,
                0.0,
                0.10003157516571344,
                0.0,
                0.03514789972099553,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.11231573834180927,
                0.04186100046331343,
                0.0,
                0.05396691637600865,
                0.11841562313711787,
                0.0,
                0.1830731985872228,
                0.0,
                0.11304577385286503,
                0.0,
                0.0,
                0.18491036054767845,
                0.0,
                0.0,
                0.0,
                0.0,
                0.05265646367632861,
                0.09162932868651534,
                0.0,
                0.0,
                0.029096742074255257,
                0.0,
                0.0,
                0.0,
                0.06707640215070425,
                0.0,
                0.04510781775866199,
                0.0,
                0.0,
                0.08018580454819926,
                0.0,
                0.0,
                0.053834136466898615,
                0.044909438983842205,
                1.0,
                0.04690891861861407,
                0.0,
                0.0,
                0.0,
                0.09419027328770117,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.023184338446115803,
                0.0,
                0.0,
                0.05194302303555382,
                0.0,
                0.0,
                0.08859534791153502,
                0.04533784842492507,
                0.052217828787877035,
                0.19474928024198038,
                0.08122259816289232,
                0.0,
                0.0,
                0.0,
                0.051246463093183925,
                0.0,
                0.1433480495048222,
                0.0,
                0.08858008250556372,
                0.10241930416326182,
                0.034119633369343136,
                0.03961634060496744,
                0.06345689092256268,
                0.06329831126043763,
                0.037132378335313285,
                0.09004072060847834,
                0.05033228609003731,
                0.0,
                0.13479375360226417,
                0.11362488152176414,
                0.031316014491561364,
                0.05653139054375393,
                0.0,
                0.12158853914368115,
                0.03210732624394159,
                0.0,
                0.08180398030343006,
                0.13211171602859423,
                0.028231268373532164,
                0.020587300717855615,
                0.034919855551378436,
                0.06057967476391525,
                0.0,
                0.1546151404836984,
                0.13481453010467684,
                0.10986262721353655,
                0.06093080106114496,
                0.06021413340263207,
                0.0,
                0.038963847101126124,
                0.0,
                0.1417580165299906,
                0.0,
                0.32727356682625797,
                0.0,
                0.0,
                0.0,
                0.17141904805597158,
                0.0,
                0.0,
                0.0,
                0.02864762143685672,
                0.02825642247157489,
                0.10715089030972987,
                0.0,
                0.11952060109179194,
                0.0,
                0.0,
                0.06699049142726805,
                0.0,
                0.05447155878372832,
                0.04690891861861407,
                1.0,
                0.16876767277812874,
                0.0,
                0.10477099383271479,
                0.0,
                0.06291273727345664,
                0.2654296022027721,
                0.0,
                0.02246374026132117,
                0.13458353101418888,
                0.027026732188015667,
                0.0,
                0.1477717053870621,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.04958476394009215,
                0.009954830318041303,
                0.0,
                0.0,
                0.0,
                0.013617407948139714,
                0.0,
                0.0,
                0.04841474597651399,
                0.03572572301086211,
                0.0,
                0.0,
                0.10749667368363035,
                0.0,
                0.08356996822071526,
                0.0911294820889565,
                0.01875813992326458,
                0.0,
                0.0,
                0.025886295035225222,
                0.06277057283558696,
                0.035088417869667696,
                0.0,
                0.09015510152555864,
                0.0,
                0.07509900316428414,
                0.0,
                0.0,
                0.055275612177950025,
                0.0,
                0.0,
                0.0371890732606113,
                0.0346175588390564,
                0.0,
                0.07248125914055037,
                0.0,
                0.0635768196362703,
                0.025759749814152112,
                0.0702899023411807,
                0.052940876812039114,
                0.0,
                0.09280927413154065,
                0.009084020467897231,
                0.0,
                0.02113323115154247,
                0.0,
                0.06421804648076974,
                0.0,
                0.013853339692333945,
                0.0,
                0.0,
                0.0,
                0.1037220762249517,
                0.0,
                0.0,
                0.04167490871008084,
                0.019971270729692646,
                0.04744591334720787,
                0.06992907410983203,
                0.0,
                0.06005865644064929,
                0.0,
                0.03543052753833895,
                0.0,
                0.0,
                0.03797405135138399,
                0.0,
                0.16876767277812874,
                1.0,
                0.0,
                0.15958628014584095,
                0.049366996576795705,
                0.0,
                0.09618570379816628,
                0.051049382353182,
                0.03771930699878954,
                0.051453163579033456,
                0.01884129147180545,
                0.0,
                0.0,
                0.026572494419455594
            ],
            [
                0.0,
                0.0,
                0.06060814683806853,
                0.0,
                0.2003136810844977,
                0.05193482937790413,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.16045067347317063,
                0.0,
                0.0,
                0.3118423189132016,
                0.0,
                0.0,
                0.03513365226126542,
                0.0,
                0.0,
                0.0,
                0.062011130155261746,
                0.0,
                0.07121387034569453,
                0.0,
                0.03343967605423698,
                0.11168911538573896,
                0.0,
                0.052677895471356095,
                0.03534848539909245,
                0.0,
                0.024026534986732077,
                0.0,
                0.0,
                0.10699304597654435,
                0.0,
                0.07484958773097639,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.10967487923431231,
                0.039430576590267045,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.033227845486117784,
                0.0,
                0.0,
                0.11514864273278815,
                0.0,
                0.0,
                0.04291553194748021,
                0.14138061532635907,
                0.0,
                0.0,
                0.0,
                0.048150761065917265,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.06642556143280656,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.058077710465484246,
                0.0,
                0.15608648103611256,
                0.03133652981653753,
                0.09820413118066786,
                0.0,
                0.0,
                0.04286585472154953,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.1941784769027003,
                0.0459581845151896,
                0.059048220032726896,
                0.0,
                0.0,
                0.0,
                0.04497090861157849,
                0.18364357095442282,
                0.0,
                0.33718549461155817,
                0.0,
                0.07237323640964403,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.37306489506742657,
                0.0,
                0.04517868415268845,
                0.0,
                0.2853734536023934,
                0.16217678098536437,
                0.0,
                0.0,
                0.0,
                0.2921516985380887,
                0.028595332029959536,
                0.0,
                0.06652470277669102,
                0.0,
                0.20215017875868574,
                0.0,
                0.04360853761019819,
                0.0,
                0.0,
                0.0,
                0.1471247678732248,
                0.0,
                0.0,
                0.0,
                0.11904003223716858,
                0.26016557033349974,
                0.22012776168713016,
                0.0,
                0.18905695206906303,
                0.0,
                0.11153075915404126,
                0.0,
                0.0,
                0.06294356203147926,
                0.0,
                0.10477099383271479,
                0.15958628014584095,
                0.0,
                1.0,
                0.15540097729019334,
                0.0,
                0.08483922847465655,
                0.041466486817209894,
                0.11873554351645323,
                0.16196796360531143,
                0.05930997044904688,
                0.0,
                0.0,
                0.08364680633138968
            ],
            [
                0.0,
                0.0,
                0.0,
                0.12617680160183803,
                0.0,
                0.08903308454047115,
                0.0,
                0.0,
                0.0,
                0.0,
                0.07009113238410651,
                0.11521229897775749,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.021851853381531866,
                0.0,
                0.03368161759583641,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.08444582717640786,
                0.024004268673367503,
                0.0,
                0.041282322677493974,
                0.0,
                0.0,
                0.033175442243204005,
                0.0,
                0.0,
                0.0,
                0.12755789073722315,
                0.04486558475338539,
                0.0,
                0.0,
                0.18310822786843803,
                0.04625352226574559,
                0.0,
                0.0,
                0.0,
                0.09037526213691091,
                0.0,
                0.0,
                0.037946268293257965,
                0.0,
                0.03956225665093406,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.01936144254253636,
                0.04855974347437785,
                0.0,
                0.0,
                0.0,
                0.04982242456314796,
                0.06809511724776841,
                0.0,
                0.0691464930447564,
                0.0,
                0.06361811377070682,
                0.0,
                0.0,
                0.045582704477069594,
                0.09419027328770117,
                0.0,
                0.049366996576795705,
                0.0,
                0.15540097729019334,
                1.0,
                0.0,
                0.0,
                0.06175010529026467,
                0.03960862369260309,
                0.0,
                0.0,
                0.0,
                0.0,
                0.04771286488238531
            ],
            [
                0.1346756229057693,
                0.0,
                0.0,
                0.13636447157381157,
                0.10907018667976667,
                0.0,
                0.09112125002353051,
                0.022968962559080063,
                0.013313514297546625,
                0.08706825343063063,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.10775792595393896,
                0.0,
                0.0591958987654363,
                0.0,
                0.21388711704992108,
                0.09405922580852698,
                0.032148392620119766,
                0.016138606133927206,
                0.0,
                0.0,
                0.0,
                0.0,
                0.08237261854877763,
                0.024333016623319412,
                0.031730502851160414,
                0.07026023840828007,
                0.0,
                0.02142937803040025,
                0.07921998243631617,
                0.0,
                0.014417546511041551,
                0.037820364726221335,
                0.0,
                0.0,
                0.017691021576735112,
                0.0,
                0.0,
                0.027250152999480342,
                0.0,
                0.09673555937601727,
                0.0,
                0.05029397532881875,
                0.06195076244926812,
                0.019739779815653336,
                0.0,
                0.04116084508044019,
                0.0,
                0.15111157755396218,
                0.0,
                0.0,
                0.0,
                0.022238570010659556,
                0.0,
                0.0,
                0.1749913144692058,
                0.0,
                0.1450519426669525,
                0.06099627271428401,
                0.0,
                0.0,
                0.0,
                0.0,
                0.12772118586685002,
                0.0,
                0.0,
                0.0,
                0.06291273727345664,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.04903034672114464,
                0.05473566101540061,
                0.0,
                0.017967538194313168,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.01156304933827042,
                0.046005936689142074,
                0.0,
                0.0,
                0.06577070915113496,
                0.0,
                0.0,
                0.0,
                0.04149727163820328,
                0.0,
                0.0,
                0.0400784764965221,
                0.0,
                0.08293492719937447,
                0.016958379187411596,
                0.0,
                0.0,
                0.0,
                0.03006826807834817,
                0.07291126091561549,
                0.04075700881545991,
                0.0,
                0.11420268932376847,
                0.03392131370428358,
                0.0,
                0.039925177199128144,
                0.041475921898311056,
                0.06420547718009688,
                0.0,
                0.05562957281777155,
                0.04319702849958888,
                0.016694385959587107,
                0.0,
                0.01667074679149634,
                0.0,
                0.017601060594730305,
                0.0,
                0.08164535032609178,
                0.06149356152052946,
                0.0,
                0.0493392489969509,
                0.010551558741266554,
                0.0,
                0.0,
                0.0,
                0.09022164289219037,
                0.0,
                0.14485428836034162,
                0.0,
                0.0,
                0.0,
                0.12291818660688243,
                0.05607783010009917,
                0.0,
                0.0,
                0.02319766198092557,
                0.022880885197767573,
                0.03717568133052223,
                0.0,
                0.02503054946371427,
                0.0,
                0.0,
                0.0,
                0.0,
                0.044108821076968736,
                0.0,
                0.2654296022027721,
                0.09618570379816628,
                0.0,
                0.08483922847465655,
                0.0,
                0.0,
                1.0,
                0.034305464914723374,
                0.018190210121214658,
                0.08490476987964878,
                0.021885132737057684,
                0.0,
                0.09094079860819128,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.07638249112002939,
                0.0,
                0.023757181523374884,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.030813204307840396,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.014531243584475075,
                0.0,
                0.0,
                0.037361629453577384,
                0.0,
                0.020083112667104285,
                0.0,
                0.022807658481081232,
                0.07355119851262912,
                0.05520199120078586,
                0.027159866833797317,
                0.0,
                0.05165313782354007,
                0.023200918474209523,
                0.055375045914809434,
                0.04783675721649899,
                0.0,
                0.0,
                0.06049382144524374,
                0.0,
                0.027856065799319926,
                0.05762372518494832,
                0.0,
                0.023949439825428853,
                0.0,
                0.0,
                0.0,
                0.07670445653929217,
                0.0,
                0.07053520275280464,
                0.029396165758163742,
                0.0,
                0.025956687082853667,
                0.0,
                0.030160543407826784,
                0.018170189987918046,
                0.0,
                0.0,
                0.0,
                0.038511913033728765,
                0.0,
                0.17310413633014576,
                0.05343774455581727,
                0.0,
                0.0,
                0.051049382353182,
                0.0,
                0.041466486817209894,
                0.06175010529026467,
                0.0,
                0.034305464914723374,
                1.0,
                0.023977508615440846,
                0.0,
                0.0,
                0.0,
                0.0,
                0.028883498645735764
            ],
            [
                0.0,
                0.0,
                0.0,
                0.04177533187292635,
                0.16842435798925898,
                0.32342487793342967,
                0.11787426035619741,
                0.0,
                0.0,
                0.1410688353337396,
                0.0958398959847448,
                0.025278669571123197,
                0.0,
                0.08812548310105732,
                0.0,
                0.0723399621752234,
                0.06822642064432727,
                0.0,
                0.0,
                0.11186952809685248,
                0.02080628629109306,
                0.0,
                0.0,
                0.06400170597259078,
                0.015431733174665098,
                0.02600389932794601,
                0.3561729505167161,
                0.0,
                0.14081308391322897,
                0.04824935197092149,
                0.0,
                0.0,
                0.06499521494282025,
                0.16320875801555723,
                0.0,
                0.0,
                0.0,
                0.1609219223622877,
                0.0,
                0.12389575608912659,
                0.055527835668240974,
                0.2908485136168356,
                0.2105859128192589,
                0.0,
                0.0,
                0.0,
                0.06905204881839068,
                0.1642136484481718,
                0.0,
                0.03846712746607064,
                0.0,
                0.22532006941113913,
                0.0,
                0.1255280685311244,
                0.0,
                0.0,
                0.0,
                0.09304196380890921,
                0.024116153368363157,
                0.0,
                0.0,
                0.2460200821121824,
                0.47759454134137413,
                0.1709479845513659,
                0.0,
                0.03922434675520138,
                0.0,
                0.06449135057645619,
                0.06947564368054991,
                0.0,
                0.04527534181451392,
                0.0,
                0.02246374026132117,
                0.03771930699878954,
                0.0,
                0.11873554351645323,
                0.03960862369260309,
                0.0,
                0.018190210121214658,
                0.023977508615440846,
                1.0,
                0.03472722871078408,
                0.07241444751109764,
                0.0,
                0.0,
                0.04836778259769535
            ],
            [
                0.07231594629042616,
                0.0,
                0.0,
                0.010362599241843368,
                0.07107965060467264,
                0.17333232401129195,
                0.03206704195469646,
                0.09428309100845281,
                0.029194688810233318,
                0.1162474477013555,
                0.030197109696619484,
                0.0,
                0.0,
                0.08605000648241065,
                0.0,
                0.0,
                0.08091235379573074,
                0.03825723865749299,
                0.023310555678371387,
                0.055828932172190746,
                0.09803228685343102,
                0.14788037021381117,
                0.024524878078045258,
                0.012311575028371777,
                0.0,
                0.031680027595898975,
                0.10228904483582789,
                0.0,
                0.23136455919369053,
                0.04553895111808621,
                0.0,
                0.07072417743153053,
                0.11027061128779957,
                0.016347718832915942,
                0.0,
                0.3580392737965248,
                0.010998639171357849,
                0.08776484431619765,
                0.0,
                0.03182639632802687,
                0.0375741597157234,
                0.062112593160000416,
                0.05293425379149796,
                0.02078818334146141,
                0.045507305529875176,
                0.014519679336486433,
                0.26745603421429365,
                0.03837972963034619,
                0.0,
                0.015058783777680305,
                0.0,
                0.16429518806215496,
                0.0,
                0.15985796506210614,
                0.0,
                0.0,
                0.0,
                0.09343981256957903,
                0.0,
                0.026749065034369728,
                0.017200153586177422,
                0.04428703724689406,
                0.10114842006633724,
                0.1264639560911616,
                0.1785855959352988,
                0.1831477532464159,
                0.0,
                0.0,
                0.059989272589012765,
                0.0,
                0.0,
                0.0,
                0.13458353101418888,
                0.051453163579033456,
                0.06642556143280656,
                0.16196796360531143,
                0.0,
                0.04903034672114464,
                0.08490476987964878,
                0.0,
                0.03472722871078408,
                1.0,
                0.04178126612398474,
                0.06543227505987852,
                0.038161456470060806,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.05026102926141349,
                0.03605461555386118,
                0.03776888085782185,
                0.1521002888746637,
                0.0,
                0.0,
                0.0,
                0.029821519661554403,
                0.030413449613484196,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.029827393505456563,
                0.04872896783928347,
                0.0,
                0.0,
                0.0,
                0.018566334673425448,
                0.03128599310732875,
                0.09183180082230767,
                0.0,
                0.08545418667562267,
                0.0,
                0.0,
                0.0,
                0.0,
                0.039645129346543524,
                0.0,
                0.0,
                0.0,
                0.06645963558115293,
                0.0,
                0.156463978980435,
                0.0,
                0.07006906847602905,
                0.07017470101091114,
                0.0,
                0.0,
                0.06332093657264655,
                0.03449240937948276,
                0.14022987000137502,
                0.0,
                0.0,
                0.0,
                0.0723296769891213,
                0.0,
                0.18533820657395997,
                0.14331670353027498,
                0.0,
                0.0,
                0.14304843410927126,
                0.02901479499449704,
                0.0,
                0.07144121325912926,
                0.09234889892441484,
                0.0910878241163797,
                0.054875770883862175,
                0.0,
                0.04719187021709005,
                0.0,
                0.1579032309421129,
                0.11656681902362821,
                0.0,
                0.054471985684799246,
                0.0,
                0.027026732188015667,
                0.01884129147180545,
                0.0,
                0.05930997044904688,
                0.0,
                0.05473566101540061,
                0.021885132737057684,
                0.0,
                0.07241444751109764,
                0.04178126612398474,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.04481954610327172,
                0.09222019573068417,
                0.10643042629061492,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.07779126841640799,
                0.0,
                0.07828312558008348,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.11217986677308436,
                0.0,
                0.0,
                0.0,
                0.0,
                0.04358757673991212,
                0.0,
                0.0,
                0.1259341289646825,
                0.13193944672072444,
                0.0,
                0.05585164394234836,
                0.0,
                0.0,
                0.0,
                0.13938743221602357,
                0.0,
                0.0,
                0.06239388982344334,
                0.0,
                0.08935642105390958,
                0.05837128537037522,
                0.08659262965670726,
                0.0,
                0.0,
                0.0,
                0.11104001822836912,
                0.10803486956565231,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.14492826379266974,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.11986413314473537,
                0.15784543117356964,
                0.0,
                0.06217058171896685,
                0.08551542018665982,
                0.0,
                0.0,
                0.0,
                0.0,
                0.1437377501415755,
                0.08289961144328568,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.06543227505987852,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0818410622259356,
                0.0,
                0.09401792700408025,
                0.05474194940776308,
                0.0,
                0.039777299413508854,
                0.014303876559610362,
                0.025084040159149272,
                0.01453947806480481,
                0.049082802794604787,
                0.0,
                0.0,
                0.0,
                0.03511824343914339,
                0.0,
                0.0,
                0.07745996423165356,
                0.0,
                0.07825590312901247,
                0.0,
                0.01387794786826978,
                0.26244346235007354,
                0.03510875031734477,
                0.017624716107001066,
                0.0,
                0.0,
                0.0,
                0.0,
                0.01363696788459931,
                0.026573701994707637,
                0.0,
                0.11541686973287249,
                0.14152450283718776,
                0.02340268428395575,
                0.0,
                0.0,
                0.01574517415617457,
                0.0413030212046375,
                0.0,
                0.0,
                0.10576329971265452,
                0.0,
                0.03695317454430729,
                0.02975946042071931,
                0.0,
                0.02078574233439138,
                0.0,
                0.026105258108174784,
                0.0,
                0.021557500838577014,
                0.0,
                0.044951106882888996,
                0.0,
                0.24359059253753806,
                0.0,
                0.0,
                0.0,
                0.2610553556342015,
                0.0,
                0.038292799765427286,
                0.0,
                0.0,
                0.0,
                0.3693566044425419,
                0.0,
                0.1532927939293228,
                0.0,
                0.0,
                0.019132122770996938,
                0.0,
                0.0,
                0.0,
                0.1477717053870621,
                0.0,
                0.0,
                0.0,
                0.0,
                0.017967538194313168,
                0.09094079860819128,
                0.0,
                0.0,
                0.038161456470060806,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.10534311847851176,
                0.07149223826595646,
                0.0,
                0.04792333555107574,
                0.06893430965770411,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.08714129699759991,
                0.0,
                0.0,
                0.0,
                0.05277274549342628,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.029312638015921044,
                0.0,
                0.0,
                0.0,
                0.0,
                0.06310670277729977,
                0.0,
                0.0,
                0.0,
                0.15576639005890974,
                0.08534382454363935,
                0.0,
                0.0,
                0.04680123355704976,
                0.0,
                0.0,
                0.09804792450060813,
                0.0,
                0.04864578190520694,
                0.0,
                0.0,
                0.04633780939843355,
                0.0,
                0.04831116182216548,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.02364308467123169,
                0.0,
                0.0,
                0.0,
                0.0,
                0.06084029120684765,
                0.03665317415540348,
                0.0,
                0.14922219884709503,
                0.0,
                0.07768679669401486,
                0.0,
                0.07011855493341863,
                0.0,
                0.0,
                0.0,
                0.026572494419455594,
                0.0,
                0.08364680633138968,
                0.04771286488238531,
                0.0,
                0.0,
                0.028883498645735764,
                0.04836778259769535,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P87-1015": {
        "input_sentences": [
            "We consider the structural descriptions produced by various grammatical formalisms in terms of the complexity of the paths and the relationship between paths in the sets of structural descriptions that each system can generate.",
            "CHARACTERIZING STRUCTURAL DESCRIPTIONS PRODUCED BY VARIOUS GRAMMATICAL FORMALISMS*",
            "In considering the relationship between formalisms, we show that it is useful to abstract away from the details of the formalism, and examine the nature of their derivation process as reflected by properties their trees. find that several of the formalisms considered can be seen as being closely related since they have derivation tree sets with the same structure as those produced by Context-Free Grammars On the basis of this observation, we describe a class of formalisms which we call Linear Context- Free Rewriting Systems, and show they are recognizable in polynomial time and generate only semilinear languages.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.5495946540701895,
                0.1270909128320098,
                0.0
            ],
            [
                0.5495946540701895,
                1.0,
                0.11393957122021557,
                0.0
            ],
            [
                0.1270909128320098,
                0.11393957122021557,
                1.0,
                0.11432201079877596
            ],
            [
                0.0,
                0.0,
                0.11432201079877596,
                1.0
            ]
        ]
    },
    "D09-1034": {
        "input_sentences": [
            "In this paper, we present novel methods for calculating separate lexical and syntactic surprisal measures from a single incremental parser using a lexicalized PCFG.",
            "We also present an approximation to entropy measures that would otherwise be intractable to calculate for a grammar of that size.",
            "Deriving lexical and syntactic expectation-based measures for psycholinguistic modeling via incremental top-down parsing",
            "Empirical results demonstrate the utility of our methods in predicting human reading times.",
            "Abstract",
            "A number of recent publications have made use of the incremental output of stochastic parsers to derive measures of high utility for psycholinguistic modeling, following the work of Hale (2001; 2003; 2006)."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.1051122885769276,
                0.21579382168927752,
                0.06330384934181253,
                0.0,
                0.053509202714855576
            ],
            [
                0.1051122885769276,
                1.0,
                0.048422658993676065,
                0.0,
                0.0,
                0.031432848950392236
            ],
            [
                0.21579382168927752,
                0.048422658993676065,
                1.0,
                0.0,
                0.0,
                0.18781981674304835
            ],
            [
                0.06330384934181253,
                0.0,
                0.0,
                1.0,
                0.0,
                0.05509758013196887
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.053509202714855576,
                0.031432848950392236,
                0.18781981674304835,
                0.05509758013196887,
                0.0,
                1.0
            ]
        ]
    },
    "W05-0638": {
        "input_sentences": [
            "The experimental results show that full parsing information not only increases the F-score of argument classification models by 0.7%, but also effectively removes all labeling inconsistencies, which increases the F-score by 0.64%.",
            "In addition, to take advantage of SVM-based and Maximum Entropy-based argument classification models, we incorporate their scoring matrices, and use the combined matrix in the above-mentioned integer linear programs.",
            "Exploiting Full Parsing Information To Label Semantic Roles Using An Ensemble Of ME And SVM Via Integer Linear Programming",
            "Abstract",
            "In this paper, we propose a method that exploits full parsing information by representing it as features of argument classification models and as constraints in integer linear learning programs.",
            "The ensemble of SVM and ME also boosts the F-score by 0.77%.",
            "Our system achieves an F-score of 76.53% in the development set and 76.38% in Test WSJ."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.08859959186045827,
                0.08420401873412922,
                0.0,
                0.18276823787870936,
                0.1328962085466801,
                0.07532851983153278
            ],
            [
                0.08859959186045827,
                1.0,
                0.11507728502249548,
                0.0,
                0.2121027334757955,
                0.06054079563440391,
                0.0
            ],
            [
                0.08420401873412922,
                0.11507728502249548,
                1.0,
                0.0,
                0.18991033400291968,
                0.2044318016481378,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.18276823787870936,
                0.2121027334757955,
                0.18991033400291968,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.1328962085466801,
                0.06054079563440391,
                0.2044318016481378,
                0.0,
                0.0,
                1.0,
                0.07720885213126388
            ],
            [
                0.07532851983153278,
                0.0,
                0.0,
                0.0,
                0.0,
                0.07720885213126388,
                1.0
            ]
        ]
    },
    "W12-3145": {
        "input_sentences": [
            "Kriya - The SFU System for Translation Task at WMT-12",
            "models for morpheme segmentation and morphology Transactions on Speech and Language 4(1):3:1\u20133:34, February.",
            "KenLM: Faster and smaller model queries.",
            "Kenneth Heafield.",
            "In of the Sixth on Statistical Machine pages 187\u2013197.",
            "Abstract",
            "2011."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P04-1036": {
        "input_sentences": [
            "This is a very promising result given that our method does not require any hand-tagged text, such as SemCor.",
            "The acquired predominant senses give a of 64% on the nouns of the 2 English all-words task.",
            "Finding Predominant Word Senses in Untagged Text",
            "word sense disambiguation the heuristic of choosing the most common sense is extremely powerful because the distribution of the senses of a word is often skewed.",
            "Whilst there are a few hand-tagged corpora available for some languages, one would expect the frequency distribution of the senses of words, particularly topical words, to depend on the genre and domain of the text under consideration.",
            "Abstract",
            "The problem with using the predominant, or first sense heuristic, aside from the fact that it does not take surrounding context into account, is that it assumes some quantity of handtagged data.",
            "Furthermore, we demonstrate that our method discovers appropriate predominant senses for words from two domainspecific corpora.",
            "We present work on the use of a thesaurus acquired from raw textual corpora and the WordNet similarity package to find predominant noun senses automatically."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.09477258186856681,
                0.0,
                0.166334844301741,
                0.0,
                0.06708029646431188,
                0.09053623944518177,
                0.0
            ],
            [
                0.0,
                1.0,
                0.12736831820616012,
                0.03050402017781022,
                0.13659685139695746,
                0.0,
                0.03772961772257243,
                0.1739064811577693,
                0.15196435058548835
            ],
            [
                0.09477258186856681,
                0.12736831820616012,
                1.0,
                0.23598590670624442,
                0.10102359633544658,
                0.0,
                0.046491337042759866,
                0.11334467476973316,
                0.08597130631579723
            ],
            [
                0.0,
                0.03050402017781022,
                0.23598590670624442,
                1.0,
                0.06585353943284725,
                0.0,
                0.15923972414038476,
                0.02714543376969908,
                0.020589660753194645
            ],
            [
                0.166334844301741,
                0.13659685139695746,
                0.10102359633544658,
                0.06585353943284725,
                1.0,
                0.0,
                0.0,
                0.17015623956699327,
                0.055338235223308795
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.06708029646431188,
                0.03772961772257243,
                0.046491337042759866,
                0.15923972414038476,
                0.0,
                0.0,
                1.0,
                0.03357547080922753,
                0.02546680813634491
            ],
            [
                0.09053623944518177,
                0.1739064811577693,
                0.11334467476973316,
                0.02714543376969908,
                0.17015623956699327,
                0.0,
                0.03357547080922753,
                1.0,
                0.11738372283221297
            ],
            [
                0.0,
                0.15196435058548835,
                0.08597130631579723,
                0.020589660753194645,
                0.055338235223308795,
                0.0,
                0.02546680813634491,
                0.11738372283221297,
                1.0
            ]
        ]
    },
    "N10-1091": {
        "input_sentences": [
            "Ensemble Models for Dependency Parsing: Cheap and Good?",
            "This study proves that fast and accurate ensemble parsers can be built with minimal effort.",
            "Previous work on dependency parsing used various kinds of combination models but a systematic analysis and comparison of these approaches is lacking.",
            "Abstract",
            "In this paper we implemented such a study for English dependency parsing and find several non-obvious facts: (a) the diversity of base parsers is more important than complex models for learning (e.g., stacking, supervised meta-classification), (b) approximate, linear-time re-parsing algorithms guarantee well-formed dependency trees without significant performance loss, and (c) the simplest scoring model for re-parsing (unweighted voting) performs essentially as well as other more complex models."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.11545926835730373,
                0.19155977633761767,
                0.0,
                0.23695864045898835
            ],
            [
                0.11545926835730373,
                1.0,
                0.0,
                0.0,
                0.06965186617093432
            ],
            [
                0.19155977633761767,
                0.0,
                1.0,
                0.0,
                0.1348202309282242
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.23695864045898835,
                0.06965186617093432,
                0.1348202309282242,
                0.0,
                1.0
            ]
        ]
    },
    "E12-1055": {
        "input_sentences": [
            "We also explore adapting multiple (4\u201310) data sets with no priori between in-domain and out-of-domain data except for an in-domain development set.",
            "We investigate the problem of domain adaptation for parallel data in Statistical Machine Translation (SMT).",
            "Perplexity Minimization for Translation Model Domain Adaptation in Statistical Machine Translation",
            "While techniques for domain adaptation of monolingual data can be borrowed for parallel data, we explore conceptual differences between translation model and language model domain adaptation and their effect on performance, such as the fact that translation models typically consist of several features that have different characteristics and can be optimized separately.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.20498516549659912,
                0.1063816407227266,
                0.23622621602994867,
                0.0
            ],
            [
                0.20498516549659912,
                1.0,
                0.4516716487170141,
                0.2945289385797102,
                0.0
            ],
            [
                0.1063816407227266,
                0.4516716487170141,
                1.0,
                0.3454358556531734,
                0.0
            ],
            [
                0.23622621602994867,
                0.2945289385797102,
                0.3454358556531734,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "D11-1033": {
        "input_sentences": [
            "Performance is further improved when we use these domain-adapted models in combination with a true in-domain model.",
            "We explore efficient domain adaptation for the task of statistical machine translation based on extracting sentences from a large generaldomain parallel corpus that are most relevant to the target domain.",
            "Domain Adaptation via Pseudo In-Domain Data Selection",
            "These sentences may be selected with simple cross-entropy based methods, of which we present three.",
            "Abstract",
            "As these sentences are not themselves identical the in-domain data, we call them These subcorpora \u2013 1% the size of the original \u2013 can then used to train small domain-adapted Statistical Machine Translation (SMT) systems which outperform systems trained on the entire corpus.",
            "The results show that more training data is not always better, and that best results are attained via proper domain-relevant data selection, as well as combining inand general-domain systems during decoding."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.10282733369436076,
                0.19459783421153592,
                0.0,
                0.0,
                0.14154554387108484,
                0.09164014171882381
            ],
            [
                0.10282733369436076,
                1.0,
                0.24208947464787134,
                0.11680298438476507,
                0.0,
                0.2640549383396075,
                0.11400493666980072
            ],
            [
                0.19459783421153592,
                0.24208947464787134,
                1.0,
                0.0,
                0.0,
                0.18841525306491508,
                0.33293437582417496
            ],
            [
                0.0,
                0.11680298438476507,
                0.0,
                1.0,
                0.0,
                0.042648512479109335,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.14154554387108484,
                0.2640549383396075,
                0.18841525306491508,
                0.042648512479109335,
                0.0,
                1.0,
                0.18880486957267412
            ],
            [
                0.09164014171882381,
                0.11400493666980072,
                0.33293437582417496,
                0.0,
                0.0,
                0.18880486957267412,
                1.0
            ]
        ]
    },
    "P10-1021": {
        "input_sentences": [
            "Previous work has investigated the contributions of semantic and syntactic contexts in isolation, essentially treating them as independent factors.",
            "In this paper we analyze reading times in terms of a single predictive measure which integrates a model of semantic composition with an incremental parser and a language model.",
            "Abstract",
            "Syntactic and Semantic Factors in Processing Difficulty: An Integrated Measure",
            "There is evidence that the language processor is highly predictive, such that prior context allows upcoming linguistic material to be anticipated.",
            "The analysis of reading times can provide insights into the processes that underlie language comprehension, with longer reading times indicating greater cognitive load."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.03682765627129264,
                0.0,
                0.23649199891508643,
                0.0,
                0.0
            ],
            [
                0.03682765627129264,
                1.0,
                0.0,
                0.12418459724075503,
                0.08718515898893452,
                0.19510826997764252
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.23649199891508643,
                0.12418459724075503,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.08718515898893452,
                0.0,
                0.0,
                1.0,
                0.03495598015310731
            ],
            [
                0.0,
                0.19510826997764252,
                0.0,
                0.0,
                0.03495598015310731,
                1.0
            ]
        ]
    },
    "E12-1014": {
        "input_sentences": [
            "We estimate the parameters of a phrasebased statistical machine translation sysfrom instead of a corpus.",
            "In this paper, we examine an idealization where a phrase-table is given.",
            "We propose a novel algorithm to estimate reordering probabilities from monolingual data.",
            "We examine the degradation in translation performance when bilingually estimated translation probabilities are removed and show that 80%+ of the loss can be recovered with monolingually estimated features alone.",
            "Toward Statistical Machine Translation without Parallel Corpora",
            "We report translation results for an end-to-end translation system using these monolingual features alone.",
            "We further show that our monolingual features add 1.5 BLEU points when combined with standard bilingually estimated phrase table features.",
            "Our method only requires monolingual corpora in source and target languages, a small bilingual dictionary, and a small bitext for tuning feature weights.",
            "Abstract",
            "We extend existing research on bilingual lexicon induction estimate and phrasal translation probabilities for MT-scale phrasetables."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.07975355605902551,
                0.06988735237217339,
                0.3534197624977263,
                0.08483637737011153,
                0.0,
                0.0,
                0.0,
                0.0999045933893193
            ],
            [
                0.0,
                1.0,
                0.0,
                0.08540912957362436,
                0.0,
                0.0,
                0.19582731253279756,
                0.0,
                0.0,
                0.0
            ],
            [
                0.07975355605902551,
                0.0,
                1.0,
                0.05809759734699289,
                0.0,
                0.05574619541324133,
                0.05264664227575046,
                0.04288830595653827,
                0.0,
                0.1293315058454423
            ],
            [
                0.06988735237217339,
                0.08540912957362436,
                0.05809759734699289,
                1.0,
                0.10098715005979599,
                0.17207120694140698,
                0.27096574351488645,
                0.0,
                0.0,
                0.10110992372980475
            ],
            [
                0.3534197624977263,
                0.0,
                0.0,
                0.10098715005979599,
                1.0,
                0.12258847532784999,
                0.0,
                0.0966414931581528,
                0.0,
                0.05620206680091345
            ],
            [
                0.08483637737011153,
                0.0,
                0.05574619541324133,
                0.17207120694140698,
                0.12258847532784999,
                1.0,
                0.15505733912927436,
                0.035781626348217306,
                0.0,
                0.068787004479326
            ],
            [
                0.0,
                0.19582731253279756,
                0.05264664227575046,
                0.27096574351488645,
                0.0,
                0.15505733912927436,
                1.0,
                0.03379212641212303,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.04288830595653827,
                0.0,
                0.0966414931581528,
                0.035781626348217306,
                0.03379212641212303,
                1.0,
                0.0,
                0.054227600147404485
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0999045933893193,
                0.0,
                0.1293315058454423,
                0.10110992372980475,
                0.05620206680091345,
                0.068787004479326,
                0.0,
                0.054227600147404485,
                0.0,
                1.0
            ]
        ]
    },
    "P14-2022": {
        "input_sentences": [
            "We contribute a faster decoding algorithm for phrase-based machine translation.",
            "Translation hypotheses keep track of state, such as context for the language model and coverage of words in the source sentence.",
            "Most features depend upon only part of the state, but traditional algorithms, including cube pruning, handle state atomically.",
            "Moreover, we exploit shared words in hypotheses to iteratively refine language model scores rather than handling language model state atomically.",
            "When tuned to attain the same accuracy, our algorithm is 4.0\u20137.7 times as fast as the Moses decoder with cube pruning.",
            "Abstract",
            "Since our algorithm and cube pruning are both approximate, improvement can be used to increase speed or accuracy.",
            "For example, cube pruning will repeatedly query the language model with hypotheses that differ only in source coverage, despite the fact that source coverage is irrelevant to the language model.",
            "Faster Phrase-Based Decoding by Refining Feature State",
            "Our key contribution avoids this behavior by placing hypotheses into equivalence classes, masking the parts of state that matter least to the score."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.10428871099692634,
                0.0,
                0.0,
                0.07802408898031522,
                0.0,
                0.08330165133408066,
                0.0,
                0.508364174823593,
                0.0
            ],
            [
                0.10428871099692634,
                1.0,
                0.08420904559688532,
                0.37517343373561235,
                0.0,
                0.0,
                0.0,
                0.46138657260303184,
                0.05518653483924493,
                0.08243488714040108
            ],
            [
                0.0,
                0.08420904559688532,
                1.0,
                0.13371285454060983,
                0.10205728460857362,
                0.0,
                0.10896045631127202,
                0.06770679807129609,
                0.10262103531705508,
                0.06843564522550515
            ],
            [
                0.0,
                0.37517343373561235,
                0.13371285454060983,
                1.0,
                0.0,
                0.0,
                0.0,
                0.31755830977340893,
                0.04328028390464829,
                0.06464992465058736
            ],
            [
                0.07802408898031522,
                0.0,
                0.10205728460857362,
                0.0,
                1.0,
                0.0,
                0.28167016008259727,
                0.07117895626170508,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.08330165133408066,
                0.0,
                0.10896045631127202,
                0.0,
                0.28167016008259727,
                0.0,
                1.0,
                0.07599351270006177,
                0.0,
                0.0
            ],
            [
                0.0,
                0.46138657260303184,
                0.06770679807129609,
                0.31755830977340893,
                0.07117895626170508,
                0.0,
                0.07599351270006177,
                1.0,
                0.0,
                0.02959052229184539
            ],
            [
                0.508364174823593,
                0.05518653483924493,
                0.10262103531705508,
                0.04328028390464829,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.044849411280149194
            ],
            [
                0.0,
                0.08243488714040108,
                0.06843564522550515,
                0.06464992465058736,
                0.0,
                0.0,
                0.0,
                0.02959052229184539,
                0.044849411280149194,
                1.0
            ]
        ]
    },
    "N07-2041": {
        "input_sentences": [
            "In this paper we propose a statistical parsing technique that simultaneously identifies biomedical named-entities (NEs) and extracts subcellular localization relations for bacterial proteins from the text in MEDLINE articles.",
            "We then propose a semi-supervised approach that incorporates noisy automatically labeled data to improve the F-score of our parser to Our key contributions are: learning from noisy data, and building an annotated corpus that can benefit relation extraction research.",
            "Simultaneous Identification of Biomedical Named-Entity and Functional Relation Using Statistical Parsing Techniques",
            "Abstract",
            "We build a parser that derives both syntactic and domain-dependent semantic information achieves an F-score of the relation extraction task."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.029848124972362357,
                0.20254546380526303,
                0.0,
                0.0
            ],
            [
                0.029848124972362357,
                1.0,
                0.029206341019250074,
                0.0,
                0.1393288514500273
            ],
            [
                0.20254546380526303,
                0.029206341019250074,
                1.0,
                0.0,
                0.04414918680480012
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.1393288514500273,
                0.04414918680480012,
                0.0,
                1.0
            ]
        ]
    },
    "P13-2009": {
        "input_sentences": [
            "Semantic parsing is the problem of deriving a structured meaning representation from a natural language utterance.",
            "These results support the use of machine translation methods as an informative baseline in semantic parsing evaluations, and suggest that research in semantic parsing could benefit from advances in machine translation.",
            "Here we approach it as a straightforward machine translation task, and demonstrate that standard machine translation components can be adapted into a semantic parser.",
            "Semantic Parsing as Machine Translation",
            "Abstract",
            "In experiments on the multilingual GeoQuery corpus we find that our parser is competitive with the state of the art, and in some cases achieves higher accuracy than recently proposed purpose-built systems."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.1312808742618138,
                0.034392063574738674,
                0.2090808208031968,
                0.0,
                0.0
            ],
            [
                0.1312808742618138,
                1.0,
                0.3092585402220348,
                0.6278953457208092,
                0.0,
                0.0
            ],
            [
                0.034392063574738674,
                0.3092585402220348,
                1.0,
                0.492531983760786,
                0.0,
                0.04782158888714564
            ],
            [
                0.2090808208031968,
                0.6278953457208092,
                0.492531983760786,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.04782158888714564,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "W11-2147": {
        "input_sentences": [
            "Experiments with word alignment normalization and clause reordering for SMT between English and German",
            "This resulted in small improvements for both transla tion directions.",
            "For English?German we attempted to improve the trans lation tables with a combination of standard statistical word alignments and phrase-basedword alignments.",
            "For German?English trans lation we tried to make the German text moresimilar to the English text by normalizing Ger man morphology and performing rule-basedclause reordering of the German text.",
            "This paper presents the LIU system for theWMT 2011 shared task for translation be tween German and English.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.13511291021442176,
                0.18108639939966426,
                0.08511166447052676,
                0.0
            ],
            [
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.13511291021442176,
                0.0,
                1.0,
                0.15994853463670436,
                0.05889441050648904,
                0.0
            ],
            [
                0.18108639939966426,
                0.0,
                0.15994853463670436,
                1.0,
                0.11166764614270029,
                0.0
            ],
            [
                0.08511166447052676,
                0.0,
                0.05889441050648904,
                0.11166764614270029,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P14-1008": {
        "input_sentences": [
            "In this paper, we equip the DCS framework logical inference, by defining abdenotations an abstraction of the computing process of denotations in original DCS.",
            "Dependency-based Compositional Semantics (DCS) is a framework of natural language semantics with easy-to-process structures as well as strict semantics.",
            "Logical Inference on Dependency-based Compositional Semantics",
            "Experiments on FraCaS and PASCAL RTE datasets show promising results.",
            "An inference engine is built to achieve inference on abstract denotations.",
            "Abstract",
            "Furthermore, we propose a way to generate on-the-fly knowledge in logical inference, by combining our framework with the idea of tree transformation."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.18664162173463483,
                0.13080042308717488,
                0.0,
                0.16853021732190604,
                0.0,
                0.11610920203212545
            ],
            [
                0.18664162173463483,
                1.0,
                0.5567940748249749,
                0.0,
                0.0,
                0.0,
                0.03833032425807289
            ],
            [
                0.13080042308717488,
                0.5567940748249749,
                1.0,
                0.0,
                0.1638490380195514,
                0.0,
                0.1371606569752501
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.16853021732190604,
                0.0,
                0.1638490380195514,
                0.0,
                1.0,
                0.34185671375630083,
                0.09262915304899486
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.34185671375630083,
                1.0,
                0.0
            ],
            [
                0.11610920203212545,
                0.03833032425807289,
                0.1371606569752501,
                0.0,
                0.09262915304899486,
                0.0,
                1.0
            ]
        ]
    },
    "C10-1132": {
        "input_sentences": [
            "A simple joint model combining the character-based generative model and the discriminative one is thus proposed in this paper to take advantage of both approaches.",
            "The character-based tagging approach is a dominant technique for Chinese word segmentation, and both discrimi native and generative models can be adopted in that framework.",
            "In addition, closed tests also show that the proposed joint model outperforms all the existing approaches reported in the literature and achieves the best F score in four out of five corpora.",
            "However, generative and discriminative charac ter-based approaches are significantly different and complement each other.",
            "A Character-Based Joint Model for Chinese Word Segmentation",
            "Abstract",
            "Experiments on the Sec ond SIGHAN Bakeoff show that this joint approach achieves 21% relative error reduction over the discriminative model and 14% over the generative one."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.12236485086530557,
                0.22030950774615324,
                0.22812656788067628,
                0.3526973069317199,
                0.0,
                0.18824601079309192
            ],
            [
                0.12236485086530557,
                1.0,
                0.0,
                0.08416511614504105,
                0.4418483685751145,
                0.0,
                0.08541863149823394
            ],
            [
                0.22030950774615324,
                0.0,
                1.0,
                0.05443763717064354,
                0.11084308790608627,
                0.0,
                0.11287109795264282
            ],
            [
                0.22812656788067628,
                0.08416511614504105,
                0.05443763717064354,
                1.0,
                0.07575302454249241,
                0.0,
                0.09407030086744737
            ],
            [
                0.3526973069317199,
                0.4418483685751145,
                0.11084308790608627,
                0.07575302454249241,
                1.0,
                0.0,
                0.1092158259028051
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.18824601079309192,
                0.08541863149823394,
                0.11287109795264282,
                0.09407030086744737,
                0.1092158259028051,
                0.0,
                1.0
            ]
        ]
    },
    "P11-1089": {
        "input_sentences": [
            "Morphological taggers operate on n-grams and do not take into account syntactic relations; parsers use the \u201cpipeline\u201d approach, assuming that morphological information has been separately obtained.",
            "A Discriminative Model for Joint Morphological Disambiguation and Dependency Parsing",
            "Most previous studies of morphological disambiguation and dependency parsing have been pursued independently.",
            "In this paper, we propose a discriminative model that jointly infers morphological properties and syntactic structures.",
            "However, in morphologically-rich languages, there is often considerable interaction between morphology and syntax, such that neither can be disambiguated without the other.",
            "Abstract",
            "In evaluations on various highly-inflected languages, this joint model outperforms both a baseline tagger in morphological disambiguation, and a pipeline parser in head selection."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.07584398866170822,
                0.06146631431547778,
                0.11662169883760831,
                0.0,
                0.0,
                0.0911958014419536
            ],
            [
                0.07584398866170822,
                1.0,
                0.4343191438837163,
                0.25774957268890963,
                0.0,
                0.0,
                0.2699461492378048
            ],
            [
                0.06146631431547778,
                0.4343191438837163,
                1.0,
                0.04099668308569163,
                0.0,
                0.0,
                0.08748493000304669
            ],
            [
                0.11662169883760831,
                0.25774957268890963,
                0.04099668308569163,
                1.0,
                0.0,
                0.0,
                0.0760305410166498
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0679708251928666
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0911958014419536,
                0.2699461492378048,
                0.08748493000304669,
                0.0760305410166498,
                0.0679708251928666,
                0.0,
                1.0
            ]
        ]
    },
    "W06-0508": {
        "input_sentences": [
            "The relations extracted can be used for various tasks, including semantic web annotation and ontology learning.",
            "A Hybrid Approach For Extracting Semantic Relations From Texts",
            "We suggest that the use of knowledge intensive strategies to process the input text and corpusbased techniques to deal with unpredicted cases and ambiguity problems allows to accurately discover the relevant relations between pairs of entities in that text.",
            "Abstract",
            "We present an approach for extracting relations from texts that exploits linguistic and empirical strategies, by means of a pipeline method involving a parser, partof-speech tagger, named entity recognition system, pattern-based classification and word sense disambiguation models, and resources such as ontology, knowledge base and lexical databases."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.15766849504641986,
                0.02105734948027468,
                0.0,
                0.056790914102424275
            ],
            [
                0.15766849504641986,
                1.0,
                0.03298161578994914,
                0.0,
                0.2085375083610477
            ],
            [
                0.02105734948027468,
                0.03298161578994914,
                1.0,
                0.0,
                0.06060495983206642
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.056790914102424275,
                0.2085375083610477,
                0.06060495983206642,
                0.0,
                1.0
            ]
        ]
    },
    "C10-1061": {
        "input_sentences": [
            "Our experiments show that data driven LCFRS parsing is feasible with a reasonable speed and yields output of competitive quality.",
            "Data-Driven Parsing with Probabilistic Linear Context-Free Rewriting Systems",
            "This paper presents a first efficient imple mentation of a weighted deductive CYKparser for Probabilistic Linear ContextFree Rewriting Systems (PLCFRS), to gether with context-summary estimatesfor parse items used to speed up parsing.",
            "We evaluate our parser with a gram mar extracted from the German NeGratreebank.",
            "Abstract",
            "LCFRS, an extension of CFG, can de scribe discontinuities both in constituencyand dependency structures in a straight forward way and is therefore a naturalcandidate to be used for data-driven parsing."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.1770821183870285,
                0.07360752340794291,
                0.0,
                0.0,
                0.17269492005076345
            ],
            [
                0.1770821183870285,
                1.0,
                0.34817942678338043,
                0.0,
                0.0,
                0.14890442587851024
            ],
            [
                0.07360752340794291,
                0.34817942678338043,
                1.0,
                0.0,
                0.0,
                0.06189493390543049
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.17269492005076345,
                0.14890442587851024,
                0.06189493390543049,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P12-1025": {
        "input_sentences": [
            "Reducing Approximation and Estimation Errors for Chinese Lexical Processing with Heterogeneous Annotations",
            "The analysis is further exploited to improve processing accuracy by (1) integrating systems that are respectively trained on heterogeneous annotations to reduce the approximation error, and (2) re-training models with high quality automatically converted data to reduce the estimation error.",
            "Evaluation on the CTB and PPD data shows that our novel model achieves a relative error reduction of 11% over the best reported result in the literature.",
            "We empirically analyze the diversity between two representative corpora, i.e.",
            "We address the issue of consuming heterogeneous annotation data for Chinese word segmentation and part-of-speech tagging.",
            "Penn Chinese Treebank (CTB) and PKU\u2019s People\u2019s Daily (PPD), on manually mapped data, and show that their linguistic annotations are systematically different and highly compatible.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.24360192128030228,
                0.0,
                0.0,
                0.1281430780068903,
                0.10217274596606582,
                0.0
            ],
            [
                0.24360192128030228,
                1.0,
                0.0939797471782157,
                0.0,
                0.05857000283268841,
                0.046699814876729064,
                0.0
            ],
            [
                0.0,
                0.0939797471782157,
                1.0,
                0.0,
                0.032587990686155546,
                0.12034280190422095,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.1281430780068903,
                0.05857000283268841,
                0.032587990686155546,
                0.0,
                1.0,
                0.07499997031336665,
                0.0
            ],
            [
                0.10217274596606582,
                0.046699814876729064,
                0.12034280190422095,
                0.0,
                0.07499997031336665,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P14-1012": {
        "input_sentences": [
            "Moreover, to learn high dimensional feature representation, we introduce a natural horizontal composition of more DAEs for large hidden layers feature learning.",
            "Using the unsupervised pre-trained deep belief net (DBN) to initialize DAE\u2019s parameters and using the input original phrase features as a teacher for semi-supervised fine-tuning, we learn new semi-supervised DAE features, which are more effective and stable than the unsupervised DBN features.",
            "On two Chinese- English tasks, our semi-supervised DAE features obtain statistically significant improvements of 1.34/2.45 (IWSLT) and 0.82/1.52 (NIST) BLEU points over the unsupervised DBN features and the baseline features, respectively.",
            "In this paper, instead of designing new features based on intuition, linguistic knowledge and domain, we learn some new and effective features using the deep autoencoder (DAE) paradigm for phrase-based translation model.",
            "Learning New Semi-Supervised Deep Auto-encoder Features for Statistical Machine Translation",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.021158239610106842,
                0.0,
                0.02574867849607202,
                0.06063555241201858,
                0.0
            ],
            [
                0.021158239610106842,
                1.0,
                0.3234130452737731,
                0.29406832405189415,
                0.2527860993187766,
                0.0
            ],
            [
                0.0,
                0.3234130452737731,
                1.0,
                0.11677201091876027,
                0.15239067623315636,
                0.0
            ],
            [
                0.02574867849607202,
                0.29406832405189415,
                0.11677201091876027,
                1.0,
                0.22019775509791184,
                0.0
            ],
            [
                0.06063555241201858,
                0.2527860993187766,
                0.15239067623315636,
                0.22019775509791184,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P14-2110": {
        "input_sentences": [
            "Learning Polylingual Topic Models from Code-Switched Social Media Documents",
            "We experiment on two code-switching corpora (English-Spanish Twitter data and English-Chinese Weibo data) and show that csLDA improves perplexity over LDA, and learns semantically coherent aligned topics as judged by human annotators.",
            "Code-switched documents are in social media, providing evidence polylingual topic models to infer aligned topics across languages.",
            "Abstract",
            "We Code-Switched LDA (csLDA), which infers language specific topic distributions based on code-switched documents to facilitate multi-lingual corpus analysis."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.027165330410330014,
                0.6010305842810572,
                0.0,
                0.2709087889152935
            ],
            [
                0.027165330410330014,
                1.0,
                0.10281634697550306,
                0.0,
                0.09736607104978133
            ],
            [
                0.6010305842810572,
                0.10281634697550306,
                1.0,
                0.0,
                0.2009870009558809
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.2709087889152935,
                0.09736607104978133,
                0.2009870009558809,
                0.0,
                1.0
            ]
        ]
    },
    "D11-1140": {
        "input_sentences": [
            "In this paper, we introduce factored lexicons, which both model word meaning model systematic variation in word usage.",
            "Such lexicons can be inefficient when words appear repeatedly with closely related lexical content.",
            "Traditional CCG lexicons list lexical items that pair words and phrases with syntactic and semantic content.",
            "We consider the problem of learning factored probabilistic CCG grammars for semantic parsing from data containing sentences paired with logical-form meaning representations.",
            "Lexical Generalization in CCG Grammar Induction for Semantic Parsing",
            "We also present an algorithm for learning factored CCG lexicons, along with a probabilistic parse-selection model.",
            "Abstract",
            "Evaluations on benchmark datasets demonstrate that the approach learns highly accurate parsers, whose generalization performance benefits greatly from the lexical factoring."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.04085123124431552,
                0.036291903543245733,
                0.08853166620263712,
                0.0,
                0.2331056339823224,
                0.0,
                0.0
            ],
            [
                0.04085123124431552,
                1.0,
                0.2722118249564968,
                0.0,
                0.0688396699440976,
                0.054920794080956015,
                0.0,
                0.03987287208369899
            ],
            [
                0.036291903543245733,
                0.2722118249564968,
                1.0,
                0.08106266378629476,
                0.20186730136910472,
                0.09758237882153768,
                0.0,
                0.0354227371752752
            ],
            [
                0.08853166620263712,
                0.0,
                0.08106266378629476,
                1.0,
                0.19813707668932254,
                0.2262977111022281,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0688396699440976,
                0.20186730136910472,
                0.19813707668932254,
                1.0,
                0.06778814092685465,
                0.0,
                0.13519012376406056
            ],
            [
                0.2331056339823224,
                0.054920794080956015,
                0.09758237882153768,
                0.2262977111022281,
                0.06778814092685465,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.03987287208369899,
                0.0354227371752752,
                0.0,
                0.13519012376406056,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P01-1018": {
        "input_sentences": [
            "We then introduce a formalism which, under these constraints, maximally squeezes strong generative power out of context-free grammar.",
            "We consider the question \u201cHow much strong generative power can be squeezed out of a formal system without increasing its weak generative power?\u201d and propose some theoretical and practical constraints on this problem.",
            "Finally, we generalize this result to formalisms beyond CFG.",
            "Abstract",
            "Constraints On Strong Generative Power"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.238435587667789,
                0.0,
                0.0,
                0.45167210392589197
            ],
            [
                0.238435587667789,
                1.0,
                0.0,
                0.0,
                0.5278953151973058
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.45167210392589197,
                0.5278953151973058,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "D12-1046": {
        "input_sentences": [
            "Joint Chinese Word Segmentation, POS Tagging and Parsing",
            "In this paper, we propose a novel decoding algorithm for discriminative joint Chinese word segmentation, part-of-speech (POS) tagging, and parsing.",
            "Our experimental results on Chinese Tree Bank 5 corpus show that our approach outperforms the state-of-the-art pipeline system.",
            "Previous work often used a pipeline method \u2013 Chinese word segmentation followed by POS tagging and parsing, which suffers from error propagation and is unable to leverage information in later modules for earlier components.",
            "We extend the CYK parsing algorithm so that it can deal with word segmentation and POS tagging features.",
            "As far as we know, this is the first work on joint Chinese word segmentation, POS tagging and parsing.",
            "Abstract",
            "In our approach, we train the three individual models separately during training, and incorporate them together in a unified framework during decoding."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.5231304109099408,
                0.06504648937122004,
                0.2925797076760502,
                0.4046957571361989,
                0.6868269699744741,
                0.0,
                0.0
            ],
            [
                0.5231304109099408,
                1.0,
                0.03402779671301544,
                0.15305734270048255,
                0.3061132021602685,
                0.3593000750267762,
                0.0,
                0.07712809208227743
            ],
            [
                0.06504648937122004,
                0.03402779671301544,
                1.0,
                0.07847014245258696,
                0.0,
                0.04467568320231189,
                0.0,
                0.07346275597559679
            ],
            [
                0.2925797076760502,
                0.15305734270048255,
                0.07847014245258696,
                1.0,
                0.15116885944367803,
                0.27562480238442166,
                0.0,
                0.0
            ],
            [
                0.4046957571361989,
                0.3061132021602685,
                0.0,
                0.15116885944367803,
                1.0,
                0.27795596063538114,
                0.0,
                0.0
            ],
            [
                0.6868269699744741,
                0.3593000750267762,
                0.04467568320231189,
                0.27562480238442166,
                0.27795596063538114,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.07712809208227743,
                0.07346275597559679,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P12-2058": {
        "input_sentences": [
            "We propose a novel heuristic algorithm for Cube Pruning running in linear time in the beam size.",
            "Heuristic Cube Pruning in Linear Time",
            "Empirically, we show a gain in running time of a standard machine translation system, at a small loss in accuracy.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.5829495577403239,
                0.11735318906753682,
                0.0
            ],
            [
                0.5829495577403239,
                1.0,
                0.07970385532520921,
                0.0
            ],
            [
                0.11735318906753682,
                0.07970385532520921,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "W10-2803": {
        "input_sentences": [
            "In this paper, we argue in favor of reconsidering models for word meaning, using as a basis results from cognitive science on human concept representation.",
            "More specifically, we argue for a more flexible representation of word meaning than the assignment of a single best-fitting dictionary sense to each occurrence: Either use dictionary senses, but view them as having fuzzy boundaries, and assume that an occurrence can activate multiple senses to different degrees.",
            "We argue that distributional models provide a flexible framework for experimenting with alternative models of word meanings, and discuss example models.",
            "Or move away from dictionary senses completely, and only model similarities between individual word usages.",
            "Abstract",
            "What Is Word Meaning Really? (And How Can Distributional Models Help Us Describe It?)"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.10183003747836954,
                0.16927729964015933,
                0.027054790482824227,
                0.0,
                0.17592902027816007
            ],
            [
                0.10183003747836954,
                1.0,
                0.07308005537275573,
                0.20247494703184624,
                0.0,
                0.07111284201925301
            ],
            [
                0.16927729964015933,
                0.07308005537275573,
                1.0,
                0.02599686132090279,
                0.0,
                0.32849795758542605
            ],
            [
                0.027054790482824227,
                0.20247494703184624,
                0.02599686132090279,
                1.0,
                0.0,
                0.04822899442360328
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.17592902027816007,
                0.07111284201925301,
                0.32849795758542605,
                0.04822899442360328,
                0.0,
                1.0
            ]
        ]
    },
    "P12-1048": {
        "input_sentences": [
            "Translation Model Adaptation for Statistical Machine Translation with Monolingual Topic Information",
            "Experimental result on the NIST Chinese-English translation task shows that our approach significantly outperforms the baseline system.",
            "To adapt a translation model trained from the data in one domain to another, previous works paid more attention to the studies of parallel corpus while ignoring the in-domain monolingual corpora which can be obtained more easily.",
            "In this paper, we propose a novel approach for translation model adaptation by utilizing in-domain monolingual topic information instead of the in-domain bilingual corpora, which incorporates the topic information into translation probability estimation.",
            "Our method establishes the relationship between the out-of-domain bilingual corpus and the in-domain monolingual corpora via topic mapping and phrase-topic distribution probability estimation from in-domain monolingual corpora.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.08609740509151238,
                0.15464952414259261,
                0.4910074286227582,
                0.1580639537598134,
                0.0
            ],
            [
                0.08609740509151238,
                1.0,
                0.026294011852850914,
                0.09610318849859112,
                0.0,
                0.0
            ],
            [
                0.15464952414259261,
                0.026294011852850914,
                1.0,
                0.22610492540165666,
                0.3025960197614599,
                0.0
            ],
            [
                0.4910074286227582,
                0.09610318849859112,
                0.22610492540165666,
                1.0,
                0.4598706143748725,
                0.0
            ],
            [
                0.1580639537598134,
                0.0,
                0.3025960197614599,
                0.4598706143748725,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P04-1040": {
        "input_sentences": [
            "Enriching The Output Of A Parser Using Memory-Based Learning",
            "This general framework allows us to accurately recover both grammatical and semantic information as well as non-local dependencies.",
            "Our method is largely independent of the choice of parser and corpus, and shows state of the art performance.",
            "We describe a method for enriching the output of a parser with information available in a corpus.",
            "The method is based on graph rewriting using memorybased learning, applied to dependency structures.",
            "Abstract",
            "It also facilitates dependency-based evaluation of phrase structure parsers."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.07822435913783136,
                0.39502492913917886,
                0.30340464999334765,
                0.0,
                0.092697354594617
            ],
            [
                0.0,
                1.0,
                0.0,
                0.09656833309698316,
                0.0,
                0.0,
                0.0
            ],
            [
                0.07822435913783136,
                0.0,
                1.0,
                0.2635135090062682,
                0.06008135830031526,
                0.0,
                0.0
            ],
            [
                0.39502492913917886,
                0.09656833309698316,
                0.2635135090062682,
                1.0,
                0.08118116778770522,
                0.0,
                0.0
            ],
            [
                0.30340464999334765,
                0.0,
                0.06008135830031526,
                0.08118116778770522,
                1.0,
                0.0,
                0.16864483466736604
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.092697354594617,
                0.0,
                0.0,
                0.0,
                0.16864483466736604,
                0.0,
                1.0
            ]
        ]
    },
    "P14-1004": {
        "input_sentences": [
            "Quantitatively, we show our models achieve superior performance on held-out log likelihood evaluation and an ordering task.",
            "Our methods synthesize hidden Markov models (for underlying state) and topic models (to connect words to states).",
            "We show that our models extract meaningful state representations and dialogue structures consistent with human annotations.",
            "We apply them to two real, non-trivial datasets: human-computer spoken dialogues in bus query service, and humanhuman text-based chats from a live technical support service.",
            "Discovering Latent Structure in Task-Oriented Dialogues",
            "Abstract",
            "A key challenge for computational conversation models is to discover latent structure in task-oriented dialogue, since it provides a basis for analysing, evaluating, and building conversational systems.",
            "We propose three new unsupervised models to discover latent structures in task-oriented dialogues."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0610453238236123,
                0.03545501934274752,
                0.0,
                0.0672951031149057,
                0.0,
                0.05965442056546081,
                0.08893251063531543
            ],
            [
                0.0610453238236123,
                1.0,
                0.14118523681561343,
                0.0,
                0.0,
                0.0,
                0.049347098659916426,
                0.07356640689484631
            ],
            [
                0.03545501934274752,
                0.14118523681561343,
                1.0,
                0.05348625668600657,
                0.0,
                0.0,
                0.09256223704197121,
                0.1379913181979644
            ],
            [
                0.0,
                0.0,
                0.05348625668600657,
                1.0,
                0.05923014338976622,
                0.0,
                0.0,
                0.04388735063308135
            ],
            [
                0.0672951031149057,
                0.0,
                0.0,
                0.05923014338976622,
                1.0,
                0.0,
                0.29095968223795243,
                0.39758152644076244
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.05965442056546081,
                0.049347098659916426,
                0.09256223704197121,
                0.0,
                0.29095968223795243,
                0.0,
                1.0,
                0.2471727859356697
            ],
            [
                0.08893251063531543,
                0.07356640689484631,
                0.1379913181979644,
                0.04388735063308135,
                0.39758152644076244,
                0.0,
                0.2471727859356697,
                1.0
            ]
        ]
    },
    "D10-1004": {
        "input_sentences": [
            "Dependency Parsing.",
            "We present a unified view of two state-of-theart non-projective dependency parsers, both approximate: the loopy belief propagation parser of Smith and Eisner (2008) and the relaxed linear program of Martins et al. (2009).",
            "We also propose a new aggressive online algorithm to learn the model parameters, which makes use of the underlying variational representation.",
            "The algorithm does not require a learning rate parameter and provides a single framework for a wide family of convex loss functions, including CRFs and structured SVMs.",
            "Experiments show state-of-the-art performance for 14 languages.",
            "Turbo Parsers: Dependency Parsing by Approximate Variational Inference",
            "Abstract",
            "By representing the model assumptions with a factor graph, we shed light on the optimization problems tackled in each method."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0993181415487934,
                0.0,
                0.0,
                0.0,
                0.47936917005257945,
                0.0,
                0.0
            ],
            [
                0.0993181415487934,
                1.0,
                0.0,
                0.0,
                0.06182975195968488,
                0.17548624043009434,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0479769525272371,
                0.0,
                0.08741434685889668,
                0.0,
                0.06170329354045934
            ],
            [
                0.0,
                0.0,
                0.0479769525272371,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.06182975195968488,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.47936917005257945,
                0.17548624043009434,
                0.08741434685889668,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.06170329354045934,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P12-3029": {
        "input_sentences": [
            "The annotations are produced automatically with statistical models that are specifically adapted to historical text.",
            "Syntactic Annotations",
            "The corpus will facilitate the study of linguistic trends, especially those related to the evolution of syntax.",
            "This new edition introduces syntactic annotations: words are tagged with their part-of-speech, and headmodifier relationships are recorded.",
            "We present a new edition of the Google Books Ngram Corpus, which describes how often words and phrases were used over a period of five centuries, in eight languages; it reflects 6% of all books ever published.",
            "Syntactic Annotations for the Google Books NGram Corpus",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.1395151599136691,
                0.0,
                0.04381953425042085,
                0.0,
                0.0705427235592171,
                0.0
            ],
            [
                0.1395151599136691,
                1.0,
                0.0,
                0.3140843925315073,
                0.0,
                0.5056276579754372,
                0.0
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.04356400827207837,
                0.09290010954000999,
                0.0
            ],
            [
                0.04381953425042085,
                0.3140843925315073,
                0.0,
                1.0,
                0.1743565989652558,
                0.15880975580234385,
                0.0
            ],
            [
                0.0,
                0.0,
                0.04356400827207837,
                0.1743565989652558,
                1.0,
                0.4426090078949184,
                0.0
            ],
            [
                0.0705427235592171,
                0.5056276579754372,
                0.09290010954000999,
                0.15880975580234385,
                0.4426090078949184,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P01-1005": {
        "input_sentences": [
            "In this paper, we evaluate the performance of different learning methods on a prototypical natural language disambiguation task, confusion set disambiguation, when trained on orders of magnitude more labeled data than has previously been used.",
            "The amount of readily available on-line text has reached hundreds of billions of words and continues to grow.",
            "We are fortunate that for this particular application, correctly labeled training data is free.",
            "Yet for most core natural language tasks, algorithms continue to be optimized, tested and compared after training on corpora consisting of only one million words or less.",
            "Scaling To Very Very Large Corpora For Natural Language Disambiguation",
            "Abstract",
            "Since this will often not be the case, we examine methods for effectively exploiting very large corpora when labeled data comes at a cost."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.08820780697614163,
                0.06619883766617657,
                0.27417964510203574,
                0.0,
                0.12895294113936098
            ],
            [
                0.0,
                1.0,
                0.0,
                0.06420135936680478,
                0.0,
                0.0,
                0.0
            ],
            [
                0.08820780697614163,
                0.0,
                1.0,
                0.07722891258559583,
                0.0,
                0.0,
                0.13051345000212472
            ],
            [
                0.06619883766617657,
                0.06420135936680478,
                0.07722891258559583,
                1.0,
                0.22213486395330623,
                0.0,
                0.04897434244272847
            ],
            [
                0.27417964510203574,
                0.0,
                0.0,
                0.22213486395330623,
                1.0,
                0.0,
                0.20283993350103183
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.12895294113936098,
                0.0,
                0.13051345000212472,
                0.04897434244272847,
                0.20283993350103183,
                0.0,
                1.0
            ]
        ]
    },
    "D12-1108": {
        "input_sentences": [
            "Document-Wide Decoding for Phrase-Based Statistical Machine Translation",
            "Moreover, by optionally initialising the state with the output of a traditional DP decoder, we can ensure that the final hypothesis is no worse than what would have been found by DP search alone.",
            "In this paper, we present a method for decoding complete documents in phrase-based SMT.",
            "The initial state is improved by the application of a series of operations using a hill climbing strategy to find a (local) maximum of the score function.",
            "This setup gives us complete freedom to define scoring functions over the entire document.",
            "Our decoder uses a local search approach whose state consists of a complete translation of an entire document at any time.",
            "We start by describing the decoding algorithm and the state operations used by our decoder, then we present empirical results demonstrating the effectiveness of our approach and its usability with a document-level semantic language model, and finally we discuss some related work.",
            "Research into models with a more varied, non-local dependency structure is to some extent stifled by the difficulty of decoding such models effectively, as can be seen by the problems some researchers encountered when they attempted to solve discourse-level problems.",
            "Consider, for instance, the work on cache-based language models by Tiedemann (2010) and Gong et al. (2011), where error propagation was a serious issue, or the works on pronominal anaphora by Le Nagard and Koehn (2010), who implemented cross-sentence dependencies with an ad-hoc two-pass decoding strategy, and Hardmeier and Federico (2010) with the use of an external decoder driver to manage backward-only dependencies between sentences.",
            "any obvious way, especially if joint optimisation of a number of interdependent decisions over an entire document is required.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.2627012606866291,
                0.0,
                0.05595984018539598,
                0.160218325128874,
                0.0684896844287762,
                0.031551593108568345,
                0.055917127742587926,
                0.04861950024379003,
                0.0
            ],
            [
                0.0,
                1.0,
                0.0,
                0.03460179608402873,
                0.0,
                0.15486952111172586,
                0.054631258490876515,
                0.0,
                0.017585750118296037,
                0.0,
                0.0
            ],
            [
                0.2627012606866291,
                0.0,
                1.0,
                0.0,
                0.0782269304313678,
                0.07499795507710831,
                0.09305561477744735,
                0.028709532234520857,
                0.05088030185555635,
                0.0,
                0.0
            ],
            [
                0.0,
                0.03460179608402873,
                0.0,
                1.0,
                0.0,
                0.1007418316939907,
                0.07477710090092136,
                0.03293938111348858,
                0.029759292854723635,
                0.0,
                0.0
            ],
            [
                0.05595984018539598,
                0.0,
                0.0782269304313678,
                0.0,
                1.0,
                0.1915373979875412,
                0.030019826323731166,
                0.0,
                0.0,
                0.10809945230517368,
                0.0
            ],
            [
                0.160218325128874,
                0.15486952111172586,
                0.07499795507710831,
                0.1007418316939907,
                0.1915373979875412,
                1.0,
                0.15657510791408627,
                0.04073825580318462,
                0.022734281403781503,
                0.1036374279693397,
                0.0
            ],
            [
                0.0684896844287762,
                0.054631258490876515,
                0.09305561477744735,
                0.07477710090092136,
                0.030019826323731166,
                0.15657510791408627,
                1.0,
                0.05054702404657115,
                0.0733240122733401,
                0.026082078655508472,
                0.0
            ],
            [
                0.031551593108568345,
                0.0,
                0.028709532234520857,
                0.03293938111348858,
                0.0,
                0.04073825580318462,
                0.05054702404657115,
                1.0,
                0.054187262639238135,
                0.0,
                0.0
            ],
            [
                0.055917127742587926,
                0.017585750118296037,
                0.05088030185555635,
                0.029759292854723635,
                0.0,
                0.022734281403781503,
                0.0733240122733401,
                0.054187262639238135,
                1.0,
                0.0,
                0.0
            ],
            [
                0.04861950024379003,
                0.0,
                0.0,
                0.0,
                0.10809945230517368,
                0.1036374279693397,
                0.026082078655508472,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P08-1108": {
        "input_sentences": [
            "Previous studies of data-driven dependency parsing have shown that the distribution of parsing errors are correlated with theoretical properties of the models used for learning and inference.",
            "Integrating Graph-Based and Transition-Based Dependency Parsers",
            "In this paper, we show how these results can be exploited to improve parsing accuracy by integrating a graph-based and a transition-based model.",
            "By letting one model generate features for the other, we consistently improve accuracy for both models, resulting in a significant improvement of the state of the art when evaluated on data sets from the CoNLL-X shared task.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.06420805446928936,
                0.1003744963162654,
                0.07702286604730259,
                0.0
            ],
            [
                0.06420805446928936,
                1.0,
                0.5737493065249882,
                0.0,
                0.0
            ],
            [
                0.1003744963162654,
                0.5737493065249882,
                1.0,
                0.14748422034256006,
                0.0
            ],
            [
                0.07702286604730259,
                0.0,
                0.14748422034256006,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P12-1002": {
        "input_sentences": [
            "We present experiments on learning on 1.5 million training sentences, and show significant improvements over tuning discriminative models on small development sets.",
            "Joint Feature Selection in Distributed Stochastic Learning for Large-Scale Discriminative Training in SMT",
            "The goal of this paper is to show that this common wisdom can also be brought to bear upon SMT.",
            "With a few exceptions, discriminative training in statistical machine translation (SMT) has been content with tuning weights for large feature sets on small development data.",
            "Evidence from machine learning indicates that increasing the training sample size results in better prediction.",
            "Joint Feature Selection in Distributed",
            "We deploy local features for SCFG-based SMT that can be read off from rules at runtime, and present a learnalgorithm that applies regularization for joint feature selection over distributed stochastic learning processes.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.163144928797828,
                0.0,
                0.32823198258737846,
                0.07921622026249882,
                0.0,
                0.08339811445297106,
                0.0
            ],
            [
                0.163144928797828,
                1.0,
                0.06431107008922929,
                0.28475841948144387,
                0.10555174473565836,
                0.5682100808558768,
                0.3499002739010843,
                0.0
            ],
            [
                0.0,
                0.06431107008922929,
                1.0,
                0.04597952211077914,
                0.0,
                0.0,
                0.03950394419794238,
                0.0
            ],
            [
                0.32823198258737846,
                0.28475841948144387,
                0.04597952211077914,
                1.0,
                0.10364889306734454,
                0.08286517669969069,
                0.05784498516458602,
                0.0
            ],
            [
                0.07921622026249882,
                0.10555174473565836,
                0.0,
                0.10364889306734454,
                1.0,
                0.0,
                0.03241829305784823,
                0.0
            ],
            [
                0.0,
                0.5682100808558768,
                0.0,
                0.08286517669969069,
                0.0,
                1.0,
                0.3490307235705317,
                0.0
            ],
            [
                0.08339811445297106,
                0.3499002739010843,
                0.03950394419794238,
                0.05784498516458602,
                0.03241829305784823,
                0.3490307235705317,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "N03-1004": {
        "input_sentences": [
            "The answering agents adopt fundamentally different strategies, one utilizing primarily knowledge-based mechanisms and the other adopting statistical techniques.",
            "Abstract",
            "In Question Answering Two Heads Are Better Than One",
            "We present our multi-level answer resolution algorithm that combines results from the answering agents at the question, passage, and/or answer levels.",
            "Experiments evaluating the effectiveness of our answer resolution algorithm show a 35.0% relative improvement over our baseline system in the number of questions correctly answered, and a 32.8% improvement according to the average precision metric.",
            "Motivated by the success of ensemble methods in machine learning and other areas of natural language processing, we developed a multistrategy and multi-source approach to question answering which is based on combining the results from different answering agents searching for answers in multiple corpora."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.05994396322152722,
                0.06967436021150795,
                0.0,
                0.1477134047558649
            ],
            [
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.05994396322152722,
                0.0,
                1.0,
                0.14448998865541002,
                0.0,
                0.14337040984827396
            ],
            [
                0.06967436021150795,
                0.0,
                0.14448998865541002,
                1.0,
                0.17159657145966087,
                0.17933520755468638
            ],
            [
                0.0,
                0.0,
                0.0,
                0.17159657145966087,
                1.0,
                0.0
            ],
            [
                0.1477134047558649,
                0.0,
                0.14337040984827396,
                0.17933520755468638,
                0.0,
                1.0
            ]
        ]
    },
    "P12-1110": {
        "input_sentences": [
            "Incremental Joint Approach to Word Segmentation, POS Tagging, and Dependency Parsing in Chinese",
            "Based on an extension of the incremental joint model for POS tagging and dependency parsing (Hatori et al., 2011), we propose an efficient character-based decoding method that can combine features from state-of-the-art segmentation, POS tagging, and dependency parsing models.",
            "In experiments using the Chinese Treebank (CTB), we show that the accuracies of the three tasks can be improved significantly over the baseline models, particularly by 0.6% for POS tagging and 2.4% for dependency parsing.",
            "We propose the first joint model for word segmentation, POS tagging, and dependency parsing for Chinese.",
            "We also perform comparison experiments with the partially joint models.",
            "We also describe our method to align comparable states in the beam, and how we can combine features of different characteristics in our incremental framework.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.38861248215739824,
                0.25619454333975755,
                0.7138535150397509,
                0.07861249131360082,
                0.07208193990263688,
                0.0
            ],
            [
                0.38861248215739824,
                1.0,
                0.2009158371971305,
                0.4713068031027406,
                0.081920549080303,
                0.16484859775437619,
                0.0
            ],
            [
                0.25619454333975755,
                0.2009158371971305,
                1.0,
                0.25940425183925747,
                0.15957780855687148,
                0.0,
                0.0
            ],
            [
                0.7138535150397509,
                0.4713068031027406,
                0.25940425183925747,
                1.0,
                0.07959738028994993,
                0.0,
                0.0
            ],
            [
                0.07861249131360082,
                0.081920549080303,
                0.15957780855687148,
                0.07959738028994993,
                1.0,
                0.0,
                0.0
            ],
            [
                0.07208193990263688,
                0.16484859775437619,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "D10-1069": {
        "input_sentences": [
            "We show that dependency parsers have more difficulty parsing questions than constituency parsers.",
            "Uptraining with 100K unlabeled questions achieves results comparable to having 2K labeled questions for training.",
            "It is well known that parsing accuracies drop significantly on out-of-domain data.",
            "What is less known is that some parsers suffer more from domain shifts than others.",
            "With 100K unlabeled and 2K labeled questions, uptraining is able to improve parsing accuracy to 84%, closing the gap between in-domain and out-of-domain performance.",
            "Uptraining for Accurate Deterministic Question Parsing",
            "We propose an in which a deterministic parser is trained on the output of a more accurate, but slower, latent variable constituency parser (converted to dependencies).",
            "Abstract",
            "In particular, deterministic shift-reduce dependency parsers, which are of highest interest for practical applications because of their linear running time, drop to 60% labeled accuracy on a question test set."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.14220799333631212,
                0.07703672993080614,
                0.23523647988396765,
                0.1128994041125147,
                0.10452252834828252,
                0.081069988809532,
                0.0,
                0.18751862651045043
            ],
            [
                0.14220799333631212,
                1.0,
                0.0,
                0.0,
                0.36930555596816056,
                0.09787046705527558,
                0.0,
                0.0,
                0.041252511235869996
            ],
            [
                0.07703672993080614,
                0.0,
                1.0,
                0.27715932799702686,
                0.17885594357363918,
                0.10603652525928609,
                0.0,
                0.0,
                0.07573162177362662
            ],
            [
                0.23523647988396765,
                0.0,
                0.27715932799702686,
                1.0,
                0.153330173092272,
                0.0,
                0.0,
                0.0,
                0.06823874876393454
            ],
            [
                0.1128994041125147,
                0.36930555596816056,
                0.17885594357363918,
                0.153330173092272,
                1.0,
                0.15539938580840199,
                0.0,
                0.0,
                0.08544255131593806
            ],
            [
                0.10452252834828252,
                0.09787046705527558,
                0.10603652525928609,
                0.0,
                0.15539938580840199,
                1.0,
                0.19594642272910429,
                0.0,
                0.18043006358932037
            ],
            [
                0.081069988809532,
                0.0,
                0.0,
                0.0,
                0.0,
                0.19594642272910429,
                1.0,
                0.0,
                0.03555714047215734
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.18751862651045043,
                0.041252511235869996,
                0.07573162177362662,
                0.06823874876393454,
                0.08544255131593806,
                0.18043006358932037,
                0.03555714047215734,
                0.0,
                1.0
            ]
        ]
    },
    "P11-2084": {
        "input_sentences": [
            "Experiments on a document-aligned English-Italian Wikipedia corpus confirm that the developed methods which only use knowledge from word-topic distributions outperform methods based on similarity measures in the original word-document space.",
            "The best results, obtained by combining knowledge from wordtopic distributions with similarity measures in the original space, are also reported.",
            "Identifying Word Translations from Comparable Corpora Using Latent Topic Models",
            "A topic model outputs a set of multinomial distributions over words for each topic.",
            "In this paper, we investigate the value of bilingual topic models, i.e., a bilingual Latent Dirichlet Allocation model for finding translations of terms in comparable corpora without using any linguistic resources.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.2406880352044895,
                0.135495862538359,
                0.09080648405217641,
                0.016279278290296052,
                0.0
            ],
            [
                0.2406880352044895,
                1.0,
                0.0,
                0.05965387012604221,
                0.0,
                0.0
            ],
            [
                0.135495862538359,
                0.0,
                1.0,
                0.11165659277290771,
                0.41934776010745384,
                0.0
            ],
            [
                0.09080648405217641,
                0.05965387012604221,
                0.11165659277290771,
                1.0,
                0.12645668377664235,
                0.0
            ],
            [
                0.016279278290296052,
                0.0,
                0.41934776010745384,
                0.12645668377664235,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "N09-2064": {
        "input_sentences": [
            "the output of multiple parsers via parse selection or parse hybridization improves f-score over the best individual parser (Henderson and Brill, 1999; Sagae and Lavie, 2006).",
            "We propose three ways to improve upon existing methods for parser combination.",
            "Second, we propose an efficient lineartime algorithm for computing expected f-score using Minimum Bayes Risk parse selection.",
            "We present results on WSJ section 23 and also on the English side of a Chinese-English parallel corpus.",
            "Combining Constituent Parsers",
            "Abstract",
            "Third, we extend these parser combination from multiple outputs to muloutputs.",
            "First, we propose a method of parse hybridization that recomproductions of conthereby preserving the structure of the output of the individual parsers to a greater extent."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.05567345686149226,
                0.17726253592461566,
                0.0,
                0.084035351827084,
                0.0,
                0.14088356302044505,
                0.2871434783593358
            ],
            [
                0.05567345686149226,
                1.0,
                0.06182111235853504,
                0.0,
                0.0,
                0.0,
                0.23023633253361275,
                0.06676172584383445
            ],
            [
                0.17726253592461566,
                0.06182111235853504,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.09072618419485903
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.084035351827084,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.100772350706149
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.14088356302044505,
                0.23023633253361275,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.2871434783593358,
                0.06676172584383445,
                0.09072618419485903,
                0.0,
                0.100772350706149,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "W03-1022": {
        "input_sentences": [
            "We present a new framework for classifying common nouns that extends namedentity classification.",
            "We used a fixed set 26 semantic labels, which we called su- These are the labels used by lexicographers developing WordNet.",
            "Supersense Tagging Of Unknown Nouns In WordNet",
            "This framework has a number of practical advantages.",
            "We also define a more realistic evaluation procedure than cross-validation.",
            "Abstract",
            "We show how information contained in the dictionary can be used as additional training data that improves accuracy in learning new nouns."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.08757924767229369,
                0.12778629794308544,
                0.0,
                0.0,
                0.12876555366634165
            ],
            [
                0.0,
                1.0,
                0.08562761556760151,
                0.0,
                0.0,
                0.0,
                0.10630026831943039
            ],
            [
                0.08757924767229369,
                0.08562761556760151,
                1.0,
                0.0,
                0.0,
                0.0,
                0.07453519673902247
            ],
            [
                0.12778629794308544,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.12876555366634165,
                0.10630026831943039,
                0.07453519673902247,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "D11-1022": {
        "input_sentences": [
            "However, in cases where lightweight decomare not readily available due to the presence of rich features or logical constraints), the original subgradient algorithm is inefficient.",
            "We sidestep that difficulty by adopting an augmented Lagrangian method that accelerates model consensus by regularizing towards the averaged votes.",
            "We show how first-order logical constraints can be handled efficiently, even though the corresponding subproblems are no longer combinatorial, and report experiments in dependency parsing, with state-of-the-art results.",
            "Dual Decomposition with Many Overlapping Components",
            "Abstract",
            "Dual decomposition has been recently proposed as a way of combining complementary models, with a boost in predictive power."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.09397985590619753,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.09397985590619753,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.2286244614433553
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.2286244614433553,
                0.0,
                1.0
            ]
        ]
    },
    "D07-1092": {
        "input_sentences": [
            "An easy way out commercial translation systems usually offer their users is the possibility to add unknown wordsand their translations into a dedicated lex icon.",
            "Recently, Stroppa and Yvon (2005) have shown how analogical learning alone deals nicely with morphology in differentlanguages.",
            "In this study we show that ana logical learning offers as well an elegant andeffective solution to the problem of identify ing potential translations of unknown words.",
            "In particular, they drastically impact machine transla tion quality.",
            "Translating Unknown Words by Analogical Learning",
            "Abstract",
            "Unknown words are a well-known hindranceto natural language applications."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.07612390105321662,
                0.0,
                0.05574469000438112,
                0.0,
                0.04030484466348048
            ],
            [
                0.0,
                1.0,
                0.043608813612345323,
                0.0,
                0.21299018550199683,
                0.0,
                0.0
            ],
            [
                0.07612390105321662,
                0.043608813612345323,
                1.0,
                0.0,
                0.21862215076279065,
                0.0,
                0.10066864315790312
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.05574469000438112,
                0.21299018550199683,
                0.21862215076279065,
                0.0,
                1.0,
                0.0,
                0.20757333367366157
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.04030484466348048,
                0.0,
                0.10066864315790312,
                0.0,
                0.20757333367366157,
                0.0,
                1.0
            ]
        ]
    },
    "W06-3114": {
        "input_sentences": [
            " Evaluation was done automatically using the BLEU score and manually on fluency and adequacy",
            "We evaluated machine translation performance for six European language pairs that participated in a shared task: translating French, German, Spanish texts to English and back"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0
            ],
            [
                0.0,
                1.0
            ]
        ]
    },
    "D09-1161": {
        "input_sentences": [
            "For feature weight tuning, we compare the simulated-annealing algorithm and the perceptron algorithm.",
            "Our experiments are carried out on both the Chinese and English Penn Treebank syntactic parsing task by combining two stateof-the-art parsing models, a head-driven lexicalized model and a latent-annotation-based un-lexicalized model.",
            "In this paper, we propose a linear model-based general framework to combine k-best parse outputs from multiple parsers.",
            "K-Best Combination of Syntactic Parsers",
            "As a result, it is able to fully utilize both the logarithm of the probability of each k-best parse tree from each individual parser and any additional useful features.",
            "Experimental results show that our F-Scores of 85.45 on Chinese and 92.62 on English outperform the previously best-reported systems by 1.21 and 0.52, respectively.",
            "Abstract",
            "The proposed framework leverages on the strengths of previous system combination and re-ranking techniques in parsing by integrating them into a linear model."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                1.0,
                0.10886951279464328,
                0.08919846677445885,
                0.0,
                0.07107738255780965,
                0.0,
                0.1533745667611031
            ],
            [
                0.0,
                0.10886951279464328,
                1.0,
                0.21581748242594956,
                0.09443731540768516,
                0.03130257991692563,
                0.0,
                0.18563629198413467
            ],
            [
                0.0,
                0.08919846677445885,
                0.21581748242594956,
                1.0,
                0.07011542360467948,
                0.06384113401695045,
                0.0,
                0.137943090475529
            ],
            [
                0.0,
                0.0,
                0.09443731540768516,
                0.07011542360467948,
                1.0,
                0.02793557427031746,
                0.0,
                0.0
            ],
            [
                0.0,
                0.07107738255780965,
                0.03130257991692563,
                0.06384113401695045,
                0.02793557427031746,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.1533745667611031,
                0.18563629198413467,
                0.137943090475529,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "W12-3401": {
        "input_sentences": [
            "The standard approach for lexical generalization in parsing is to map a word to a single generalized class, either replacing the word with the class or adding a new feature for the class.",
            "We use a richer framework that allows for probabilistic generalization, with a word represented as a probability distribution over a space of generalized classes: lemmas, clusters, or synsets.",
            "Probabilistic Lexical Generalization for French Dependency Parsing",
            "Probabilistic lexical information is introduced into parser feature vectors by modifying the weights of lexical features.",
            "A distributional thesaurus is created from a large text corpus and used for distributional clustering and WordNet automatic sense ranking.",
            "Abstract",
            "This paper investigates the impact on French dependency parsing of lexical generalization methods beyond lemmatization and morphological analysis.",
            "We obtain improvements in parsing accuracy with some lexical generalization configurations in experiments run on the French Treebank and two out-of-domain treebanks, with slightly better performance for the probabilistic lexical generalization approach compared to the standard single-mapping approach."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.1428683436312548,
                0.14028191663997502,
                0.09651174109939835,
                0.0,
                0.0,
                0.07518980893318498,
                0.21102351400982255
            ],
            [
                0.1428683436312548,
                1.0,
                0.11700916333218744,
                0.03496231996318872,
                0.0,
                0.0,
                0.027551959470116648,
                0.05847378571868955
            ],
            [
                0.14028191663997502,
                0.11700916333218744,
                1.0,
                0.20681308013441216,
                0.0,
                0.0,
                0.454962156912211,
                0.3377626875527608
            ],
            [
                0.09651174109939835,
                0.03496231996318872,
                0.20681308013441216,
                1.0,
                0.0,
                0.0,
                0.06766825531076781,
                0.11564072190110067
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.07518980893318498,
                0.027551959470116648,
                0.454962156912211,
                0.06766825531076781,
                0.0,
                0.0,
                1.0,
                0.15290416103196583
            ],
            [
                0.21102351400982255,
                0.05847378571868955,
                0.3377626875527608,
                0.11564072190110067,
                0.0,
                0.0,
                0.15290416103196583,
                1.0
            ]
        ]
    },
    "W11-1310": {
        "input_sentences": [
            "We propose an exemplar-based model which is designed to handle polysemy.",
            "This model is tested for compositionality detection and it is found to outperform existing prototype-based models.",
            "We have participated in the shared task (Biemann and Giesbrecht, 2011) and our best performing exemplar-model is ranked first in two types of evaluations and second in two other evaluations.",
            "In this paper, we highlight the problems of polysemy in word space models of compositionality detection.",
            "Exemplar-Based Word-Space Model for Compositionality Detection: Shared Task System Description",
            "Abstract",
            "Most models represent each word as a single prototype-based vector without addressing polysemy."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.14242575501716828,
                0.1035278478154242,
                0.09256765269503545,
                0.23929062456439046,
                0.0,
                0.1576792812458283
            ],
            [
                0.14242575501716828,
                1.0,
                0.039795697721812656,
                0.24836383725981231,
                0.29935522118777713,
                0.0,
                0.2510758453125056
            ],
            [
                0.1035278478154242,
                0.039795697721812656,
                1.0,
                0.0,
                0.23950191783717967,
                0.0,
                0.0
            ],
            [
                0.09256765269503545,
                0.24836383725981231,
                0.0,
                1.0,
                0.36532528554236937,
                0.0,
                0.23636084851403483
            ],
            [
                0.23929062456439046,
                0.29935522118777713,
                0.23950191783717967,
                0.36532528554236937,
                1.0,
                0.0,
                0.14244395413538444
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.1576792812458283,
                0.2510758453125056,
                0.0,
                0.23636084851403483,
                0.14244395413538444,
                0.0,
                1.0
            ]
        ]
    },
    "A00-2030": {
        "input_sentences": [
            "Since 1995, a few statistical parsing algorithms have demonstrated a breakthrough in parsing accuracy, as measured against the UPenn TREEBANK as a gold standard.",
            "A Novel Use of Statistical Parsing to Extract Information from Text",
            "In this paper we report adapting a lexic al ized, probabilistic context-free parser to information extraction and evaluate this new technique on MUC-7 template elements and template relations.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.21268347212012056,
                0.0,
                0.0
            ],
            [
                0.21268347212012056,
                1.0,
                0.05519964129862864,
                0.0
            ],
            [
                0.0,
                0.05519964129862864,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "W12-3134": {
        "input_sentences": [
            "Joshua 4.0: Packing, PRO, and Paraphrases",
            "The main con",
            "We present Joshua 4.0, the newest version of our open-source decoder for parsing-based statistical machine translation.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.09581273984464105,
                0.0
            ],
            [
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.09581273984464105,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "W04-1506": {
        "input_sentences": [
            "The Dependency syntactic model is applied to establish the dependency-based grammatical relations between the components within the clause.",
            "Such a deep analysis is used to improve the output of the shallow parsing where syntactic structure ambiguity is not fully and explicitly resolved.",
            "Previous to the completion of the grammar for the dependency parsing, the design of the Dependency Structure-based Scheme had to be accomplished; we concentrated on issues that must be resolved by any practical system that uses such models.",
            "Towards A Dependency Parser For Basque",
            "The manually tagged corpus has been used to evaluate the accuracy of the parser.",
            "We present the Dependency Parser, for the linguistic processing of Basque, which can serve as a representative of agglutinative languages that are also characterized by the free order of its constituents.",
            "Abstract",
            "We have evaluated the application of the grammar to corpus, measuring the linking of the verb with its dependents, with satisfactory results.",
            "This scheme was used both to the manual tagging of the corpus and to develop the parser."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.06646766158434347,
                0.19490563731238153,
                0.2123299746149681,
                0.0,
                0.07473384469558378,
                0.0,
                0.0,
                0.0
            ],
            [
                0.06646766158434347,
                1.0,
                0.16390650070343799,
                0.0,
                0.06813145610886143,
                0.0,
                0.0,
                0.0,
                0.06997941984624487
            ],
            [
                0.19490563731238153,
                0.16390650070343799,
                1.0,
                0.17453230791250895,
                0.0,
                0.06143018863703928,
                0.0,
                0.06062567271503728,
                0.08076941908715798
            ],
            [
                0.2123299746149681,
                0.0,
                0.17453230791250895,
                1.0,
                0.1439488657651009,
                0.3519702992057696,
                0.0,
                0.0,
                0.14785326322207504
            ],
            [
                0.0,
                0.06813145610886143,
                0.0,
                0.1439488657651009,
                1.0,
                0.050665725353673724,
                0.0,
                0.07560130944034218,
                0.2800714983916237
            ],
            [
                0.07473384469558378,
                0.0,
                0.06143018863703928,
                0.3519702992057696,
                0.050665725353673724,
                1.0,
                0.0,
                0.0,
                0.05203995729482315
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.06062567271503728,
                0.0,
                0.07560130944034218,
                0.0,
                0.0,
                1.0,
                0.07765188176513191
            ],
            [
                0.0,
                0.06997941984624487,
                0.08076941908715798,
                0.14785326322207504,
                0.2800714983916237,
                0.05203995729482315,
                0.0,
                0.07765188176513191,
                1.0
            ]
        ]
    },
    "P04-1006": {
        "input_sentences": [
            "Attention Shifting For Parsing Speech",
            "This attention-shifting technique provides a six-times increase in speed (measured as the number of parser analyses evaluated) while performing equivalently when used as the first-stage of a multi-stage parsing-based language model.",
            "Our technique applies a probabilistic parser iteratively where on each iteration it focuses on a different subset of the wordlattice.",
            "We present a technique that improves the efficiency of word-lattice parsing as used in speech recognition language modeling.",
            "Abstract",
            "The parser\u2019s attention is shifted towards word-lattice subsets for which there are few or no syntactic analyses posited."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.23673571205965177,
                0.0,
                0.24856154671058772,
                0.0,
                0.11956851162506964
            ],
            [
                0.23673571205965177,
                1.0,
                0.0705518201881785,
                0.16620583337924102,
                0.0,
                0.1360358069787404
            ],
            [
                0.0,
                0.0705518201881785,
                1.0,
                0.052451732967176284,
                0.0,
                0.060629692183762206
            ],
            [
                0.24856154671058772,
                0.16620583337924102,
                0.052451732967176284,
                1.0,
                0.0,
                0.1667820723808189
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.11956851162506964,
                0.1360358069787404,
                0.060629692183762206,
                0.1667820723808189,
                0.0,
                1.0
            ]
        ]
    },
    "P10-1155": {
        "input_sentences": [
            "Our contribution thus lies in finding a convenient middle ground between pure supervised and pure unsupervised WSD.",
            "However such approaches have not proved effective, since they typically do not better Wordnet first sense baseline accuracy.",
            "Accuracy figures close to self domain training lend credence to the viability of our approach.",
            "Finally, our approach is not restricted to any specific set of target words, a departure from a commonly observed practice in domain specific WSD.",
            "We show that if we have ANY sense marked corpora, be it from mixed domain or a specific domain, a small amount of annotation in ANY other domain can deliver the goods almost as if exhaustive sense marking were available in that domain.",
            "In spite of decades of research on word sense disambiguation (WSD), all-words general purpose WSD has remained a distant goal.",
            "Many supervised WSD systems have been built, but the effort of creatthe training corpus sense corpora has always been a matter of concern.",
            "Abstract",
            "All Words Domain Adapted WSD: Finding a Middle Ground between Supervision and Unsupervision",
            "Therefore, attempts have been made to develop unsupervised and knowledge based techniques for WSD which do not need sense marked corpora.",
            "We have tested our approach across Tourism and Health domain corpora, using also the well known mixed domain SemCor corpus.",
            "Our research reported here proposes to stick to the supervised approach, but with far less demand on annotation."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0,
                0.027096527476643813,
                0.0,
                0.05580592045151232,
                0.089378628086321,
                0.0,
                0.3017101854957735,
                0.1090498763343432,
                0.0,
                0.06375825474403
            ],
            [
                0.0,
                1.0,
                0.08974028504522838,
                0.0,
                0.06482859309149283,
                0.0386800306330138,
                0.044080408595596234,
                0.0,
                0.0,
                0.04552523991579468,
                0.0,
                0.0
            ],
            [
                0.0,
                0.08974028504522838,
                1.0,
                0.08223287197614777,
                0.12807962900907519,
                0.0,
                0.08424098743137524,
                0.0,
                0.05189285791696318,
                0.0,
                0.1349166612884673,
                0.058641417306959445
            ],
            [
                0.027096527476643813,
                0.0,
                0.08223287197614777,
                1.0,
                0.20403717898389143,
                0.09829780620103275,
                0.0293961470890394,
                0.0,
                0.14048847388665536,
                0.03035966978223983,
                0.10925030967815741,
                0.047485558414859894
            ],
            [
                0.0,
                0.06482859309149283,
                0.12807962900907519,
                0.20403717898389143,
                1.0,
                0.05340031251523937,
                0.0978627986892229,
                0.0,
                0.14504778654429226,
                0.1618662687898673,
                0.3268671179029049,
                0.06518266607397166
            ],
            [
                0.05580592045151232,
                0.0386800306330138,
                0.0,
                0.09829780620103275,
                0.05340031251523937,
                1.0,
                0.0968517526162548,
                0.0,
                0.1374731167388025,
                0.10002627957855834,
                0.0,
                0.07778257710835897
            ],
            [
                0.089378628086321,
                0.044080408595596234,
                0.08424098743137524,
                0.0293961470890394,
                0.0978627986892229,
                0.0968517526162548,
                1.0,
                0.0,
                0.041111598687947774,
                0.13033900878380153,
                0.12560239102484771,
                0.06916927035065581
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.3017101854957735,
                0.0,
                0.05189285791696318,
                0.14048847388665536,
                0.14504778654429226,
                0.1374731167388025,
                0.041111598687947774,
                0.0,
                1.0,
                0.042459120802652274,
                0.09501268680501822,
                0.0
            ],
            [
                0.1090498763343432,
                0.04552523991579468,
                0.0,
                0.03035966978223983,
                0.1618662687898673,
                0.10002627957855834,
                0.13033900878380153,
                0.0,
                0.042459120802652274,
                1.0,
                0.05007142579923426,
                0.0
            ],
            [
                0.0,
                0.0,
                0.1349166612884673,
                0.10925030967815741,
                0.3268671179029049,
                0.0,
                0.12560239102484771,
                0.0,
                0.09501268680501822,
                0.05007142579923426,
                1.0,
                0.05368444560621506
            ],
            [
                0.06375825474403,
                0.0,
                0.058641417306959445,
                0.047485558414859894,
                0.06518266607397166,
                0.07778257710835897,
                0.06916927035065581,
                0.0,
                0.0,
                0.0,
                0.05368444560621506,
                1.0
            ]
        ]
    },
    "N12-1007": {
        "input_sentences": [
            "Standard entity clustering systems commonly rely on mention (string) matching, syntactic features, and linguistic resources like English WordNet.",
            "Consequently, we develop new methods for clustering text mentions across documents and languages simultaneously, producing cross-lingual entity clusters.",
            "On an Arabic-English corpus that contains seven different text genres, our best model yields a 24.3% F1 gain over the baseline.",
            "When co-referent text mentions appear in different languages, these techniques cannot be easily applied.",
            "Our approach extends standard clustering algorithms with cross-lingual mention and context similarity measures.",
            "Entity Clustering Across Languages",
            "Abstract",
            "Crucially, we do not assume a pre-existing entity list (knowledge base), so entity characteristics are unknown."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.06234765327247069,
                0.05045978588648968,
                0.0,
                0.1596108733100837,
                0.18714583513156666,
                0.0,
                0.06619334939289764
            ],
            [
                0.06234765327247069,
                1.0,
                0.04052766516095266,
                0.18523459350212282,
                0.17215896679745854,
                0.33315009777609667,
                0.0,
                0.07139725761794005
            ],
            [
                0.05045978588648968,
                0.04052766516095266,
                1.0,
                0.12029029721638025,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.18523459350212282,
                0.12029029721638025,
                1.0,
                0.0,
                0.16632280815500608,
                0.0,
                0.0
            ],
            [
                0.1596108733100837,
                0.17215896679745854,
                0.0,
                0.0,
                1.0,
                0.1149917206030925,
                0.0,
                0.0
            ],
            [
                0.18714583513156666,
                0.33315009777609667,
                0.0,
                0.16632280815500608,
                0.1149917206030925,
                1.0,
                0.0,
                0.21430958025990043
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.06619334939289764,
                0.07139725761794005,
                0.0,
                0.0,
                0.0,
                0.21430958025990043,
                0.0,
                1.0
            ]
        ]
    },
    "D07-1026": {
        "input_sentences": [
            "Instance Based Lexical Entailment",
            "We demonstrate the effectiveness of our technique largelysurpassing both the random and most fre quent baselines and outperforming current state-of-the-art unsupervised approaches ona benchmark ontology available in the liter ature.",
            "The approach is fully unsupervised and based on kernel methods.",
            "In this paper we propose an instance based method for lexical entailment and apply it to automatic ontology population from text.",
            "Abstract",
            "Instance Based Lexical Entailment for Ontology Population"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.11736533237485014,
                0.44740520227188313,
                0.0,
                0.7800429793267447
            ],
            [
                0.0,
                1.0,
                0.06854846473934505,
                0.03662634384627384,
                0.0,
                0.06385737633495707
            ],
            [
                0.11736533237485014,
                0.06854846473934505,
                1.0,
                0.052509860270876604,
                0.0,
                0.09155000353535173
            ],
            [
                0.44740520227188313,
                0.03662634384627384,
                0.052509860270876604,
                1.0,
                0.0,
                0.5735648087725097
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.7800429793267447,
                0.06385737633495707,
                0.09155000353535173,
                0.5735648087725097,
                0.0,
                1.0
            ]
        ]
    },
    "P05-1061": {
        "input_sentences": [
            "We evaluate the new method against a standard baseline for extracting genomic variation relations from biomedical text.",
            "complex relation is any relation in which some of the arguments may be be unspecified.",
            "Simple Algorithms For Complex Relation Extraction With Applications To Biomedical IE",
            "Abstract",
            "We present here a simple two-stage method for extracting complex relations between named entities in text.",
            "The first stage creates a graph from pairs of entities that are likely to be related, and the second stage scores maximal cliques in that graph as potential complex relation instances."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.09659496656536723,
                0.0,
                0.33086182423769284,
                0.0
            ],
            [
                0.0,
                1.0,
                0.27879292819665347,
                0.0,
                0.06411348975645113,
                0.14870531685831168
            ],
            [
                0.09659496656536723,
                0.27879292819665347,
                1.0,
                0.0,
                0.16946911700792627,
                0.08565944892116031
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.33086182423769284,
                0.06411348975645113,
                0.16946911700792627,
                0.0,
                1.0,
                0.20906479552219825
            ],
            [
                0.0,
                0.14870531685831168,
                0.08565944892116031,
                0.0,
                0.20906479552219825,
                1.0
            ]
        ]
    },
    "P11-2067": {
        "input_sentences": [
            "Speculations as to cause have suggested the parser, the data, or other factors.",
            "Clause Restructuring For SMT Not Absolutely Helpful",
            "We systematically investigate possible factors to give an initial answer to the question: Under what conditions does this use of syntax help PSMT?",
            "An early work proposing this idea showed improved translation performance, but subsequent work has had mixed results.",
            "Abstract",
            "There are a number of systems that use a syntax-based reordering step prior to phrasebased statistical MT."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.08144334807210837,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.08144334807210837,
                0.0,
                1.0,
                0.0,
                0.0,
                0.12061682783202671
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.12061682783202671,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "N10-1035": {
        "input_sentences": [
            "Efficient Parsing of Well-Nested Linear Context-Free Rewriting Systems",
            "The use of well-nested linear context-free rewriting systems has been empirically motivated for modeling of the syntax of languages with discontinuous constituents or relatively free word order.",
            "Abstract",
            "We present a chart-based parsing algorithm that asymptotically improves the known running time upper bound for this class of rewriting systems.",
            "Our result is obtained through a linear space construction of a binary normal form for the grammar at hand.",
            "Linear Context-Free Rewriting Systems"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.3899263656413529,
                0.0,
                0.1802383229236981,
                0.05512248833033561,
                0.6797836732901541
            ],
            [
                0.3899263656413529,
                1.0,
                0.0,
                0.04948867524055049,
                0.029593285568207332,
                0.45178353923139836
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.1802383229236981,
                0.04948867524055049,
                0.0,
                1.0,
                0.0,
                0.13560344654673268
            ],
            [
                0.05512248833033561,
                0.029593285568207332,
                0.0,
                0.0,
                1.0,
                0.08108827925146052
            ],
            [
                0.6797836732901541,
                0.45178353923139836,
                0.0,
                0.13560344654673268,
                0.08108827925146052,
                1.0
            ]
        ]
    },
    "D07-1122": {
        "input_sentences": [
            "Then we present evaluation results and error analyses focusing on Chinese.",
            "A Two-Stage Parser for Multilingual Dependency Parsing",
            "The parser first identifies dependencies using a deterministic parsing method and then labels those dependencies as a sequence labeling problem.",
            "We describe the features used ineach stage.",
            "We present a two-stage multilingual de pendency parsing system submitted to the Multilingual Track of CoNLL-2007.",
            "For four languages with different values of ROOT, we design some spe cial features for the ROOT labeler.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0,
                0.0,
                0.08665635549866692,
                0.0,
                0.0
            ],
            [
                0.0,
                1.0,
                0.17844733462538206,
                0.15314452174471074,
                0.42163781359175756,
                0.0,
                0.0
            ],
            [
                0.0,
                0.17844733462538206,
                1.0,
                0.0,
                0.045083185753217195,
                0.0,
                0.0
            ],
            [
                0.0,
                0.15314452174471074,
                0.0,
                1.0,
                0.09164609671121099,
                0.112795770076881,
                0.0
            ],
            [
                0.08665635549866692,
                0.42163781359175756,
                0.045083185753217195,
                0.09164609671121099,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.112795770076881,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P14-1078": {
        "input_sentences": [
            "Relation Extraction with Manifold Models",
            "Medical Relation Extraction with Manifold Models",
            "In this paper, we present a manifold model for medical relation extraction.",
            "Abstract",
            "Our model is built upon a medical corpus containing 80M sentences (11 gigabyte text) and designed to accurately and efficiently detect the key medical relations that can facilitate clinical decision making.",
            "Effectiveness of our model is demonstrated both theoretically with a proof to show that the solution is a closed-form solution and experimentally with positive results in experiments.",
            "Our approach integrates domain specific parsing and typing systems, and can utilize labeled as well as unlabeled examples.",
            "To provide users with more flexibility, we also take label weight into consideration."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.9015750672636621,
                0.4846129411178613,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.9015750672636621,
                1.0,
                0.582553259980236,
                0.0,
                0.13781649408064703,
                0.0,
                0.0,
                0.0
            ],
            [
                0.4846129411178613,
                0.582553259980236,
                1.0,
                0.0,
                0.16086053220160193,
                0.06388398970868361,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.13781649408064703,
                0.16086053220160193,
                0.0,
                1.0,
                0.030226480888060292,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.06388398970868361,
                0.0,
                0.030226480888060292,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "C10-1135": {
        "input_sentences": [
            "Joint Tokenization and Translation",
            "Interestingly, as a tokenizer, our joint de coder achieves significant improvements over monolingual Chinese tokenizers.",
            "Taking a sequence of atomic units that can be combined to form words in different ways as input, our joint decoder produces a tokenization on the source side and a translation on thetarget side simultaneously.",
            "By integrat ing tokenization and translation features in a discriminative framework, our jointdecoder outperforms the baseline trans lation systems using 1-best tokenizationsand lattices significantly on both ChineseEnglish and Korean-Chinese tasks.",
            "While using lattices to offer more alternatives to translation systems have elegantly alleviated this prob lem, we take a further step to tokenize and translate jointly.",
            "Abstract",
            "As tokenization is usually ambiguous for many natural languages such as Chineseand Korean, tokenization errors might po tentially introduce translation mistakes fortranslation systems that rely on 1-best tokenizations."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.1532403130783967,
                0.2694276088933261,
                0.14344049373891105,
                0.0770235670463815,
                0.0,
                0.23722522559572537
            ],
            [
                0.1532403130783967,
                1.0,
                0.04128717113877712,
                0.05266814465095064,
                0.0,
                0.0,
                0.0
            ],
            [
                0.2694276088933261,
                0.04128717113877712,
                1.0,
                0.038646829246552925,
                0.02075227549774136,
                0.0,
                0.06391502530143615
            ],
            [
                0.14344049373891105,
                0.05266814465095064,
                0.038646829246552925,
                1.0,
                0.14431951133332674,
                0.0,
                0.1663014165171296
            ],
            [
                0.0770235670463815,
                0.0,
                0.02075227549774136,
                0.14431951133332674,
                1.0,
                0.0,
                0.05574790285309895
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.23722522559572537,
                0.0,
                0.06391502530143615,
                0.1663014165171296,
                0.05574790285309895,
                0.0,
                1.0
            ]
        ]
    },
    "D07-1030": {
        "input_sentences": [
            "We also interpolate the model trained on a real bilingual corpus and the models trained on the synthetic bilingual corpora.",
            "This paper proposes a method using the ex isting Rule-based Machine Translation (RBMT) system as a black box to produce synthetic bilingual corpus, which will be used as training data for the Statistical Ma chine Translation (SMT) system.",
            "We use the existing RBMT system to translate the monolingual corpus into synthetic bilingual corpus.",
            "Using RBMT Systems to Produce Bilingual Corpus for SMT",
            "The interpolated model achieves an abso lute improvement of 0.0245 BLEU score (13.1% relative) as compared with the in dividual model trained on the real bilingual corpus.",
            "With the synthetic bilingual corpus, we can build an SMT system even if there is no real bilingual corpus.",
            "Abstract",
            "In our experi ments using BLEU as a metric, the system achieves a relative improvement of 11.7% over the best RBMT system that is used to produce the synthetic bilingual corpora."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.07145588475044208,
                0.17524589575995328,
                0.12316760494894011,
                0.35768080290382237,
                0.36786819078708854,
                0.0,
                0.14882191892398927
            ],
            [
                0.07145588475044208,
                1.0,
                0.12289097241642061,
                0.276262219830118,
                0.02423705167464986,
                0.1797506077706563,
                0.0,
                0.16827200351357144
            ],
            [
                0.17524589575995328,
                0.12289097241642061,
                1.0,
                0.24472821928760635,
                0.07345877166237355,
                0.345328104725285,
                0.0,
                0.11269863862022629
            ],
            [
                0.12316760494894011,
                0.276262219830118,
                0.24472821928760635,
                1.0,
                0.062079790067758406,
                0.37685661536350357,
                0.0,
                0.266446534779969
            ],
            [
                0.35768080290382237,
                0.02423705167464986,
                0.07345877166237355,
                0.062079790067758406,
                1.0,
                0.17821371169492076,
                0.0,
                0.2301341581470188
            ],
            [
                0.36786819078708854,
                0.1797506077706563,
                0.345328104725285,
                0.37685661536350357,
                0.17821371169492076,
                1.0,
                0.0,
                0.10468391293354411
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.14882191892398927,
                0.16827200351357144,
                0.11269863862022629,
                0.266446534779969,
                0.2301341581470188,
                0.10468391293354411,
                0.0,
                1.0
            ]
        ]
    },
    "P11-1061": {
        "input_sentences": [
            "We use graph-based label propagation for cross-lingual knowledge transfer and use the projected labels as features in an unsupervised model (Berg- Kirkpatrick et al., 2010).",
            "We describe a novel approach for inducing unsupervised part-of-speech taggers for languages that have no labeled training data, but have translated text in a resource-rich language.",
            "Our method does not assume any knowledge about the target language (in particular no tagging dictionary is assumed), making it applicable to a wide array of resource-poor languages.",
            "Abstract",
            "Unsupervised Part-of-Speech Tagging with Bilingual Graph-Based Projections",
            "Across eight European languages, our approach results in an average absolute improvement of 10.4% over a state-of-the-art baseline, and 16.7% over vanilla hidden Markov models induced with the Expectation Maximization algorithm."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.029767875056616735,
                0.03813501822591,
                0.0,
                0.17722115273305802,
                0.0
            ],
            [
                0.029767875056616735,
                1.0,
                0.13169363614263954,
                0.0,
                0.14243875773907877,
                0.07399922069329141
            ],
            [
                0.03813501822591,
                0.13169363614263954,
                1.0,
                0.0,
                0.07593843807864022,
                0.028120434072375446
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.17722115273305802,
                0.14243875773907877,
                0.07593843807864022,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.07399922069329141,
                0.028120434072375446,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "W06-2932": {
        "input_sentences": [
            "The second stage takes the output from the first and labels all the edges in the dependency graph with appropriate syntactic categories using a globally trained sequence classifier over components of the graph.",
            "Multilingual Dependency Analysis with a Two-Stage Discriminative Parser",
            "We report results on the CoNLL-X shared task (Buchholz et al., 2006) data sets and present an error analysis.",
            "The first stage based on the unlabeled dependency parsing models described by McDonald and Pereira (2006) augmented with morphological features for a subset of the languages.",
            "Abstract",
            "present a two-stage multilingual pendency parser and evaluate it on 13 diverse languages."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0976442128844634,
                0.0,
                0.052771583978781796,
                0.0,
                0.03056413098443932
            ],
            [
                0.0976442128844634,
                1.0,
                0.09500267527973784,
                0.11673273974410864,
                0.0,
                0.32594717748762453
            ],
            [
                0.0,
                0.09500267527973784,
                1.0,
                0.051343971226085174,
                0.0,
                0.07023371956586016
            ],
            [
                0.052771583978781796,
                0.11673273974410864,
                0.051343971226085174,
                1.0,
                0.0,
                0.10634825651019743
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.03056413098443932,
                0.32594717748762453,
                0.07023371956586016,
                0.10634825651019743,
                0.0,
                1.0
            ]
        ]
    },
    "D12-1129": {
        "input_sentences": [
            "The acquired glosses are then used as the sense inventory for fullyunsupervised domain WSD.",
            "Our experiments, on new and gold-standard datasets, show that our wide-coverage framework enables highperformance results on dozens of domains at a coarse and fine-grained level.",
            "We present a new minimally-supervised framework for performing domain-driven Word Sense Disambiguation (WSD).",
            "A New Minimally-Supervised Framework for Domain Word Sense Disambiguation",
            "Glossaries for several domains are iteratively acquired from the Web by means of a bootstrapping technique.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.2257733282778034,
                0.1778860925476825,
                0.09882405606522016,
                0.0
            ],
            [
                0.0,
                1.0,
                0.08426432362980506,
                0.11296325392873986,
                0.0627563784199212,
                0.0
            ],
            [
                0.2257733282778034,
                0.08426432362980506,
                1.0,
                0.7459445501008778,
                0.0,
                0.0
            ],
            [
                0.1778860925476825,
                0.11296325392873986,
                0.7459445501008778,
                1.0,
                0.0,
                0.0
            ],
            [
                0.09882405606522016,
                0.0627563784199212,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "D11-1039": {
        "input_sentences": [
            "Instead, we model meaning with latent variables, and introduce a loss function to measure how well potential meanings match the conversation.",
            "Experiments on DARPA Communicator conversational logs demonstrate effective learning, despite requiring no explicit meaning annotations.",
            "We demonstrate learning without any explicit annotation of the meanings of user utterances.",
            "Conversations provide rich opportunities for interactive, continuous learning.",
            "When something goes wrong, a system can ask for clarification, rewording, or otherwise redirect the interaction to achieve its goals.",
            "Bootstrapping Semantic Parsers from Conversations",
            "Abstract",
            "This loss drives the overall learning approach, which induces a weighted CCG grammar that could be used to automatically bootstrap the semantic analysis component in a complete dialog system.",
            "In this paper, we present an approach for using conversational interactions of this type to induce semantic parsers."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.06097585719412181,
                0.08682102967552979,
                0.0,
                0.0,
                0.0,
                0.0,
                0.05219501452842094,
                0.0
            ],
            [
                0.06097585719412181,
                1.0,
                0.23335430744010724,
                0.050624512432095356,
                0.0,
                0.0,
                0.0,
                0.03196455353824917,
                0.0721147399967092
            ],
            [
                0.08682102967552979,
                0.23335430744010724,
                1.0,
                0.07208217314901301,
                0.0,
                0.0,
                0.0,
                0.04551302071038251,
                0.0
            ],
            [
                0.0,
                0.050624512432095356,
                0.07208217314901301,
                1.0,
                0.0,
                0.16724133387954587,
                0.0,
                0.043334317605004016,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.16724133387954587,
                0.0,
                1.0,
                0.0,
                0.07982919461584698,
                0.2468899149563858
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.05219501452842094,
                0.03196455353824917,
                0.04551302071038251,
                0.043334317605004016,
                0.0,
                0.07982919461584698,
                0.0,
                1.0,
                0.10839636743737885
            ],
            [
                0.0,
                0.0721147399967092,
                0.0,
                0.0,
                0.0,
                0.2468899149563858,
                0.0,
                0.10839636743737885,
                1.0
            ]
        ]
    },
    "P11-1060": {
        "input_sentences": [
            "On two stansemantic parsing benchmarks our system obtains the highest published accuracies, despite requiring no annotated logical forms.",
            "Learning Dependency-Based Compositional Semantics",
            "In tackling this challenging learning problem, we introduce a new semantic representation which highlights a parallel between dependency syntax and efficient evaluation of logical forms.",
            "Compositional question answering begins by mapping questions to logical forms, but training a semantic parser to perform this mapping typically requires the costly annotation of the target logical forms.",
            "In this paper, we learn to map questions to answers via latent logical forms, which are induced automatically from question-answer pairs.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.05808337155681906,
                0.09743181104032199,
                0.06472779823155181,
                0.0
            ],
            [
                0.0,
                1.0,
                0.181138822410469,
                0.07596271981172245,
                0.0,
                0.0
            ],
            [
                0.05808337155681906,
                0.181138822410469,
                1.0,
                0.12715772395210725,
                0.05716975546285531,
                0.0
            ],
            [
                0.09743181104032199,
                0.07596271981172245,
                0.12715772395210725,
                1.0,
                0.1875085053728042,
                0.0
            ],
            [
                0.06472779823155181,
                0.0,
                0.05716975546285531,
                0.1875085053728042,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "W07-1712": {
        "input_sentences": [
            "We show that it is feasible to boost performance by considering several heuristics and patterns acquired from the Web data.",
            "In this paper, we discuss named entity recognition for Ukrainian language, which is a Slavonic language with a rich morphology.",
            "Named Entity Recognition for Ukrainian: A Resource-Light Approach",
            "The approach we follow uses a restricted number of features.",
            "Abstract",
            "Kruislaan 419, 1098VA the katrenko@science.uva.nl Pieter HCSL, University of Kruislaan 419, 1098VA the pitera@science.uva.nl Abstract Named entity recognition (NER) is a subtask of information extraction (IE) which can be used further on for different purposes."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                1.0,
                0.2894979496097446,
                0.0,
                0.0,
                0.06987810201070326
            ],
            [
                0.0,
                0.2894979496097446,
                1.0,
                0.12909823740658932,
                0.0,
                0.1065040256857209
            ],
            [
                0.0,
                0.0,
                0.12909823740658932,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.13283122300642156
            ],
            [
                0.0,
                0.06987810201070326,
                0.1065040256857209,
                0.0,
                0.13283122300642156,
                1.0
            ]
        ]
    },
    "D10-1025": {
        "input_sentences": [
            "The OPCA method is shown to perform best.",
            "Both of these variants start with a basic model of documents (PCA and PLSA).",
            "We use discriminative training to create a projection of documents from multiple languages into a single translingual vector space.",
            "The two discriminative variants, OPCA and CPLSA, significantly outperform their corresponding baselines.",
            "Translingual Document Representations from Discriminative Projections",
            "Representing documents by vectors that are independent of language enhances machine translation and multilingual text categorization.",
            "The largest differences in performance are observed on the task of retrieval when the documents are only comparable and not parallel.",
            "Abstract",
            "We explore two variants to create these projections: Oriented Principal Component Analysis (OPCA) and Coupled Probabilistic Latent Semantic Analysis (CPLSA).",
            "We evaluate these algorithms on two tasks: parallel document retrieval for Wikipedia and Europarl documents, and cross-lingual text classification on Reuters.",
            "Each model is then made discriminative by encouraging comparable document pairs to have similar vector representations."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0,
                0.10526845390267081,
                0.0,
                0.0,
                0.0,
                0.0,
                0.06756570824571763,
                0.0,
                0.0
            ],
            [
                0.0,
                1.0,
                0.04884859070110403,
                0.09451032022268739,
                0.0,
                0.04863659780940353,
                0.056213235916515183,
                0.0,
                0.06066068689751535,
                0.04438679226211262,
                0.11654801310615485
            ],
            [
                0.0,
                0.04884859070110403,
                1.0,
                0.05677266826327667,
                0.2085528481298521,
                0.036582048753306146,
                0.04228082204552288,
                0.0,
                0.058992359502842685,
                0.033385554740046675,
                0.14180952921521559
            ],
            [
                0.10526845390267081,
                0.09451032022268739,
                0.05677266826327667,
                1.0,
                0.10028690881973341,
                0.0,
                0.0,
                0.0,
                0.18921267671878295,
                0.0,
                0.068192016813507
            ],
            [
                0.0,
                0.0,
                0.2085528481298521,
                0.10028690881973341,
                1.0,
                0.0,
                0.0,
                0.0,
                0.10420791482068457,
                0.09060215665712985,
                0.3702668234152687
            ],
            [
                0.0,
                0.04863659780940353,
                0.036582048753306146,
                0.0,
                0.0,
                1.0,
                0.04209733192635548,
                0.0,
                0.0,
                0.09926870018873032,
                0.0
            ],
            [
                0.0,
                0.056213235916515183,
                0.04228082204552288,
                0.0,
                0.0,
                0.04209733192635548,
                1.0,
                0.0,
                0.0,
                0.1910467552660308,
                0.10087795228428624
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.06756570824571763,
                0.06066068689751535,
                0.058992359502842685,
                0.18921267671878295,
                0.10420791482068457,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.04438679226211262,
                0.033385554740046675,
                0.0,
                0.09060215665712985,
                0.09926870018873032,
                0.1910467552660308,
                0.0,
                0.0,
                1.0,
                0.06160668289426111
            ],
            [
                0.0,
                0.11654801310615485,
                0.14180952921521559,
                0.068192016813507,
                0.3702668234152687,
                0.0,
                0.10087795228428624,
                0.0,
                0.0,
                0.06160668289426111,
                1.0
            ]
        ]
    },
    "D07-1066": {
        "input_sentences": [
            "The results of the ex periments show that, contrary to Ku?bler etal.",
            "We use thePARSEVAL metric, the Leaf-Ancestor metric as well as a dependency-based evaluation, and present novel approaches measur ing the effect of controlled error insertion on treebank trees and parser output.",
            "Recent studies focussed on the question whether less-configurational languages like German are harder to parse than English, or whether the lower parsing scores are an artefact of treebank encoding schemes and data structures, as claimed by Ku?bler et al(2006).",
            "Treebank Annotation Schemes and Parser Evaluation for German",
            "(2006), the question whether or not Ger man is harder to parse than English remains undecided.",
            "Abstract",
            "Wealso provide extensive past-parsing crosstreebank conversion.",
            "This claim is based on the assumption that PARSEVAL metrics fully re flect parse quality across treebank encodingschemes.",
            "In this paper we present new ex periments to test this claim."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.12465329568975456,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.24374324412260565
            ],
            [
                0.0,
                1.0,
                0.018856216174169486,
                0.18936472146247565,
                0.0,
                0.0,
                0.0,
                0.0784500094968681,
                0.062475020798521644
            ],
            [
                0.12465329568975456,
                0.018856216174169486,
                1.0,
                0.1889149960733471,
                0.2637650298807632,
                0.0,
                0.05819842740786964,
                0.06625371965465406,
                0.0
            ],
            [
                0.0,
                0.18936472146247565,
                0.1889149960733471,
                1.0,
                0.0,
                0.0,
                0.0,
                0.066464093158657,
                0.0
            ],
            [
                0.0,
                0.0,
                0.2637650298807632,
                0.0,
                1.0,
                0.0,
                0.0,
                0.06473802515255109,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.05819842740786964,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0784500094968681,
                0.06625371965465406,
                0.066464093158657,
                0.06473802515255109,
                0.0,
                0.0,
                1.0,
                0.09623780061216919
            ],
            [
                0.24374324412260565,
                0.062475020798521644,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.09623780061216919,
                1.0
            ]
        ]
    },
    "W06-3119": {
        "input_sentences": [
            "Syntax Augmented Machine Translation Via Chart Parsing",
            "Considering phrases that correspond to syntactic categories in the parse trees we develop techniques to augment (declare a syntactically motivated category for a phrase pair) and generalize (form mixed terminal and nonterminal phrases) the phrase table into a synchronous bilingual grammar.",
            "We use a target language parser to generate parse trees for each sentence on the target side of the bilingual training corpus, matching them with phrase table lattices built for the corresponding source sentence.",
            "We present results on the French-to-English task for this workshop, representing significant improvements over the workshop\u2019s baseline system.",
            "Abstract",
            "Our translation system is available open-source under the GNU General",
            "We present translation results on the shared task \u201dExploiting Parallel Texts for Statistical Machine Translation\u201d generated by a chart parsing decoder operating on phrase tables augmented and generalized with target language syntactic categories."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.1070457964411118,
                0.4067168198606376
            ],
            [
                0.0,
                1.0,
                0.15992627412049568,
                0.0,
                0.0,
                0.0,
                0.10210544908686837
            ],
            [
                0.0,
                0.15992627412049568,
                1.0,
                0.0,
                0.0,
                0.06695902729809794,
                0.12697448880933024
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.13274058189231178
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.1070457964411118,
                0.0,
                0.06695902729809794,
                0.0,
                0.0,
                1.0,
                0.09856495701393257
            ],
            [
                0.4067168198606376,
                0.10210544908686837,
                0.12697448880933024,
                0.13274058189231178,
                0.0,
                0.09856495701393257,
                1.0
            ]
        ]
    },
    "D07-1119": {
        "input_sentences": [
            "DeSR implements an incre mental deterministic Shift/Reduce parsing algorithm, using specific rules to handle non-projective dependencies.",
            "For the multi lingual track we adopted a second order averaged perceptron and performed feature selection to tune a feature model for each language.",
            "Multilingual Dependency Parsing and Domain Adaptation using DeSR",
            "Abstract",
            "We describe our experiments using the DeSR parser in the multilingual and do main adaptation tracks of the CoNLL 2007 shared task.",
            "For the domain adaptation track we applied a tree revision method which learns how to correct the mistakes made by the base parser on the adaptation domain."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.20201771013882103,
                0.0,
                0.08012477440813684,
                0.0
            ],
            [
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.04408892510324349
            ],
            [
                0.20201771013882103,
                0.0,
                1.0,
                0.0,
                0.31965760336780896,
                0.29216706617197713
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.08012477440813684,
                0.0,
                0.31965760336780896,
                0.0,
                1.0,
                0.13960924640846678
            ],
            [
                0.0,
                0.04408892510324349,
                0.29216706617197713,
                0.0,
                0.13960924640846678,
                1.0
            ]
        ]
    },
    "C02-1154": {
        "input_sentences": [
            "The algorithm makes use of competing evidence to boost the learning of several categories of names simultaneously.",
            "We present results of the algorithm on a large corpus.",
            "Unsupervised Learning Of Generalized Names",
            "Nomen uses a novel form of bootstrap ping to grow sets of textual instances and of their contextual patterns.",
            "Examples of these are names of diseases and infectious agents, such as bacteria and viruses.",
            "We present an algorithm, Nomen, for learning generalized names in text.",
            "Abstract",
            "These names exhibitcertain properties that make their identi ca tion more complex than that of regular propernames.",
            "We also investigate the relative merits of several evaluation strategies."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0901573640536203,
                0.18741332523381704,
                0.0,
                0.045915272386412034,
                0.2284038592293916,
                0.0,
                0.03782472488960719,
                0.0
            ],
            [
                0.0901573640536203,
                1.0,
                0.0,
                0.0,
                0.0,
                0.2846511994536956,
                0.0,
                0.0,
                0.0
            ],
            [
                0.18741332523381704,
                0.0,
                1.0,
                0.0,
                0.08279044279147635,
                0.4625460326198179,
                0.0,
                0.06820226820658229,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0976750065781454,
                0.0,
                0.0,
                0.0
            ],
            [
                0.045915272386412034,
                0.0,
                0.08279044279147635,
                0.0,
                1.0,
                0.06241079796383836,
                0.0,
                0.043590455220157406,
                0.0
            ],
            [
                0.2284038592293916,
                0.2846511994536956,
                0.4625460326198179,
                0.0976750065781454,
                0.06241079796383836,
                1.0,
                0.0,
                0.05141363952403883,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.03782472488960719,
                0.0,
                0.06820226820658229,
                0.0,
                0.043590455220157406,
                0.05141363952403883,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "W11-0131": {
        "input_sentences": [
            "Evaluations show that using relationally-clustered headwords as a semantic space in this framework improves on a syntax-only model in perplexity and parsing accuracy.",
            "As such, syntax and semantics are fully interactive; composition of semantic vectors necessarily produces a hypothetical syntactic parse.",
            "Distributed models of semantics assume that word meanings can be discovered from \u201cthe company they keep.\u201d Many such approaches learn semantics from large corpora, with each document considered to be unstructured bags of words, ignoring syntax and compositionality within a docu- In contrast, this paper proposes a semantic framework, in which semantic vectors are defined and composed in syntactic context.",
            "Abstract",
            "Structured Composition of Semantic Vectors"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.07178879245877604,
                0.08829086321297627,
                0.0,
                0.05793998885539891
            ],
            [
                0.07178879245877604,
                1.0,
                0.20646509079773384,
                0.0,
                0.30100717674366195
            ],
            [
                0.08829086321297627,
                0.20646509079773384,
                1.0,
                0.0,
                0.12501026304708251
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.05793998885539891,
                0.30100717674366195,
                0.12501026304708251,
                0.0,
                1.0
            ]
        ]
    },
    "A97-1014": {
        "input_sentences": [
            "An Annotation Scheme for Free Word Order Languages",
            "Since the requirements for such a formalism differ from those posited for configurational languages, several features have been added, influencing the architecture of the scheme.",
            "We describe an annotation scheme and a tool developed for creating linguistically annotated corpora for non-configurational languages.",
            "The resulting scheme reflects a stratificational notion of language, and makes only minimal assumpabout the interrelation of the particu- \u2022lar representational strata.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.11876052256333934,
                0.22387863664261495,
                0.041384884321766735,
                0.0
            ],
            [
                0.11876052256333934,
                1.0,
                0.1533259351413394,
                0.02834292804578929,
                0.0
            ],
            [
                0.22387863664261495,
                0.1533259351413394,
                1.0,
                0.02888333946430978,
                0.0
            ],
            [
                0.041384884321766735,
                0.02834292804578929,
                0.02888333946430978,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "W10-1403": {
        "input_sentences": [
            "All the experiments were done with two data-driven parsers, MaltParser and MSTParser, on a part of multi-layered and multi-representational Hindi Treebank which is under development.",
            "Further, we compare the results of various experiments based on various criterions and do some error analysis.",
            "Two Methods to Incorporate &rsquo;Local Morphosyntactic&rsquo; Features in Hindi Dependency Parsing",
            "We first explore which information provided by the shallow parser is most beneficial and show that local morphosyntactic features in the form of chunk type, head/non-head information, chunk boundary information, distance to the end of the chunk and suffix concatenation are very crucial in Hindi dependency parsing.",
            "This paper is also the first attempt at complete sentence level parsing for Hindi.",
            "In this paper we explore two strategies to incorporate local morphosyntactic features in Hindi dependency parsing.",
            "These features are obtained using a shallow parser.",
            "Abstract",
            "We then investigate the best way to incorporate this information during dependency parsing."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.05814854226158433,
                0.031366288776516156,
                0.015085016480587571,
                0.038545423416096354,
                0.0379396527227308,
                0.0,
                0.0,
                0.0
            ],
            [
                0.05814854226158433,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.031366288776516156,
                0.0,
                1.0,
                0.15326801746335666,
                0.10133611381097317,
                0.465709796506648,
                0.07527246206287576,
                0.0,
                0.20301229130393805
            ],
            [
                0.015085016480587571,
                0.0,
                0.15326801746335666,
                1.0,
                0.04873566515340281,
                0.23642929717533287,
                0.1588802972196077,
                0.0,
                0.2182776060511059
            ],
            [
                0.038545423416096354,
                0.0,
                0.10133611381097317,
                0.04873566515340281,
                1.0,
                0.2529941150676302,
                0.0,
                0.0,
                0.06455318738222236
            ],
            [
                0.0379396527227308,
                0.0,
                0.465709796506648,
                0.23642929717533287,
                0.2529941150676302,
                1.0,
                0.09104714588958873,
                0.0,
                0.24555712935614807
            ],
            [
                0.0,
                0.0,
                0.07527246206287576,
                0.1588802972196077,
                0.0,
                0.09104714588958873,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.20301229130393805,
                0.2182776060511059,
                0.06455318738222236,
                0.24555712935614807,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "W06-2207": {
        "input_sentences": [
            "A Hybrid Approach For The Acquisition Of Information Extraction Patterns",
            "We show that the combination of the two methods always outperforms the decision list learner alone.",
            "In this paper we present a hybrid approach for the acquisition of syntacticosemantic patterns from raw text.",
            "Our approach co-trains a decision list learner whose feature space covers the set of all syntactico-semantic patterns with an Expectation Maximization clustering algorithm that uses the text words as attributes.",
            "Abstract",
            "Furthermore, using a modular architecture we investigate several algorithms for pattern ranking, the most important component of the decision list learner."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.4204070902332055,
                0.11184679172329436,
                0.0,
                0.0
            ],
            [
                0.0,
                1.0,
                0.0,
                0.16520927315758088,
                0.0,
                0.20182005259661406
            ],
            [
                0.4204070902332055,
                0.0,
                1.0,
                0.14947085335172045,
                0.0,
                0.0
            ],
            [
                0.11184679172329436,
                0.16520927315758088,
                0.14947085335172045,
                1.0,
                0.0,
                0.10290813642323277
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.20182005259661406,
                0.0,
                0.10290813642323277,
                0.0,
                1.0
            ]
        ]
    },
    "W09-0402": {
        "input_sentences": [
            "We explored novel automatic evaluation measures for machine translation output oriented to the syntactic structure of the the on the detailed tags as well as the precision, recall and F-measure obtained We also introduced Fbased on both word and grams.",
            "Syntax-Oriented Evaluation Measures for Machine Translation Output",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.38191611176970136,
                0.0
            ],
            [
                0.38191611176970136,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "C04-1180": {
        "input_sentences": [
            "Unlike the dependency structures returned by the parser itself, these can be used directly for semantic in terpretation.",
            "Abstract",
            "Wide-Coverage Semantic Representations From A CCG Parser",
            "We demonstrate that well-formed semantic representations can be produced for over 97% of the sentences in unseen WSJ text.We believe this is a major step towards wide coverage semantic interpretation, one of the key objectives of the field of NLP.",
            "This paper shows how to construct semantic representations from the derivations producedby a wide-coverage CCG parser."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.16536459085404295,
                0.052796769408046736,
                0.09864755256878013
            ],
            [
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.16536459085404295,
                0.0,
                1.0,
                0.2761632032390249,
                0.5965458025766242
            ],
            [
                0.052796769408046736,
                0.0,
                0.2761632032390249,
                1.0,
                0.16474399971835543
            ],
            [
                0.09864755256878013,
                0.0,
                0.5965458025766242,
                0.16474399971835543,
                1.0
            ]
        ]
    },
    "D12-1133": {
        "input_sentences": [
            "A Transition-Based System for Joint Part-of-Speech Tagging and Labeled Non-Projective Dependency Parsing",
            "We present a transitionbased system for joint part-of-speech tagging and labeled dependency parsing with nonprojective trees.",
            "Most current dependency parsers presuppose that input words have been morphologically disambiguated using a part-of-speech tagger before parsing begins.",
            "Experimental evaluation on Chinese, Czech, English and German shows consistent improvements in both tagging and parsing accuracy when compared to a pipeline system, which lead to improved state-of-theart results for all languages.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.42568122396878877,
                0.13741352649104213,
                0.06699485318218065,
                0.0
            ],
            [
                0.42568122396878877,
                1.0,
                0.13741352649104213,
                0.06699485318218065,
                0.0
            ],
            [
                0.13741352649104213,
                0.13741352649104213,
                1.0,
                0.021879298147270645,
                0.0
            ],
            [
                0.06699485318218065,
                0.06699485318218065,
                0.021879298147270645,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P14-1126": {
        "input_sentences": [
            "We obtain stateof-the art performance of all the three data sets when compared with previously studied unsupervised and projected parsing systems.",
            "We perform experiments on three Data sets \u2014 Version 1.0 and version 2.0 of Google Universal Dependency Treebanks and Treebanks from CoNLL shared-tasks, across ten languages.",
            "We present a novel approach for inducing unsupervised dependency parsers for languages that have no labeled training data, but have translated text in a resourcerich language.",
            "Unsupervised Dependency Parsing with Transferring Distribution via Parallel Guidance and Entropy Regularization",
            "Our method can be used as a purely monolingual dependency parser, requiring no human translations for the test data, thus making it applicable to a wide range of resource-poor languages.",
            "Abstract",
            "We train probabilistic parsing models for resource-poor languages by transferring cross-lingual knowledge from resource-rich language with entropy regularization."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.07826987106732412,
                0.07555106302228452,
                0.11909545045072263,
                0.02894756796202898,
                0.0,
                0.04030828824742507
            ],
            [
                0.07826987106732412,
                1.0,
                0.0790319716211499,
                0.03641518043396105,
                0.07045360772938294,
                0.0,
                0.024649700453862968
            ],
            [
                0.07555106302228452,
                0.0790319716211499,
                1.0,
                0.09897449708224025,
                0.08230290353824653,
                0.0,
                0.0810808779084621
            ],
            [
                0.11909545045072263,
                0.03641518043396105,
                0.09897449708224025,
                1.0,
                0.037922311959405625,
                0.0,
                0.2696270710081269
            ],
            [
                0.02894756796202898,
                0.07045360772938294,
                0.08230290353824653,
                0.037922311959405625,
                1.0,
                0.0,
                0.16550058152222671
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.04030828824742507,
                0.024649700453862968,
                0.0810808779084621,
                0.2696270710081269,
                0.16550058152222671,
                0.0,
                1.0
            ]
        ]
    },
    "P12-3012": {
        "input_sentences": [
            "Our aim is to provide the research community with easy-to-use tools to perform multilingual lexical semantic analysis and foster further research in this direction.",
            "In this paper we present an API for programmatic access to BabelNet \u2013 a wide-coverage multilingual lexical knowledge base \u2013 and multilingual knowledge-rich Word Sense Disambiguation (WSD).",
            "Multilingual WSD with Just a Few Lines of Code: the BabelNet API",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.08205924893266757,
                0.04431832591036525,
                0.0
            ],
            [
                0.08205924893266757,
                1.0,
                0.26691664308354,
                0.0
            ],
            [
                0.04431832591036525,
                0.26691664308354,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "W11-2205": {
        "input_sentences": [
            "Inwe argue that the rarely used evaluation is more appropriate and more informative, as it takes into account the way these methods are likely to be applied.",
            "Finally, bearing the issue of evaluation in mind, we propose directions for future work in unsupervised natural language processing.",
            "Using unsupervised part-of-speech tagging as our case study, we discuss the reasons that render this evaluation paradigm unsuitable for the evaluation of unsupervised learning methods.",
            "The primary advantage of these methods is that they do not require annotated data to learn a model.",
            "Evaluating unsupervised learning for natural language processing tasks",
            "However, this advantage makes them difficult to evaluate against a manually labeled gold standard.",
            "The development of unsupervised learning methods for natural language processing tasks has become an important and popular area of research.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.04675253793303023,
                0.10964966235679999,
                0.043681114170067224,
                0.0,
                0.0,
                0.03970512208597641,
                0.0
            ],
            [
                0.04675253793303023,
                1.0,
                0.1493404202953002,
                0.0,
                0.29702317925409344,
                0.0,
                0.20750098405686662,
                0.0
            ],
            [
                0.10964966235679999,
                0.1493404202953002,
                1.0,
                0.03944312244655625,
                0.1694013622336534,
                0.0,
                0.1541970144068631,
                0.0
            ],
            [
                0.043681114170067224,
                0.0,
                0.03944312244655625,
                1.0,
                0.0,
                0.0949493278376059,
                0.0514413332406072,
                0.0
            ],
            [
                0.0,
                0.29702317925409344,
                0.1694013622336534,
                0.0,
                1.0,
                0.0,
                0.5321279871639477,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0949493278376059,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.03970512208597641,
                0.20750098405686662,
                0.1541970144068631,
                0.0514413332406072,
                0.5321279871639477,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "W12-3154": {
        "input_sentences": [
            "Analysing the Effect of Out-of-Domain Data on SMT Systems",
            "Nevertheless, it is frequently necessary to supplement scarce in-domain training data with out-of-domain data.",
            "In this paper, we first try to relate the effect of the outof-domain data on translation performance to measures of corpus similarity, then we separately analyse the effect of adding the outof-domain data at different parts of the training pipeline (alignment, phrase extraction, and phrase scoring).",
            "In statistical machine translation (SMT), it is known that performance declines when the training data is in a different domain from the test data.",
            "Abstract",
            "Through experiments in 2 domains and 8 language pairs it is shown that the out-of-domain data improves coverage and translation of rare words, but may degrade the translation quality for more common words."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.20807764281407387,
                0.22569597381032994,
                0.2435002723112735,
                0.0,
                0.06389687180626558
            ],
            [
                0.20807764281407387,
                1.0,
                0.18642084203402323,
                0.26277549963077157,
                0.0,
                0.09800991081612424
            ],
            [
                0.22569597381032994,
                0.18642084203402323,
                1.0,
                0.23592917823834064,
                0.0,
                0.08916195734702936
            ],
            [
                0.2435002723112735,
                0.26277549963077157,
                0.23592917823834064,
                1.0,
                0.0,
                0.13717798640858053
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.06389687180626558,
                0.09800991081612424,
                0.08916195734702936,
                0.13717798640858053,
                0.0,
                1.0
            ]
        ]
    },
    "P11-1144": {
        "input_sentences": [
            "We construct a large graph where vertices correspond to potential predicates and use label propagation to learn possible semantic frames for new ones.",
            "Semi-Supervised Frame-Semantic Parsing for Unknown Predicates",
            "The label-propagated graph is used within a frame-semantic parser and, for unknown predicates, results in over 15% absolute improvement in frame identification accuracy and over 13% absolute improvement full frame-semantic parsing on a blind test set, over a state-of-the-art supervised baseline.",
            "Our approach makes use of large amounts of unlabeled data in a graph-based semi-supervised learning framework.",
            "Abstract",
            "We describe a new approach to disambiguating semantic frames evoked by lexical predicates previously unseen in a lexicon or annotated data."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.1009856292122636,
                0.10884874081238124,
                0.16031095416988947,
                0.0,
                0.1794183706830721
            ],
            [
                0.1009856292122636,
                1.0,
                0.43459329487293835,
                0.18216870770731633,
                0.0,
                0.11094747514805589
            ],
            [
                0.10884874081238124,
                0.43459329487293835,
                1.0,
                0.052110541572472364,
                0.0,
                0.05719698508414797
            ],
            [
                0.16031095416988947,
                0.18216870770731633,
                0.052110541572472364,
                1.0,
                0.0,
                0.12984789715901676
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.1794183706830721,
                0.11094747514805589,
                0.05719698508414797,
                0.12984789715901676,
                0.0,
                1.0
            ]
        ]
    },
    "W09-1116": {
        "input_sentences": [
            "pronouns like reflect the gender and number of the entities to which they refer.",
            "Glen Glenda or Glendale: Unsupervised and Semi-supervised Learning of English Noun Gender",
            "Indeed, broad-coverage models of noun gender have proved to be the most important source of world knowledge in automatic pronoun resolution systems.",
            "Our model collectively classifies all occurrences of a noun in a document using a wide variety of contextual, morphological, and categorical gender features.",
            "Previous approaches predict gender by counting the co-occurrence of nouns with pronouns of each gender class.",
            "While this provides useful statistics for frequent nouns, many infrequent nouns cannot be classified using this method.",
            "Rather than using co-occurrence information directly, we use it to automatically annotate training examples for a large-scale discriminative gender model.",
            "By leveraging large volumes of unlabeled data, our full semi-supervised system reduces error by 50% over the existing stateof-the-art in gender classification.",
            "Abstract",
            "Pronoun resolution systems can use this fact to filter noun candidates that do not agree with the pronoun gender."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.028493717557065677,
                0.02357553063868095,
                0.023468572342174046,
                0.1627275757902304,
                0.0,
                0.023738440378366282,
                0.022154347564024138,
                0.0,
                0.02601463091151459
            ],
            [
                0.028493717557065677,
                1.0,
                0.06495386857852567,
                0.064659183583258,
                0.04915601348281999,
                0.0,
                0.020319255922231983,
                0.15804874937949223,
                0.0,
                0.07167392934829449
            ],
            [
                0.02357553063868095,
                0.06495386857852567,
                1.0,
                0.053498619847910704,
                0.040671390092173694,
                0.0,
                0.016812030216499116,
                0.015690144539261035,
                0.0,
                0.32956313574590307
            ],
            [
                0.023468572342174046,
                0.064659183583258,
                0.053498619847910704,
                1.0,
                0.04048687069927022,
                0.04959575453494642,
                0.1250860247837926,
                0.015618960939723595,
                0.0,
                0.05903353230723692
            ],
            [
                0.1627275757902304,
                0.04915601348281999,
                0.040671390092173694,
                0.04048687069927022,
                1.0,
                0.15855504694422126,
                0.1160432383547007,
                0.03821963228838854,
                0.0,
                0.04487921048827463
            ],
            [
                0.0,
                0.0,
                0.0,
                0.04959575453494642,
                0.15855504694422126,
                1.0,
                0.05016606229311226,
                0.0,
                0.0,
                0.0
            ],
            [
                0.023738440378366282,
                0.020319255922231983,
                0.016812030216499116,
                0.1250860247837926,
                0.1160432383547007,
                0.05016606229311226,
                1.0,
                0.0737353885737864,
                0.0,
                0.08658340821460599
            ],
            [
                0.022154347564024138,
                0.15804874937949223,
                0.015690144539261035,
                0.015618960939723595,
                0.03821963228838854,
                0.0,
                0.0737353885737864,
                1.0,
                0.0,
                0.01731343083610139
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.02601463091151459,
                0.07167392934829449,
                0.32956313574590307,
                0.05903353230723692,
                0.04487921048827463,
                0.0,
                0.08658340821460599,
                0.01731343083610139,
                0.0,
                1.0
            ]
        ]
    },
    "W11-1002": {
        "input_sentences": [
            "We then show that the correlation of HMEANT, the human variant of MEANT, can be greatly improved by introducing a simple length-based weighting scheme that approximates the degree of contribution of each semantic frame to the overall sentence.",
            "We argue that failing to capture the degree of contribution of each semantic frame in a sentence explains puzzling results in recent work on the MEANT family of semantic MT evaluation metrics, which have disturbingly indicated that dissociating semantic roles and fillers from their predicates actually improves correlation with human adequacy judgments even though, intuitively, properly segregating event frames should more accurately reflect the preservation of meaning.",
            "Structured vs. Flat Semantic Role Representations for Machine Translation Evaluation",
            "The new results also show that, without flattening the structure of semantic frames, weighting the degree of each frame\u2019s contribution gives HMEANT higher correlations than the previously bestperforming flattened model, as well as HTER.",
            "Our analysis finds that both properly structured and flattened representations fail to adequately account for the contribution of each semantic frame to the overall sentence.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.1932192379139903,
                0.025152254367455818,
                0.18749220123980387,
                0.1748654403666537,
                0.0
            ],
            [
                0.1932192379139903,
                1.0,
                0.09051603843706328,
                0.14413695986351557,
                0.14118717138046707,
                0.0
            ],
            [
                0.025152254367455818,
                0.09051603843706328,
                1.0,
                0.02528078029001175,
                0.19022155987424194,
                0.0
            ],
            [
                0.18749220123980387,
                0.14413695986351557,
                0.02528078029001175,
                1.0,
                0.13598739548759914,
                0.0
            ],
            [
                0.1748654403666537,
                0.14118717138046707,
                0.19022155987424194,
                0.13598739548759914,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "W06-2905": {
        "input_sentences": [
            "What Are The Productive Units Of Natural Language Grammar? A DOP Approach To The Automatic Identification Of Constructions",
            "The statistical grammar formalism used is that of stochastic tree substitution grammars (STSGs), such as used in Data-Oriented Parsing.",
            "We report quantitative results on the ATIS corpus of phrase-structure annotated sentences, and give examples of the MWEs extracted from this corpus.",
            "In this MWEs have no special status, but emerge in a general procedure for finding the best statistical grammar to describe the training corpus.",
            "We present an algorithm for calculating the expected frequencies of arbitrary subtrees given the parameters of an STSG, and a method for estimating the parameters of an STSG given observed frequencies in a tree bank.",
            "We explore a novel computational approach to identifying \u201cconstructions\u201d or \u201cmulti-word expressions\u201d (MWEs) in an annotated corpus.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.04533977086933603,
                0.0,
                0.052894650434400246,
                0.0,
                0.14569063270283414,
                0.0
            ],
            [
                0.04533977086933603,
                1.0,
                0.0,
                0.10021779528629218,
                0.035798190747123836,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                1.0,
                0.135358725180165,
                0.0,
                0.19833589326414044,
                0.0
            ],
            [
                0.052894650434400246,
                0.10021779528629218,
                0.135358725180165,
                1.0,
                0.0,
                0.0993309340086693,
                0.0
            ],
            [
                0.0,
                0.035798190747123836,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.14569063270283414,
                0.0,
                0.19833589326414044,
                0.0993309340086693,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "D10-1044": {
        "input_sentences": [
            "We incorporate instance weighting into a mixture-model framework, and find that it yields consistent improvements over a wide range of baselines.",
            "We describe a new approach to SMT adaptation that weights out-of-domain phrase pairs according to their relevance to the target domain, determined by both how similar to it they appear to be, and whether they belong to general language or not.",
            "Instance Weighting",
            "Discriminative Instance Weighting for Domain Adaptation in Statistical Machine Translation",
            "This extends previous work on discriminative weighting by using a finer granularity, focusing on the properties of instances rather than corpus components, and using a simpler training procedure.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.27703027930910296,
                0.10444092661534823,
                0.025189489816718418,
                0.0
            ],
            [
                0.0,
                1.0,
                0.0,
                0.1946613010370093,
                0.0,
                0.0
            ],
            [
                0.27703027930910296,
                0.0,
                1.0,
                0.3770018457037177,
                0.09092684698416184,
                0.0
            ],
            [
                0.10444092661534823,
                0.1946613010370093,
                0.3770018457037177,
                1.0,
                0.09977178919585633,
                0.0
            ],
            [
                0.025189489816718418,
                0.0,
                0.09092684698416184,
                0.09977178919585633,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "I08-2105": {
        "input_sentences": [
            "The best configurationuses the syntactically-constrained graph, se lectional preferences computed from thecorpus and a PageRank tie-breaking algo rithm.",
            "We present experiments that analyze the necessity of using a highly interconnectedword/sense graph for unsupervised all words word sense disambiguation.",
            "We also com pare two methods for computing selectional preferences between the senses of every two grammatically related words: one using a Lesk-based measure on WordNet, the other using dependency relations from the British National Corpus.",
            "We show that allowing only grammatically related words to influence each other?s senses leads to disambiguation results on a par with thebest graph-based systems, while greatly reducing the computation load.",
            "Abstract",
            "Unsupervised All-words Word Sense Disambiguation with Grammatical Dependencies",
            "We especially note good performancewhen disambiguating verbs with grammati cally constrained links."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0386697558212047,
                0.04179378078735191,
                0.034723532683839264,
                0.0,
                0.0,
                0.05941377442654629
            ],
            [
                0.0386697558212047,
                1.0,
                0.11366951427249579,
                0.10195790328289572,
                0.0,
                0.4680972495705,
                0.0
            ],
            [
                0.04179378078735191,
                0.11366951427249579,
                1.0,
                0.18210114516311487,
                0.0,
                0.038545040222792204,
                0.0
            ],
            [
                0.034723532683839264,
                0.10195790328289572,
                0.18210114516311487,
                1.0,
                0.0,
                0.10197983895350818,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.4680972495705,
                0.038545040222792204,
                0.10197983895350818,
                0.0,
                1.0,
                0.0
            ],
            [
                0.05941377442654629,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "N10-1002": {
        "input_sentences": [
            "As an illustration of the functionality of our proposed technique, we develop a lexical acquisition model for English verb particle constructions which operates over unlexicalised features mined from a partial parsing chart.",
            "In this paper, we present an innovative chart mining technique for improving parse coverage based on partial parse outputs from precision grammars.",
            "Chart Mining-based Lexical Acquisition with Precision Grammars",
            "The proposed technique is shown to outperform a state-of-the-art parser over the target task, despite being based on relatively simplistic features.",
            "Abstract",
            "The general approach of mining features from partial analyses is applicable to a range of lexical acquisition tasks, and is particularly suited to domain-specific lexical tuning and lexical acquisition using lowcoverage grammars."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.09907054969946234,
                0.19358924138690117,
                0.11886132395716846,
                0.0,
                0.18502360182699323
            ],
            [
                0.09907054969946234,
                1.0,
                0.37349882133570905,
                0.07483688870124812,
                0.0,
                0.08494730407269302
            ],
            [
                0.19358924138690117,
                0.37349882133570905,
                1.0,
                0.07311767500725397,
                0.0,
                0.38731385335087853
            ],
            [
                0.11886132395716846,
                0.07483688870124812,
                0.07311767500725397,
                1.0,
                0.0,
                0.029949632730777723
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.18502360182699323,
                0.08494730407269302,
                0.38731385335087853,
                0.029949632730777723,
                0.0,
                1.0
            ]
        ]
    }
}