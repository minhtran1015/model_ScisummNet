{
    "W11-2139": {
        "input_sentences": [
            "We present the results of several modeling and training improvements to our core hierarchical phrase-based translation system, including: feature engineering to improve modeling of the derivation structure of translations; better handing of OOVs; and using development set translations into other languages to create additional pseudoreferences for training.",
            "Abstract",
            "The CMU-ARK German-English Translation System",
            "This paper describes the German-English translation system developed by the ARK research group at Carnegie Mellon University for the Sixth Workshop on Machine Translation (WMT11)."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.03784999541878948,
                0.03478782856295148
            ],
            [
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.03784999541878948,
                0.0,
                1.0,
                0.37632490414910114
            ],
            [
                0.03478782856295148,
                0.0,
                0.37632490414910114,
                1.0
            ]
        ]
    },
    "D12-1126": {
        "input_sentences": [
            "The underlying problem is how to tag part-of-speech (POS) for the English words involved.",
            "In modern Chinese articles or conversations, it is very popular to involve a few English words, especially in emails and Internet literature.",
            "Part-of-Speech Tagging for Chinese-English Mixed Texts with Dynamic Features",
            "Dynamic Features",
            "Experiments show that our method achieves higher performance than traditional sequence labeling methods.",
            "Due to the lack of specially annotated corpus, most of the English words are tagged as the oversimplified type, \u201cforeign words\u201d.",
            "Abstract",
            "Meanwhile, our method also boosts the performance of POS tagging for pure Chinese texts.",
            "In this paper, we present a method using dynamic features to tag POS of mixed texts.",
            "Therefore, it becomes an important and challenging topic to analyze Chinese-English mixed texts."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.11590659971257838,
                0.21262147699514683,
                0.0,
                0.0,
                0.1847158172893763,
                0.0,
                0.09772564569744746,
                0.19951300790777693,
                0.06036132148786438
            ],
            [
                0.11590659971257838,
                1.0,
                0.11800127648061418,
                0.0,
                0.0,
                0.13956027037214888,
                0.0,
                0.05836329436680251,
                0.0,
                0.10215235969943613
            ],
            [
                0.21262147699514683,
                0.11800127648061418,
                1.0,
                0.5053551827781617,
                0.0,
                0.052124226142999025,
                0.0,
                0.3294265508132168,
                0.3827897404642627,
                0.35576635883623525
            ],
            [
                0.0,
                0.0,
                0.5053551827781617,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.3996713065560648,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.19038521555442572,
                0.07306312974357668,
                0.0
            ],
            [
                0.1847158172893763,
                0.13956027037214888,
                0.052124226142999025,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.04512334829605968
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.09772564569744746,
                0.05836329436680251,
                0.3294265508132168,
                0.0,
                0.19038521555442572,
                0.0,
                0.0,
                1.0,
                0.25178861193332636,
                0.1561424773763962
            ],
            [
                0.19951300790777693,
                0.0,
                0.3827897404642627,
                0.3996713065560648,
                0.07306312974357668,
                0.0,
                0.0,
                0.25178861193332636,
                1.0,
                0.15652842291718252
            ],
            [
                0.06036132148786438,
                0.10215235969943613,
                0.35576635883623525,
                0.0,
                0.0,
                0.04512334829605968,
                0.0,
                0.1561424773763962,
                0.15652842291718252,
                1.0
            ]
        ]
    },
    "W01-0510": {
        "input_sentences": [
            "Despite the small amount of training data used, the model is shown to outperform the slot level accuracy of a simple semantic grammar authored manually for the MiPad personal information management task.",
            "The task of template filling is cast as constrained parsing using the SLM.",
            "Training proceeds in stages: first a constrained syntactic parser is trained such that the parses on training data meet the specified semantic spans, then the non-terminal labels are enriched to contain semantic information and finally a constrained syntactic+semantic parser is trained on the parse trees resulting from the previous stage.",
            "The paper presents a data-driven approach to information extraction (viewed as template filling) using the structured language model (SLM) as a statistical parser.",
            "The model is automatically trained from a set of sentences annotated with frame/slot labels and spans.",
            "Abstract",
            "Information Extraction Using The Structured Language Model"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.06655442482166088,
                0.16435479679723042,
                0.08381786317451212,
                0.08825258888168074,
                0.0,
                0.09798686896931909
            ],
            [
                0.06655442482166088,
                1.0,
                0.09107719030596993,
                0.29704416300629644,
                0.0,
                0.0,
                0.11312055399751217
            ],
            [
                0.16435479679723042,
                0.09107719030596993,
                1.0,
                0.10271763287421697,
                0.15575877804602486,
                0.0,
                0.03352282262418517
            ],
            [
                0.08381786317451212,
                0.29704416300629644,
                0.10271763287421697,
                1.0,
                0.03749686080060163,
                0.0,
                0.514272243870114
            ],
            [
                0.08825258888168074,
                0.0,
                0.15575877804602486,
                0.03749686080060163,
                1.0,
                0.0,
                0.07291247242593155
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.09798686896931909,
                0.11312055399751217,
                0.03352282262418517,
                0.514272243870114,
                0.07291247242593155,
                0.0,
                1.0
            ]
        ]
    },
    "W06-2204": {
        "input_sentences": [
            "Our experiments with several demonstrate that usually competitive with various fully-supervised algorithms when very little labelled training data is available.",
            "Transductive Pattern Learning For Information Extraction",
            "Compared to previous work, two novel features.",
            "The requirement for large labelled training corpora is widely recognized as a key bottleneck in the use of learning algorithms for extraction.",
            "First, the algorithm does not require redundancy in the fragments to be extracted, but only redundancy of the extraction patterns themselves.",
            "Abstract",
            "We present a semi-supervised learning algorithm for information extraction that can acquire extraction patterns from a small amount of labelled text in conjunction with a large amount of unlabelled text.",
            "Second, most bootstrapping methods identify the highest quality fragments in the unlabelled data and then assume that they are as reliable as manually labelled data in subsequent iterations. contrast, scoring mechanism prevents errors from snowballing by recording the reliability of fragments extracted from unlabelled data."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0,
                0.16705073220358235,
                0.0,
                0.0,
                0.08311892344855369,
                0.13237941807754364
            ],
            [
                0.0,
                1.0,
                0.0,
                0.15036328741515306,
                0.06955400315935216,
                0.0,
                0.26852340054845847,
                0.0
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.16705073220358235,
                0.15036328741515306,
                0.0,
                1.0,
                0.041010181811105856,
                0.0,
                0.18969127194173202,
                0.021987680112525
            ],
            [
                0.0,
                0.06955400315935216,
                0.0,
                0.041010181811105856,
                1.0,
                0.0,
                0.1833987395845558,
                0.12264358530760344
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.08311892344855369,
                0.26852340054845847,
                0.0,
                0.18969127194173202,
                0.1833987395845558,
                0.0,
                1.0,
                0.08043159223084567
            ],
            [
                0.13237941807754364,
                0.0,
                0.0,
                0.021987680112525,
                0.12264358530760344,
                0.0,
                0.08043159223084567,
                1.0
            ]
        ]
    },
    "D08-1094": {
        "input_sentences": [
            "This makes it possible to integrate syntax into the computation of word meaning in context.",
            "We address the task of computing vector space representations for the meaning of word occurrences, which can vary widely according to context.",
            "In addition, the model performs at and above the state of the art for modeling the contextual adequacy of paraphrases.",
            "This task is a crucial step towards a robust, vector-based compositional account of sentence meaning.",
            "We argue that existing models for this task do not take syntactic structure sufficiently into account. present a novel vector space model that addresses these issues by incorporating the selectional preferences for words\u2019 argument positions.",
            "A Structured Vector Space Model for Word Meaning in Context",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.17548424344204644,
                0.0,
                0.053252479013257616,
                0.0,
                0.2824357134358599,
                0.0
            ],
            [
                0.17548424344204644,
                1.0,
                0.0,
                0.14320710607252835,
                0.10288575640253957,
                0.3737241642859834,
                0.0
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.04005301246686281,
                0.08888299224438508,
                0.0
            ],
            [
                0.053252479013257616,
                0.14320710607252835,
                0.0,
                1.0,
                0.12933269319136162,
                0.13857038818177173,
                0.0
            ],
            [
                0.0,
                0.10288575640253957,
                0.04005301246686281,
                0.12933269319136162,
                1.0,
                0.16559100373895358,
                0.0
            ],
            [
                0.2824357134358599,
                0.3737241642859834,
                0.08888299224438508,
                0.13857038818177173,
                0.16559100373895358,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "W09-1210": {
        "input_sentences": [
            "The semantic role labeler works not as well as our parser and we reached therefore the fourth place (ranked by the macro F1 score) in the joint task for syntactic and semantic dependency parsing.",
            "For this task, our system has the highest accuracy for English with 89.88, German with 87.48 and the out-of-domain data in average with 78.79.",
            "Efficient Parsing of Syntactic and Semantic Dependency Structures",
            "For the applications of syntactic and semantic parsing, the parsing time and memory footprint are very important.",
            "We think that also the development of systems can profit from this since one can perform more experiments in the given time.",
            "Abstract",
            "Our system combines and implements efficient parsing techniques to get a high accuracy as well as very good parsing and training time.",
            "For the subtask of syntactic dependency parsing, we could reach the second place with an accuracy in average of 85.68 which is only 0.09 points behind the first ranked system.",
            "In this paper, we describe our system for the 2009 CoNLL shared task for joint parsing of syntactic and semantic dependency structures of multiple languages."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.039749290282465655,
                0.29054398597393205,
                0.17933205560265086,
                0.0,
                0.0,
                0.047842820495640176,
                0.1976542762393916,
                0.26817541405359957
            ],
            [
                0.039749290282465655,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.050619744212930196,
                0.10704252300879312,
                0.04914530959282534
            ],
            [
                0.29054398597393205,
                0.0,
                1.0,
                0.30291672253438734,
                0.0,
                0.0,
                0.2483060851042223,
                0.18505371193810755,
                0.41542873556591997
            ],
            [
                0.17933205560265086,
                0.0,
                0.30291672253438734,
                1.0,
                0.07777915902450919,
                0.0,
                0.21543484515154937,
                0.10600118132228442,
                0.16738323034528804
            ],
            [
                0.0,
                0.0,
                0.0,
                0.07777915902450919,
                1.0,
                0.0,
                0.06593609801317635,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.047842820495640176,
                0.050619744212930196,
                0.2483060851042223,
                0.21543484515154937,
                0.06593609801317635,
                0.0,
                1.0,
                0.11079888914834939,
                0.059152005189119006
            ],
            [
                0.1976542762393916,
                0.10704252300879312,
                0.18505371193810755,
                0.10600118132228442,
                0.0,
                0.0,
                0.11079888914834939,
                1.0,
                0.10225545764668223
            ],
            [
                0.26817541405359957,
                0.04914530959282534,
                0.41542873556591997,
                0.16738323034528804,
                0.0,
                0.0,
                0.059152005189119006,
                0.10225545764668223,
                1.0
            ]
        ]
    },
    "C08-1081": {
        "input_sentences": [
            "Parsing the SynTagRus Treebank of Russian",
            "We present the first results on parsing the SYNTAGRUS treebank of Russian with a data-driven dependency parser, achieving a labeled attachment score of over 82% and an unlabeled attachment score of 89%.",
            "We conjecture that the latter result can be generalized to richly inflected languages in general, provided that sufficient amounts of training data are available.",
            "Abstract",
            "A feature analysis shows that high parsing accuracy is crucially dependent on the use of both lexical and morphological features."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.3377312534024911,
                0.0,
                0.0,
                0.08554239210665184
            ],
            [
                0.3377312534024911,
                1.0,
                0.03988554181515318,
                0.0,
                0.028890339305226883
            ],
            [
                0.0,
                0.03988554181515318,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.08554239210665184,
                0.028890339305226883,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "D11-1132": {
        "input_sentences": [
            "This paper describes a novel approach to the semantic relation detection problem.",
            "Third, we integrate the relation topics in a kernel function, and use it together with SVM to construct detectors for new relations.",
            "Instead of relying only on the training instances for a new relation, we leverage the knowledge learned from previously trained relation detectors.",
            "The experimental results on Wikipedia and ACE data have confirmed that backgroundknowledge-based topics generated from the Wikipedia relation repository can significantly improve the performance over the state-of-theart relation detection approaches.",
            "Specifically, we detect a new semantic relation by projecting the new relation\u2019s training instances onto a lower dimension topic space constructed from existing relation detectors through a three step process.",
            "Relation Extraction with Relation Topics",
            "First, we construct a large relation repository of more than 7,000 relations from Wikipedia.",
            "Similar to the topics defined over words, each relation topic is an interpretable multinomial distribution over the existing relations.",
            "Second, we construct a set of non-redundant relation topics defined at multiple scales from the relation repository to characterize the existing relations.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.023118416690743798,
                0.039931185363224424,
                0.09332705183627803,
                0.1156640167165396,
                0.0900175860332344,
                0.03030639090906372,
                0.022620224854513805,
                0.03877049406276754,
                0.0
            ],
            [
                0.023118416690743798,
                1.0,
                0.16269694518755273,
                0.05633044188683733,
                0.19088143088460605,
                0.17404653568302456,
                0.19876667077399202,
                0.12258687963414236,
                0.18403930074754632,
                0.0
            ],
            [
                0.039931185363224424,
                0.16269694518755273,
                1.0,
                0.046886987011088586,
                0.3132944295285684,
                0.14486869594044133,
                0.04877321780253426,
                0.03640358091076918,
                0.06239481820547934,
                0.0
            ],
            [
                0.09332705183627803,
                0.05633044188683733,
                0.046886987011088586,
                1.0,
                0.05500936210097474,
                0.162517722002704,
                0.25241380736730135,
                0.05511654533610656,
                0.10838382967786536,
                0.0
            ],
            [
                0.1156640167165396,
                0.19088143088460605,
                0.3132944295285684,
                0.05500936210097474,
                1.0,
                0.1699647399010535,
                0.057222350378257396,
                0.15346539391859323,
                0.11435566283508283,
                0.0
            ],
            [
                0.0900175860332344,
                0.17404653568302456,
                0.14486869594044133,
                0.162517722002704,
                0.1699647399010535,
                1.0,
                0.1099503380558493,
                0.17029590845100862,
                0.21627032074228217,
                0.0
            ],
            [
                0.03030639090906372,
                0.19876667077399202,
                0.04877321780253426,
                0.25241380736730135,
                0.057222350378257396,
                0.1099503380558493,
                1.0,
                0.1012920024022276,
                0.2702113140415874,
                0.0
            ],
            [
                0.022620224854513805,
                0.12258687963414236,
                0.03640358091076918,
                0.05511654533610656,
                0.15346539391859323,
                0.17029590845100862,
                0.1012920024022276,
                1.0,
                0.2579511645001478,
                0.0
            ],
            [
                0.03877049406276754,
                0.18403930074754632,
                0.06239481820547934,
                0.10838382967786536,
                0.11435566283508283,
                0.21627032074228217,
                0.2702113140415874,
                0.2579511645001478,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P14-1060": {
        "input_sentences": [
            "Traditional models of distributional semantics suffer from computational issues such as data sparsity for individual lexemes and complexities of modeling semantic composition when dealing with structures larger than single lexical items.",
            "Hellinger PCA embeddings learnt using the framework show competitive results on empirical tasks.",
            "We design a segmentation model to optimally partition a sentence into lineal constituents, which can be used to define distributional contexts that are less noisy, semantically more interpretable, and linguistically disambiguated.",
            "Vector space semantics with frequency-driven motifs",
            "In this work, we present a frequencydriven paradigm for robust distributional semantics in terms of semantically cohelineal constituents, or The framework subsumes issues such as differential compositional as well as noncompositional behavior of phrasal consituents, and circumvents some problems of data sparsity by design.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.027950252087105776,
                0.04700467735299054,
                0.14676661670902477,
                0.0
            ],
            [
                0.0,
                1.0,
                0.0,
                0.0,
                0.04645048737663035,
                0.0
            ],
            [
                0.027950252087105776,
                0.0,
                1.0,
                0.0,
                0.13625125921064493,
                0.0
            ],
            [
                0.04700467735299054,
                0.0,
                0.0,
                1.0,
                0.04399029929421255,
                0.0
            ],
            [
                0.14676661670902477,
                0.04645048737663035,
                0.13625125921064493,
                0.04399029929421255,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "W05-0104": {
        "input_sentences": [
            "The course work was organized around four substantial programming assignments in which the students implemented the important parts of several core tools, including language models (for speech reranking), a maximum entropy classifier, a part-of-speech tagger, a PCFG parser, and a word-alignment system.",
            "In the fall term of 2004, I taught a new statistical NLP course focusing on core tools and machine-learning algorithms.",
            "Using provided scaffolding, students built realistic tools with nearly state-of-theart performance in most cases.",
            "Abstract",
            "This paper briefly outlines the coverage of the course, the scope of the assignments, and some of the lessons learned in teaching the course in this way.",
            "A Core-Tools Statistical NLP Course"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0689722930667944,
                0.06106257005348404,
                0.0,
                0.08183534639388546,
                0.14728527921502757
            ],
            [
                0.0689722930667944,
                1.0,
                0.031220061737390656,
                0.0,
                0.06228250557618252,
                0.46829047298134274
            ],
            [
                0.06106257005348404,
                0.031220061737390656,
                1.0,
                0.0,
                0.0,
                0.06666815478570393
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.08183534639388546,
                0.06228250557618252,
                0.0,
                0.0,
                1.0,
                0.13299972809539504
            ],
            [
                0.14728527921502757,
                0.46829047298134274,
                0.06666815478570393,
                0.0,
                0.13299972809539504,
                1.0
            ]
        ]
    },
    "W12-2802": {
        "input_sentences": [
            "Toward Learning Perceptually Grounded Word Meanings from Unaligned Parallel Data",
            "In this paper, we present an approach which is capable of jointly learninga policy for following natural language com mands such as ?Pick up the tire pallet,?",
            "and a specific object in the environment.",
            "Abstract",
            "com mands given to a robotic forklift by untrained users.",
            "In order for robots to effectively understand natural language commands, they must be ableto acquire a large vocabulary of meaning rep resentations that can be mapped to perceptualfeatures in the external world.",
            "Previous ap proaches to learning these grounded meaning representations require detailed annotations at training time.",
            "as well as a mapping between specific phrases in the language and aspects of the external world; for example the mapping between the words ?the tire pallet?",
            "We assume the action policy takes a parametric form that factors based on the structure of the language, based on the G3 framework and use stochastic gradient ascentto optimize policy parameters.",
            "Our prelimi nary evaluation demonstrates the effectivenessof the model on a corpus of ?pick up?"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.15850127058588157,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                1.0,
                0.0,
                0.0,
                0.16104863681824003,
                0.08120186056613109,
                0.0,
                0.1534115697327828,
                0.1127034595115597,
                0.07356405465935874
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.12616309547491664,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.16104863681824003,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.08120186056613109,
                0.0,
                0.0,
                0.0,
                1.0,
                0.05351551775198901,
                0.13420722660520926,
                0.022898956904635694,
                0.0
            ],
            [
                0.15850127058588157,
                0.0,
                0.0,
                0.0,
                0.0,
                0.05351551775198901,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.1534115697327828,
                0.12616309547491664,
                0.0,
                0.0,
                0.13420722660520926,
                0.0,
                1.0,
                0.02665493303638215,
                0.0
            ],
            [
                0.0,
                0.1127034595115597,
                0.0,
                0.0,
                0.0,
                0.022898956904635694,
                0.0,
                0.02665493303638215,
                1.0,
                0.0
            ],
            [
                0.0,
                0.07356405465935874,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "W04-0837": {
        "input_sentences": [
            "Whilst there are hand-tagged corpora available for some languages, these are relatively small in size and many word forms either do not occur, or occur infrequently.",
            "We evaluate on the and English alldata.",
            "For accurate first sense heuristic should be used only as a back-off, where the evidence from the context is not strong enough.",
            "In this paper however, we examine the performance of the automatically acquired first sense in isolation since it turned out that the first sense taken from SemCor many systems in",
            "word sense disambiguation the heuristic of choosing the most common sense is extremely powerful because the distribution of the senses of a word is often skewed.",
            "The first (or predominant) sense heuristic assumes the availability of handtagged data.",
            "Using Automatically Acquired Predominant Senses For Word Sense Disambiguation",
            "Abstract",
            "In this paper we investigate the performance of an unsupervised first sense heuristic where predominant senses are acquired automatically from raw text."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0,
                0.0,
                0.08283022203314287,
                0.0,
                0.06323859053553922,
                0.0,
                0.0
            ],
            [
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                1.0,
                0.07318959952117035,
                0.1220242113433204,
                0.12670572375593261,
                0.05237453494288719,
                0.0,
                0.10073532769474954
            ],
            [
                0.0,
                0.0,
                0.07318959952117035,
                1.0,
                0.10571376567494037,
                0.07634478349104613,
                0.2417355764568301,
                0.0,
                0.3419809003822796
            ],
            [
                0.08283022203314287,
                0.0,
                0.1220242113433204,
                0.10571376567494037,
                1.0,
                0.12728464230736486,
                0.40186639160102433,
                0.0,
                0.15794790281925317
            ],
            [
                0.0,
                0.0,
                0.12670572375593261,
                0.07634478349104613,
                0.12728464230736486,
                1.0,
                0.1636310992003208,
                0.0,
                0.18704922164797572
            ],
            [
                0.06323859053553922,
                0.0,
                0.05237453494288719,
                0.2417355764568301,
                0.40186639160102433,
                0.1636310992003208,
                1.0,
                0.0,
                0.3900652147961629
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.10073532769474954,
                0.3419809003822796,
                0.15794790281925317,
                0.18704922164797572,
                0.3900652147961629,
                0.0,
                1.0
            ]
        ]
    },
    "W11-0610": {
        "input_sentences": [
            "In this paper, we discuss previous work identifying language errors associated with atypical language in ASD and describe a procedure for reproducing those results.",
            "Our classifiers achieve results well above chance, demonstrating the potential for using NLP techniques to enhance neurodevelopmental diagnosis and atypical language analysis.",
            "We then present methods for automatically extracting lexical and syntactic features from transcripts of children\u2019s speech to 1) identify certain syntactic and semantic errors that have previously been found to distinguish ASD language from that of children with typical development; and 2) perform diagnostic classification.",
            "Atypical or idiosyncratic language is a characteristic of autism spectrum disorder (ASD).",
            "Abstract",
            "We expect further improvement with additional data, features, and classification techniques.",
            "We describe our data set, which consists of transcribed data from a widely used clinical diagnostic instrument (the ADOS) for children with autism, children with developmental language disorder, and typically developing children.",
            "Classification of Atypical Language in Autism"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.13187487231398765,
                0.10205724774511372,
                0.18212353577990814,
                0.0,
                0.0,
                0.03141553982299722,
                0.20555381024242458
            ],
            [
                0.13187487231398765,
                1.0,
                0.013763124971565425,
                0.07762054680068463,
                0.0,
                0.08192113210469175,
                0.01463154141199088,
                0.13843271845335153
            ],
            [
                0.10205724774511372,
                0.013763124971565425,
                1.0,
                0.06622337512894727,
                0.0,
                0.10285032471627177,
                0.21784230835256901,
                0.11810638061848054
            ],
            [
                0.18212353577990814,
                0.07762054680068463,
                0.06622337512894727,
                1.0,
                0.0,
                0.0,
                0.13439482834437586,
                0.3879812645032711
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.08192113210469175,
                0.10285032471627177,
                0.0,
                0.0,
                1.0,
                0.12534470824229235,
                0.16916379995296657
            ],
            [
                0.03141553982299722,
                0.01463154141199088,
                0.21784230835256901,
                0.13439482834437586,
                0.0,
                0.12534470824229235,
                1.0,
                0.12555857791089306
            ],
            [
                0.20555381024242458,
                0.13843271845335153,
                0.11810638061848054,
                0.3879812645032711,
                0.0,
                0.16916379995296657,
                0.12555857791089306,
                1.0
            ]
        ]
    },
    "I08-1012": {
        "input_sentences": [
            "We thentrain another parser which uses the informa tion on short dependency relations extractedfrom the output of the first parser.",
            "Our proposed approach achieves an unlabeled at tachment score of 86.52, an absolute 1.24% improvement over the baseline system on the data set of Chinese Treebank.",
            "Abstract",
            "Dependency Parsing with Short Dependency Relations in Unlabeled Data",
            "This paper presents an effective dependencyparsing approach of incorporating short de pendency information from unlabeled data.",
            "The unlabeled data is automatically parsed by a deterministic dependency parser, which can provide relatively high performance for short dependencies between words."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0,
                0.2881659320284415,
                0.037313444000216654,
                0.20359345559664951
            ],
            [
                0.0,
                1.0,
                0.0,
                0.08613497552914895,
                0.12286715403836027,
                0.055454739274520215
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.2881659320284415,
                0.08613497552914895,
                0.0,
                1.0,
                0.16581745847419083,
                0.2791822424167421
            ],
            [
                0.037313444000216654,
                0.12286715403836027,
                0.0,
                0.16581745847419083,
                1.0,
                0.10675528576354017
            ],
            [
                0.20359345559664951,
                0.055454739274520215,
                0.0,
                0.2791822424167421,
                0.10675528576354017,
                1.0
            ]
        ]
    },
    "P12-2006": {
        "input_sentences": [
            "We compare our approach with Moses and observe the same performance, but a substantially better trade-off between translation quality and speed.",
            "At a speed of roughly 70 words per second, Moses 17.2% whereas our approach yields 20.0% with identical models.",
            "Two look-ahead methods are shown to further increase translation speed by a factor of 2 without changing the search space and a factor of 4 with the side-effect of some additional search errors.",
            "Abstract",
            "In this work we present two extensions to the well-known dynamic programming beam search in phrase-based statistical machine translation (SMT), aiming at increased efficiency of decoding by minimizing the number of language model computations and hypothesis expansions.",
            "Our results show that language model based pre-sorting yields a small improvement in translation quality and a speedup by a factor of 2.",
            "Fast and Scalable Decoding with Language Model Look-Ahead for Phrase-based Statistical Machine Translation"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.19440153436390656,
                0.06739936640760665,
                0.0,
                0.02122090634018364,
                0.10481883816331648,
                0.03472289717174186
            ],
            [
                0.19440153436390656,
                1.0,
                0.0390975482350061,
                0.0,
                0.0,
                0.06746352571140075,
                0.0
            ],
            [
                0.06739936640760665,
                0.0390975482350061,
                1.0,
                0.0,
                0.09144039723130377,
                0.13417011548759256,
                0.14962016511017284
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.02122090634018364,
                0.0,
                0.09144039723130377,
                0.0,
                1.0,
                0.1244103459470001,
                0.35099580110075296
            ],
            [
                0.10481883816331648,
                0.06746352571140075,
                0.13417011548759256,
                0.0,
                0.1244103459470001,
                1.0,
                0.20356753760504714
            ],
            [
                0.03472289717174186,
                0.0,
                0.14962016511017284,
                0.0,
                0.35099580110075296,
                0.20356753760504714,
                1.0
            ]
        ]
    },
    "W12-3706": {
        "input_sentences": [
            "We propose an approach based on the order of the words without using any syntactic and semantic information.",
            "We present an accuracy above 81% for Spanish opinions in the financial products domain.",
            "It consists of building one probabilistic model for the positive and another one for the negative opinions.",
            "In order to reduce the complexity of the training corpus we first lemmatize the texts and we replace most namedentities with wildcards.",
            "The classification of opinion texts in positive and negative can be tackled by evaluating separate key words but this is a very limited approach.",
            "Abstract",
            "Then the test opinions are compared to both models and a decision and confidence measure are calculated.",
            "Opinum: statistical sentiment analysis for opinion classification"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0,
                0.08043811576938974,
                0.156669186161381,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                1.0,
                0.0783189732254673,
                0.0,
                0.0,
                0.0,
                0.06952106848944942,
                0.0
            ],
            [
                0.0,
                0.0783189732254673,
                1.0,
                0.0,
                0.18321954723350445,
                0.0,
                0.0783189732254673,
                0.0
            ],
            [
                0.08043811576938974,
                0.0,
                0.0,
                1.0,
                0.07272996726972251,
                0.0,
                0.0,
                0.0
            ],
            [
                0.156669186161381,
                0.0,
                0.18321954723350445,
                0.07272996726972251,
                1.0,
                0.0,
                0.0,
                0.19187978225624547
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.06952106848944942,
                0.0783189732254673,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.19187978225624547,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P13-1092": {
        "input_sentences": [
            "Our GUSP system produces a semantic parse by annotating the dependency-tree nodes and edges with latent states, and learns a probabilistic grammar using EM.",
            "On the challenging ATIS dataset, GUSP attained an accuracy of 84%, effectively tying with the best published results by supervised approaches.",
            "We present the first unsupervised approach for semantic parsing that rivals the accuracy of supervised approaches in translating natural-language questions to database queries.",
            "To compensate for the lack of example annotations or question-answer pairs, GUSP adopts a novel grounded-learning approach to leverage database for indirect supervision.",
            "Grounded Unsupervised Semantic",
            "Abstract",
            "Grounded Unsupervised Semantic Parsing"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.03680612605796076,
                0.028375515018618222,
                0.03326973771044591,
                0.08354281803775586,
                0.0,
                0.06828026344273917
            ],
            [
                0.03680612605796076,
                1.0,
                0.16818564379442075,
                0.0362006212199834,
                0.0,
                0.0,
                0.0
            ],
            [
                0.028375515018618222,
                0.16818564379442075,
                1.0,
                0.1013507415747642,
                0.21631216184278498,
                0.0,
                0.3147671861900417
            ],
            [
                0.03326973771044591,
                0.0362006212199834,
                0.1013507415747642,
                1.0,
                0.10900781745413778,
                0.0,
                0.08909302640141686
            ],
            [
                0.08354281803775586,
                0.0,
                0.21631216184278498,
                0.10900781745413778,
                1.0,
                0.0,
                0.8173085975132054
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.06828026344273917,
                0.0,
                0.3147671861900417,
                0.08909302640141686,
                0.8173085975132054,
                0.0,
                1.0
            ]
        ]
    },
    "W07-2214": {
        "input_sentences": [
            "We present an example from natural language which seems to require both types of context sensitivity, and introduce partially ordered multisets (pomsets) mcfgs as a formalism which succintly expresses both.",
            "Pomset mcfgs",
            "Abstract",
            "This paper identifies two orthogonal dimensions of context sensitivity, the first being context sensitivity in concurrency and the second being structural context sensitivity."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.12255132163600414,
                0.0,
                0.2195531574234772
            ],
            [
                0.12255132163600414,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.2195531574234772,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P05-1022": {
        "input_sentences": [
            "Coarse-To-Fine N-Best Parsing And MaxEnt Discriminative Reranking",
            "This paper describes a simple yet novel method for constructing sets of 50-best parses based on a coarse-to-fine generative parser (Charniak, 2000).",
            "We used these parses as the input to a MaxEnt reranker (Johnson et al., 1999; Riezler et al., 2002) that selects the best parse from the set of parses for each sentence, obtaining an f-score of 91.0% on sentences of length 100 or less.",
            "This method generates 50-best lists that are of substantially higher quality than previously obtainable.",
            "Abstract",
            "A discriminative reranker requires a source of candidate parses for each sentence.",
            "Discriminative reranking is one method for constructing high-performance statistical parsers (Collins, 2000)."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.21941170337727534,
                0.09467049656119805,
                0.060177310672596435,
                0.0,
                0.10072434990566387,
                0.1948449342944911
            ],
            [
                0.21941170337727534,
                1.0,
                0.07113492897701716,
                0.1443659094662486,
                0.0,
                0.058333090318011024,
                0.1780445130318675
            ],
            [
                0.09467049656119805,
                0.07113492897701716,
                1.0,
                0.024734087777161906,
                0.0,
                0.19612617844537855,
                0.0
            ],
            [
                0.060177310672596435,
                0.1443659094662486,
                0.024734087777161906,
                1.0,
                0.0,
                0.0,
                0.06051419542991648
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.10072434990566387,
                0.058333090318011024,
                0.19612617844537855,
                0.0,
                0.0,
                1.0,
                0.07634952715544875
            ],
            [
                0.1948449342944911,
                0.1780445130318675,
                0.0,
                0.06051419542991648,
                0.0,
                0.07634952715544875,
                1.0
            ]
        ]
    },
    "C08-1074": {
        "input_sentences": [
            "Random Restarts in Minimum Error Rate Training for Statistical Machine Translation",
            "We findthat all of our random restart methods out perform MERT without random restarts,and we develop some refinements of ran dom restarts that are superior to the most common approach with regard to resulting model quality and training time.",
            "Och?s (2003) minimum error rate training (MERT) procedure is the most commonly used method for training feature weights instatistical machine translation (SMT) models.",
            "The use of multiple randomized start ing points in MERT is a well-established practice, although there seems to be nopublished systematic study of its benefits.",
            "Abstract",
            "We compare several ways of perform ing random restarts with MERT."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.22065072851110923,
                0.4399246770301224,
                0.0,
                0.0,
                0.18447676097787194
            ],
            [
                0.22065072851110923,
                1.0,
                0.07125841943517848,
                0.022506237865503785,
                0.0,
                0.30230519236580244
            ],
            [
                0.4399246770301224,
                0.07125841943517848,
                1.0,
                0.024888284884630473,
                0.0,
                0.039998894098870724
            ],
            [
                0.0,
                0.022506237865503785,
                0.024888284884630473,
                1.0,
                0.0,
                0.13691510529286435
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.18447676097787194,
                0.30230519236580244,
                0.039998894098870724,
                0.13691510529286435,
                0.0,
                1.0
            ]
        ]
    },
    "P09-1065": {
        "input_sentences": [
            "Current SMT systems usually decode with single translation models and cannot benefit from the strengths of other models in phase.",
            "Our joint decoder draws connections among multiple models by integrating the translation hypergraphs they produce individually.",
            "Therefore, one model can share translations and even derivations with other models.",
            "Abstract",
            "Comparable to the state-of-the-art system combination technique, joint decoding achieves an absolute improvement of 1.5 BLEU points over individual decoding.",
            "Joint Decoding",
            "We instead propose a method that combines multiple translation models in one decoder.",
            "Joint Decoding with Multiple Translation Models"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.10942124443329948,
                0.09288818042721149,
                0.0,
                0.0,
                0.0,
                0.12966390362832428,
                0.21481164595125388
            ],
            [
                0.10942124443329948,
                1.0,
                0.05249914520291542,
                0.0,
                0.03788927265388329,
                0.1447110757863302,
                0.27584756133555166,
                0.386337666965412
            ],
            [
                0.09288818042721149,
                0.05249914520291542,
                1.0,
                0.0,
                0.0,
                0.0,
                0.06221135703048742,
                0.10306433499709082
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.03788927265388329,
                0.0,
                0.0,
                1.0,
                0.4098570930993458,
                0.0,
                0.26790087536883
            ],
            [
                0.0,
                0.1447110757863302,
                0.0,
                0.0,
                0.4098570930993458,
                1.0,
                0.0,
                0.6536445992503371
            ],
            [
                0.12966390362832428,
                0.27584756133555166,
                0.06221135703048742,
                0.0,
                0.0,
                0.0,
                1.0,
                0.3457207211539403
            ],
            [
                0.21481164595125388,
                0.386337666965412,
                0.10306433499709082,
                0.0,
                0.26790087536883,
                0.6536445992503371,
                0.3457207211539403,
                1.0
            ]
        ]
    },
    "D11-1094": {
        "input_sentences": [
            "This paper presents a novel method for the computation of word meaning in context.",
            "The factorization model allows us to determine which dimensions are important for a particular context, and adapt the dependency-based feature vector of the word accordingly.",
            "The evaluation on a lexical substitution task \u2013 carried out for both English and French \u2013 indicates that our approach is able to reach better results than state-of-the-art methods in lexical substitution, while at the same time providing more accurate meaning representations.",
            "Latent Vector Weighting for Word Meaning in Context",
            "We make use of a factorization model in which words, together with their window-based context words and their dependency relations, are linked to latent dimensions.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.09606190501553862,
                0.037078097517338725,
                0.2728679790105563,
                0.03829321454780142,
                0.0
            ],
            [
                0.09606190501553862,
                1.0,
                0.0,
                0.22831725938232475,
                0.2946922048017521,
                0.0
            ],
            [
                0.037078097517338725,
                0.0,
                1.0,
                0.048717365252502226,
                0.0,
                0.0
            ],
            [
                0.2728679790105563,
                0.22831725938232475,
                0.048717365252502226,
                1.0,
                0.1464402048533234,
                0.0
            ],
            [
                0.03829321454780142,
                0.2946922048017521,
                0.0,
                0.1464402048533234,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P14-2093": {
        "input_sentences": [
            "By contrast, we argue that the relevance between a sentence pair and target domain can be better evaluated by the combination of language model and translation model.",
            "When the selected sentence pairs are evaluated on an end-to-end MT task, our methods can increase the translation performance by 3 BLEU points.",
            "In this paper, we study and experiment with novel methods that apply translation models into domain-relevant data selection.",
            "The results show that our methods outperform previous methods.",
            "Abstract",
            "Most current data selection methods solely use language models trained on a small scale in-domain data to select domain-relevant sentence pairs from general-domain parallel corpus.",
            "Data selection has been demonstrated to be an effective approach to addressing the lack of high-quality bitext for statistical machine translation in the domain of interest.",
            "Effective Selection of Translation Model Training Data"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.11816556375185273,
                0.07041066341523418,
                0.0,
                0.0,
                0.15657898563432035,
                0.06065175694442089,
                0.2595971480904044
            ],
            [
                0.11816556375185273,
                1.0,
                0.06726893593079615,
                0.10140687334907186,
                0.0,
                0.10012218347251949,
                0.025456273846832442,
                0.04543067754498493
            ],
            [
                0.07041066341523418,
                0.06726893593079615,
                1.0,
                0.12980190983813572,
                0.0,
                0.33224963501852167,
                0.15734390077085791,
                0.20658702054117367
            ],
            [
                0.0,
                0.10140687334907186,
                0.12980190983813572,
                1.0,
                0.0,
                0.08512576985468516,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.15657898563432035,
                0.10012218347251949,
                0.33224963501852167,
                0.08512576985468516,
                0.0,
                1.0,
                0.16363790414886448,
                0.14601863772865675
            ],
            [
                0.06065175694442089,
                0.025456273846832442,
                0.15734390077085791,
                0.0,
                0.0,
                0.16363790414886448,
                1.0,
                0.28963839664495117
            ],
            [
                0.2595971480904044,
                0.04543067754498493,
                0.20658702054117367,
                0.0,
                0.0,
                0.14601863772865675,
                0.28963839664495117,
                1.0
            ]
        ]
    },
    "P05-1063": {
        "input_sentences": [
            "We describe a method for discriminative training of a language model that makes use of syntactic features.",
            "The reranking model makes use of syntactic features together with a parameter estimation method that is based on the perceptron algorithm.",
            "We follow where a baseline recogniser is used to produce 1000-best output for each acoustic input, and a second \u201creranking\u201d model is then used to choose an utterance from these 1000-best lists.",
            "The syntactic features provide an additional 0.3% reduction in test\u2013set error rate beyond the model of (Roark et al., 2004a; Roark et al., 2004b) (signifiat < which makes use of a discriminatively trained n-gram model, giving a total reduction of 1.2% over the baseline Switchboard system.",
            "Abstract",
            "Discriminative Syntactic Language Modeling For Speech Recognition",
            "We describe experiments on the Switchboard speech recognition task."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.43548914033273706,
                0.03370266333720936,
                0.19440815036683606,
                0.0,
                0.37412429302415245,
                0.0
            ],
            [
                0.43548914033273706,
                1.0,
                0.07454891987785289,
                0.15272028473513075,
                0.0,
                0.06345641672252904,
                0.0
            ],
            [
                0.03370266333720936,
                0.07454891987785289,
                1.0,
                0.05036947475439484,
                0.0,
                0.0,
                0.0
            ],
            [
                0.19440815036683606,
                0.15272028473513075,
                0.05036947475439484,
                1.0,
                0.0,
                0.031638508114769745,
                0.05792969716412967
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.37412429302415245,
                0.06345641672252904,
                0.0,
                0.031638508114769745,
                0.0,
                1.0,
                0.3360162229019465
            ],
            [
                0.0,
                0.0,
                0.0,
                0.05792969716412967,
                0.0,
                0.3360162229019465,
                1.0
            ]
        ]
    },
    "W11-2123": {
        "input_sentences": [
            "The structure uses linear probing hash tables and is designed for speed.",
            "Our code is thread-safe, and integrated into the Moses, cdec, and Joshua translation systems.",
            "Compared with the widely- SRILM, our is 2.4 times as fast while using 57% of the mem- The structure is a trie with bit-level packing, sorted records, interpolation search, and optional quantization aimed lower memory consumption. simultaneously uses less memory than the smallest lossless baseline and less CPU than the baseline.",
            "Abstract",
            "This paper describes the several performance techniques used and presents benchmarks against alternative implementations.",
            "We present KenLM, a library that implements two data structures for efficient language model queries, reducing both time and costs.",
            "KenLM: Faster and Smaller Language Model Queries"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.08652933685732783,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.08652933685732783,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.368590733672213
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.368590733672213,
                1.0
            ]
        ]
    },
    "D09-1092": {
        "input_sentences": [
            "Meanwhile, massive collections of interlinked documents in dozens of languages, such as Wikipedia, are now widely available, calling for tools that can characterize content in many languages.",
            "We explore the model\u2019s characteristics using two large corpora, each with over ten different languages, and demonstrate its usefulness in supporting machine translation and tracking topic trends across languages.",
            "Topic models are a useful tool for analyzing large text collections, but have previously been applied in only monolingual, or at most bilingual, contexts.",
            "Abstract",
            "Polylingual Topic Models",
            "We introduce a polylingual topic model that discovers topics aligned across multiple languages."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.13161452296986548,
                0.054097090116774924,
                0.0,
                0.0,
                0.09707033339965308
            ],
            [
                0.13161452296986548,
                1.0,
                0.07688447168563078,
                0.0,
                0.068377968249451,
                0.18733356376193128
            ],
            [
                0.054097090116774924,
                0.07688447168563078,
                1.0,
                0.0,
                0.23322753292515866,
                0.03896540412920627
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.068377968249451,
                0.23322753292515866,
                0.0,
                1.0,
                0.2935628177359411
            ],
            [
                0.09707033339965308,
                0.18733356376193128,
                0.03896540412920627,
                0.0,
                0.2935628177359411,
                1.0
            ]
        ]
    },
    "P13-1155": {
        "input_sentences": [
            "We show that the proposed approach has a very high precision of (92.43) and a reasonable recall of (56.4).",
            "We introduce a social media text normalization system that can be deployed as a preprocessing step for Machine Translation and various NLP applications to handle social media text.",
            "The proposed approach uses Random Walks on a contextual similarity bipartite graph constructed from n-gram sequences on large unlabeled text corpus.",
            "Social Text Normalization using Contextual Graph Random Walks",
            "Abstract",
            "The proposed approach is domain and language independent and can be deployed as a preprocessing step for any NLP application to handle social media text.",
            "When used as a preprocessing step for a state-of-the-art machine translation system, the translation quality on social media text improved by 6%.",
            "The proposed system is based on unsupervised learning of the normalization equivalences from unlabeled text."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.09225663607694415,
                0.0,
                0.0,
                0.10802648750383795,
                0.0,
                0.058912023043353585
            ],
            [
                0.0,
                1.0,
                0.0392218837094729,
                0.228856880264927,
                0.0,
                0.5060214410802711,
                0.46984647067645635,
                0.1179734685020534
            ],
            [
                0.09225663607694415,
                0.0392218837094729,
                1.0,
                0.3847111610290877,
                0.0,
                0.10842786314698247,
                0.021399820099649705,
                0.1568223096794174
            ],
            [
                0.0,
                0.228856880264927,
                0.3847111610290877,
                1.0,
                0.0,
                0.0959735992034558,
                0.08911254188675241,
                0.14276993885429187
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.10802648750383795,
                0.5060214410802711,
                0.10842786314698247,
                0.0959735992034558,
                0.0,
                1.0,
                0.22285025774113773,
                0.08838312963650624
            ],
            [
                0.0,
                0.46984647067645635,
                0.021399820099649705,
                0.08911254188675241,
                0.0,
                0.22285025774113773,
                1.0,
                0.03144127694318666
            ],
            [
                0.058912023043353585,
                0.1179734685020534,
                0.1568223096794174,
                0.14276993885429187,
                0.0,
                0.08838312963650624,
                0.03144127694318666,
                1.0
            ]
        ]
    },
    "P08-1043": {
        "input_sentences": [
            "Using a treebank grammar, a data-driven lexicon, and a linguistically motivated unknown-tokens handling technique our model outperforms previous pipelined, integrated or factorized systems for Hebrew morphological and syntactic processing, yielding an error reduction of 12% over the best published results so far.",
            "A Single Generative Model for Joint Morphological Segmentation and Syntactic Parsing",
            "Morphological processes in Semitic languages deliver space-delimited words which introduce multiple, distinct, syntactic units into the structure of the input sentence.",
            "Abstract",
            "These words are in turn highly ambiguous, breaking the assumption underlying most parsers that the yield of a tree for a given sentence is known in advance.",
            "Here we propose a single joint model for performing both morphological segmentation and syntactic disambiguation which bypasses the associated circularity."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.09604468891830532,
                0.034764289943667565,
                0.0,
                0.0,
                0.07220874904808894
            ],
            [
                0.09604468891830532,
                1.0,
                0.08235276508092304,
                0.0,
                0.0,
                0.4626878962536718
            ],
            [
                0.034764289943667565,
                0.08235276508092304,
                1.0,
                0.0,
                0.09821935144927076,
                0.06191482542259787
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.09821935144927076,
                0.0,
                1.0,
                0.0
            ],
            [
                0.07220874904808894,
                0.4626878962536718,
                0.06191482542259787,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "N12-1052": {
        "input_sentences": [
            "Specifically, we show that by augmenting direct-transfer systems with cross-lingual cluster features, the relative error of delexicalized dependency parsers, trained on English treebanks and transferred to foreign languages, can be reduced by up to 13%.",
            "When applying the same method to direct transfer of named-entity recognizers, we observe relative improvements of up to 26%.",
            "It has been established that incorporating word cluster features derived from large unlabeled corpora can significantly improve prediction of linguistic structure.",
            "While previous work has focused primarily on English, we extend these results to other languages along two dimensions.",
            "Abstract",
            "Cross-lingual Word Clusters for Direct Transfer of Linguistic Structure",
            "Second, and more interestingly, we provide an algorithm for inducing cross-lingual clusters and we show that features derived from these clusters significantly improve the accuracy of cross-lingual structure prediction.",
            "First, we show that these results hold true for a number of languages across families."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.1310985477099124,
                0.08664432268218127,
                0.10188787230211573,
                0.0,
                0.22538423301182633,
                0.14914749789825882,
                0.053564239877775574
            ],
            [
                0.1310985477099124,
                1.0,
                0.0,
                0.0,
                0.0,
                0.15417041554023989,
                0.0,
                0.0
            ],
            [
                0.08664432268218127,
                0.0,
                1.0,
                0.0,
                0.0,
                0.2679318402419458,
                0.2836852466233723,
                0.0
            ],
            [
                0.10188787230211573,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.19038705179470286
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.22538423301182633,
                0.15417041554023989,
                0.2679318402419458,
                0.0,
                0.0,
                1.0,
                0.45065542992094054,
                0.0
            ],
            [
                0.14914749789825882,
                0.0,
                0.2836852466233723,
                0.0,
                0.0,
                0.45065542992094054,
                1.0,
                0.0
            ],
            [
                0.053564239877775574,
                0.0,
                0.0,
                0.19038705179470286,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P07-1051": {
        "input_sentences": [
            "Is the End of Supervised Parsing in Sight?",
            "How far can we get with unsupervised parsing if we make our training corpus several orders of magnitude larger than has hitherto be attempted?",
            "We train both on Penn\u2019s WSJ data and on the (much larger) NANC corpus, showing that U-DOP* outperforms a treebank-PCFG on the standard WSJ test set.",
            "Abstract",
            "We present a new algorithm for unsupervised parsing using an all-subtrees model, termed U-DOP*, which parses directly with packed forests of all binary trees.",
            "While U-DOP* performs worse than state-of-the-art supervised parsers on handannotated sentences, we show that the model outperforms supervised parsers when evaluated as a language model in syntax-based machine translation on Europarl.",
            "We argue that supervised parsers miss the fluidity between constituents and non-constituents and that in the field of syntax-based language modeling the end of supervised parsing has come in sight."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.08211089481596957,
                0.0,
                0.0,
                0.06682881616569034,
                0.14687208863154474,
                0.43913295366315486
            ],
            [
                0.08211089481596957,
                1.0,
                0.11014619833552818,
                0.0,
                0.09205995694446105,
                0.0,
                0.02949112089896079
            ],
            [
                0.0,
                0.11014619833552818,
                1.0,
                0.0,
                0.03274898474036551,
                0.06425378466671507,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.06682881616569034,
                0.09205995694446105,
                0.03274898474036551,
                0.0,
                1.0,
                0.10928267559117975,
                0.02400237753460082
            ],
            [
                0.14687208863154474,
                0.0,
                0.06425378466671507,
                0.0,
                0.10928267559117975,
                1.0,
                0.2860006210415143
            ],
            [
                0.43913295366315486,
                0.02949112089896079,
                0.0,
                0.0,
                0.02400237753460082,
                0.2860006210415143,
                1.0
            ]
        ]
    },
    "P13-2112": {
        "input_sentences": [
            "Although accuracy does not increase much in later iterations, they may still have some benefit as the vocabulary size continues to grow.",
            "In of the sixth conference on Applied natural language processing pages 224\u2013231.",
            "On individual languages, self training and revision and the method of Das and Petrov are split \u2014 each performs better on half of the cases.",
            "Abstract",
            "The poor performance on unknown words is expected because we do not use any language-specific rules to handle this case.",
            "We exemplify this in Figure 1 (right panel) for Dutch.",
            "Figure 1: Overall accuracy, accuracy on known tokens, accuracy on unknown tokens, and proportion of known tokens for Italian (left) and Dutch (right).",
            "Table 2 shows results for our seed model, self training and revision, and the results reported by Das and Petrov.",
            "P103/12/G084).",
            "Given the improvements of our model over that of Das and Petrov on languages from the same family as our source language, and the observation of Snyder et al. (2008) that a better tagger can be learned from a more-closely related language, we also plan to consider strategies for selecting an appropriate source language for a given target language.",
            "Finally, we thank Siva Reddy and Spandana Gella for many discussions and suggestions.",
            "The average accuracy of self training and revision is on par with that reported by Das and Petrov.",
            "We would like to thank Prokopis Prokopidis for providing us the Greek Treebank and Antonia Marti for the Spanish CoNLL 06 dataset.",
            "In of re-implemented label propagation from Das and Petrov (2011).",
            "2009.",
            "In many cases, GS outperformed other methods, thus we would like to try GS first for our model.",
            "Pascal Denis and Benoit Sagot.",
            "(Findings are similar for other languages.)",
            "References Thorsten Brants.",
            "We find that for all languages, accuracy rises quickly in the first 5\u20136 iterations, and then subsequently improves only slightly.",
            "TnT: A statistical part-oftagger.",
            "Our model performs poorly on unknown words as indicated by the low accuracy on unknown words, and high accuracy on known words compared to the overall accuracy.",
            "Unsupervised part-of-speech tagging with bilingual projections.",
            "Compared to Das and Petrov, our model performs poorest on Italian, in terms of percentage point difference in accuracy.",
            "Dipanjan Das and Slav Petrov.",
            "Figure 1 (left panel) shows accuracy, accuracy on known words, accuracy on unknown words, and proportion of known tokens for each iteration of our model for Italian; iteration 0 is the seed model, and iteration 31 is the final model.",
            "We examine the impact of self-training and revision over training iterations.",
            "2000.",
            "This might be because selftraining with revision already found the local maximal point. the 49th Annual Meeting of the Association for Computational Linguistics: Human Language - Volume 1 (ACL pages 600\u2013609.",
            "Seattle, Washington, USA.",
            "It took over a day to complete this step on an eight core Intel Xeon 3.16GHz CPU with 32 Gb Ram, but only 15 minutes for our model. in fact have tried EM, but it did not help.",
            "One way to improve the performance of our tagger might be to reduce the proportion of unknown words by using a larger training corpus, as Das and Petrov did.",
            "Interestingly, our method achieves higher accuracies on Germanic languages \u2014 the family of our source language, English \u2014 while Das and Petrov perform better on Romance languages.",
            "Simpler unsupervised POS tagging with bilingual projections",
            "7 Acknowledgements This work is funded by Erasmus Mundus European Masters Program in Language and Communication Technologies (EM-LCT) and by the Czech Science Foundation (grant no.",
            "Portland, Oregon, USA.",
            "Coupling an annotated corpus and a morphosyntactic lexicon for state-of-the-art POS tagging with less effort.",
            "6 Conclusion We have proposed a method for unsupervised POS tagging that performs on par with the current stateof-the-art (Das and Petrov, 2011), but is substantially less-sophisticated (specifically not requiring convex optimization or a feature-based HMM). complexity of our algorithm is to that of Das and Petrov 637 where the size of training We our code are available for In future work we intend to consider using a larger training corpus to reduce the proportion of unknown tokens and improve accuracy.",
            "Self training and revision improve the accuracy for every language over the seed model, and gives an average improvement of roughly two percentage points.",
            "In of the 23rd Pacific Asia Conference on Language, Information",
            "2011.",
            "Using our final model with unsupervised HMM methods might improve the final performance too, i.e. use our final model as the initial state for HMM, then experiment with different inference algorithms such as Expectation Maximization (EM), Variational Bayers (VB) or Gibbs Gao and Johnson (2008) compare EM, VB and GS for unsupervised English POS tagging.",
            "This might be because our model relies on alignments, which might be more accurate for more-related languages, whereas Das and Petrov additionally rely on label propagation.",
            "The overall performance dropped slightly.",
            "Moreover, on average for the final model, approximately 10% of the test data tokens are unknown."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.09070355583884175,
                0.0,
                0.0,
                0.0,
                0.0,
                0.05713507201895293,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.141788613942896,
                0.0,
                0.08926914928084569,
                0.0,
                0.04405921457450315,
                0.0,
                0.07059745117073112,
                0.09927522117076713,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.06493605963471134,
                0.04090083667379303,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                1.0,
                0.0,
                0.0,
                0.04796205659778813,
                0.0,
                0.0,
                0.0,
                0.0,
                0.10110971554045894,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.10578008238368444,
                0.0,
                0.0,
                0.0,
                0.03843302699175461,
                0.0,
                0.035814771527909676,
                0.0,
                0.0,
                0.0,
                0.046667008057666534,
                0.18819656383951613,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.233080126337122,
                0.0,
                0.11117600049851044,
                0.0,
                0.33211360454490607,
                0.0,
                0.111342950253068,
                0.0,
                0.09913777529200142,
                0.0,
                0.10632987570296495,
                0.0,
                0.06644841197060346,
                0.0,
                0.04968548713600954,
                0.0,
                0.15155704220942065,
                0.13634484824621496,
                0.0,
                0.28121593778916465,
                0.0,
                0.041249745188589884,
                0.0,
                0.0,
                0.12080700935999836,
                0.2784500387036231,
                0.0,
                0.0,
                0.0,
                0.0,
                0.19508397166685815,
                0.16534871751800959,
                0.0,
                0.0,
                0.0,
                0.1305605813971831,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.04796205659778813,
                0.0,
                0.0,
                1.0,
                0.0,
                0.03582672041097661,
                0.0,
                0.0,
                0.09620237343045628,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.21556090984411377,
                0.0,
                0.0,
                0.0,
                0.10435417395559152,
                0.0,
                0.0,
                0.03344498998221597,
                0.0,
                0.0,
                0.1792963901504284,
                0.03656768684354663,
                0.0,
                0.03407650794424143,
                0.0,
                0.0,
                0.024193943618503418,
                0.044402033098879495,
                0.05950299952943608,
                0.0,
                0.07451511580279034,
                0.0,
                0.11531362755421255,
                0.05708653516419446
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.27553903223297016,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.13925613589830663,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.09070355583884175,
                0.0,
                0.0,
                0.0,
                0.03582672041097661,
                0.27553903223297016,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.12333447378807408,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.10712860467035715,
                0.0,
                0.3627075051878079,
                0.0,
                0.15398188915341873,
                0.0,
                0.5080434508232073,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.08170998206643944,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.1569165798707006,
                0.08829048411772128,
                0.0,
                0.0,
                0.0,
                0.0,
                0.09483662830791574,
                0.20995689157753775
            ],
            [
                0.0,
                0.0,
                0.233080126337122,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.05459916505889382,
                0.0,
                0.42714988543201765,
                0.0,
                0.10334818883163978,
                0.0,
                0.03633053470642247,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.02444498396730018,
                0.0,
                0.1085844462847365,
                0.12655487474280236,
                0.14866422062328372,
                0.26102378080556055,
                0.0,
                0.03828788841429091,
                0.0,
                0.023705504185451504,
                0.11213269979954354,
                0.05534347642641864,
                0.0,
                0.0,
                0.0,
                0.0,
                0.11324928119716388,
                0.25955904558068704,
                0.0,
                0.0,
                0.03216685091560606,
                0.10349414887544764,
                0.0,
                0.039576674924692155
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.10110971554045894,
                0.11117600049851044,
                0.0,
                0.09620237343045628,
                0.0,
                0.0,
                0.05459916505889382,
                0.0,
                1.0,
                0.0,
                0.051865212756990305,
                0.0,
                0.05710007038320639,
                0.0,
                0.020072689345100068,
                0.0,
                0.054529212425908316,
                0.0,
                0.034076778024562944,
                0.0,
                0.013505900014590953,
                0.0,
                0.05999311255933476,
                0.06992180837270341,
                0.03204294398943426,
                0.0,
                0.0,
                0.0705060137790527,
                0.0,
                0.013097336032310591,
                0.08318463919904592,
                0.3030771575070263,
                0.0,
                0.07183732869814709,
                0.0,
                0.0,
                0.06054077676164528,
                0.11216893479212123,
                0.12543939486745861,
                0.0,
                0.04027936211780113,
                0.13429220439089942,
                0.0,
                0.02186618797369152
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.08190215034278438,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.05713507201895293,
                0.0,
                0.33211360454490607,
                0.0,
                0.0,
                0.0,
                0.12333447378807408,
                0.42714988543201765,
                0.0,
                0.051865212756990305,
                0.0,
                1.0,
                0.0,
                0.14725982886425487,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.06748137365205366,
                0.0,
                0.12138403450934353,
                0.0,
                0.1630569501944479,
                0.18032680985752106,
                0.09599512842023288,
                0.37193024595279445,
                0.0,
                0.054556039725545985,
                0.0,
                0.0,
                0.15977679308408305,
                0.078858381162189,
                0.0,
                0.0,
                0.0,
                0.0,
                0.24966483075195395,
                0.3775816210694709,
                0.0,
                0.0,
                0.0,
                0.09831187060715597,
                0.0,
                0.12165027912925375
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.08190215034278438,
                0.0,
                1.0,
                0.0,
                0.0,
                0.08086191124963885,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.111342950253068,
                0.0,
                0.0,
                0.0,
                0.0,
                0.10334818883163978,
                0.0,
                0.05710007038320639,
                0.0,
                0.14725982886425487,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.11355813809042822,
                0.19852754837982925,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.10421038501258616,
                0.08681771220652762,
                0.0,
                0.0,
                0.0,
                0.0,
                0.16200862517602027,
                0.0,
                0.0,
                0.4181706810613262,
                0.0,
                0.3823756623760705,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.09913777529200142,
                0.0,
                0.0,
                0.0,
                0.0,
                0.03633053470642247,
                0.0,
                0.020072689345100068,
                0.0,
                0.0,
                0.08086191124963885,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.02696066333755999,
                0.0,
                0.03991969209844506,
                0.0,
                0.06396456543511536,
                0.0,
                0.0,
                0.0,
                0.0,
                0.02614508229770233,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0370580552185211,
                0.0,
                0.0,
                0.17026424536891416,
                0.038048308928746215,
                0.0,
                0.04364958512928506
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.10632987570296495,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.054529212425908316,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.12215122766088321,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.16581771053765484,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.10336155182557294,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.141788613942896,
                0.0,
                0.06644841197060346,
                0.0,
                0.0,
                0.0,
                0.10712860467035715,
                0.0,
                0.0,
                0.034076778024562944,
                0.0,
                0.06748137365205366,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.12215122766088321,
                0.0,
                1.0,
                0.0,
                0.10543444867319697,
                0.0,
                0.05203767522217858,
                0.0,
                0.083381587053122,
                0.11725246958632564,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.10362396710223111,
                0.0,
                0.0,
                0.0,
                0.0,
                0.024114807715132698,
                0.04830736261871309,
                0.0,
                0.0,
                0.0,
                0.06459342618638117,
                0.1827729531987195,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.08926914928084569,
                0.0,
                0.04968548713600954,
                0.0,
                0.21556090984411377,
                0.0,
                0.3627075051878079,
                0.02444498396730018,
                0.0,
                0.013505900014590953,
                0.0,
                0.12138403450934353,
                0.0,
                0.0,
                0.0,
                0.02696066333755999,
                0.0,
                0.0,
                0.0,
                0.10543444867319697,
                0.0,
                1.0,
                0.0,
                0.23917009130027997,
                0.0,
                0.4567905789547513,
                0.0,
                0.0,
                0.0,
                0.0,
                0.017591706886661788,
                0.20733826729608223,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.10111290976477026,
                0.11182873423925337,
                0.0,
                0.0,
                0.0238708195509115,
                0.025600787581628006,
                0.09333686040659102,
                0.11019052384188976
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.6821576976823215,
                0.0,
                0.0,
                0.09542952299555654,
                0.09615100177027228,
                0.0,
                0.0,
                0.0,
                0.14098119210199575,
                0.0,
                0.0,
                0.0
            ],
            [
                0.04405921457450315,
                0.0,
                0.15155704220942065,
                0.0,
                0.0,
                0.0,
                0.15398188915341873,
                0.1085844462847365,
                0.0,
                0.05999311255933476,
                0.0,
                0.1630569501944479,
                0.0,
                0.11355813809042822,
                0.0,
                0.03991969209844506,
                0.0,
                0.0,
                0.0,
                0.05203767522217858,
                0.0,
                0.23917009130027997,
                0.0,
                1.0,
                0.13905745329965813,
                0.1835745970085889,
                0.0,
                0.0,
                0.07043571688490859,
                0.0,
                0.02604741261774867,
                0.07299355109902433,
                0.060810955755342296,
                0.0,
                0.0,
                0.0,
                0.0,
                0.12989965292905944,
                0.17331811991175286,
                0.0,
                0.0,
                0.03534467066625858,
                0.1137185177835588,
                0.0,
                0.04348652421552913
            ],
            [
                0.0,
                0.0,
                0.13634484824621496,
                0.0,
                0.0,
                0.0,
                0.0,
                0.12655487474280236,
                0.0,
                0.06992180837270341,
                0.0,
                0.18032680985752106,
                0.0,
                0.19852754837982925,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.13905745329965813,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.12761067582569455,
                0.10631250356648787,
                0.0,
                0.0,
                0.0,
                0.0,
                0.12888138193568255,
                0.0,
                0.0,
                0.0,
                0.0,
                0.13253862101296573,
                0.0,
                0.0
            ],
            [
                0.07059745117073112,
                0.0,
                0.0,
                0.0,
                0.10435417395559152,
                0.13925613589830663,
                0.5080434508232073,
                0.14866422062328372,
                0.0,
                0.03204294398943426,
                0.0,
                0.09599512842023288,
                0.0,
                0.0,
                0.0,
                0.06396456543511536,
                0.0,
                0.0,
                0.0,
                0.083381587053122,
                0.0,
                0.4567905789547513,
                0.0,
                0.1835745970085889,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.041736580149332674,
                0.13714963084541518,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.08499085958755534,
                0.17041508075476947,
                0.0,
                0.0,
                0.11771943172971427,
                0.060738240448787686,
                0.0,
                0.19556192557649058
            ],
            [
                0.09927522117076713,
                0.0,
                0.28121593778916465,
                0.0,
                0.0,
                0.0,
                0.0,
                0.26102378080556055,
                0.0,
                0.0,
                0.0,
                0.37193024595279445,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.11725246958632564,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.051045524642274895,
                0.0,
                0.0,
                0.1218599688619304,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.1230734112796111,
                0.2662507931855356,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.10578008238368444,
                0.041249745188589884,
                0.0,
                0.03344498998221597,
                0.0,
                0.0,
                0.03828788841429091,
                0.0,
                0.0705060137790527,
                0.0,
                0.054556039725545985,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.07043571688490859,
                0.0,
                0.0,
                0.051045524642274895,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.02680018943943174,
                0.0,
                0.024974422698578212,
                0.0,
                0.0,
                0.0,
                0.07159652935799214,
                0.04360931186121037,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.2891473410216564,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.023705504185451504,
                0.0,
                0.013097336032310591,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.02614508229770233,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.017591706886661788,
                0.0,
                0.02604741261774867,
                0.0,
                0.041736580149332674,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.06054312747366323,
                0.0,
                0.0,
                0.04003175615700063,
                0.0,
                0.0,
                0.0,
                0.024180207921136055,
                0.0,
                0.0,
                0.07308532994364707,
                0.02482634384129499,
                0.0,
                0.028481150396957117
            ],
            [
                0.0,
                0.0,
                0.12080700935999836,
                0.0,
                0.1792963901504284,
                0.0,
                0.08170998206643944,
                0.11213269979954354,
                0.0,
                0.08318463919904592,
                0.0,
                0.15977679308408305,
                0.0,
                0.10421038501258616,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.20733826729608223,
                0.0,
                0.07299355109902433,
                0.12761067582569455,
                0.13714963084541518,
                0.1218599688619304,
                0.0,
                0.0,
                0.0,
                0.06054312747366323,
                1.0,
                0.055805186830389895,
                0.0,
                0.0,
                0.0,
                0.07690064187840952,
                0.3599267424697228,
                0.11053612838693776,
                0.0,
                0.0,
                0.09617705093610689,
                0.06957170849847515,
                0.11091495090648071,
                0.054908950307551115
            ],
            [
                0.0,
                0.03843302699175461,
                0.2784500387036231,
                0.0,
                0.03656768684354663,
                0.0,
                0.0,
                0.05534347642641864,
                0.0,
                0.3030771575070263,
                0.0,
                0.078858381162189,
                0.0,
                0.08681771220652762,
                0.0,
                0.0,
                0.0,
                0.16581771053765484,
                0.0,
                0.10362396710223111,
                0.0,
                0.0,
                0.0,
                0.060810955755342296,
                0.10631250356648787,
                0.0,
                0.0,
                0.0,
                0.02680018943943174,
                0.0,
                0.0,
                0.055805186830389895,
                1.0,
                0.0,
                0.027306238358139317,
                0.0,
                0.0,
                0.08675643598275248,
                0.03558030363228244,
                0.04768103265844199,
                0.0,
                0.034220909070646136,
                0.14564442856842033,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.6821576976823215,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.18811489281328797,
                0.1364731170820657,
                0.0,
                0.0,
                0.0,
                0.17614389477686285,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.035814771527909676,
                0.0,
                0.0,
                0.03407650794424143,
                0.0,
                0.0,
                0.0,
                0.0,
                0.07183732869814709,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.024974422698578212,
                0.0,
                0.04003175615700063,
                0.0,
                0.027306238358139317,
                0.0,
                1.0,
                0.0,
                0.0,
                0.03325698459180172,
                0.03315639035554597,
                0.04443275548510048,
                0.0,
                0.05432052919517385,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.2891473410216564,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.09542952299555654,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.07690064187840952,
                0.0,
                0.18811489281328797,
                0.0,
                0.0,
                1.0,
                0.14861394974524295,
                0.0,
                0.0,
                0.0,
                0.1052670547309224,
                0.0,
                0.0,
                0.0
            ],
            [
                0.06493605963471134,
                0.0,
                0.19508397166685815,
                0.0,
                0.024193943618503418,
                0.0,
                0.1569165798707006,
                0.11324928119716388,
                0.0,
                0.06054077676164528,
                0.0,
                0.24966483075195395,
                0.0,
                0.16200862517602027,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.024114807715132698,
                0.0,
                0.10111290976477026,
                0.09615100177027228,
                0.12989965292905944,
                0.12888138193568255,
                0.08499085958755534,
                0.1230734112796111,
                0.0,
                0.0,
                0.0,
                0.0,
                0.3599267424697228,
                0.08675643598275248,
                0.1364731170820657,
                0.03325698459180172,
                0.0,
                0.14861394974524295,
                1.0,
                0.09923339498413002,
                0.0,
                0.13573535688119404,
                0.13470365657701658,
                0.07026448121909039,
                0.0,
                0.06574684619148864
            ],
            [
                0.04090083667379303,
                0.046667008057666534,
                0.16534871751800959,
                0.0,
                0.044402033098879495,
                0.0,
                0.08829048411772128,
                0.25955904558068704,
                0.0,
                0.11216893479212123,
                0.0,
                0.3775816210694709,
                0.0,
                0.0,
                0.0,
                0.0370580552185211,
                0.0,
                0.0,
                0.0,
                0.04830736261871309,
                0.0,
                0.11182873423925337,
                0.0,
                0.17331811991175286,
                0.0,
                0.17041508075476947,
                0.2662507931855356,
                0.0,
                0.07159652935799214,
                0.0,
                0.024180207921136055,
                0.11053612838693776,
                0.03558030363228244,
                0.0,
                0.03315639035554597,
                0.0,
                0.0,
                0.09923339498413002,
                1.0,
                0.05789632796154076,
                0.0,
                0.06376161152514,
                0.03518887454508236,
                0.0,
                0.12745403240708386
            ],
            [
                0.0,
                0.18819656383951613,
                0.0,
                0.0,
                0.05950299952943608,
                0.0,
                0.0,
                0.0,
                0.0,
                0.12543939486745861,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.04360931186121037,
                0.0,
                0.0,
                0.0,
                0.04768103265844199,
                0.0,
                0.04443275548510048,
                0.0,
                0.0,
                0.0,
                0.05789632796154076,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.4181706810613262,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.13573535688119404,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.07451511580279034,
                0.0,
                0.0,
                0.03216685091560606,
                0.0,
                0.04027936211780113,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.17026424536891416,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0238708195509115,
                0.14098119210199575,
                0.03534467066625858,
                0.0,
                0.11771943172971427,
                0.0,
                0.0,
                0.0,
                0.0,
                0.07308532994364707,
                0.09617705093610689,
                0.034220909070646136,
                0.17614389477686285,
                0.05432052919517385,
                0.0,
                0.1052670547309224,
                0.13470365657701658,
                0.06376161152514,
                0.0,
                0.0,
                1.0,
                0.033687758542280524,
                0.05370683235338853,
                0.16370194144341657
            ],
            [
                0.0,
                0.0,
                0.1305605813971831,
                0.0,
                0.0,
                0.0,
                0.0,
                0.10349414887544764,
                0.0,
                0.13429220439089942,
                0.0,
                0.09831187060715597,
                0.0,
                0.3823756623760705,
                0.0,
                0.038048308928746215,
                0.0,
                0.10336155182557294,
                0.0,
                0.06459342618638117,
                0.0,
                0.025600787581628006,
                0.0,
                0.1137185177835588,
                0.13253862101296573,
                0.060738240448787686,
                0.0,
                0.0,
                0.0,
                0.0,
                0.02482634384129499,
                0.06957170849847515,
                0.14564442856842033,
                0.0,
                0.0,
                0.0,
                0.0,
                0.07026448121909039,
                0.03518887454508236,
                0.0,
                0.0,
                0.033687758542280524,
                1.0,
                0.0,
                0.04144793260202287
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.11531362755421255,
                0.0,
                0.09483662830791574,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.1827729531987195,
                0.0,
                0.09333686040659102,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.11091495090648071,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.05370683235338853,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.05708653516419446,
                0.0,
                0.20995689157753775,
                0.039576674924692155,
                0.0,
                0.02186618797369152,
                0.0,
                0.12165027912925375,
                0.0,
                0.0,
                0.0,
                0.04364958512928506,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.11019052384188976,
                0.0,
                0.04348652421552913,
                0.0,
                0.19556192557649058,
                0.0,
                0.0,
                0.0,
                0.0,
                0.028481150396957117,
                0.054908950307551115,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.06574684619148864,
                0.12745403240708386,
                0.0,
                0.0,
                0.16370194144341657,
                0.04144793260202287,
                0.0,
                1.0
            ]
        ]
    },
    "W06-3120": {
        "input_sentences": [
            "We have studied different techniques to improve the standard Phrase-Based translation system.",
            "Mainly we introduce two reordering approaches and add morphological information.",
            "Abstract",
            "This paper reports translation results for the \u201cExploiting Parallel Texts for Statistical Machine Translation\u201d (HLT-NAACL Workshop on Parallel Texts 2006).",
            "TALP Phrase-Based Statistical Translation System For European Language Pairs"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0,
                0.07829590496171927,
                0.266273569273078
            ],
            [
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.07829590496171927,
                0.0,
                0.0,
                1.0,
                0.1387454185427328
            ],
            [
                0.266273569273078,
                0.0,
                0.0,
                0.1387454185427328,
                1.0
            ]
        ]
    },
    "W05-1518": {
        "input_sentences": [
            "We were able to significantly improve over the best parsing result for the given setting, known so far.",
            "We differ from them in exploring context features more deeply.",
            "Improving Parsing Accuracy By Combining Diverse Dependency Parsers",
            "All our experiments were conducted on Czech but the method is language-independent.",
            "This paper explores the possibilities of improving parsing results by combining outputs of several parsers.",
            "Abstract",
            "To some extent, we are porting the ideas of Henderson and Brill (1999) to the world of dependency structures.",
            "Moreover, our experiments show that even parsers far below the state of the art can contribute to the total improvement."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.07585422909713817,
                0.0,
                0.06308343369529341,
                0.0,
                0.0,
                0.0878578179586461
            ],
            [
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.07585422909713817,
                0.0,
                1.0,
                0.0,
                0.3955170755124895,
                0.0,
                0.10488517001957286,
                0.08753377505266655
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.11174927650196473
            ],
            [
                0.06308343369529341,
                0.0,
                0.3955170755124895,
                0.0,
                1.0,
                0.0,
                0.0,
                0.07279661477492955
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.10488517001957286,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0878578179586461,
                0.0,
                0.08753377505266655,
                0.11174927650196473,
                0.07279661477492955,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "W10-1401": {
        "input_sentences": [
            "Thereis ample evidence that the application of read ily available statistical parsing models to suchlanguages is susceptible to serious performance degradation.",
            "In this paper we re view the current state-of-affairs with respectto parsing MRLs and point out central challenges.",
            "The overarching analysis suggests itself as a source of directions for future investigations.",
            "We synthesize the contributions of re searchers working on parsing Arabic, Basque, French, German, Hebrew, Hindi and Korean to point out shared solutions across languages.",
            "The first workshop on statistical parsing of MRLs hosts a variety of contributions which show that despite languagespecific idiosyncrasies, the problems associ ated with parsing MRLs cut across languagesand parsing frameworks.",
            "The term Morphologically Rich Languages(MRLs) refers to languages in which signif icant information concerning syntactic units and relations is expressed at word-level.",
            "Statistical Parsing of Morphologically Rich Languages (SPMRL) What How and Whither",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.028465050396028826,
                0.0,
                0.023296892625919413,
                0.09616812655274914,
                0.0,
                0.1205267608668863,
                0.0
            ],
            [
                0.028465050396028826,
                1.0,
                0.0,
                0.08727918262112203,
                0.15129947842325242,
                0.042305429656200294,
                0.05255731553153129,
                0.0
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.023296892625919413,
                0.08727918262112203,
                0.0,
                1.0,
                0.10245772919668522,
                0.06924878322585963,
                0.11442878978091929,
                0.0
            ],
            [
                0.09616812655274914,
                0.15129947842325242,
                0.0,
                0.10245772919668522,
                1.0,
                0.061339427938562355,
                0.17756295882104614,
                0.0
            ],
            [
                0.0,
                0.042305429656200294,
                0.0,
                0.06924878322585963,
                0.061339427938562355,
                1.0,
                0.3155333178385339,
                0.0
            ],
            [
                0.1205267608668863,
                0.05255731553153129,
                0.0,
                0.11442878978091929,
                0.17756295882104614,
                0.3155333178385339,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P13-1007": {
        "input_sentences": [
            "Plurality, Negation, and Quantification:Towards Comprehensive Quantifier Scope Disambiguation",
            "We give an algorithm for finding a guaranteed approximation of the optimal solution, which works very well in practice.",
            "We also present a general model for learning to build partial orders from a set of pairpreferences.",
            "No corpusbased method, however, has yet addressed QSD when incorporating the implicit universal of plurals and/or operators such as negation.",
            "In this paper we report early, though promising, results for automatic QSD when handling both phenomena.",
            "Abstract",
            "Recent work on statistical quantifier scope disambiguation (QSD) has improved upon earlier work by scoping an arbitrary number and type of noun phrases.",
            "Finally, we significantly improve the performance of the previous model using a rich set of automatically generated features."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0,
                0.09594169584755254,
                0.0,
                0.0,
                0.21437443106287143,
                0.0
            ],
            [
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.143480755608925
            ],
            [
                0.09594169584755254,
                0.0,
                0.0,
                1.0,
                0.05898197511222707,
                0.0,
                0.04222482903920795,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.05898197511222707,
                1.0,
                0.0,
                0.04393024758751845,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.21437443106287143,
                0.0,
                0.0,
                0.04222482903920795,
                0.04393024758751845,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.143480755608925,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P04-1013": {
        "input_sentences": [
            "One problem is that much of the work on discriminative methods conflates changes to the learning method with changes to the parameterization of the problem.",
            "We show how a parser can be trained with a discriminative learning method while still parameterizing the problem according to a generative probability model.",
            "Discriminative methods have shown significant improvements over traditional generative methods in many machine learning applications, but there has been difficulty in extending them to natural language parsing.",
            "Abstract",
            "We present three methods for training a neural network to estimate the probabilities for a statistical parser, one generative, one discriminative, and one where the probability model is generative but the training criteria is discriminative.",
            "The latter model outperforms the previous two, achieving state-ofthe-art levels of performance (90.1% F-measure on constituents).",
            "Discriminative Training Of A Neural Network Statistical Parser"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.3075690772939663,
                0.1389597322183653,
                0.0,
                0.08408054228891987,
                0.0,
                0.04509334888344975
            ],
            [
                0.3075690772939663,
                1.0,
                0.1263719841254611,
                0.0,
                0.32106965935346116,
                0.05466806724710594,
                0.1553109194729801
            ],
            [
                0.1389597322183653,
                0.1263719841254611,
                1.0,
                0.0,
                0.18210153279473695,
                0.0,
                0.04084698877051038
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.08408054228891987,
                0.32106965935346116,
                0.18210153279473695,
                0.0,
                1.0,
                0.039388235096239226,
                0.6380754849050481
            ],
            [
                0.0,
                0.05466806724710594,
                0.0,
                0.0,
                0.039388235096239226,
                1.0,
                0.0
            ],
            [
                0.04509334888344975,
                0.1553109194729801,
                0.04084698877051038,
                0.0,
                0.6380754849050481,
                0.0,
                1.0
            ]
        ]
    },
    "W12-3160": {
        "input_sentences": [
            "However, these methods have not yet met with wide-spread adoption.",
            "Large-Margin Learning",
            "Optimization Strategies for Online Large-Margin Learning in Machine Translation",
            "The introduction of large-margin based dis criminative methods for optimizing statistical machine translation systems in recent years has allowed exploration into many new types of features for the translation process.",
            "Abstract",
            "Thismay be partly due to the perceived complex ity of implementation, and partly due to the lack of standard methodology for applying these methods to MT. This papers aims to shedlight on large-margin learning for MT, explic itly presenting the simple passive-aggressivealgorithm which underlies many previous ap proaches, with direct application to MT, andempirically comparing several widespread op timization strategies.",
            "By removing the limitation on the number of parameters which can be optimized, these methods have allowed integrating millions of sparse features."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0,
                0.0416426585340159,
                0.0,
                0.027234798567015748,
                0.05805060997985027
            ],
            [
                0.0,
                1.0,
                0.4866908078138695,
                0.15512525670944652,
                0.0,
                0.16875002732283834,
                0.0
            ],
            [
                0.0,
                0.4866908078138695,
                1.0,
                0.2811269516216097,
                0.0,
                0.12695701341466215,
                0.0
            ],
            [
                0.0416426585340159,
                0.15512525670944652,
                0.2811269516216097,
                1.0,
                0.0,
                0.039266086962272115,
                0.12921163167387764
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.027234798567015748,
                0.16875002732283834,
                0.12695701341466215,
                0.039266086962272115,
                0.0,
                1.0,
                0.01824587558308581
            ],
            [
                0.05805060997985027,
                0.0,
                0.0,
                0.12921163167387764,
                0.0,
                0.01824587558308581,
                1.0
            ]
        ]
    },
    "W04-1505": {
        "input_sentences": [
            "We show that DG allows for the expression of the majority of English LDDs in a context-free way and offers simple yet powerful statistical models.",
            "We present and evaluate an implemented statistical minimal parsing strategy exploiting DG charateristics to permit fast, robust, deeplinguistic analysis of unrestricted text, and compare its probability model to (Collins, 1999) and an adaptation, (Dubey and Keller, 2003).",
            "Abstract",
            "Fast Deep-Linguistic Statistical Dependency Parsing"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.05786375218384446,
                0.0,
                0.052338609028865876
            ],
            [
                0.05786375218384446,
                1.0,
                0.0,
                0.15535740157354963
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.052338609028865876,
                0.15535740157354963,
                0.0,
                1.0
            ]
        ]
    },
    "N06-1045": {
        "input_sentences": [
            "This redundancy leads to misrepresentation of tree weight and reduced information for debugging and tuning purposes. is due to nondeterminism in the weighted automata that produce the results.",
            "We also demonstrate our algorithm\u2019s effectiveness on two large-scale tasks.",
            "Ranked lists of output trees from syntactic statistical NLP applications frequently contain multiple repeated entries.",
            "A Better N-Best List: Practical Determinization Of Weighted Finite Tree Automata",
            "Abstract",
            "We introduce an algorithm that determinizes such automata while preserving proper weights, returning the sum of the weight of all multiply derived trees."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0,
                0.17751249265257416,
                0.0,
                0.0924594168011026
            ],
            [
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.08326729380678478
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.05570945812052304
            ],
            [
                0.17751249265257416,
                0.0,
                0.0,
                1.0,
                0.0,
                0.05053610460098275
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0924594168011026,
                0.08326729380678478,
                0.05570945812052304,
                0.05053610460098275,
                0.0,
                1.0
            ]
        ]
    },
    "E09-1034": {
        "input_sentences": [
            "Parsing Mildly Non-Projective Dependency Structures",
            "We present parsing algorithms for various mildly non-projective dependency formalisms.",
            "The third case includes all the degree in a number of dependency treebanks.",
            "In particular, algorithms are presented for: all well-nested structures of degree at most with the same complexity as the best existing parsers for constituency formalisms of equivalent generative power; all well-nested structures with degree bounded by any constant and a new class of structures with gap deup to includes some ill-nested structures.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.6292214704307451,
                0.10693767167847647,
                0.2113800349448257,
                0.0
            ],
            [
                0.6292214704307451,
                1.0,
                0.0816373962851974,
                0.08068492332362451,
                0.0
            ],
            [
                0.10693767167847647,
                0.0816373962851974,
                1.0,
                0.13997323099569697,
                0.0
            ],
            [
                0.2113800349448257,
                0.08068492332362451,
                0.13997323099569697,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P10-1044": {
        "input_sentences": [
            "We present which utilizes LinkLDA (Erosheva et al., 2004) to model selectional preferences.",
            "We also evaleffectiveness at filtering improper applications of inference rules, where we show substantial improvement Pantel system (Pantel et al.,",
            "A Latent Dirichlet Allocation Method for Selectional Preferences",
            "By simultaneously inferring latent topics and topic distributions over relations, the benefits of previous approaches: like traditional classbased approaches, it produces humaninterpretable classes describing each relation\u2019s preferences, but it is competitive with non-class-based methods in predictive power. compare several state-ofthe-art methods achieving an 85% increase in recall at 0.9 precision over mutual information (Erk, 2007).",
            "computation of preferthe admissible argument values for a relation, is a well-known NLP task with applicability.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.12629737234531183,
                0.17989332340527617,
                0.024838524342442686,
                0.0,
                0.0
            ],
            [
                0.12629737234531183,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.17989332340527617,
                0.0,
                1.0,
                0.0792100098042098,
                0.0,
                0.0
            ],
            [
                0.024838524342442686,
                0.0,
                0.0792100098042098,
                1.0,
                0.03266017357834997,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.03266017357834997,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P06-1109": {
        "input_sentences": [
            "An All-Subtrees Approach To Unsupervised Parsing",
            "To the best of our knowledge this is the first paper which tests a maximum likelihood estimator for DOP on the Wall Street Journal, leading the surprising result that unsupervised parsing model beats a widely used supervised model (a treebank PCFG).",
            "Abstract",
            "We investigate generalizations of the allsubtrees &quot;DOP&quot; approach to unsupervised parsing.",
            "We report state-ofthe-art results on English (WSJ), German (NEGRA) and Chinese (CTB) data.",
            "We will test both a relative frequency estimator for unsupervised DOP and a maximum likelihood estimator which is known to be statistically consistent.",
            "Unsupervised DOP models assign all possible binary trees to a set of sentences and next use (a large random subset of) all subtrees from these binary trees to compute the most probable parse trees."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.11182235227494688,
                0.0,
                0.33809637698629663,
                0.0,
                0.060097762178551575,
                0.12952586974535968
            ],
            [
                0.11182235227494688,
                1.0,
                0.0,
                0.0818052041812729,
                0.0,
                0.21624841817457072,
                0.027096044186571827
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.33809637698629663,
                0.0818052041812729,
                0.0,
                1.0,
                0.0,
                0.06853321380136415,
                0.04387747133088673
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.060097762178551575,
                0.21624841817457072,
                0.0,
                0.06853321380136415,
                0.0,
                1.0,
                0.03973970290745381
            ],
            [
                0.12952586974535968,
                0.027096044186571827,
                0.0,
                0.04387747133088673,
                0.0,
                0.03973970290745381,
                1.0
            ]
        ]
    },
    "P11-2121": {
        "input_sentences": [
            "The bootstrapping technique gives a significant improvement to parsing accuracy, showing near state-of-theart performance with respect to other parsing approaches evaluated on the same data set.",
            "This paper suggests two ways of improving transition-based, non-projective dependency parsing.",
            "The new addition to the algorithm shows a clear advantage in parsing speed.",
            "First, we add a transition to an existing non-projective parsing algorithm, so it can perform either projective or non-projective parsing as needed.",
            "Second, we present a bootstrapping technique that narrows down discrepancies between gold-standard and automatic parses used as features.",
            "Getting the Most out of Transition-based Dependency Parsing",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0521072643931925,
                0.0541950497038431,
                0.07317608677480973,
                0.10044691648347362,
                0.08038586824213408,
                0.0
            ],
            [
                0.0521072643931925,
                1.0,
                0.04010867640945497,
                0.4213511766092257,
                0.0,
                0.44390446181839444,
                0.0
            ],
            [
                0.0541950497038431,
                0.04010867640945497,
                1.0,
                0.12296927058602616,
                0.0,
                0.0618756485254685,
                0.0
            ],
            [
                0.07317608677480973,
                0.4213511766092257,
                0.12296927058602616,
                1.0,
                0.0,
                0.15576902824672947,
                0.0
            ],
            [
                0.10044691648347362,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.08038586824213408,
                0.44390446181839444,
                0.0618756485254685,
                0.15576902824672947,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "N12-1090": {
        "input_sentences": [
            "To build a coreference resolver for a new language, the typical approach is to first coreference-annotate documents from this target language and then train a resolver on these annotated documents using supervised learning techniques.",
            "However, the high cost associated with manually coreference-annotating documents needed by a supervised approach makes it difficult to deploy coreference technologies across a large number of natural languages.",
            "Translation-Based Projection for Multilingual Coreference Resolution",
            "Experimental results on two target languages demonstrate the promise of our approach.",
            "Abstract",
            "To alleviate this corpus annotation bottleneck, we examine a translation-based projection approach to multilingual coreference resolution."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.19314427420401145,
                0.07650331850165208,
                0.08989428388126203,
                0.0,
                0.07344939346168315
            ],
            [
                0.19314427420401145,
                1.0,
                0.08917349539203005,
                0.10478221947042012,
                0.0,
                0.08561379137117253
            ],
            [
                0.07650331850165208,
                0.08917349539203005,
                1.0,
                0.0,
                0.0,
                0.6400540952577286
            ],
            [
                0.08989428388126203,
                0.10478221947042012,
                0.0,
                1.0,
                0.0,
                0.04897390032354159
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.07344939346168315,
                0.08561379137117253,
                0.6400540952577286,
                0.04897390032354159,
                0.0,
                1.0
            ]
        ]
    },
    "E09-1018": {
        "input_sentences": [
            "Our program significantly outperforms all of them.",
            "We have compared it to several systems available on the web (all we have found so far).",
            "While EM frequently fails to find good models for the tasks to which it is set, in this case it works quite well.",
            "EM Works for Pronoun Anaphora Resolution",
            "We present an algorithm for pronounanaphora (in English) that uses Expectation Maximization (EM) to learn virtually all of its parameters in an unsupervised fashion.",
            "The algorithm is fast and robust, and has been made publically available for downloading.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.13721137870372932,
                0.0
            ],
            [
                0.0,
                0.0,
                1.0,
                0.19208695904323586,
                0.04755314207065487,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.19208695904323586,
                1.0,
                0.07041419189977115,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.04755314207065487,
                0.07041419189977115,
                1.0,
                0.08509151865760584,
                0.0
            ],
            [
                0.0,
                0.13721137870372932,
                0.0,
                0.0,
                0.08509151865760584,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P12-1099": {
        "input_sentences": [
            "Mixing Multiple Translation Models in Statistical Machine Translation",
            "Our experimental results show that ensemble decoding outperforms various strong baselines including mixture models, the current state-of-the-art for domain adaptation in machine translation.",
            "We propose a novel approach, ensemble decoding, which combines a number of translation systems dynamically at the decoding step.",
            "In this paper, we evaluate performance on a domain adaptation setting where we translate sentences from the medical domain.",
            "Abstract",
            "Statistical machine translation is often faced with the problem of combining training data from many diverse sources into a single translation model which then has to translate sentences in a new domain."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.20946443823555969,
                0.08991503566526544,
                0.0,
                0.0,
                0.2950496791282229
            ],
            [
                0.20946443823555969,
                1.0,
                0.17873249133676067,
                0.14088836287521986,
                0.0,
                0.11318239477858229
            ],
            [
                0.08991503566526544,
                0.17873249133676067,
                1.0,
                0.0,
                0.0,
                0.054228771051092896
            ],
            [
                0.0,
                0.14088836287521986,
                0.0,
                1.0,
                0.0,
                0.2031925018588875
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.2950496791282229,
                0.11318239477858229,
                0.054228771051092896,
                0.2031925018588875,
                0.0,
                1.0
            ]
        ]
    },
    "W99-0613": {
        "input_sentences": [
            "The first method uses a similar algorithm to that of (Yarowsky 95), with modifications motivated by (Blum and Mitchell 98).",
            "The approach gains leverage from natural redundancy in the data: for many named-entity instances both the spelling of the name and the context in which it appears are sufficient to determine its type.",
            "We present two algorithms.",
            "Unsupervised Models for Named Entity Classification Collins",
            "Abstract",
            "A large number of rules is needed for coverage of the domain, suggesting that a fairly large number of labeled examples should be required to train a classi- However, we show that the use of data can reduce the requirements for supervision to just 7 simple &quot;seed&quot; rules.",
            "The second algorithm extends ideas from boosting algorithms, designed for supervised learning tasks, to the framework suggested by (Blum and Mitchell 98).",
            "This paper discusses the use of unlabeled examples for the problem of named entity classification."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.24403252043743348,
                0.0
            ],
            [
                0.0,
                1.0,
                0.0,
                0.12946096103744403,
                0.0,
                0.032921701835538185,
                0.0,
                0.10547843178746845
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.14644803232993356,
                0.0
            ],
            [
                0.0,
                0.12946096103744403,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.29999688581755607
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.032921701835538185,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.09128298762907389
            ],
            [
                0.24403252043743348,
                0.0,
                0.14644803232993356,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.10547843178746845,
                0.0,
                0.29999688581755607,
                0.0,
                0.09128298762907389,
                0.0,
                1.0
            ]
        ]
    },
    "E03-1005": {
        "input_sentences": [
            "An Efficient Implementation of a New DOP Model",
            "Two apparently opposing DOP models exist in the literature: one which computes the parse tree involving the most frequent subtrees from a treebank and one which computes the parse tree involving the fewest subtrees from a treebank.",
            "Together with a PCFGreduction of DOP we obtain improved accuracy and efficiency on the Wall Street Journal treebank Our results show an 11% relative reduction in error rate over previous models, and an average processing time of 3.6 seconds per WSJ sentence.",
            "This paper proposes an integration of the two models which outperforms each of them separately.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.039151837335847796,
                0.04478316447511461,
                0.0,
                0.0
            ],
            [
                0.039151837335847796,
                1.0,
                0.0852565832391971,
                0.03537696649082205,
                0.0
            ],
            [
                0.04478316447511461,
                0.0852565832391971,
                1.0,
                0.04046534254315847,
                0.0
            ],
            [
                0.0,
                0.03537696649082205,
                0.04046534254315847,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P13-2083": {
        "input_sentences": [
            "In this paper we present a novel approach to modelling distributional semantics that represents meaning as distributions over relations in syntactic neighborhoods.",
            "We argue that our model approximates meaning in compositional configurations more effectively than standard distributional vectors or bag-of-words models.",
            "Abstract",
            "We test our hypothesis on the problem of judging event coreferentiality, which involves compositional interactions in the predicate-argument structure of sentences, and demonstrate that our model outperforms both state-of-the-art window-based word embeddings as well as simple approaches to compositional semantics previously employed in the literature.",
            "A Structured Distributional Semantic Model for Event Co-reference"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0958418685907325,
                0.0,
                0.0356609107029053,
                0.06135399677050564
            ],
            [
                0.0958418685907325,
                1.0,
                0.0,
                0.09822673917852053,
                0.12569305457401644
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0356609107029053,
                0.09822673917852053,
                0.0,
                1.0,
                0.0968172452833018
            ],
            [
                0.06135399677050564,
                0.12569305457401644,
                0.0,
                0.0968172452833018,
                1.0
            ]
        ]
    },
    "N12-1086": {
        "input_sentences": [
            "To achieve compactness, we induce sparse measures at graph vertices by incorporating sparsity-inducing penalties in Gaussian and entropic pairwise Markovnetworks constructed from labeled and unla beled data.",
            "Graph-Based Lexicon Expansion with Sparsity-Inducing Penalties",
            "Sparse measures are desirable forhigh-dimensional multi-class learning problems such as the induction of labels on natu ral language types, which typically associate with only a few labels.",
            "We present novel methods to construct compact natural language lexicons within a graph based semi-supervised learning framework, an attractive platform suited for propagating soft labels onto new natural language types from seed data.",
            "Abstract",
            "Compared to standard graph-based learning methods, for two lexicon expansion problems, our approach producessignificantly smaller lexicons and obtains bet ter predictive performance."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.27747188603023437,
                0.07932604995406119,
                0.04878206211956929,
                0.0,
                0.02203577413780586
            ],
            [
                0.27747188603023437,
                1.0,
                0.0,
                0.08060402657942886,
                0.0,
                0.2774231416195876
            ],
            [
                0.07932604995406119,
                0.0,
                1.0,
                0.18760537572526317,
                0.0,
                0.07395054637918091
            ],
            [
                0.04878206211956929,
                0.08060402657942886,
                0.18760537572526317,
                1.0,
                0.0,
                0.1376511951298103
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.02203577413780586,
                0.2774231416195876,
                0.07395054637918091,
                0.1376511951298103,
                0.0,
                1.0
            ]
        ]
    },
    "W08-0406": {
        "input_sentences": [
            "We present a novel approach to word reordering which successfully integrates syntactic structural knowledge with phrase-based SMT.",
            "Unlike previous approaches, this makes it possible to successfully integrate syntactic reordering with phrase-based SMT.",
            "This is done by constructing a lattice of alternatives based on automatically learned probabilistic syntactic rules.",
            "Manual evaluation supports the claim that the present approach is significantly superior to previous approaches.",
            "On an English- Danish task, we achieve an absolute improvement in translation quality of 1.1 % BLEU.",
            "Abstract",
            "In decoding, the alternatives are scored based on the output word order, not the order of the input.",
            "Syntactic Reordering Integrated with Phrase-Based SMT"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.3420345967244699,
                0.08729059382979974,
                0.15693056016884827,
                0.0,
                0.0,
                0.1082050814940026,
                0.41815733136806116
            ],
            [
                0.3420345967244699,
                1.0,
                0.09086961280669914,
                0.16336490123880237,
                0.0,
                0.0,
                0.03487803364934749,
                0.4353022831736816
            ],
            [
                0.08729059382979974,
                0.09086961280669914,
                1.0,
                0.0,
                0.0,
                0.0,
                0.11980566766514912,
                0.14522536998578014
            ],
            [
                0.15693056016884827,
                0.16336490123880237,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.1082050814940026,
                0.03487803364934749,
                0.11980566766514912,
                0.0,
                0.0,
                0.0,
                1.0,
                0.055741134848651626
            ],
            [
                0.41815733136806116,
                0.4353022831736816,
                0.14522536998578014,
                0.0,
                0.0,
                0.0,
                0.055741134848651626,
                1.0
            ]
        ]
    },
    "P09-2003": {
        "input_sentences": [
            "Experiments show that, compared to previous approaches, the constraint propagation helps to considerably decrease the number of items in the chart.",
            "We present a CYK and an Earley-style algorithm for parsing Range Concatenation Grammar (RCG), using the deductive parsing framework.",
            "Abstract",
            "An Earley Parsing Algorithm for Range Concatenation Grammars",
            "The characteristic property of the Earley parser is that we use a technique of range boundary constraint propagation to compute the yields of non-terminals as late as possible."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0,
                0.0,
                0.10276703756906368
            ],
            [
                0.0,
                1.0,
                0.0,
                0.49864143077017503,
                0.06653209209897797
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.49864143077017503,
                0.0,
                1.0,
                0.12132806386411743
            ],
            [
                0.10276703756906368,
                0.06653209209897797,
                0.0,
                0.12132806386411743,
                1.0
            ]
        ]
    },
    "N12-1049": {
        "input_sentences": [
            "While most approaches to the task have used regular expressions and similar linear pattern interpretation rules, the possibility of phrasal embedding and modification in time expressions motivates our use of a comof time This is used to construct a parse which evaluates to the time the phrase would represent, as a logical parse might evaluate to a concrete entity.",
            "In this way, we can employ a loosely supervised EM-style bootstrapping approach to learn these latent parses while capturing both syntactic uncertainty and pragmatic ambiguity in a probabilistic framework.",
            "Abstract",
            "We present a probabilistic approach for learning to interpret temporal phrases given only a corpus of utterances and the times they reference.",
            "Parsing Time: Learning to Interpret Time Expressions",
            "We achieve an accuracy of 72% on an adapted TempEval-2 task \u2013 comparable to state of the art systems."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0,
                0.0,
                0.35867855172004304,
                0.03443898511151448
            ],
            [
                0.0,
                1.0,
                0.0,
                0.09876543571051094,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.09876543571051094,
                0.0,
                1.0,
                0.17218195895375613,
                0.0
            ],
            [
                0.35867855172004304,
                0.0,
                0.0,
                0.17218195895375613,
                1.0,
                0.0
            ],
            [
                0.03443898511151448,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "D07-1013": {
        "input_sentences": [
            "We show that, in spite of similar performance overall, the two models produce different types of errors, in a way that can be explained by theoretical properties of the two models.",
            "We present a comparative error analysisof the two dominant approaches in datadriven dependency parsing: global, exhaus tive, graph-based models, and local, greedy, transition-based models.",
            "Characterizing the Errors of Data-Driven Dependency Parsing Models",
            "Abstract",
            "This analysisleads to new directions for parser develop ment."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.10652630837470763,
                0.18164671435914218,
                0.0,
                0.0
            ],
            [
                0.10652630837470763,
                1.0,
                0.2059922956891051,
                0.0,
                0.0
            ],
            [
                0.18164671435914218,
                0.2059922956891051,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "C10-1045": {
        "input_sentences": [
            "Better Arabic Parsing: Baselines Evaluations and Analysis",
            "Third,we develop a human interpretable grammar that is competitive with a latent vari able PCFG.",
            "First, we identify sources of syntactic ambiguity under studied in the existing parsing literature.",
            "Fourth, we show how to build better models for three different parsers.Finally, we show that in application set tings, the absence of gold segmentation lowers parsing performance by 2?5% F1.",
            "Abstract",
            "In this paper, we offer broad insightinto the underperformance of Arabic constituency parsing by analyzing the inter play of linguistic phenomena, annotationchoices, and model design.",
            "Second, we show that although the PennArabic Treebank is similar to other tree banks in gross statistical terms, annotation consistency remains problematic."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.06404475072342918,
                0.12220903679007672,
                0.0,
                0.1261990130060454,
                0.0
            ],
            [
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.06404475072342918,
                0.0,
                1.0,
                0.03484880854200166,
                0.0,
                0.03598657969943479,
                0.0
            ],
            [
                0.12220903679007672,
                0.0,
                0.03484880854200166,
                1.0,
                0.0,
                0.02438739859798149,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.1261990130060454,
                0.0,
                0.03598657969943479,
                0.02438739859798149,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "H05-1094": {
        "input_sentences": [
            "On two standard text data sets, we show that joint decoding outperforms cascaded decoding.",
            "Many learning tasks have subtasks for which much training data exists.",
            "Therefore, we wantto transfer learning from the old, general purpose subtask to a more specific new task, for which there is often less data.",
            "Abstract",
            "Composition Of Conditional Random Fields For Transfer Learning",
            "Specifically, we perform joint decoding ofseparately-trained sequence models, preserv ing uncertainty between the tasks and allowinginformation from the new task to affect predic tions on the old task.",
            "While work in transfer learning often considers how the old task should affect learning on the new task, in this paper we show that it helps to take into account how the new task affects the old."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.07870671042336533,
                0.0598882306781799,
                0.0,
                0.0,
                0.16389370522638824,
                0.0
            ],
            [
                0.07870671042336533,
                1.0,
                0.14694183616355166,
                0.0,
                0.08031530805255507,
                0.07643085021558825,
                0.08541562943612103
            ],
            [
                0.0598882306781799,
                0.14694183616355166,
                1.0,
                0.0,
                0.14218604311112398,
                0.1699627481771582,
                0.409882330183191
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.08031530805255507,
                0.14218604311112398,
                0.0,
                1.0,
                0.0,
                0.13747523492032995
            ],
            [
                0.16389370522638824,
                0.07643085021558825,
                0.1699627481771582,
                0.0,
                0.0,
                1.0,
                0.326659227326244
            ],
            [
                0.0,
                0.08541562943612103,
                0.409882330183191,
                0.0,
                0.13747523492032995,
                0.326659227326244,
                1.0
            ]
        ]
    },
    "E09-1038": {
        "input_sentences": [
            "Lexical probabilities for rare events are estimated in a semi-supervised manner from a lexicon and large unannotated corpora.",
            "We present a framework for interfacing a PCFG parser with lexical information from an external resource following a different tagging scheme than the treebank.",
            "This is achieved by defining a stochastic mapping layer between the two resources.",
            "Abstract",
            "Enhancing Unlexicalized Parsing Performance Using a Wide Coverage Lexicon Fuzzy Tag-Set Mapping and EM-HMM-Based Lexical Probabilities",
            "We show that this solution greatly enhances the performance of an unlexicalized Hebrew PCFG parser, resulting in state-of-the-art Hebrew parsing results both when a segmentation oracle is assumed, and in a real-word parsing scenario of parsing unsegmented tokens."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.04068115708228679,
                0.0,
                0.0,
                0.14553621826234303,
                0.0
            ],
            [
                0.04068115708228679,
                1.0,
                0.0,
                0.0,
                0.03513168186144273,
                0.07130067824641996
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.07410839552271431,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.14553621826234303,
                0.03513168186144273,
                0.07410839552271431,
                0.0,
                1.0,
                0.1675547438929288
            ],
            [
                0.0,
                0.07130067824641996,
                0.0,
                0.0,
                0.1675547438929288,
                1.0
            ]
        ]
    },
    "C10-2096": {
        "input_sentences": [
            "More importantly,our model takes into account all the probabilities of different steps, such as segmen tation, parsing, and translation.",
            "The main advantage of our model is that we can make global decision to search for the best segmentation, parse-tree and translation in one step.",
            "In order to alleviate this problem, we use compact structures, lattice and forest, in each module insteadof 1-best results.",
            "Medium-scale experiments show an improvement of +0.9 BLEU points over a state-of-the-art forest-based baseline.",
            "Abstract",
            "We integrate both lat tice and forest into a single tree-to-stringsystem, and explore the algorithms of lattice parsing, lattice-forest-based rule ex traction and decoding.",
            "Machine Translation with Lattices and Forests",
            "Traditional 1-best translation pipelinessuffer a major drawback: the errors of 1 best outputs, inevitably introduced by each module, will propagate and accumulate along the pipeline."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.10477654927162382,
                0.0,
                0.0,
                0.0,
                0.052852370800175096,
                0.06960719161947129,
                0.03407492410719467
            ],
            [
                0.10477654927162382,
                1.0,
                0.048064285053167476,
                0.0,
                0.0,
                0.04917188864698301,
                0.06475995349920069,
                0.11417972813044201
            ],
            [
                0.0,
                0.048064285053167476,
                1.0,
                0.05059342988670058,
                0.0,
                0.17864338991728462,
                0.0,
                0.14354040450072186
            ],
            [
                0.0,
                0.0,
                0.05059342988670058,
                1.0,
                0.0,
                0.12884212387253305,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.052852370800175096,
                0.04917188864698301,
                0.17864338991728462,
                0.12884212387253305,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.06960719161947129,
                0.06475995349920069,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.057853263790342946
            ],
            [
                0.03407492410719467,
                0.11417972813044201,
                0.14354040450072186,
                0.0,
                0.0,
                0.0,
                0.057853263790342946,
                1.0
            ]
        ]
    },
    "E12-1047": {
        "input_sentences": [
            "There have been some results on an a manner that minimizes parsing complexity, but the present work shows that parsing long sentences with such an optimally binarized grammar remains infeasible.",
            "The resulting parser has been applied to a discontinuous treebank with favorable results.",
            "Abstract",
            "Efficient parsing with Linear Context-Free Rewriting Systems",
            "Previous work on treebank parsing with discontinuous constituents using Linear Rewriting systems has been limited to sentences of up to 30 words, for reasons of computational complexity.",
            "Linear Context-Free Rewriting Systems",
            "Instead, we introduce a technique which removes this length restriction, while maintaining a respectable accuracy."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0727889899304163,
                0.0,
                0.12501454347317423,
                0.21802615859352312,
                0.0,
                0.0
            ],
            [
                0.0727889899304163,
                1.0,
                0.0,
                0.0,
                0.1525032133594692,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.12501454347317423,
                0.0,
                0.0,
                1.0,
                0.2619231234634759,
                0.8109710326710888,
                0.0
            ],
            [
                0.21802615859352312,
                0.1525032133594692,
                0.0,
                0.2619231234634759,
                1.0,
                0.24223102266746363,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.8109710326710888,
                0.24223102266746363,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P05-1039": {
        "input_sentences": [
            "What To Do When Lexicalization Fails: Parsing German With Suffix Analysis And Smoothing",
            "In addition to the high accuracy of the model, the use of smoothing in an unlexicalized parser allows us to better examine the interplay between smoothing and parsing results.",
            "Abstract",
            "In this paper, we present an unlexicalized parser for German which employs smoothing and suffix analysis to achieve labelled bracket of 76.2, higher than previously reported results on the NEGRA corpus."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.17929008377668199,
                0.0,
                0.25568845451102185
            ],
            [
                0.17929008377668199,
                1.0,
                0.0,
                0.1841865488459004
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.25568845451102185,
                0.1841865488459004,
                0.0,
                1.0
            ]
        ]
    },
    "A00-2005": {
        "input_sentences": [
            "Bagging and boosting, two effective machine learning techniques, are applied to natural language parsing.",
            "Abstract",
            "Experiments using these techniques with a trainable statistical parser are described.",
            "The best resulting system provides roughly as large of a gain in F-measure as doubling the corpus size.",
            "Bagging And Boosting A Treebank Parser",
            "Error analysis of the result of the boosting technique reveals some inconsistent annotations in the Penn Treebank, suggesting a semi-automatic method for finding inconsistent treebank annotations."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0898661226995404,
                0.0,
                0.24537991376743748,
                0.034268493532312705
            ],
            [
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0898661226995404,
                0.0,
                1.0,
                0.0,
                0.16895096685987404,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.24537991376743748,
                0.0,
                0.16895096685987404,
                0.0,
                1.0,
                0.24519658672093742
            ],
            [
                0.034268493532312705,
                0.0,
                0.0,
                0.0,
                0.24519658672093742,
                1.0
            ]
        ]
    },
    "D07-1091": {
        "input_sentences": [
            "Factored Translation Models",
            "We present an extension of phrase-based statistical machine translation models that enables the straight-forward integration of additional annotation at the word-level ?may it be linguistic markup or automatically generated word classes.",
            "Abstract",
            "In a num ber of experiments we show that factoredtranslation models lead to better translation performance, both in terms of auto matic scores, as well as more grammatical coherence."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.12663001672534585,
                0.0,
                0.1627318523151344
            ],
            [
                0.12663001672534585,
                1.0,
                0.0,
                0.04589664083340155
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.1627318523151344,
                0.04589664083340155,
                0.0,
                1.0
            ]
        ]
    },
    "E06-1010": {
        "input_sentences": [
            "In particular, we define a new measure the non-projectivity in an acyclic dependency graph obeying the single-head constraint.",
            "The constraints are evaluated experimentally using data from the Prague Dependency Treebank and the Danish Dependency Treebank.",
            "We investigate a series of graph-theoretic constraints on non-projective dependency and their effect on i.e. whether they allow naturally occurring syntactic constructions to be adequately and i.e. whether they reduce the search space for the parser.",
            "The results indicate that, whereas complete linguistic coverage in principle requires unrestricted non-projective dependency graphs, limiting the degree of non-projectivity to at most 2 can reduce average running time from quadratic to linear, while excluding less than 0.5% of the dependency graphs found in the two treebanks.",
            "Constraints On Non-Projective Dependency Parsing",
            "Abstract",
            "This is a substantial improvement over the commonly used projective approximation (degree 0), which excludes 15\u201325% of the graphs."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.05129100981074695,
                0.102484553057344,
                0.12498347321662312,
                0.1262625585338991,
                0.0,
                0.0
            ],
            [
                0.05129100981074695,
                1.0,
                0.07963776422979703,
                0.06976879402634241,
                0.19891845469741057,
                0.0,
                0.0
            ],
            [
                0.102484553057344,
                0.07963776422979703,
                1.0,
                0.12353594111367149,
                0.24357229018595836,
                0.0,
                0.030435994975001514
            ],
            [
                0.12498347321662312,
                0.06976879402634241,
                0.12353594111367149,
                1.0,
                0.22033921561666306,
                0.0,
                0.16026068232914603
            ],
            [
                0.1262625585338991,
                0.19891845469741057,
                0.24357229018595836,
                0.22033921561666306,
                1.0,
                0.0,
                0.07602274054474525
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.030435994975001514,
                0.16026068232914603,
                0.07602274054474525,
                0.0,
                1.0
            ]
        ]
    },
    "W12-3117": {
        "input_sentences": [
            "In total, more than 300 features were extracted and used to train classifiers in order to predict the translation quality of unseen data.",
            "In this paper, we focus on a subset of our feature set that we consider to be relatively novel: features based on a topic model built using the Latent Dirichlet Allocation approach, and features based on source and target language syntax extracted using part-of-speech (POS) taggers and parsers.",
            "DCU-Symantec Submission for the WMT 2012 Quality Estimation Task",
            "Two sets features are proposed: one i.e. respecting the data limitation suggested by the organisers, and one i.e. using data or tools trained on data that was not provided by the workshop organisers.",
            "We evaluate nine feature combinations using four classification-based and four regression-based machine learning techniques.",
            "This paper describes the features and the machine learning methods used by Dublin City (DCU) and the WMT 2012 quality estimation task.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0807645462152195,
                0.06237700103028172,
                0.16497880754310057,
                0.0,
                0.14268497348725223,
                0.0
            ],
            [
                0.0807645462152195,
                1.0,
                0.0,
                0.07272416348566986,
                0.2557058695268642,
                0.0802739372163283,
                0.0
            ],
            [
                0.06237700103028172,
                0.0,
                1.0,
                0.0,
                0.0,
                0.4862784798342898,
                0.0
            ],
            [
                0.16497880754310057,
                0.07272416348566986,
                0.0,
                1.0,
                0.03495679968365924,
                0.025433517597516324,
                0.0
            ],
            [
                0.0,
                0.2557058695268642,
                0.0,
                0.03495679968365924,
                1.0,
                0.12880732829201122,
                0.0
            ],
            [
                0.14268497348725223,
                0.0802739372163283,
                0.4862784798342898,
                0.025433517597516324,
                0.12880732829201122,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "N01-1023": {
        "input_sentences": [
            "We propose a novel Co-Training method for statistical parsing.",
            "The algorithm takes as input a small corpus (9695 sentences) annotated with parse trees, a dictionary of possible lexicalized structures for each word in the training set and a large pool of unlabeled text.",
            "Applying Co-Training Methods To Statistical Parsing",
            "Using empirical results based on parsing the Wall Street Journal corpus we show that training a statistical parser on the combined labeled and unlabeled data strongly outperforms training only on the labeled data.",
            "The algorithm iteratively labels the entire data set with parse trees.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.03953421072961048,
                0.34692615700469626,
                0.17309329184377167,
                0.0,
                0.0
            ],
            [
                0.03953421072961048,
                1.0,
                0.045111716240822254,
                0.10328206497924951,
                0.24868667338512895,
                0.0
            ],
            [
                0.34692615700469626,
                0.045111716240822254,
                1.0,
                0.1975133769142783,
                0.0,
                0.0
            ],
            [
                0.17309329184377167,
                0.10328206497924951,
                0.1975133769142783,
                1.0,
                0.11525383770882917,
                0.0
            ],
            [
                0.0,
                0.24868667338512895,
                0.0,
                0.11525383770882917,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "W09-1207": {
        "input_sentences": [
            "2008.",
            "dependency parser.",
            "Bilexical grammars and their cubicparsing algorithms.",
            "In Jason Eisner.",
            "Multilingual Dependency-based Syntactic and Semantic Parsing",
            "2000.",
            "In EMNLP/CoNLL- Chang and Chih-Jen Lin, 2001. a for support vector Wanxiang Che, Zhenghua Li, Yuxuan Hu, Yongqiang Li, Bing Qin, Ting Liu, and Sheng Li.",
            "A cascaded syntactic and semantic dependency parsing system.",
            "Abstract",
            "In in Probabilistic"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                1.0,
                0.0,
                0.0,
                0.20426973400040402,
                0.0,
                0.0,
                0.2300858752242662,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.20426973400040402,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.6492129958573976,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.2300858752242662,
                0.0,
                0.0,
                0.6492129958573976,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "N09-1061": {
        "input_sentences": [
            "The parsing complexity of an is exponential in both the of a production, defined as the number of nonterminals on its right-hand side, and a measure for the discontinuity of a phrase, In this paper, we present an algorithm that transforms an LCFRS into a strongly equivalent form in which productions have rank at most and has minimal fan-out.",
            "Linear Context-free Rewriting Systems (LCFRS) is an expressive grammar formalism with applications in syntax-based machine translation.",
            "Our results generalize previous work on Synchronous Context-Free Grammar, and are particularly relevant for machine translation from or to languages that require syntactic analyses with discontinuous constituents.",
            "Abstract",
            "Optimal Reduction of Rule Length in Linear Context-Free Rewriting Systems"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.04139724142839572,
                0.0,
                0.0,
                0.0
            ],
            [
                0.04139724142839572,
                1.0,
                0.2213958601220332,
                0.0,
                0.3367773551240035
            ],
            [
                0.0,
                0.2213958601220332,
                1.0,
                0.0,
                0.08609064791129394
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.3367773551240035,
                0.08609064791129394,
                0.0,
                1.0
            ]
        ]
    },
    "E09-1055": {
        "input_sentences": [
            "Our second contribution is an algorithm that computes this transformation for a large, empirically relevant class of grammars.",
            "For efficient parsing, the extracted grammars need to be transformed in order to minimize the number of nonterminal symbols per production.",
            "Treebank Grammar Techniques for Non-Projective Dependency Parsing",
            "In this paper, we provide two key tools for this approach.",
            "Abstract",
            "First, we show how to reduce nonprojective dependency parsing to parsing with Linear Context-Free Rewriting Systems (LCFRS), by presenting a technique for extracting LCFRS from dependency treebanks.",
            "We propose to attack this problem using chart-parsing algorithms developed for mildly contextsensitive grammar formalisms.",
            "An open problem in dependency parsing is the accurate and efficient treatment of non-projective structures."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.06887110984006725,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.06887110984006725,
                1.0,
                0.04326749888472311,
                0.0,
                0.0,
                0.04491988007591836,
                0.02938725336276652,
                0.11236681622949254
            ],
            [
                0.0,
                0.04326749888472311,
                1.0,
                0.0,
                0.0,
                0.17593711701605116,
                0.13973612149588505,
                0.36470051035126083
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.04491988007591836,
                0.17593711701605116,
                0.0,
                0.0,
                1.0,
                0.04491988007591836,
                0.14147733230359855
            ],
            [
                0.0,
                0.02938725336276652,
                0.13973612149588505,
                0.0,
                0.0,
                0.04491988007591836,
                1.0,
                0.11236681622949254
            ],
            [
                0.0,
                0.11236681622949254,
                0.36470051035126083,
                0.0,
                0.0,
                0.14147733230359855,
                0.11236681622949254,
                1.0
            ]
        ]
    },
    "W11-2138": {
        "input_sentences": [
            "We also provide a description of the systems we",
            "We use target-side monolingual data to extend the vocabulary of the translation model in statistical machine translation.",
            "We empirically evaluate the gains for several pairs of European languages and discuss some approaches of the underlying back-off techniques needed to translate unseen forms of known words.",
            "Abstract",
            "Improving Translation Model by Monolingual Data",
            "This method called \u201creverse self-training\u201d improves the decoder\u2019s ability to produce grammatically correct translations into languages with morphology richer than the source language esp. in small-data setting."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                1.0,
                0.0,
                0.0,
                0.5226601274035401,
                0.03292816764221489
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.037837176350990764
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.5226601274035401,
                0.0,
                0.0,
                1.0,
                0.057098837973667944
            ],
            [
                0.0,
                0.03292816764221489,
                0.037837176350990764,
                0.0,
                0.057098837973667944,
                1.0
            ]
        ]
    },
    "D12-1127": {
        "input_sentences": [
            "We achieve highest accuracy reported for several languages and show that our approach yields better out-of-domain taggers than those trained using fully supervised Penn",
            "However, parallel text is not always available and techniques for using it require multiple complex algorithmic steps.",
            "Despite significant recent work, purely unsupervised techniques for part-of-speech (POS) tagging have not achieved useful accuracies required by many language processing tasks.",
            "Use of parallel text between resource-rich and resource-poor languages is one source of weak supervision that significantly improves accuracy.",
            "In this paper we show that we can build POS-taggers exceeding state-of-the-art bilingual methods by using simple hidden Markov models and a freely available and naturally growing resource, the Wiktionary.",
            "Wiki-ly Supervised Part-of-Speech Tagging",
            "Abstract",
            "Across eight languages for which we have labeled data to evaluate results, we achieve accuracy that significantly exceeds best unsupervised and parallel text methods."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.052021442357392145,
                0.0,
                0.08275452516976176,
                0.08104408679335673,
                0.09734336694632954,
                0.0,
                0.14873080551465806
            ],
            [
                0.052021442357392145,
                1.0,
                0.06315458426570209,
                0.10434063435502434,
                0.10218403657558967,
                0.0,
                0.0,
                0.1121921071112247
            ],
            [
                0.0,
                0.06315458426570209,
                1.0,
                0.0,
                0.04199331357036109,
                0.17599399827275,
                0.0,
                0.05401235067445396
            ],
            [
                0.08275452516976176,
                0.10434063435502434,
                0.0,
                1.0,
                0.09317292505037257,
                0.0,
                0.0,
                0.23839276674527998
            ],
            [
                0.08104408679335673,
                0.10218403657558967,
                0.04199331357036109,
                0.09317292505037257,
                1.0,
                0.0,
                0.0,
                0.05009202240207654
            ],
            [
                0.09734336694632954,
                0.0,
                0.17599399827275,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.14873080551465806,
                0.1121921071112247,
                0.05401235067445396,
                0.23839276674527998,
                0.05009202240207654,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "W11-2133": {
        "input_sentences": [
            "During inference, documents containing only the source language can be used to infer a full topic-word distribution on all words in the target language\u2019s vocabulary, from which we perform Minimum Discrimination Information (MDI) adaptation on a background language model (LM).",
            "Our topic modeling approach is simpler to construct than its counterparts.",
            "Bilingual Latent Semantic Models",
            "We apply our approach on the English-French IWSLT 2010 TED Talk exercise, and report a 15% reduction in perplexity and relative BLEU and NIST improvements of 3% and 2.4%, respectively over a baseline only using a 5-gram background LM over the entire translation task.",
            "Abstract",
            "This work presents a simplified approach to bilingual topic modeling for language model adaptation by combining text in the source and target language into very short documents and performing Probabilistic Latent Semantic Analysis (PLSA) during model training.",
            "Topic Adaptation for Lecture Translation through Bilingual Latent Semantic Models"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.03606315555431805,
                0.0,
                0.05649297405274419,
                0.0,
                0.3652440159532255,
                0.08213446946217977
            ],
            [
                0.03606315555431805,
                1.0,
                0.0,
                0.04749882677116277,
                0.0,
                0.1561542436012336,
                0.08124930165289805
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.2163122070433179,
                0.6789348096346639
            ],
            [
                0.05649297405274419,
                0.04749882677116277,
                0.0,
                1.0,
                0.0,
                0.021572401062125202,
                0.06363856156690602
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.3652440159532255,
                0.1561542436012336,
                0.2163122070433179,
                0.021572401062125202,
                0.0,
                1.0,
                0.23271660346612996
            ],
            [
                0.08213446946217977,
                0.08124930165289805,
                0.6789348096346639,
                0.06363856156690602,
                0.0,
                0.23271660346612996,
                1.0
            ]
        ]
    },
    "D12-1069": {
        "input_sentences": [
            "We present a method for training a semantic parser using only a knowledge base and an unlabeled text corpus, without any individually annotated sentences.",
            "We demonstrate recovery of this richer structure by extracting logical forms from natural language queries against Freebase.",
            "We apply our approach to train a semantic parser that uses 77 relations from Freebase in its knowledge representation.",
            "On this task, the trained semantic parser achieves 80% precision and 56% recall, despite never having seen an annotated logical form.",
            "Weakly Supervised Training of Semantic Parsers",
            "Abstract",
            "Our key observation is that multiple forms of weak supervision can be combined to train an accurate semantic parser: supervision a knowledge base, supervision dependencyparsed sentences.",
            "This semantic parser extracts instances of binary relations with state-of-theart accuracy, while simultaneously recovering much richer semantic structures, such as conjunctions of multiple relations with partially shared arguments."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.11510576125132296,
                0.10658467759327597,
                0.14507899673589514,
                0.0,
                0.17055002943874842,
                0.05731767584550558
            ],
            [
                0.0,
                1.0,
                0.07833837159079275,
                0.06227075616125336,
                0.0,
                0.0,
                0.050654929387640844,
                0.05209905745109052
            ],
            [
                0.11510576125132296,
                0.07833837159079275,
                1.0,
                0.05477883691435853,
                0.04387865081764366,
                0.0,
                0.14124948508242505,
                0.18009806961717942
            ],
            [
                0.10658467759327597,
                0.06227075616125336,
                0.05477883691435853,
                1.0,
                0.034878906853246454,
                0.0,
                0.035420931779491495,
                0.052539448240923006
            ],
            [
                0.14507899673589514,
                0.0,
                0.04387865081764366,
                0.034878906853246454,
                1.0,
                0.0,
                0.028372685232761752,
                0.05836313171701002
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.17055002943874842,
                0.050654929387640844,
                0.14124948508242505,
                0.035420931779491495,
                0.028372685232761752,
                0.0,
                1.0,
                0.07959668160203912
            ],
            [
                0.05731767584550558,
                0.05209905745109052,
                0.18009806961717942,
                0.052539448240923006,
                0.05836313171701002,
                0.0,
                0.07959668160203912,
                1.0
            ]
        ]
    },
    "P08-1028": {
        "input_sentences": [
            "Experimental results demonstrate that the multiplicative models are superior to the additive alternatives when compared against human judgments.",
            "This paper proposes a framework for representing the meaning of phrases and sentences in vector space.",
            "Central to our approach is vector composition which we operationalize in terms of additive and multiplicative functions.",
            "Abstract",
            "Under this framework, we introduce a wide range of composition models which we evaluate empirically on a sentence similarity task.",
            "Vector-based Models of Semantic Composition"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.15876756217170362,
                0.0,
                0.04927434272346614,
                0.08247283944278769
            ],
            [
                0.0,
                1.0,
                0.06211777527427815,
                0.0,
                0.07588958357228515,
                0.09053857780810368
            ],
            [
                0.15876756217170362,
                0.06211777527427815,
                1.0,
                0.0,
                0.05714845012173264,
                0.1913042240967014
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.04927434272346614,
                0.07588958357228515,
                0.05714845012173264,
                0.0,
                1.0,
                0.1665912655471916
            ],
            [
                0.08247283944278769,
                0.09053857780810368,
                0.1913042240967014,
                0.0,
                0.1665912655471916,
                1.0
            ]
        ]
    },
    "W05-0636": {
        "input_sentences": [
            "To do this, we jointly perform parsing and semantic role labeling, using a probabilistic SRL system to rerank the results of a probabilistic parser.",
            "In this paper, we attempt to use this insight to bridge the gap between SRL results from gold parses and from automatically-generated parses.",
            "Our current results are negative, because a locallytrained SRL model can return inaccurate probability estimates.",
            "Abstract",
            "A striking feature of human syntactic prois that it is that is, it seems to take into account semantic information from the discourse context and world knowledge.",
            "Joint Parsing And Semantic Role Labeling"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0727007296634865,
                0.09074854881118093,
                0.0,
                0.040084083614452,
                0.3783098344643069
            ],
            [
                0.0727007296634865,
                1.0,
                0.08572224173087356,
                0.0,
                0.0,
                0.0
            ],
            [
                0.09074854881118093,
                0.08572224173087356,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.040084083614452,
                0.0,
                0.0,
                0.0,
                1.0,
                0.07565291959538456
            ],
            [
                0.3783098344643069,
                0.0,
                0.0,
                0.0,
                0.07565291959538456,
                1.0
            ]
        ]
    },
    "A00-2018": {
        "input_sentences": [
            "This represents a 13% decrease in error rate over the best single-parser results on this corpus [9].",
            "We also present some partial results showing the effects of different conditioning information, including a surprising 2% improvement due to guessing the lexical head's pre-terminal before guessing the lexical head.",
            "A Maximum-Entropy-Inspired Parser *",
            "The major technical innovation is the use of a &quot;maximum-entropy-inspired&quot; model for conditioning and smoothing that let us successfully to test and combine many different conditioning events.",
            "We present a new parser for parsing down to Penn tree-bank style parse trees that achieves 90.1% average precision/recall for sentences of 40 and less, and for of length 100 and less when trained and tested on the previously established [5,9,10,15,17] &quot;standard&quot; sections of the Wall Street Journal treebank.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.045667976875145996,
                0.10027237144034327,
                0.0,
                0.027235078959552114,
                0.0
            ],
            [
                0.045667976875145996,
                1.0,
                0.0,
                0.09491164494923993,
                0.023748647662372096,
                0.0
            ],
            [
                0.10027237144034327,
                0.0,
                1.0,
                0.2923665094141451,
                0.05214448684945389,
                0.0
            ],
            [
                0.0,
                0.09491164494923993,
                0.2923665094141451,
                1.0,
                0.10587994618584398,
                0.0
            ],
            [
                0.027235078959552114,
                0.023748647662372096,
                0.05214448684945389,
                0.10587994618584398,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "N06-1039": {
        "input_sentences": [
            "surface text patterns for a question answering system. of the 40th Annual Meeting of the As",
            "Abstract",
            "Preemptive Information Extraction Using Unrestricted Relation Discovery"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "W06-2920": {
        "input_sentences": [
            "In this paper, we describe how treebanks for 13 languages were converted into the same dependency format and how parsing performance was measured.",
            "The tenth CoNLL (CoNLL-X) saw a shared task on Multilingual Dependency Parsing.",
            "Each year the Conference on Computational Natural Language Learning features a shared task, in which participants train and test their systems on exactly the same data sets, in order to better compare systems.",
            "CoNLL-X Shared Task On Multilingual Dependency Parsing",
            "Finally, we try to draw general conclusions about multi-lingual parsing: What makes a particular language, treebank or annotation scheme easier or harder to parse and which phenomena are challenging for any dependency parser?",
            "His work was made possible by the MITRE Cor",
            "We also give an overview of the parsing approaches that participants took and the results that they achieved.",
            "Abstract",
            "Acknowledgement Many thanks to Amit Dubey and Yuval Krymolowski, the other two organizers of the shared task, for discussions, converting treebanks, writing and helping with the also to Alexander Yeh for additional help with the paper reviews."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.09876187942769671,
                0.0,
                0.15199805298303262,
                0.05991328307306113,
                0.0,
                0.047648731630020834,
                0.0,
                0.11669111607428324
            ],
            [
                0.09876187942769671,
                1.0,
                0.0698713718565137,
                0.8029870165477709,
                0.06402751812973247,
                0.0,
                0.05092076200497288,
                0.0,
                0.07359669365621221
            ],
            [
                0.0,
                0.0698713718565137,
                1.0,
                0.1075345319771749,
                0.03591088317420022,
                0.0,
                0.06442839585029339,
                0.0,
                0.04375794817131517
            ],
            [
                0.15199805298303262,
                0.8029870165477709,
                0.1075345319771749,
                1.0,
                0.09854063277704198,
                0.0,
                0.07836886788727618,
                0.0,
                0.11326793502266844
            ],
            [
                0.05991328307306113,
                0.06402751812973247,
                0.03591088317420022,
                0.09854063277704198,
                1.0,
                0.0,
                0.030890765201905864,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.047648731630020834,
                0.05092076200497288,
                0.06442839585029339,
                0.07836886788727618,
                0.030890765201905864,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.11669111607428324,
                0.07359669365621221,
                0.04375794817131517,
                0.11326793502266844,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P05-1065": {
        "input_sentences": [
            "Reading proficiency is a fundamental component of language competency.",
            "In this paper, we also use support vector machines to combine features from traditional reading level measures, statistical language models, and other language processing tools to produce a better method of assessing reading level.",
            "This task can be addressed with natural language processing technology to assess reading level.",
            "Abstract",
            "However, finding topical texts at an appropriate reading level for foreign and second language learners is a challenge for teachers.",
            "Existing measures of reading level are not well suited to this task, but previous work and our own pilot experiments have shown the benefit of using statistical language models.",
            "Reading Level Assessment Using Support Vector Machines And Statistical Language Models"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.1024915497551787,
                0.08645918070734644,
                0.0,
                0.06852861613531792,
                0.0622246902262749,
                0.09116075750908677
            ],
            [
                0.1024915497551787,
                1.0,
                0.21052885402508215,
                0.0,
                0.11397904204518185,
                0.22169215100650402,
                0.4654959976852997
            ],
            [
                0.08645918070734644,
                0.21052885402508215,
                1.0,
                0.0,
                0.09614972762704942,
                0.16832769575642773,
                0.12790396916036498
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.06852861613531792,
                0.11397904204518185,
                0.09614972762704942,
                0.0,
                1.0,
                0.06919897884743072,
                0.10137826813838202
            ],
            [
                0.0622246902262749,
                0.22169215100650402,
                0.16832769575642773,
                0.0,
                0.06919897884743072,
                1.0,
                0.30231413411703223
            ],
            [
                0.09116075750908677,
                0.4654959976852997,
                0.12790396916036498,
                0.0,
                0.10137826813838202,
                0.30231413411703223,
                1.0
            ]
        ]
    },
    "C04-1074": {
        "input_sentences": [
            "The factors used in the algorithms and the algorithms themselves are evaluated on a Germancorpus annotated with syntactic and coreference in formation (Negra) (Skut et al, 1997).",
            "The paper aims at a deeper understanding of sev eral well-known algorithms and proposes ways to optimize them.",
            "Abstract",
            "It describes and discusses factorsand strategies of factor interaction used in the algo rithms.",
            "A commonformat for pronoun resolution algorithms with sev eral open parameters is proposed, and the parameter settings optimal on the evaluation data are given.",
            "Optimizing Algorithms For Pronoun Resolution"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0602420050389642,
                0.0,
                0.06085096225481543,
                0.051945440948322166,
                0.11423234007106052
            ],
            [
                0.0602420050389642,
                1.0,
                0.0,
                0.0,
                0.15088669328836155,
                0.06882559164676821
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.06085096225481543,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.051945440948322166,
                0.15088669328836155,
                0.0,
                0.0,
                1.0,
                0.2861149798843129
            ],
            [
                0.11423234007106052,
                0.06882559164676821,
                0.0,
                0.0,
                0.2861149798843129,
                1.0
            ]
        ]
    },
    "I05-6010": {
        "input_sentences": [
            "The information gained from cor pus research and the analyses that are proposed are realized in the framework of SILVA, a parsing and extraction tool for German text corpora.",
            "This article is devoted to the problem of quantifying noun groups in German.After a thorough description of the phenom ena, the results of corpus-based in vestigations are described.",
            "We argue that a more sophisticatedand fine-grained annotation in the tree bank would have very positve effects onstochastic parsers trained on the tree bank and on grammars induced from the treebank, and it would make the treebank more valuable as a source ofdata for theoretical linguistic investigations.",
            "Abstract",
            "Moreover,some examples are given that under line the necessity of integrating somekind of information other than gram mar sensu stricto into the treebank.",
            "Some remarks on the Annotation of Quantifying Noun Groups in Treebanks"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.04478733333808305,
                0.0,
                0.0,
                0.05096385333466977,
                0.0
            ],
            [
                0.04478733333808305,
                1.0,
                0.0,
                0.0,
                0.0,
                0.24304433017845503
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.07368512903032723,
                0.05730294295912977
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.05096385333466977,
                0.0,
                0.07368512903032723,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.24304433017845503,
                0.05730294295912977,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "W04-0305": {
        "input_sentences": [
            "This suggests that one word lookahead is sufficient, but that other modifications to our left-corner parsing model could make deterministic parsing more effective.",
            "We simulate the effects of lookahead by summing probabilities over possible parses for the lookahead words and using this sum to choose which parse to pursue.",
            "We find that a large improvement is achieved with one word lookahead, but that more lookahead results in relatively small additional improvements.",
            "Experiments with an incremental statistical parser show that performance is severely degraded when the search for the most probable parse is pruned to only the most probable analysis after each prefix.",
            "Deterministic parsing takes the extreme position that there can only be one analysis for any sentence prefix.",
            "One method which has been extensively used to address the difficulty of deterministic parsing is lookahead, where information about a bounded number of subsequent words is used to decide which analyses to pursue.",
            "Abstract",
            "Lookahead In Deterministic Left-Corner Parsing",
            "To support incremental interpretation, any model of human sentence processing must not only process the sentence incrementally, it must to some degree restrict the number of analyses which it produces for any sentence prefix."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.05914961724092664,
                0.13602467533712898,
                0.0,
                0.16334764585092973,
                0.12441807299380131,
                0.0,
                0.5842774817332687,
                0.051262482165017616
            ],
            [
                0.05914961724092664,
                1.0,
                0.11970005610921715,
                0.052703431583432055,
                0.0,
                0.14826467533279672,
                0.0,
                0.11760316533335397,
                0.0
            ],
            [
                0.13602467533712898,
                0.11970005610921715,
                1.0,
                0.0,
                0.0,
                0.052809551313124,
                0.0,
                0.1310294178321339,
                0.0
            ],
            [
                0.0,
                0.052703431583432055,
                0.0,
                1.0,
                0.13566487340495403,
                0.0,
                0.0,
                0.0,
                0.07537934873748957
            ],
            [
                0.16334764585092973,
                0.0,
                0.0,
                0.13566487340495403,
                1.0,
                0.08726344605981,
                0.0,
                0.21651535093427643,
                0.256327068069446
            ],
            [
                0.12441807299380131,
                0.14826467533279672,
                0.052809551313124,
                0.0,
                0.08726344605981,
                1.0,
                0.0,
                0.18220948108590512,
                0.08215620416191372
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.5842774817332687,
                0.11760316533335397,
                0.1310294178321339,
                0.0,
                0.21651535093427643,
                0.18220948108590512,
                0.0,
                1.0,
                0.0
            ],
            [
                0.051262482165017616,
                0.0,
                0.0,
                0.07537934873748957,
                0.256327068069446,
                0.08215620416191372,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "D11-1006": {
        "input_sentences": [
            "We present a simple method for transferring dependency parsers from source languages with labeled training data to target languages without labeled training data.",
            "We first demonstrate that delexicalized parsers can be directly transferred between languages, producing significantly higher accuracies than unsupervised parsers.",
            "The projected parsers from our system result in state-of-theart performance when compared to previously studied unsupervised and projected parsing systems across eight different languages.",
            "Multi-Source Transfer of Delexicalized Dependency Parsers",
            "Unlike previous work on projecting syntactic resources, we show that simple methods for introducing multiple source languages can significantly improve the overall quality of the resulting parsers.",
            "Abstract",
            "Multi-Source Transfer",
            "We then use a constraint driven learning algorithm where constraints are drawn from parallel corpora to project the final parser."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.10330081403048082,
                0.06416319246089684,
                0.17016928708362056,
                0.12705360935929175,
                0.0,
                0.06733929748781982,
                0.0
            ],
            [
                0.10330081403048082,
                1.0,
                0.14132012903003177,
                0.22700437353621838,
                0.1408439798515656,
                0.0,
                0.0,
                0.0
            ],
            [
                0.06416319246089684,
                0.14132012903003177,
                1.0,
                0.0427201821099227,
                0.046348371507212036,
                0.0,
                0.0,
                0.0
            ],
            [
                0.17016928708362056,
                0.22700437353621838,
                0.0427201821099227,
                1.0,
                0.09691523025959263,
                0.0,
                0.7157790301227551,
                0.0
            ],
            [
                0.12705360935929175,
                0.1408439798515656,
                0.046348371507212036,
                0.09691523025959263,
                1.0,
                0.0,
                0.07591586614177816,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.06733929748781982,
                0.0,
                0.0,
                0.7157790301227551,
                0.07591586614177816,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P03-1013": {
        "input_sentences": [
            "This model outperforms the baseline, achieving a labeled precision and recall of up to 74%.",
            "Probabilistic Parsing For German Using Sister-Head Dependencies",
            "We observe that existing lexicalized parsing models using head-head dependencies, while successful for English, fail to outperform an unlexicalized baseline model for German.",
            "Learning curves show that this effect is not due to lack of training data.",
            "This indicates that sister-head dependencies are more appropriate for treebanks with very flat structures such as Negra.",
            "Abstract",
            "We propose an alternative model that uses sister-head dependencies instead of head-head dependencies.",
            "We present a probabilistic parsing model for German trained on the Negra treebank."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.11128695042394537,
                0.0,
                0.0,
                0.0,
                0.047342602169171376,
                0.06235071096776209
            ],
            [
                0.0,
                1.0,
                0.4082615448952272,
                0.0,
                0.25752812935430786,
                0.0,
                0.409062571132213,
                0.3718185312635713
            ],
            [
                0.11128695042394537,
                0.4082615448952272,
                1.0,
                0.0,
                0.12218489015733434,
                0.0,
                0.30502045051065885,
                0.16075978798961865
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.25752812935430786,
                0.12218489015733434,
                0.0,
                1.0,
                0.0,
                0.2998831970307866,
                0.10950250885650678
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.047342602169171376,
                0.409062571132213,
                0.30502045051065885,
                0.0,
                0.2998831970307866,
                0.0,
                1.0,
                0.052159587419998855
            ],
            [
                0.06235071096776209,
                0.3718185312635713,
                0.16075978798961865,
                0.0,
                0.10950250885650678,
                0.0,
                0.052159587419998855,
                1.0
            ]
        ]
    },
    "W08-1007": {
        "input_sentences": [
            "We report a labeled attachment score close to 90% for dependency versions of the TIGER and T\u00a8uBa- D/Z treebanks.",
            "We present a dependency-driven parser that parses both dependency structures and constituent structures.",
            "Moreover, the parser is able to recover both constituent labels and grammatical functions with an F-Score over 75% for T\u00a8uBa-D/Z and over 65% for TIGER.",
            "Constituency representations are automatically transformed into dependency representations with complex arc labels, which makes it possible to recover the constituent structure with both constituent labels and grammatical functions.",
            "Abstract",
            "A Dependency-Driven Parser for German Dependency and Constituency Representations"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.07649104698908321,
                0.22387932532515836,
                0.027614342441923078,
                0.0,
                0.10384232280314776
            ],
            [
                0.07649104698908321,
                1.0,
                0.10831275381291736,
                0.13280195503447123,
                0.0,
                0.38442698188907554
            ],
            [
                0.22387932532515836,
                0.10831275381291736,
                1.0,
                0.3524963271995955,
                0.0,
                0.07352133607704488
            ],
            [
                0.027614342441923078,
                0.13280195503447123,
                0.3524963271995955,
                1.0,
                0.0,
                0.2950956911863551
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.10384232280314776,
                0.38442698188907554,
                0.07352133607704488,
                0.2950956911863551,
                0.0,
                1.0
            ]
        ]
    },
    "P11-1086": {
        "input_sentences": [
            "Though this practice improves translation by weakening independence assumptions in the translation model, it nevertheless results in huge, redundant grammars, making both trainand decoding Here, we take the approach, where we only use minrules that cannot be formed out other rules), and instead rely on a model the derivation history to capture dependencies between minimal rules.",
            "Rule Markov Models for Fast Tree-to-String Translation",
            "Abstract",
            "Large-scale experiments on a state-of-the-art tree-to-string translation system show that our approach leads to a slimmer model, a faster decoder, yet the same translation quality (measured using B ) as composed rules.",
            "Most statistical machine translation systems on rules that can be formed out of smaller rules in the grammar)."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.05063591513359127,
                0.0,
                0.18715243666164447,
                0.2090169704736544
            ],
            [
                0.05063591513359127,
                1.0,
                0.0,
                0.19629642189627783,
                0.04805860017349097
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.18715243666164447,
                0.19629642189627783,
                0.0,
                1.0,
                0.13210411877103456
            ],
            [
                0.2090169704736544,
                0.04805860017349097,
                0.0,
                0.13210411877103456,
                1.0
            ]
        ]
    },
    "N06-2033": {
        "input_sentences": [
            "Parser Combination By Reparsing",
            "We present a novel parser combination scheme that works by reparsing input sentences once they have already been parsed by several different parsers.",
            "Abstract",
            "We apply this idea to dependency and constituent parsing, generating results that surpass state-of-theart accuracy levels for individual parsers."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.421697442660751,
                0.0,
                0.0
            ],
            [
                0.421697442660751,
                1.0,
                0.0,
                0.05200909993820063
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.05200909993820063,
                0.0,
                1.0
            ]
        ]
    },
    "W10-2924": {
        "input_sentences": [
            "We give an efficient labeling algorithm that is analogous to parsing using dynamic programming.",
            "Both entity and relation extraction can benefit from being performed jointly, allowing each task to correct the errors of the other.",
            "Joint Entity and Relation Extraction Using Card-Pyramid Parsing",
            "Abstract",
            "Experimental results show improved results for our joint extraction method compared to a pipelined approach.",
            "We present a new method for joint entity and relation extraction using a graph we call a \u201ccard-pyramid.\u201d This graph compactly encodes all possible entities and relations in a sentence, reducing the task of their joint extraction to jointly labeling its nodes."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.21294910693470254,
                0.0,
                0.0,
                0.09233785020701715
            ],
            [
                0.0,
                1.0,
                0.22878237316672978,
                0.0,
                0.0392495227366451,
                0.2276446623217787
            ],
            [
                0.21294910693470254,
                0.22878237316672978,
                1.0,
                0.0,
                0.12388408452469882,
                0.4496818676792591
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0392495227366451,
                0.12388408452469882,
                0.0,
                1.0,
                0.1508898425400733
            ],
            [
                0.09233785020701715,
                0.2276446623217787,
                0.4496818676792591,
                0.0,
                0.1508898425400733,
                1.0
            ]
        ]
    },
    "P11-1141": {
        "input_sentences": [
            "Yue Zhang and Stephen Clark.",
            "Chinese word segmentation as tagging.",
            "annotation of a large corpus.",
            "2003.",
            "In Pro",
            "2007.",
            "Abstract",
            "Chinese segmentawith a word-based perceptron algorithm.",
            "Nianwen Xue.",
            "Parsing the Internal Structure of Words: A New Paradigm for Chinese Word Segmentation",
            "Lan- 11(2):207\u2013238.",
            "Linguistics and Language 8(1):29\u201348."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.2984039655299266,
                0.0,
                0.39563845723309354,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.2984039655299266,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.18057147447676078,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.39563845723309354,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.18057147447676078,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P12-1051": {
        "input_sentences": [
            "This paper makes the connection concrete with a tree transducer based semantic parsing model and suggests that other models can be interpreted in a similar framework, increasing the generality of their contributions.",
            "Many semantic parsing models use tree transformations to map between natural language and meaning representation.",
            "Abstract",
            "Semantic Parsing with Bayesian Tree Transducers",
            "However, while tree transformations are central to several state-of-the-art approaches, little use has been made of the rich literature on tree automata.",
            "In particular, this paper further introduces a variational Bayesian inference algorithm that is applicable to a wide class of tree transducers, producing state-of-the-art semantic parsing results while remaining applicable to any domain employing probabilistic tree transducers."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.14822576276796842,
                0.0,
                0.16245218974733183,
                0.04298808623367016,
                0.0989091440295846
            ],
            [
                0.14822576276796842,
                1.0,
                0.0,
                0.22497261755868855,
                0.21204318984740228,
                0.0885314027338105
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.16245218974733183,
                0.22497261755868855,
                0.0,
                1.0,
                0.11064477150438191,
                0.4346476680398911
            ],
            [
                0.04298808623367016,
                0.21204318984740228,
                0.0,
                0.11064477150438191,
                1.0,
                0.1562010489902421
            ],
            [
                0.0989091440295846,
                0.0885314027338105,
                0.0,
                0.4346476680398911,
                0.1562010489902421,
                1.0
            ]
        ]
    },
    "E12-1083": {
        "input_sentences": [
            "We view different patent classes and different patent text sections such as title, abstract, and claims, as separate translation tasks, and investigate the influence of such tasks on machine translation performance.",
            "We study multitask learning techniques that exploit commonalities between tasks by mixtures of translation models or by multi-task metaparameter tuning.",
            "We find small but significant gains over task-specific training by techniques that model commonalities through shared parameters.",
            "Patent translation is a complex problem due to the highly specialized technical vocabulary and the peculiar textual structure of patent documents.",
            "In this paper we analyze patents along the orthogonal dimensions of topic and textual structure.",
            "Structural and Topical Dimensions in Multi-Task Patent Translation",
            "Abstract",
            "A by-product of our work is a parallel patent corpus of 23 million German-English sentence pairs."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.13833197386044702,
                0.0,
                0.1531750648265433,
                0.0,
                0.1586057687388173,
                0.17979234701731572,
                0.05348671194312779
            ],
            [
                0.13833197386044702,
                1.0,
                0.17860485219305583,
                0.034738942161562855,
                0.0,
                0.21840121435715656,
                0.0,
                0.0
            ],
            [
                0.0,
                0.17860485219305583,
                1.0,
                0.0,
                0.0,
                0.07630725086791272,
                0.0,
                0.0
            ],
            [
                0.1531750648265433,
                0.034738942161562855,
                0.0,
                1.0,
                0.15596000601430007,
                0.16411745904723757,
                0.0,
                0.07379389645743116
            ],
            [
                0.0,
                0.0,
                0.0,
                0.15596000601430007,
                1.0,
                0.12111708590308116,
                0.0,
                0.0
            ],
            [
                0.1586057687388173,
                0.21840121435715656,
                0.07630725086791272,
                0.16411745904723757,
                0.12111708590308116,
                1.0,
                0.0,
                0.05730765165229773
            ],
            [
                0.17979234701731572,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.05348671194312779,
                0.0,
                0.0,
                0.07379389645743116,
                0.0,
                0.05730765165229773,
                0.0,
                1.0
            ]
        ]
    },
    "P07-1108": {
        "input_sentences": [
            "This paper proposes a novel method for phrase-based statistical machine translation by using pivot language.",
            "Using only bilingual corpora, we can build a model for The advantage of this method lies in that we can perform between even if there is no bilingual corpus available for this language pair.",
            "To conduct transbetween languages with a small bilingual corpus, we bring in a third which is named the lan- For and there exist bilingual corpora.",
            "Moreover, with small bilingual corpus available, our method can further improve the translaquality by using the additional bilingual corpora.",
            "Abstract",
            "Pivot Language Approach for Phrase-Based Statistical Machine Translation",
            "Using BLEU as a metric, our pivot language method achieves an absolute improvement of 0.06 (22.13% relative) as compared with the model directly with 5,000 sentence pairs for French-Spanish translation."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.12476563003651421,
                0.0,
                0.0945327718706238,
                0.0,
                0.649863647801903,
                0.1758570042906886
            ],
            [
                0.12476563003651421,
                1.0,
                0.28434412269465,
                0.48197892679958304,
                0.0,
                0.05155134470164503,
                0.1297229761806556
            ],
            [
                0.0,
                0.28434412269465,
                1.0,
                0.3968824529869927,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0945327718706238,
                0.48197892679958304,
                0.3968824529869927,
                1.0,
                0.0,
                0.0,
                0.061229568020325184
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.649863647801903,
                0.05155134470164503,
                0.0,
                0.0,
                0.0,
                1.0,
                0.14086668678521927
            ],
            [
                0.1758570042906886,
                0.1297229761806556,
                0.0,
                0.061229568020325184,
                0.0,
                0.14086668678521927,
                1.0
            ]
        ]
    },
    "W03-1509": {
        "input_sentences": [
            "Chinese Named Entity Recognition Combining Statistical Model Wih Human Knowledge",
            "In this paper, we present a hybrid algorithm which can combine a class-based statistical model with various types of human knowledge very well.",
            "Named Entity Recognition is one of the key techniques in the fields of natural language processing, information retrieval, question answering and so on.",
            "The F-measure of person names, location names, and organization names on the newswire test data for the 1999 IEER evaluation in Mandarin is 86.84%, 84.40% and 76.22% respectively.",
            "Unfortunately, Chinese Named Entity Recognition (NER) is more difficult for the lack of capitalization information and the uncertainty in word segmentation.",
            "Abstract",
            "In order to avoid data sparseness problem, we employ a back-off model and YI CI CI LIN a Chinese thesaurus, to smooth the parameters in the model."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.294507325376498,
                0.17587815969144008,
                0.0,
                0.2398825811051145,
                0.0,
                0.141894506093931
            ],
            [
                0.294507325376498,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.07135947315663532
            ],
            [
                0.17587815969144008,
                0.0,
                1.0,
                0.0,
                0.20088527213385274,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.031013120517974696
            ],
            [
                0.2398825811051145,
                0.0,
                0.20088527213385274,
                0.0,
                1.0,
                0.0,
                0.037098015096972484
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.141894506093931,
                0.07135947315663532,
                0.0,
                0.031013120517974696,
                0.037098015096972484,
                0.0,
                1.0
            ]
        ]
    },
    "P05-1053": {
        "input_sentences": [
            "Extracting semantic relationships between entities is challenging.",
            "Evaluation on the ACE corpus shows that effective incorporation of diverse features enables our system outperform previously best-reported systems on the 24 ACE relation subtypes and significantly outperforms tree kernel-based systems by over 20 in F-measure on the 5 ACE relation types.",
            "Our study illustrates that the base phrase chunking information is very effective for relation extraction and contributes to most of the performance improvement from syntactic aspect while additional information from full parsing gives limited further enhancement.",
            "We also demonstrate how semantic information such as WordNet and Name List, can be used in feature-based relation extraction to further improve the performance.",
            "Exploring Various Knowledge In Relation Extraction",
            "Abstract",
            "This paper investigates the incorporation of diverse lexical, syntactic and semantic knowledge in feature-based relation extraction using SVM.",
            "This suggests that most of useful information in full parse trees for relation extraction is shallow and can be captured by chunking."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0,
                0.08415952793235286,
                0.0,
                0.0,
                0.07729434342639083,
                0.0
            ],
            [
                0.0,
                1.0,
                0.048866484267379634,
                0.05945966277921798,
                0.04695325228467944,
                0.0,
                0.12963891536350372,
                0.030407139610294884
            ],
            [
                0.0,
                0.048866484267379634,
                1.0,
                0.1894122976018193,
                0.07475895451529736,
                0.0,
                0.09529450552994968,
                0.19830202329854696
            ],
            [
                0.08415952793235286,
                0.05945966277921798,
                0.1894122976018193,
                1.0,
                0.10692327484989805,
                0.0,
                0.24880644527048656,
                0.13337159052418873
            ],
            [
                0.0,
                0.04695325228467944,
                0.07475895451529736,
                0.10692327484989805,
                1.0,
                0.0,
                0.22033626247104932,
                0.11194152654762883
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.07729434342639083,
                0.12963891536350372,
                0.09529450552994968,
                0.24880644527048656,
                0.22033626247104932,
                0.0,
                1.0,
                0.06359552574448078
            ],
            [
                0.0,
                0.030407139610294884,
                0.19830202329854696,
                0.13337159052418873,
                0.11194152654762883,
                0.0,
                0.06359552574448078,
                1.0
            ]
        ]
    },
    "E12-3010": {
        "input_sentences": [
            "Then we add a rule-based preprocessor and a statistical post-editor to the Its-2 translation pipeline.",
            "We use the Europarl corpus to evaluate two MT systems on their performance regarding null subject translation: Its-2, a rule-based system developed at LATL, and a statistical system built using the Moses toolkit.",
            "Improving machine translation of null subjects in Italian and Spanish",
            "Abstract",
            "In this study we quantify and compare the occurrence of this phenomenon in these two languages.",
            "A second evaluation of the improved Its-2 system shows an average increase of 15.46% in correct pro-drop translations for Italian-French and 12.80% for",
            "Next, we evaluate null subjects\u2019 translation into French, a \u201cnon prodrop\u201d language.",
            "Null subjects are non overtly expressed pronouns found in languages such as Italian and Spanish."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.2181783574726478,
                0.06876496230542277,
                0.0,
                0.0,
                0.0,
                0.06293942078944206,
                0.0
            ],
            [
                0.2181783574726478,
                1.0,
                0.08979854096029045,
                0.0,
                0.0,
                0.0,
                0.15398291999224553,
                0.03741723203110001
            ],
            [
                0.06876496230542277,
                0.08979854096029045,
                1.0,
                0.0,
                0.0,
                0.06282009167907142,
                0.26681878839908746,
                0.39365047158282557
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.11488098614209637
            ],
            [
                0.0,
                0.0,
                0.06282009167907142,
                0.0,
                0.0,
                1.0,
                0.07721738524252585,
                0.052351717999743946
            ],
            [
                0.06293942078944206,
                0.15398291999224553,
                0.26681878839908746,
                0.0,
                0.0,
                0.07721738524252585,
                1.0,
                0.2726732116124826
            ],
            [
                0.0,
                0.03741723203110001,
                0.39365047158282557,
                0.0,
                0.11488098614209637,
                0.052351717999743946,
                0.2726732116124826,
                1.0
            ]
        ]
    },
    "W11-0314": {
        "input_sentences": [
            "In this paper we present ULISSE, an unsupervised linguistically\u2013driven algorithm to select reliable parses from the output of a dependency parser.",
            "ULISSE: an Unsupervised Algorithm for Detecting Reliable Dependency Parses",
            "Different experiments were devised to show that the algorithm is robust enough to deal with the output of different parsers and with different languages, as well as to be used across different domains.",
            "In all cases, ULISSE appears to outperform the baseline algorithms.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.5179010824951866,
                0.06887603746201743,
                0.06030721518669817,
                0.0
            ],
            [
                0.5179010824951866,
                1.0,
                0.042199193671630233,
                0.09057264623870494,
                0.0
            ],
            [
                0.06887603746201743,
                0.042199193671630233,
                1.0,
                0.0,
                0.0
            ],
            [
                0.06030721518669817,
                0.09057264623870494,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "D07-1015": {
        "input_sentences": [
            "Structured Prediction Models via the Matrix-Tree Theorem",
            "This paper provides an algorithmic framework for learning statistical models involv ing directed spanning trees, or equivalently non-projective dependency structures.",
            "We show how partition functions and marginals for directed spanning trees can be computed by an adaptation of Kirchhoff?s Matrix-Tree Theorem.",
            "To demonstrate an application of the method, we perform experiments which use the algorithm in training both log-linear and max-margin dependency parsers.",
            "The new training methods give improvements in accuracy over perceptron-trained models.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.05803438456390597,
                0.30031348453597717,
                0.0,
                0.08451980192196172,
                0.0
            ],
            [
                0.05803438456390597,
                1.0,
                0.16350725371004118,
                0.04726152402073329,
                0.04601725000037768,
                0.0
            ],
            [
                0.30031348453597717,
                0.16350725371004118,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.04726152402073329,
                0.0,
                1.0,
                0.06883048177005709,
                0.0
            ],
            [
                0.08451980192196172,
                0.04601725000037768,
                0.0,
                0.06883048177005709,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P13-1109": {
        "input_sentences": [
            "Our method differs from previous approaches by adopting a graph propagation approach that takes into account not only one-step (from oov directly to a source language phrase that has a translation) but multi-step paraphrases from oov source language words to other source language phrases and eventually to target language translations.",
            "In this paper, we propose a novel approach to finding translations for oov words.",
            "Graph Propagation for Paraphrasing Out-of-Vocabulary Words in Statistical Machine Translation",
            "Abstract",
            "Out-of-vocabulary (oov) words or phrases still remain a challenge in statistical machine translation especially when a limited amount of parallel text is available for training or when there is a domain shift from training data to test data.",
            "We induce a lexicon by constructing a graph on source language monolingual text and employ a graph propagation technique in order to find translations for all the source language phrases.",
            "Experimental results show that our graph propagation method significantly improves performance over two strong baselines under intrinsic and extrinsic evaluation metrics."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.16696381525185527,
                0.12074337252373657,
                0.0,
                0.08208822392113527,
                0.46890296171264917,
                0.06549493218457127
            ],
            [
                0.16696381525185527,
                1.0,
                0.07094755479364064,
                0.0,
                0.07699143100647733,
                0.05089384816087056,
                0.0
            ],
            [
                0.12074337252373657,
                0.07094755479364064,
                1.0,
                0.0,
                0.2921966878345477,
                0.13072437929836148,
                0.09912988426080624
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.08208822392113527,
                0.07699143100647733,
                0.2921966878345477,
                0.0,
                1.0,
                0.06386632992358397,
                0.0
            ],
            [
                0.46890296171264917,
                0.05089384816087056,
                0.13072437929836148,
                0.0,
                0.06386632992358397,
                1.0,
                0.08040278761449857
            ],
            [
                0.06549493218457127,
                0.0,
                0.09912988426080624,
                0.0,
                0.0,
                0.08040278761449857,
                1.0
            ]
        ]
    },
    "P05-1013": {
        "input_sentences": [
            "Experiments using data from the Prague Dependency Treebank show that the combined system can handle nonprojective constructions with a precision sufficient to yield a significant improvement in overall parsing accuracy.",
            "In order to realize the full potential of dependency-based syntactic parsing, it is desirable to allow non-projective dependency structures.",
            "This leads to the best reported performance for robust non-projective parsing of Czech.",
            "Pseudo-Projective Dependency Parsing",
            "Abstract",
            "We show how a datadriven deterministic dependency parser, in itself restricted to projective structures, can be combined with graph transformation techniques to produce non-projective structures."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.08144321369095367,
                0.032450489372445726,
                0.12131451390225402,
                0.0,
                0.06863792038585723
            ],
            [
                0.08144321369095367,
                1.0,
                0.13780197977899936,
                0.30648150243898925,
                0.0,
                0.2735468919984433
            ],
            [
                0.032450489372445726,
                0.13780197977899936,
                1.0,
                0.18317317589198318,
                0.0,
                0.11970540867827119
            ],
            [
                0.12131451390225402,
                0.30648150243898925,
                0.18317317589198318,
                1.0,
                0.0,
                0.19967507121792194
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.06863792038585723,
                0.2735468919984433,
                0.11970540867827119,
                0.19967507121792194,
                0.0,
                1.0
            ]
        ]
    },
    "W05-1505": {
        "input_sentences": [
            "Our model, based on a MaxEnt classifier, improves overall dependency accuracy by .7% (a 4.5% reduction in error) with over 50% accuracy for non-projective structures.",
            "We present a corrective model for recovering non-projective dependency structures from trees generated by state-of-theart constituency-based parsers.",
            "Corrective Modeling",
            "The continuity constraint of these constituencybased parsers makes it impossible for them to posit non-projective dependency trees.",
            "Abstract",
            "Analysis of the types of dependency errors made by these parsers on a Czech corpus show that the correct governor is likely to be found within a local neighborhood of the governor proposed by the parser.",
            "Corrective Modeling For Non-Projective Dependency Parsing"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.2523031455935222,
                0.0,
                0.09735117967117567,
                0.0,
                0.019500210770886643,
                0.15521218761793484
            ],
            [
                0.2523031455935222,
                1.0,
                0.1401974069492356,
                0.23754525591804326,
                0.0,
                0.06080328261400608,
                0.26236638753320074
            ],
            [
                0.0,
                0.1401974069492356,
                1.0,
                0.0,
                0.0,
                0.0,
                0.6064243627418964
            ],
            [
                0.09735117967117567,
                0.23754525591804326,
                0.0,
                1.0,
                0.0,
                0.06964197987329572,
                0.20312743135865047
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.019500210770886643,
                0.06080328261400608,
                0.0,
                0.06964197987329572,
                0.0,
                1.0,
                0.04068803006005379
            ],
            [
                0.15521218761793484,
                0.26236638753320074,
                0.6064243627418964,
                0.20312743135865047,
                0.0,
                0.04068803006005379,
                1.0
            ]
        ]
    },
    "C10-1151": {
        "input_sentences": [
            "Heterogeneous Parsing via Collaborative Decoding",
            "Experimental results show the effectiveness of the proposed approach, which outperforms state of-the-art baselines, especially on long sentences.",
            "There often exist multiple corpora for the same natural language processing (NLP)tasks.",
            "Abstract",
            "However, such corpora are generally used independently due to distinctions in annotation standards.",
            "In this paper, we focus on the challenge of con stituent syntactic parsing with treebanksof different annotations and propose a collaborative decoding (or co-decoding) ap proach to improve parsing accuracy byleveraging bracket structure consensus be tween multiple parsing decoders trainedon individual treebanks.",
            "For the purpose of full use of readily available human annotations, it is significant to simultaneously utilize multiple corpora of different annotation standards."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.42041904276885533,
                0.0
            ],
            [
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.07842143773490254,
                0.033871194581715725,
                0.11090466082549635
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.07842143773490254,
                0.0,
                1.0,
                0.0,
                0.22620589470418923
            ],
            [
                0.42041904276885533,
                0.0,
                0.033871194581715725,
                0.0,
                0.0,
                1.0,
                0.0977011401009634
            ],
            [
                0.0,
                0.0,
                0.11090466082549635,
                0.0,
                0.22620589470418923,
                0.0977011401009634,
                1.0
            ]
        ]
    },
    "D07-1111": {
        "input_sentences": [
            "In the multilingual track, we train three LR models for each of the ten languages, and combine the analyses obtained with each individual model with a maximum spanning tree voting scheme.",
            "Dependency Parsing and Domain Adaptation with LR Models and Parser Ensembles",
            "Abstract",
            "Parser actions are determined by a classifier, based on features that represent the current state of the parser.",
            "We apply this pars ing framework to both tracks of the CoNLL 2007 shared task, in each case taking ad vantage of multiple models trained with different learners.",
            "In the domain adaptation track, we use two models to parse unlabeled data in the target domain to supplement the labeled out-of domain training set, in a scheme similar to one iteration of co-training.",
            "We present a data-driven variant of the LR algorithm for dependency parsing, and extend it with a best-first search for probabil istic generalized LR dependency parsing."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.10128742431762353,
                0.0,
                0.0,
                0.024104350904694784,
                0.09847448192609816,
                0.06247129230653035
            ],
            [
                0.10128742431762353,
                1.0,
                0.0,
                0.18203713615279954,
                0.03943512092845111,
                0.28742705179141836,
                0.38197519747963804
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.18203713615279954,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.024104350904694784,
                0.03943512092845111,
                0.0,
                0.0,
                1.0,
                0.019260060654471813,
                0.0
            ],
            [
                0.09847448192609816,
                0.28742705179141836,
                0.0,
                0.0,
                0.019260060654471813,
                1.0,
                0.03415996070482918
            ],
            [
                0.06247129230653035,
                0.38197519747963804,
                0.0,
                0.0,
                0.0,
                0.03415996070482918,
                1.0
            ]
        ]
    },
    "W99-0623": {
        "input_sentences": [
            "The resulting parsers surpass the best previously published performance results for the Penn Treebank.",
            "Three state-of-the-art statistical parsers are combined to produce more accurate parses, as well as new bounds on achievable Treebank parsing accuracy.",
            "Two general approaches are presented and two combination techniques are described for each approach.",
            "Exploiting Diversity in Natural Language Processing: Combining Parsers",
            "Abstract",
            "Both parametric and non-parametric models are explored."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.10497944026737055,
                0.0,
                0.06224277704893783,
                0.0,
                0.0
            ],
            [
                0.10497944026737055,
                1.0,
                0.0,
                0.05192171700553539,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.06224277704893783,
                0.05192171700553539,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P09-1111": {
        "input_sentences": [
            "An Optimal-Time Binarization Algorithm for Linear Context-Free Rewriting Systems with Fan-Out Two",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0
            ],
            [
                0.0,
                1.0
            ]
        ]
    },
    "W11-0115": {
        "input_sentences": [
            "These representations are then used as feature vectors in a supervised learning model using multivariate multiple regression.",
            "In a second experimental setting based on Verb-Noun pairs, a comparatively much lower performance was obtained by all the models; however, the proposed approach gives the best results in combination with a Random Indexing semantic space.",
            "This article introduces and evaluates an approach to semantic compositionality in computational linguistics based on the combination of Distributional Semantics and supervised Machine Learning.",
            "In particular, the distributional semantic representations of the constituents are used to predict those of the complex structures.",
            "This approach outperforms the rivals in a series of experiments with Adjective-Noun pairs extracted from the BNC.",
            "Abstract",
            "In brief, distributional semantic spaces containing representations for complex constructions such as Adjective-Noun and Verb-Noun pairs, as well as for their constituent parts, are built.",
            "Computing Semantic Compositionality in Distributional Semantics"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.13375122988269428,
                0.1531839387811031,
                0.0,
                0.0,
                0.04681139452763261,
                0.0
            ],
            [
                0.0,
                1.0,
                0.1520639037976498,
                0.028043130806923333,
                0.12518833573055527,
                0.0,
                0.1648478492658114,
                0.04091324873540788
            ],
            [
                0.13375122988269428,
                0.1520639037976498,
                1.0,
                0.08219436255268095,
                0.053732057617199014,
                0.0,
                0.058849673523683706,
                0.3548307665969746
            ],
            [
                0.1531839387811031,
                0.028043130806923333,
                0.08219436255268095,
                1.0,
                0.0,
                0.0,
                0.20930072640699546,
                0.15744260156089224
            ],
            [
                0.0,
                0.12518833573055527,
                0.053732057617199014,
                0.0,
                1.0,
                0.0,
                0.21936303184733663,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.04681139452763261,
                0.1648478492658114,
                0.058849673523683706,
                0.20930072640699546,
                0.21936303184733663,
                0.0,
                1.0,
                0.11272604851262648
            ],
            [
                0.0,
                0.04091324873540788,
                0.3548307665969746,
                0.15744260156089224,
                0.0,
                0.0,
                0.11272604851262648,
                1.0
            ]
        ]
    },
    "P07-1021": {
        "input_sentences": [
            "In this paper, we show how two empirically relevant relaxations of projectivity can be lexicalized, and how combining the resulting lexicons with a regular means of syntactic composition gives rise to a hierarchy of mildly context-sensitive dependency languages.",
            "Most constraints are formulated on fully specified structures, which makes them hard to integrate into models where structures are composed from lexical information.",
            "In previous work, several constraints have been proposed to identify classes of dependency structures that are wellbalanced in this sense; the best-known but also most restrictive of these is projectivity.",
            "Abstract",
            "Dependency-based representations of natural language syntax require a fine balance between structural flexibility and computational complexity.",
            "Mildly Context-Sensitive Dependency Languages"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.06732953170523145,
                0.0,
                0.023149245593213477,
                0.4031535327849477
            ],
            [
                0.0,
                1.0,
                0.15691165239375135,
                0.0,
                0.0,
                0.0
            ],
            [
                0.06732953170523145,
                0.15691165239375135,
                1.0,
                0.0,
                0.028474082175941422,
                0.05738032074855085
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.023149245593213477,
                0.0,
                0.028474082175941422,
                0.0,
                1.0,
                0.05742042103240571
            ],
            [
                0.4031535327849477,
                0.0,
                0.05738032074855085,
                0.0,
                0.05742042103240571,
                1.0
            ]
        ]
    },
    "P10-1074": {
        "input_sentences": [
            "In this paper we present a novel model which makes use of additional single-task annotated data to improve the performance of a joint model.",
            "Experiments on joint parsing and named entity recognition, using the OntoNotes corpus, show that our hierarchical joint model can produce substantial gains over a joint model trained on only the jointly annotated data.",
            "Hierarchical Joint Learning: Improving Joint Parsing and Named Entity Recognition with Non-Jointly Labeled Data",
            "Joint modeling of multiple natural language processing tasks outperforms single-task models learned from the same data, but still underperforms compared to single-task models learned on the more abundant quantities of available single-task annotated data.",
            "One of the main obstacles to producing high quality joint models is the lack of jointly annotated data.",
            "Abstract",
            "Our model utilizes a hierarchical prior to link the feature weights for shared features in several single-task models and the joint model."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.23986852343246856,
                0.07186543956174155,
                0.22696817236890393,
                0.09235793205459515,
                0.0,
                0.28032540440190434
            ],
            [
                0.23986852343246856,
                1.0,
                0.44515497710369695,
                0.07516682640580102,
                0.16220192512535153,
                0.0,
                0.234560984570071
            ],
            [
                0.07186543956174155,
                0.44515497710369695,
                1.0,
                0.06430736307180662,
                0.14808350237781195,
                0.0,
                0.09509590756584681
            ],
            [
                0.22696817236890393,
                0.07516682640580102,
                0.06430736307180662,
                1.0,
                0.14533441258815266,
                0.0,
                0.23606500225390256
            ],
            [
                0.09235793205459515,
                0.16220192512535153,
                0.14808350237781195,
                0.14533441258815266,
                1.0,
                0.0,
                0.0773098587085574
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.28032540440190434,
                0.234560984570071,
                0.09509590756584681,
                0.23606500225390256,
                0.0773098587085574,
                0.0,
                1.0
            ]
        ]
    },
    "N06-1022": {
        "input_sentences": [
            "We suggest that the search space over mlctf algorithms is almost totally unexplored so that future work should be able to improve significantly on these results.",
            "We present experiments showing that with our algorithm the work load (as measured by the total number of constituents processed) is decreased by a factor of ten with no decrease in parsing accuracy compared to standard CKY parsing with the original PCFG.",
            "We use the results of parsing at a coarser level (i.e., grammar defined in terms of a coarser partition) to prune the next finer level.",
            "We present a PCFG parsing algorithm that uses a multilevel coarse-to-fine (mlctf) scheme to improve the efficiency of search for the best parse.",
            "Abstract",
            "We define a sequence of PCFGs corresponding to each partition, where the nonterminals of each PCFG are clusters of nonterminals of the original source PCFG.",
            "Multilevel Coarse-To-Fine PCFG Parsing",
            "Our approach requires the user to specify a sequence of nested partitions or equivalence classes of the PCFG nonterminals."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.04660172965171926,
                0.05206835143420442,
                0.18445298656554832,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.04660172965171926,
                1.0,
                0.045530543918007184,
                0.16875053582416993,
                0.0,
                0.08972044505605271,
                0.1499141447041733,
                0.02274692381344717
            ],
            [
                0.05206835143420442,
                0.045530543918007184,
                1.0,
                0.030035526107417963,
                0.0,
                0.052843260550219436,
                0.06017532411358477,
                0.0
            ],
            [
                0.18445298656554832,
                0.16875053582416993,
                0.030035526107417963,
                1.0,
                0.0,
                0.055973946093327134,
                0.49913359919298467,
                0.030011318348956963
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.08972044505605271,
                0.052843260550219436,
                0.055973946093327134,
                0.0,
                1.0,
                0.11214221239329034,
                0.26261350735121736
            ],
            [
                0.0,
                0.1499141447041733,
                0.06017532411358477,
                0.49913359919298467,
                0.0,
                0.11214221239329034,
                1.0,
                0.060126824556552064
            ],
            [
                0.0,
                0.02274692381344717,
                0.0,
                0.030011318348956963,
                0.0,
                0.26261350735121736,
                0.060126824556552064,
                1.0
            ]
        ]
    },
    "W12-2429": {
        "input_sentences": [
            "This paper describes a large scale WSD system based on automatically labeled examples generated using information from the UMLS Metathesaurus.",
            "The most accurate approaches to Word Sense Disambiguation (WSD) for biomedical documents are based on supervised learning.",
            "The system is evaluated on two widely used data sets and found to outperform a state-of-the-art unsupervised approach which also uses information from the UMLS Metathesaurus.",
            "The labeled examples are generated without any use of labeled training data whatsoever and is therefore completely unsupervised (unlike some previous approaches).",
            "However, these require manually labeled training examples which are expensive to create and consequently supervised WSD systems are normally limited to disambiguating a small set of ambiguous terms.",
            "Abstract",
            "An alternative approach is to create labeled training examples automatically and use them as a substitute for manually labeled ones.",
            "Scaling up WSD with Automatically Generated Examples"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.11340149955561682,
                0.19090084647085712,
                0.1662728405739593,
                0.09226787492992683,
                0.0,
                0.1754876640923778,
                0.33583761630469
            ],
            [
                0.11340149955561682,
                1.0,
                0.0,
                0.07283752657322834,
                0.09325721424447787,
                0.0,
                0.0,
                0.0784366577463478
            ],
            [
                0.19090084647085712,
                0.0,
                1.0,
                0.12853558981288746,
                0.0,
                0.0,
                0.06782950941096844,
                0.0
            ],
            [
                0.1662728405739593,
                0.07283752657322834,
                0.12853558981288746,
                1.0,
                0.13673665672153462,
                0.0,
                0.33983171889219865,
                0.1612205694556837
            ],
            [
                0.09226787492992683,
                0.09325721424447787,
                0.0,
                0.13673665672153462,
                1.0,
                0.0,
                0.267766195330611,
                0.11232744384808081
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.1754876640923778,
                0.0,
                0.06782950941096844,
                0.33983171889219865,
                0.267766195330611,
                0.0,
                1.0,
                0.17015539663458332
            ],
            [
                0.33583761630469,
                0.0784366577463478,
                0.0,
                0.1612205694556837,
                0.11232744384808081,
                0.0,
                0.17015539663458332,
                1.0
            ]
        ]
    },
    "E09-1053": {
        "input_sentences": [
            "We propose a novel algorithm for extracting dependencies from the derivations of a large fragment of CCG.",
            "Unlike earlier proposals, our dependency structures are always tree-shaped.",
            "Dependency Trees and the Strong Generative Capacity of CCG",
            "We then use these dependency trees to compare the strong generative capacities of CCG and TAG and obtain surprising results: Both formalisms generate the same languages of derivation trees \u2013 but the mechanisms they use to bring the words in these trees into a linear order are incomparable.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.07864440790235185,
                0.029131586308236992,
                0.0
            ],
            [
                0.0,
                1.0,
                0.09001775755656882,
                0.03334452052572089,
                0.0
            ],
            [
                0.07864440790235185,
                0.09001775755656882,
                1.0,
                0.3994635764964098,
                0.0
            ],
            [
                0.029131586308236992,
                0.03334452052572089,
                0.3994635764964098,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "W10-1407": {
        "input_sentences": [
            "Direct Parsing of Discontinuous Constituents in German",
            "In both treebanks, discontinuities are annotated with crossing branches.",
            "Discontinuities occur especially frequently in languages with a relatively free word order, such as German.",
            "Generally, due to the longdistance dependencies they induce, they lie beyond the expressivity of Probabilistic CFG, i.e., they cannot be directly reconstructed by a PCFG parser.",
            "Abstract",
            "Based on an evaluation using different metrics, we show that an output quality can be achieved which is comparable to the output quality of PCFG-based systems.",
            "In this paper, we use a parser for Probabilistic Linear Context-Free Rewriting Systems (PLCFRS), a formalism with high expressivity, to directly parse the German NeGra and TIGER treebanks."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.07960236323907142,
                0.0,
                0.0,
                0.0,
                0.05871106288279993
            ],
            [
                0.0,
                1.0,
                0.11049951088374246,
                0.0,
                0.0,
                0.0,
                0.08149938604875165
            ],
            [
                0.07960236323907142,
                0.11049951088374246,
                1.0,
                0.0,
                0.0,
                0.0,
                0.09902757845247039
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.04843195225897241,
                0.21105603877269427
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.04843195225897241,
                0.0,
                1.0,
                0.03873834017542323
            ],
            [
                0.05871106288279993,
                0.08149938604875165,
                0.09902757845247039,
                0.21105603877269427,
                0.0,
                0.03873834017542323,
                1.0
            ]
        ]
    },
    "P04-1042": {
        "input_sentences": [
            "Deep Dependencies From Context-Free Statistical Parsers: Correcting The Surface Dependency Approximation",
            "We find that our algorithm compares favorably with prior work on English using an existing evaluation metric, and also introduce and argue for a new dependency-based evaluation metric.",
            "By this new evaluation metric our algorithm achieves 60% error reduction on gold-standard input trees and 5% error reduction on state-ofthe-art machine-parsed input trees, when compared with the best previous work.",
            "We use an algorithm based on loglinear classifiers to augment and reshape context-free trees so as to reintroduce underlying nonlocal dependencies lost in the context-free approximation.",
            "Our new evaluation metric quantitatively corroborates the intuition that in a language with freer word order, the surface dependencies in context-free parse trees are a poorer approximation to underlying dependency structure.",
            "Abstract",
            "We also present the first results on nonlocal dependency reconstruction for a language other than English, comparing performance on English and German.",
            "We present a linguistically-motivated algorithm for reconstructing nonlocal dependency in broad-coverage context-free parse trees derived from treebanks."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0315349737815744,
                0.0,
                0.2707476404896288,
                0.2830408547013117,
                0.0,
                0.03791508393755931,
                0.1296430668013106
            ],
            [
                0.0315349737815744,
                1.0,
                0.18347487358167147,
                0.07744815235354036,
                0.19882287446759261,
                0.0,
                0.14229423111856102,
                0.05710607189676787
            ],
            [
                0.0,
                0.18347487358167147,
                1.0,
                0.060629080743738,
                0.11542817157079112,
                0.0,
                0.0,
                0.06885289899943273
            ],
            [
                0.2707476404896288,
                0.07744815235354036,
                0.060629080743738,
                1.0,
                0.25989643544934443,
                0.0,
                0.04409600128635275,
                0.23820408696022763
            ],
            [
                0.2830408547013117,
                0.19882287446759261,
                0.11542817157079112,
                0.25989643544934443,
                1.0,
                0.0,
                0.08300429610920237,
                0.1746054242121496
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.03791508393755931,
                0.14229423111856102,
                0.0,
                0.04409600128635275,
                0.08300429610920237,
                0.0,
                1.0,
                0.14749184907934007
            ],
            [
                0.1296430668013106,
                0.05710607189676787,
                0.06885289899943273,
                0.23820408696022763,
                0.1746054242121496,
                0.0,
                0.14749184907934007,
                1.0
            ]
        ]
    },
    "W12-3131": {
        "input_sentences": [
            "Translation System",
            "This paper describes the French-English translation system developed by the Avenue research group at Carnegie Mellon University for the Seventh Workshop on Statistical Machine Translation (NAACL WMT12).",
            "The CMU-Avenue French-English Translation System",
            "Abstract",
            "We present a method for training data selection, a description of our hierarchical phrase-based translation system, and a discussion of the impact of data size on best practice for system building."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.2715108651291912,
                0.31154420869927224,
                0.0,
                0.13163503185293263
            ],
            [
                0.2715108651291912,
                1.0,
                0.3447930721285891,
                0.0,
                0.03574034137969838
            ],
            [
                0.31154420869927224,
                0.3447930721285891,
                1.0,
                0.0,
                0.04101013183572539
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.13163503185293263,
                0.03574034137969838,
                0.04101013183572539,
                0.0,
                1.0
            ]
        ]
    },
    "P04-1015": {
        "input_sentences": [
            "The perceptron approach was implemented with the same feature set as that of an existing generative model (Roark, 2001a), and experimental results show that it gives competitive performance to the generative model on parsing the Penn treebank.",
            "Incremental Parsing With The Perceptron Algorithm",
            "We demonstrate that training a perceptron model to combine with the generative model during search provides a 2.1 percent F-measure improvement over the generative model alone, to 88.8 percent.",
            "This paper describes an incremental parsing approach where parameters are estimated using a variant of the perceptron algorithm.",
            "A beam-search algorithm is used during both training and decoding phases of the method.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.13238327957158225,
                0.3510228752135376,
                0.11462233171550767,
                0.0,
                0.0
            ],
            [
                0.13238327957158225,
                1.0,
                0.0552850908583776,
                0.4786465198477012,
                0.13029321231006596,
                0.0
            ],
            [
                0.3510228752135376,
                0.0552850908583776,
                1.0,
                0.0264620163388264,
                0.11387445392016877,
                0.0
            ],
            [
                0.11462233171550767,
                0.4786465198477012,
                0.0264620163388264,
                1.0,
                0.06236439263199073,
                0.0
            ],
            [
                0.0,
                0.13029321231006596,
                0.11387445392016877,
                0.06236439263199073,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "E99-1016": {
        "input_sentences": [
            "This paper presents a new approach to partial parsing of context-free structures.",
            "The approach is based on Markov Mod- els.",
            "Cascaded Markov Models",
            "Abstract",
            "An em- pirical evaluation of the method yields very good results for NP/PP chunking of German ewspaper texts.",
            "Each layer of the resulting structure is represented byits own Markov Model, and output of a lower layer is passed as input to the next higher layer."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.1120620580524022,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.1120620580524022,
                1.0,
                0.1493915352834391,
                0.0,
                0.0,
                0.053297101285115965
            ],
            [
                0.0,
                0.1493915352834391,
                1.0,
                0.0,
                0.0,
                0.06896891312617925
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.053297101285115965,
                0.06896891312617925,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "C08-1049": {
        "input_sentences": [
            "As a derivation of the forest reranking for parsing (Huang, 2008), this strategy reranks on the pruned word lattice, which potentially contains much more candidates while using less storage, compared with the traditional n-best list reranking.",
            "Word Lattice Reranking for Chinese Word Segmentation and Part-of-Speech Tagging",
            "With aperceptron classifier trained with local features as the baseline, word lattice reranking performs reranking with non-local fea tures that can?t be easily incorporated intothe perceptron baseline.",
            "Abstract",
            "In this paper, we describe a new rerank ing strategy named word lattice reranking,for the task of joint Chinese word segmen tation and part-of-speech (POS) tagging.",
            "Word Lattice",
            "Experimental results show that, this strategy achieves im provement on both segmentation and POS tagging, above the perceptron baseline and the n-best list reranking."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.16688035282945146,
                0.09260151655061258,
                0.0,
                0.12552588273825757,
                0.18175667304304033,
                0.18168604310254896
            ],
            [
                0.16688035282945146,
                1.0,
                0.1559270005130607,
                0.0,
                0.4697279342535184,
                0.5508915299850384,
                0.22106478015073647
            ],
            [
                0.09260151655061258,
                0.1559270005130607,
                1.0,
                0.0,
                0.08715147694431996,
                0.1698268991544983,
                0.1825493526033387
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.12552588273825757,
                0.4697279342535184,
                0.08715147694431996,
                0.0,
                1.0,
                0.30790697131566225,
                0.1654842573712204
            ],
            [
                0.18175667304304033,
                0.5508915299850384,
                0.1698268991544983,
                0.0,
                0.30790697131566225,
                1.0,
                0.0
            ],
            [
                0.18168604310254896,
                0.22106478015073647,
                0.1825493526033387,
                0.0,
                0.1654842573712204,
                0.0,
                1.0
            ]
        ]
    },
    "P04-1054": {
        "input_sentences": [
            "Using this kernel within a Support Vector Machine, we detect and classify relations between entities in the Automatic Content Extraction (ACE) corpus of news articles.",
            "We examine the utility of different features such as Wordnet hypernyms, parts of speech, and entity types, and find that the dependency tree kernel achieves a 20% F1 improvement over a \u201cbag-of-words\u201d kernel.",
            "Abstract",
            "We extend previous work on tree kernels to estimate the similarity between the dependency trees of sentences.",
            "Dependency Tree Kernels For Relation Extraction"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.07536301602683898,
                0.0,
                0.0,
                0.09303699966763025
            ],
            [
                0.07536301602683898,
                1.0,
                0.0,
                0.06947841138762685,
                0.11357509635691121
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.06947841138762685,
                0.0,
                1.0,
                0.2960238424768766
            ],
            [
                0.09303699966763025,
                0.11357509635691121,
                0.0,
                0.2960238424768766,
                1.0
            ]
        ]
    },
    "P08-1013": {
        "input_sentences": [
            "The language model is applied by means of an N-best rescoring step, which allows to directly measure the performance gains relative to the baseline system without rescoring.",
            "To demonstrate that our approach is feasible and beneficial for non-trivial broad-domain speech recognition tasks, we applied it to a simplified German broadcast-news transcription task.",
            "Language Model",
            "We propose a language model based on a precise, linguistically motivated grammar (a hand-crafted Head-driven Phrase Structure Grammar) and a statistical model estimating the probability of a parse tree.",
            "We report a significant reduction in word error rate compared to a state-of-the-art baseline system.",
            "Abstract",
            "Applying a Grammar-Based Language Model to a Simplified Broadcast-News Transcription Task"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.04409111059093177,
                0.22391791397520558,
                0.06487630795959635,
                0.05689643691732357,
                0.0,
                0.07603451606036322
            ],
            [
                0.04409111059093177,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.33431368105511305
            ],
            [
                0.22391791397520558,
                0.0,
                1.0,
                0.28973254889637867,
                0.0,
                0.0,
                0.3395642390129739
            ],
            [
                0.06487630795959635,
                0.0,
                0.28973254889637867,
                1.0,
                0.0,
                0.0,
                0.2770219041763821
            ],
            [
                0.05689643691732357,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.07603451606036322,
                0.33431368105511305,
                0.3395642390129739,
                0.2770219041763821,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P10-1097": {
        "input_sentences": [
            "It employs a systematic combination of firstand second-order context vectors.",
            "We apply our model to two different tasks and show that (i) it substantially outperforms previous work on a paraphrase ranking task, and (ii) achieves promising results on a wordsense similarity task; to our knowledge, it is the first time that an unsupervised method has been applied to this task.",
            "Abstract",
            "Contextualizing Semantic Representations Using Syntactically Enriched Vector Models",
            "We present a syntactically enriched vector model that supports the computation of contextualized semantic representations in a quasi compositional fashion."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                1.0,
                0.0,
                0.0,
                0.03619788713249855
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.39406983670324713
            ],
            [
                0.0,
                0.03619788713249855,
                0.0,
                0.39406983670324713,
                1.0
            ]
        ]
    },
    "P07-1083": {
        "input_sentences": [
            "This approach achieves exceptional performance; on nine separate cognate identification experiments using six language pairs, we more than double the precision of traditional orthographic measures like Longest Common Subsequence Ratio and Dice\u2019s Coefficient.",
            "Alignment-Based Discriminative String Similarity",
            "We also show strong improvements over other recent discriminative and heuristic similarity functions.",
            "A character-based measure of similarity is an important component of many natural language processing systems, including approaches to transliteration, coreference, word alignment, spelling correction, and the identification of cognates in related vocabu- We propose an alignment-based disfor string similarity.",
            "Abstract",
            "We gather features from substring pairs consistent with a character-based alignment of the two strings."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0,
                0.05573783683258382,
                0.0,
                0.05302704053741744
            ],
            [
                0.0,
                1.0,
                0.2783636855638486,
                0.4136483976843177,
                0.0,
                0.2126348673906855
            ],
            [
                0.0,
                0.2783636855638486,
                1.0,
                0.07516141728962629,
                0.0,
                0.0
            ],
            [
                0.05573783683258382,
                0.4136483976843177,
                0.07516141728962629,
                1.0,
                0.0,
                0.18635005752899697
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.05302704053741744,
                0.2126348673906855,
                0.0,
                0.18635005752899697,
                0.0,
                1.0
            ]
        ]
    },
    "W10-3504": {
        "input_sentences": [
            "Expanding textual entailment corpora fromWikipedia using co-training",
            "In this paper we propose a novel method to automatically extract large textual entailment datasets homogeneous to existing ones.",
            "The key idea is the combination of two intuitions: (1) the use of Wikipedia to extract a large set of textual entailment pairs; (2) the application of semisupervised machine learning methods to make the extracted dataset homogeneous to the existing ones.",
            "Abstract",
            "We report empirical evidence that our method successfully expands existing textual entailment corpora."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.09035671070062312,
                0.06222936284553251,
                0.0,
                0.2057849314445246
            ],
            [
                0.09035671070062312,
                1.0,
                0.27192963037853835,
                0.0,
                0.20883466568052536
            ],
            [
                0.06222936284553251,
                0.27192963037853835,
                1.0,
                0.0,
                0.08984317689613555
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.2057849314445246,
                0.20883466568052536,
                0.08984317689613555,
                0.0,
                1.0
            ]
        ]
    },
    "P11-2074": {
        "input_sentences": [
            "The proposed approach improves the translation performance significantly on a large-scale Arabic-to-English MT task.",
            "Discriminative Feature-Tied Mixture Modeling for Statistical Machine Translation",
            "We model the feature space with a log-linear combination of multiple mixture components.",
            "Abstract",
            "In this paper we present a novel discriminative mixture model for statistical machine translation (SMT).",
            "Each component contains a large set of features trained in a maximumentropy framework.",
            "This approach aims at bridging the gap between the maximum-likelihood training and the discriminative training for SMT.",
            "It is shown that the feature space can be partitioned in a variety of ways, such as based on feature types, word alignments, or domains, for various applications.",
            "All features within the same mixture component are tied and share the same mixture weights, where the mixture weights are trained discriminatively to maximize the translation performance."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.05758808161740652,
                0.0,
                0.0,
                0.04816437750564215,
                0.08385071328379402,
                0.06628846906494912,
                0.0,
                0.09080574206408072
            ],
            [
                0.05758808161740652,
                1.0,
                0.15706107523130716,
                0.0,
                0.46407408096488423,
                0.0,
                0.07239295348653435,
                0.12873726471627112,
                0.2772329409999136
            ],
            [
                0.0,
                0.15706107523130716,
                1.0,
                0.0,
                0.1551715153983802,
                0.0,
                0.0,
                0.17703055472465407,
                0.12088921333872396
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.04816437750564215,
                0.46407408096488423,
                0.1551715153983802,
                0.0,
                1.0,
                0.0,
                0.14063676814676937,
                0.0,
                0.16287261958233687
            ],
            [
                0.08385071328379402,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.21266212759802347
            ],
            [
                0.06628846906494912,
                0.07239295348653435,
                0.0,
                0.0,
                0.14063676814676937,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.12873726471627112,
                0.17703055472465407,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.09080574206408072,
                0.2772329409999136,
                0.12088921333872396,
                0.0,
                0.16287261958233687,
                0.21266212759802347,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "W10-1404": {
        "input_sentences": [
            "The present work has examined several directions that try to explore the rich set of morphosyntactic features in the BDT: i) experimenting the impact of morphological features, ii) application of dependency tree transformations, iii) application of a two-stage parsing scheme (stacking), and iv) combinations of the individual experiments.",
            "Application of Different Techniques to Dependency Parsing of Basque",
            "All the tests were conducted using MaltParser (Vivre et al., 2007a), a freely available and state of the art dependency parser generator.",
            "Abstract",
            "We present a set of experiments on dependency parsing of the Basque Dependency Treebank (BDT)."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.18726360402015377,
                0.01532173170026992,
                0.0,
                0.2755615011987317
            ],
            [
                0.18726360402015377,
                1.0,
                0.04159085171668782,
                0.0,
                0.35183947906595825
            ],
            [
                0.01532173170026992,
                0.04159085171668782,
                1.0,
                0.0,
                0.06864668793598691
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.2755615011987317,
                0.35183947906595825,
                0.06864668793598691,
                0.0,
                1.0
            ]
        ]
    },
    "E06-2025": {
        "input_sentences": [
            "We analyze estimation methods for Data- Oriented Parsing, as well as the theoretical criteria used to evaluate them.",
            "Abstract",
            "We show that all current estimation methods are inconsistent in the \u201cweight-distribution test\u201d, and argue that these results force us to rethink both the methods proposed and the criteria used.",
            "Estimation Methods",
            "Theoretical Evaluation Of Estimation Methods For Data-Oriented Parsing"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.24550173492892394,
                0.31154420869927235,
                0.6150863983548802
            ],
            [
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.24550173492892394,
                0.0,
                1.0,
                0.33289163108465586,
                0.1288300025089341
            ],
            [
                0.31154420869927235,
                0.0,
                0.33289163108465586,
                1.0,
                0.387002827584368
            ],
            [
                0.6150863983548802,
                0.0,
                0.1288300025089341,
                0.387002827584368,
                1.0
            ]
        ]
    },
    "P08-1006": {
        "input_sentences": [
            "We evaluate eight parsers (based on dependency parsing, phrase structure parsing, or deep parsing) using five different parse representations.",
            "This paper presents a comparative evaluation of several state-of-the-art English parsers based on different frameworks.",
            "Task-oriented Evaluation of Syntactic Parsers and Their Representations",
            "We run a PPI system with several combinations of parser and parse representation, and examine their impact on PPI identification accuracy.",
            "Syntactic Parsers and Their Representations",
            "Abstract",
            "Our approach is to measure the impact of each parser when it is used as a component of an information extraction system that performs protein-protein interaction (PPI) identification in biomedical papers.",
            "Our experiments show that the levels of accuracy obtained with these different parsers are similar, but that accuracy improvements vary when the parsers are retrained with domain-specific data."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.12021035857532351,
                0.0965257363205172,
                0.05186900654724611,
                0.16019565245640235,
                0.0,
                0.0,
                0.07161303630194604
            ],
            [
                0.12021035857532351,
                1.0,
                0.1624668763457072,
                0.0,
                0.08348828488197337,
                0.0,
                0.0,
                0.09928485148381047
            ],
            [
                0.0965257363205172,
                0.1624668763457072,
                1.0,
                0.0,
                0.6025490382567462,
                0.0,
                0.0,
                0.08007240283472407
            ],
            [
                0.05186900654724611,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.26662004723806987,
                0.11446263964175288
            ],
            [
                0.16019565245640235,
                0.08348828488197337,
                0.6025490382567462,
                0.0,
                1.0,
                0.0,
                0.0,
                0.13288943762383904
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.26662004723806987,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.07161303630194604,
                0.09928485148381047,
                0.08007240283472407,
                0.11446263964175288,
                0.13288943762383904,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "D08-1008": {
        "input_sentences": [
            "To tackle the problemof joint syntactic?semantic analysis, the system relies on a syntactic and a semantic subcomponent.",
            "Using a dependency-based metric, the F1 figure of our system is 84.29 on the test set from CoNLL-2008.",
            "The syntactic model is a projective parser using pseudo-projective transfor mations, and the semantic model uses global inference mechanisms on top of a pipeline of classifiers.",
            "The complete syntactic?semanticoutput is selected from a candidate pool gen erated by the subsystems.We evaluate the system on the CoNLL 2005 test sets using segment-based and dependency-based metrics.",
            "Our system is the first dependency-based semantic role labeler for PropBank that rivals constituent-based systems in terms of performance.",
            "Abstract",
            "We present a PropBank semantic role label ing system for English that is integrated with a dependency parser.",
            "Dependency-based Semantic Role Labeling of PropBank",
            "Using the segment-based CoNLL-2005 metric, our system achieves a near state-of-the-art F1 figure of 77.97 on the WSJ+Brown test set, or 78.84 if punctuation is treated consistently."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.13016791215768073,
                0.08710941533850224,
                0.07215496098259537,
                0.0,
                0.07963552264622632,
                0.12387129076153648,
                0.0
            ],
            [
                0.0,
                1.0,
                0.03471621309591904,
                0.22417961144476903,
                0.11991983026593747,
                0.0,
                0.04411744865414601,
                0.13724742748715646,
                0.4475479050972144
            ],
            [
                0.13016791215768073,
                0.03471621309591904,
                1.0,
                0.05482234704302216,
                0.025502083254127117,
                0.0,
                0.0880422861948853,
                0.043780440412945036,
                0.02225406800461884
            ],
            [
                0.08710941533850224,
                0.22417961144476903,
                0.05482234704302216,
                1.0,
                0.13837212049289754,
                0.0,
                0.03054353016080625,
                0.14252935297131286,
                0.20631660958207396
            ],
            [
                0.07215496098259537,
                0.11991983026593747,
                0.025502083254127117,
                0.13837212049289754,
                1.0,
                0.0,
                0.212363720550516,
                0.4569487982097001,
                0.051247987032591646
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.07963552264622632,
                0.04411744865414601,
                0.0880422861948853,
                0.03054353016080625,
                0.212363720550516,
                0.0,
                1.0,
                0.3645732437144538,
                0.0
            ],
            [
                0.12387129076153648,
                0.13724742748715646,
                0.043780440412945036,
                0.14252935297131286,
                0.4569487982097001,
                0.0,
                0.3645732437144538,
                1.0,
                0.043989728607772796
            ],
            [
                0.0,
                0.4475479050972144,
                0.02225406800461884,
                0.20631660958207396,
                0.051247987032591646,
                0.0,
                0.0,
                0.043989728607772796,
                1.0
            ]
        ]
    },
    "W08-2107": {
        "input_sentences": [
            "The results obtained show that such combination can successfully be used to detect VPCs and distinguish idiomatic from compositional cases.",
            "Given the limited coverage provided by lexical resources, such as dictionaries, and the constantly growing number of VPCs, possible ways of automatically identifying them are crucial for any NLP task that requires some degree of semantic interpretation.",
            "Abstract",
            "Picking them up and Figuring them out: Verb-Particle Constructions Noise and Idiomaticity",
            "This paper investigates, in a first stage, some methods for the automatic acquisition of verb-particle constructions (VPCs) taking into account their statistical properties and some regular patterns found in productive combinations of verbs and particles.",
            "In a second stage we also study whether the combination of statistical and linguistic properties can provide some indication of the degree of idiomaticity of a given VPC."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.03296483159915582,
                0.0,
                0.0,
                0.03594543797533339,
                0.06449705241635614
            ],
            [
                0.03296483159915582,
                1.0,
                0.0,
                0.0,
                0.025097474459120035,
                0.09006501057624192
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.20208264067387743,
                0.08615197395747062
            ],
            [
                0.03594543797533339,
                0.025097474459120035,
                0.0,
                0.20208264067387743,
                1.0,
                0.14731273122136723
            ],
            [
                0.06449705241635614,
                0.09006501057624192,
                0.0,
                0.08615197395747062,
                0.14731273122136723,
                1.0
            ]
        ]
    },
    "P07-1055": {
        "input_sentences": [
            "In this paper we investigate a structured model for jointly classifying the sentiment of text at varying levels of granularity.",
            "Inference in the model is based on standard sequence classification techniques using constrained Viterbi to ensure consistent solutions.",
            "The primary advantage of such a model is that it allows classification decisions from one level in the text to influence decisions at another.",
            "Abstract",
            "Structured Models for Fine-to-Coarse Sentiment Analysis",
            "Experiments show that this method can significantly reduce classification error relative to models trained in isolation."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.04497600651017465,
                0.1146241636303756,
                0.0,
                0.1948299794864631,
                0.0
            ],
            [
                0.04497600651017465,
                1.0,
                0.08501720189677947,
                0.0,
                0.0,
                0.04581554378205222
            ],
            [
                0.1146241636303756,
                0.08501720189677947,
                1.0,
                0.0,
                0.0,
                0.04859208037710932
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.1948299794864631,
                0.0,
                0.0,
                0.0,
                1.0,
                0.09923337072177646
            ],
            [
                0.0,
                0.04581554378205222,
                0.04859208037710932,
                0.0,
                0.09923337072177646,
                1.0
            ]
        ]
    },
    "P08-1102": {
        "input_sentences": [
            "With a character-based perceptron as the core, combined with realvalued features such as language models, the cascaded model is able to efficiently utilize knowledge sources that are inconvenient to incorporate into the perceptron directly.",
            "A Cascaded Linear Model for Joint Chinese Word Segmentation and Part-of-Speech Tagging",
            "Experiments show that the cascaded model achieves improved accuracies on both segmentation only and joint segmentation and part-of-speech tagging.",
            "Cascaded Linear Model",
            "Abstract",
            "On the Penn Chinese Treebank 5.0, we obtain an error reduction of segmentation and joint segmentation and part-of-speech tagging over the perceptron-only baseline.",
            "We propose a cascaded linear model for joint Chinese word segmentation and partof-speech tagging."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.06796933082472052,
                0.04922165767715351,
                0.12709014970295665,
                0.0,
                0.09985545105671098,
                0.05500672816916665
            ],
            [
                0.06796933082472052,
                1.0,
                0.47304862096359185,
                0.5348119502855483,
                0.0,
                0.39264038195718426,
                0.8092874757148655
            ],
            [
                0.04922165767715351,
                0.47304862096359185,
                1.0,
                0.20772681383199545,
                0.0,
                0.3146032628102604,
                0.3828323243500233
            ],
            [
                0.12709014970295665,
                0.5348119502855483,
                0.20772681383199545,
                1.0,
                0.0,
                0.0,
                0.4328166132287353
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.09985545105671098,
                0.39264038195718426,
                0.3146032628102604,
                0.0,
                0.0,
                1.0,
                0.3177589435778502
            ],
            [
                0.05500672816916665,
                0.8092874757148655,
                0.3828323243500233,
                0.4328166132287353,
                0.0,
                0.3177589435778502,
                1.0
            ]
        ]
    },
    "P11-2124": {
        "input_sentences": [
            "Joint Hebrew Segmentation and Parsing using a PCFGLA Lattice Parser",
            "This result indicates that lattice parsing with the Berkeley parser is an effective methodology for parsing over uncertain inputs.",
            "We show that the methodology is very effective: using a small training set of about 5500 trees, we construct a parser which parses and segments unsegmented Hebrew text with an F-score of almost 80%, an error reduction of over 20% over the best previous result for this task.",
            "We experiment with extending a lattice parsing methodology for parsing Hebrew (Goldberg and Tsarfaty, 2008; Golderg et al., 2009) to make use of a stronger syntactic model: the PCFG-LA Berkeley Parser.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.2556712016743063,
                0.1335922476623724,
                0.20426471284871925,
                0.0
            ],
            [
                0.2556712016743063,
                1.0,
                0.15928526025185913,
                0.289225171261873,
                0.0
            ],
            [
                0.1335922476623724,
                0.15928526025185913,
                1.0,
                0.05886492310232547,
                0.0
            ],
            [
                0.20426471284871925,
                0.289225171261873,
                0.05886492310232547,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "S12-1097": {
        "input_sentences": [
            "University_Of_Sheffield: Two Approaches to Semantic Text Similarity",
            "Resultsfrom the formal evaluation show that both approaches are useful for determining the simi larity in meaning between pairs of sentences with the best performance being obtained bythe supervised approach.",
            "This paper describes the University of Sheffield?s submission to SemEval-2012 Task 6: Semantic Text Similarity.",
            "Abstract",
            "Incorporating information from WordNet alo improves perfor mance for both approaches.",
            "Two approaches were developed.",
            "This approach also makes use of information from WordNet.",
            "The first is an unsupervised technique based on the widely used vector space model and information from WordNet.The second method relies on supervised ma chine learning and represents each sentence as a set of n-grams."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.053983835901935374,
                0.35381268327851667,
                0.0,
                0.08452221088839335,
                0.1812603532706148,
                0.0,
                0.0
            ],
            [
                0.053983835901935374,
                1.0,
                0.0,
                0.0,
                0.03982462930768378,
                0.08540508230095657,
                0.0912482334567221,
                0.039754014891000604
            ],
            [
                0.35381268327851667,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.08452221088839335,
                0.03982462930768378,
                0.0,
                0.0,
                1.0,
                0.1337182928292661,
                0.21276519024653573,
                0.09269517031646436
            ],
            [
                0.1812603532706148,
                0.08540508230095657,
                0.0,
                0.0,
                0.1337182928292661,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0912482334567221,
                0.0,
                0.0,
                0.21276519024653573,
                0.0,
                1.0,
                0.12157651979442317
            ],
            [
                0.0,
                0.039754014891000604,
                0.0,
                0.0,
                0.09269517031646436,
                0.0,
                0.12157651979442317,
                1.0
            ]
        ]
    },
    "W09-1218": {
        "input_sentences": [
            "Dependency Parsing",
            "This paper describes a system for syntacticsemantic dependency parsing for multiple languages.",
            "The system consists of three parts: a state-of-the-art higher-order projective dependency parser for syntactic dependency parsing, a predicate classifier, and an argument classifier for semantic dependency parsing.",
            "All components are trained with an approximate max-margin learning algorithm.",
            "Multilingual Syntactic-Semantic Dependency Parsing with Three-Stage Approximate Max-Margin Linear Models",
            "In the closed challenge of the CoNLL-2009 Shared Task (Haji\u02c7c et al., 2009), our system achieved the 3rd best performances for English and Czech, and the 4th best performance for Japanese.",
            "Abstract",
            "For semantic dependency parsing, we explore use of global features."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.33452702897418884,
                0.4514564436438089,
                0.0,
                0.2812943846447426,
                0.0,
                0.0,
                0.349667159976535
            ],
            [
                0.33452702897418884,
                1.0,
                0.15102438280341668,
                0.0,
                0.09410057476232842,
                0.0,
                0.0,
                0.11697311615679262
            ],
            [
                0.4514564436438089,
                0.15102438280341668,
                1.0,
                0.0,
                0.22578691724725558,
                0.0,
                0.0,
                0.21027550649101298
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.30216596281051555,
                0.0,
                0.0,
                0.0
            ],
            [
                0.2812943846447426,
                0.09410057476232842,
                0.22578691724725558,
                0.30216596281051555,
                1.0,
                0.0,
                0.0,
                0.1800080959066055
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.349667159976535,
                0.11697311615679262,
                0.21027550649101298,
                0.0,
                0.1800080959066055,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "W09-2208": {
        "input_sentences": [
            "We also show that our algorithm achieves high accuracy when the training and test sets are from different domains.",
            "The algorithm is based on exploiting evidence that is independent from the features used for a classifier, which provides high-precision labels to unlabeled data.",
            "We show that our algorithm achieves an averimprovement of recall and precision compared to the supervised algorithm.",
            "Named Entity Recognition",
            "Abstract",
            "We present a simple semi-supervised learning algorithm for named entity recognition (NER) using conditional random fields (CRFs).",
            "A Simple Semi-supervised Algorithm For Named Entity Recognition",
            "Such independent evidence is used to automatically extract highaccuracy and non-redundant data, leading to a much improved classifier at the next iteration."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.10926158135945875,
                0.19278361846597786,
                0.0,
                0.0,
                0.03299014420935342,
                0.05807337050744992,
                0.0
            ],
            [
                0.10926158135945875,
                1.0,
                0.15982719616690833,
                0.0,
                0.0,
                0.027350468323393592,
                0.048145708924981954,
                0.3088475547253388
            ],
            [
                0.19278361846597786,
                0.15982719616690833,
                1.0,
                0.0,
                0.0,
                0.13487223088626113,
                0.23741893899340683,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.36446553866706705,
                0.6415777430342045,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.03299014420935342,
                0.027350468323393592,
                0.13487223088626113,
                0.36446553866706705,
                0.0,
                1.0,
                0.5680769674823902,
                0.0
            ],
            [
                0.05807337050744992,
                0.048145708924981954,
                0.23741893899340683,
                0.6415777430342045,
                0.0,
                0.5680769674823902,
                1.0,
                0.0
            ],
            [
                0.0,
                0.3088475547253388,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "D11-1086": {
        "input_sentences": [
            "In this paper, we explore techniques to recover the desired sparsity in covariance matrices in two ways.",
            "First, we explore word association measures and bilingual dictionaries to weigh the word pairs.",
            "Improving Bilingual Projections via Sparse Covariance Matrices",
            "Later, we explore different selection strategies to remove the noisy pairsbased on the association scores.",
            "Unfortunately, the presence of noise leads to dense covariance matrices which in turn leads to suboptimal document representations.",
            "Our experimental results on the task of aligning compa rable documents shows the efficacy of sparse covariance matrices on two data sets from two different language pairs.",
            "Abstract",
            "In theory, sucha covariance matrix should represent seman tic equivalence, and should be highly sparse.",
            "Mapping documents into an interlingual representation can help bridge the language bar rier of cross-lingual corpora.",
            "Many existing approaches are based on word co-occurrencesextracted from aligned training data, repre sented as a covariance matrix."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.069865511926016,
                0.13442041780470743,
                0.06834773112169427,
                0.07537448304009194,
                0.07214075108150873,
                0.0,
                0.03650151135123298,
                0.0,
                0.03303410837006869
            ],
            [
                0.069865511926016,
                1.0,
                0.12310941545796504,
                0.1449272745451155,
                0.0,
                0.06607036223653279,
                0.0,
                0.0,
                0.0,
                0.152310665850639
            ],
            [
                0.13442041780470743,
                0.12310941545796504,
                1.0,
                0.0,
                0.10166034214767561,
                0.17149061740743282,
                0.0,
                0.1437234422312281,
                0.0,
                0.044554318968374335
            ],
            [
                0.06834773112169427,
                0.1449272745451155,
                0.0,
                1.0,
                0.0,
                0.06463502848211351,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.07537448304009194,
                0.0,
                0.10166034214767561,
                0.0,
                1.0,
                0.05455907337225703,
                0.0,
                0.027605598862702384,
                0.0,
                0.024983248931152863
            ],
            [
                0.07214075108150873,
                0.06607036223653279,
                0.17149061740743282,
                0.06463502848211351,
                0.05455907337225703,
                1.0,
                0.0,
                0.07713349831752664,
                0.11462196823100847,
                0.08387198129854358
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.03650151135123298,
                0.0,
                0.1437234422312281,
                0.0,
                0.027605598862702384,
                0.07713349831752664,
                0.0,
                1.0,
                0.0,
                0.10682152981292312
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.11462196823100847,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.03303410837006869,
                0.152310665850639,
                0.044554318968374335,
                0.0,
                0.024983248931152863,
                0.08387198129854358,
                0.0,
                0.10682152981292312,
                0.0,
                1.0
            ]
        ]
    },
    "P12-1065": {
        "input_sentences": [
            "This paper introduces a novel variant of the Yarowsky algorithm based on this view.",
            "Bootstrapping via Graph Propagation",
            "The experimental results show that our proposed bootstrapping algorithm achieves state of the art performance or better on several different natural language data sets.",
            "Abstract",
            "It is a bootstrapping learning method which uses a graph propagation algorithm with a well defined objective function.",
            "Bootstrapping a classifier from a small set of seed rules can be viewed as the propagation of labels between examples via features shared between them."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.04712410475653965,
                0.0,
                0.06202853837870771,
                0.0
            ],
            [
                0.0,
                1.0,
                0.07717576400681965,
                0.0,
                0.4340051276607553,
                0.205976010020595
            ],
            [
                0.04712410475653965,
                0.07717576400681965,
                1.0,
                0.0,
                0.0791079424249923,
                0.02875535781961868
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.06202853837870771,
                0.4340051276607553,
                0.0791079424249923,
                0.0,
                1.0,
                0.08939464452404132
            ],
            [
                0.0,
                0.205976010020595,
                0.02875535781961868,
                0.0,
                0.08939464452404132,
                1.0
            ]
        ]
    },
    "N03-2024": {
        "input_sentences": [
            "References To Named Entities: A Corpus Study",
            "References included in multi-document summaries are often problematic.",
            "Abstract",
            "The interpretation of the probabilistic data helps us gain insight on how extractive summaries can be rewritten in an efficient manner to produce more fluent and easy-to-read text.",
            "In this paper, we present a corpus study performed to derive a statistical model for the syntactic realization of referential expressions."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.14218783310364055,
                0.0,
                0.0,
                0.19477400403431264
            ],
            [
                0.14218783310364055,
                1.0,
                0.0,
                0.07145656434696325,
                0.0
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.07145656434696325,
                0.0,
                1.0,
                0.0
            ],
            [
                0.19477400403431264,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "W07-0738": {
        "input_sentences": [
            "This happens, for instance, when the systems under evaluation are based on different paradigms, and therefore, do not share the same lexicon.",
            "The reason is that, while MT quality aspects are its scope to the lexical dimension.",
            "We provide experimental results showing that metrics based on deeper linguistic information (syntactic/shallow-semantic) are able to produce more reliable system rankings than metrics based on lexical matching alone, specially when the systems under evaluation are of a different nature.",
            "Linguistic Features for Automatic Evaluation of Heterogenous MT Systems",
            "Abstract",
            "Evaluation results recently reported by Callison-Burch et al. (2006) and Koehn and Monz (2006), revealed that, in certain cases, may not be a reliable MT quality indicator.",
            "In this work, we suggest using metrics which take into account linguistic features at more abstract levels."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.22509696558712622,
                0.15312381600554087,
                0.0,
                0.03235084027724377,
                0.0
            ],
            [
                0.0,
                1.0,
                0.058417260878013307,
                0.09701075341553611,
                0.0,
                0.11295347379310382,
                0.0
            ],
            [
                0.22509696558712622,
                0.058417260878013307,
                1.0,
                0.13320926534069458,
                0.0,
                0.08301301392464876,
                0.14059962537777904
            ],
            [
                0.15312381600554087,
                0.09701075341553611,
                0.13320926534069458,
                1.0,
                0.0,
                0.09478417291776962,
                0.2025389465639417
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.30168867846139075
            ],
            [
                0.03235084027724377,
                0.11295347379310382,
                0.08301301392464876,
                0.09478417291776962,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.14059962537777904,
                0.2025389465639417,
                0.30168867846139075,
                0.0,
                1.0
            ]
        ]
    },
    "P12-1045": {
        "input_sentences": [
            "We also include experimental results on a Chinese translation of the training data to demonstrate the generality of our approach.",
            "Recent work by Chen and Mooney (2011) introduced a lexicon learning method that deals with ambiguous relational data by taking intersections of graphs.",
            "While the algorithm produced good lexicons for the task of learning to interpret navigation instructions, it only works in batch settings and does not scale well to large datasets.",
            "Learning a semantic lexicon is often an important first step in building a system that learns to interpret the meaning of natural language.",
            "Fast Online Lexicon Learning for Grounded Language Acquisition",
            "Abstract",
            "In this paper we introduce a new online algorithm that is an order of magnitude faster and surpasses the stateof-the-art results.",
            "We show that by changing the grammar of the formal meaning representation language and training on additional data collected from Amazon\u2019s Mechanical Turk we can further improve the results.",
            "It is especially important in language grounding where the training data usually consist of language paired with an ambiguous perceptual context."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.03846520854302776,
                0.0,
                0.0,
                0.0,
                0.0,
                0.05586042960402971,
                0.14471321421626757,
                0.09899579911530638
            ],
            [
                0.03846520854302776,
                1.0,
                0.029102950738360035,
                0.08762483227557673,
                0.1133247302830885,
                0.0,
                0.0,
                0.03154984018244059,
                0.09081099159419102
            ],
            [
                0.0,
                0.029102950738360035,
                1.0,
                0.1008497138537648,
                0.048406717337491245,
                0.0,
                0.05590657263004891,
                0.0,
                0.0
            ],
            [
                0.0,
                0.08762483227557673,
                0.1008497138537648,
                1.0,
                0.2096425577222324,
                0.0,
                0.0,
                0.10932885751468788,
                0.1601364399912852
            ],
            [
                0.0,
                0.1133247302830885,
                0.048406717337491245,
                0.2096425577222324,
                1.0,
                0.0,
                0.09544080659259757,
                0.052476610000284966,
                0.11211674720707096
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.05586042960402971,
                0.0,
                0.05590657263004891,
                0.0,
                0.09544080659259757,
                0.0,
                1.0,
                0.04581770626716288,
                0.0
            ],
            [
                0.14471321421626757,
                0.03154984018244059,
                0.0,
                0.10932885751468788,
                0.052476610000284966,
                0.0,
                0.04581770626716288,
                1.0,
                0.15239471782726993
            ],
            [
                0.09899579911530638,
                0.09081099159419102,
                0.0,
                0.1601364399912852,
                0.11211674720707096,
                0.0,
                0.0,
                0.15239471782726993,
                1.0
            ]
        ]
    },
    "P12-2002": {
        "input_sentences": [
            "The protocol uses distance-based metrics defined for the space of trees over lattices.",
            "Joint Evaluation of Morphological Segmentation and Syntactic Parsing",
            "We present novel metrics for parse evaluation in joint segmentation and parsing scenarios where the gold sequence of terminals is not known in advance.",
            "Our evaluation of segmentation and parsing for Modern Hebrew sheds new light on the performance of the best parsing systems to date in the different scenarios.",
            "Abstract",
            "Our metrics allow us to precisely quantify the performance gap between non-realistic parsing scenarios (assuming gold segmented and tagged input) and realistic ones (not assuming gold segmentation and tags)."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.05082834483312084,
                0.0,
                0.0,
                0.034302681678313705
            ],
            [
                0.0,
                1.0,
                0.29182724387508596,
                0.22210472056362057,
                0.0,
                0.07470932013190602
            ],
            [
                0.05082834483312084,
                0.29182724387508596,
                1.0,
                0.1767222002895234,
                0.0,
                0.19353955310786694
            ],
            [
                0.0,
                0.22210472056362057,
                0.1767222002895234,
                1.0,
                0.0,
                0.13069902491299487
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.034302681678313705,
                0.07470932013190602,
                0.19353955310786694,
                0.13069902491299487,
                0.0,
                1.0
            ]
        ]
    },
    "W07-0718": {
        "input_sentences": [
            "j schroeder ed ac uk Abstract This paper evaluates the translation quality of machine translation systems for 8 language pairs: translating French, German, Spanish, and Czech to English and back.",
            "This meta-evaluation reveals surprising facts about the most commonly used methodologies.",
            "(Meta-) Evaluation of Machine Translation",
            "We measured the correlation of automatic evaluation metrics with human judgments.",
            "Abstract",
            "We measured timing and intraand inter-annotator agreement for three types of subjective evaluation.",
            "We carried out an extensive human evaluation which allowed us not only to rank the different MT systems, but also to perform higher-level analysis of the evaluation process."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.3023281877399862,
                0.0,
                0.18643827309403618,
                0.0,
                0.04205362625273956
            ],
            [
                0.0,
                1.0,
                0.2415969704624687,
                0.04628826363199768,
                0.0,
                0.03901457041881044,
                0.05989765512164341
            ],
            [
                0.3023281877399862,
                0.2415969704624687,
                1.0,
                0.07963518157001334,
                0.0,
                0.06712138575512071,
                0.10304902942897998
            ],
            [
                0.0,
                0.04628826363199768,
                0.07963518157001334,
                1.0,
                0.0,
                0.1457322824055158,
                0.14510032787430022
            ],
            [
                0.18643827309403618,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.03901457041881044,
                0.06712138575512071,
                0.1457322824055158,
                0.0,
                1.0,
                0.056019209281393846
            ],
            [
                0.04205362625273956,
                0.05989765512164341,
                0.10304902942897998,
                0.14510032787430022,
                0.0,
                0.056019209281393846,
                1.0
            ]
        ]
    },
    "W10-2009": {
        "input_sentences": [
            "We argue that syntactic and lexical probabilities, as specified in a PCFG, are sufficient to account for what is commonly referred to as an NP-coordination preference.",
            "Surprisal is estimated using a Probabilistic Context-Free Grammar (PCFG), which is induced from an automatically annotated corpus.",
            "We find that our lexicalized surprisal model can account for the reading time data from a classic experiment on this ambiguity by Frazier (1987).",
            "Modeling the Noun Phrase versus Sentence Coordination Ambiguity in Dutch: Evidence from Surprisal Theory",
            "Surprisal Theory",
            "Abstract",
            "This paper investigates whether surprisal theory can account for differential processing difficulty in the NP-/S-coordination ambiguity in Dutch."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0616275361755965,
                0.04649414993561018,
                0.051204547077405405,
                0.0,
                0.0,
                0.1705696530065279
            ],
            [
                0.0616275361755965,
                1.0,
                0.02738331899546577,
                0.030157567104265308,
                0.098579006442963,
                0.0,
                0.029821444041626018
            ],
            [
                0.04649414993561018,
                0.02738331899546577,
                1.0,
                0.08497937157663563,
                0.10179175492608217,
                0.0,
                0.1372711146329025
            ],
            [
                0.051204547077405405,
                0.030157567104265308,
                0.08497937157663563,
                1.0,
                0.30592281452658215,
                0.0,
                0.2900606525139063
            ],
            [
                0.0,
                0.098579006442963,
                0.10179175492608217,
                0.30592281452658215,
                1.0,
                0.0,
                0.30251313253882783
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.1705696530065279,
                0.029821444041626018,
                0.1372711146329025,
                0.2900606525139063,
                0.30251313253882783,
                0.0,
                1.0
            ]
        ]
    },
    "P06-1012": {
        "input_sentences": [
            "This in turn affects the accuracy of word sense disambiguation (WSD) systems trained and applied on different domains.",
            "Estimating Class Priors In Domain Adaptation For Word Sense Disambiguation",
            "Instances of a word drawn from different domains may have different sense priors (the proportions of the different senses of a word).",
            "Abstract",
            "By using well calibrated probabilities, we are able to estimate the sense priors effectively to achieve significant improvements in WSD accuracy.",
            "This paper presents a method to estimate the sense priors of words drawn from a new domain, and highlights the importance of using well calibrated probabilities when performing these estimations."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.2009806056637076,
                0.36047724524475894,
                0.0,
                0.1714943006580119,
                0.023546720785366976
            ],
            [
                0.2009806056637076,
                1.0,
                0.1875959301142697,
                0.0,
                0.08481891254557651,
                0.14936129809255017
            ],
            [
                0.36047724524475894,
                0.1875959301142697,
                1.0,
                0.0,
                0.05501296354769951,
                0.09687471108507
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.1714943006580119,
                0.08481891254557651,
                0.05501296354769951,
                0.0,
                1.0,
                0.28791636025186124
            ],
            [
                0.023546720785366976,
                0.14936129809255017,
                0.09687471108507,
                0.0,
                0.28791636025186124,
                1.0
            ]
        ]
    },
    "J01-2004": {
        "input_sentences": [
            " A new language model that utilizes probabilistic top-down parsing is then outlined, and empirical results show that it improves upon previous work in test corpus perplexity",
            " Interpolation with a trigram model yields an exceptional improvement relative to the improvement observed by other models, demonstrating the degree to which the information captured by our parsing model is orthogonal to that captured by a trigram model",
            " A small recognition experiment also demonstrates the utility of the model",
            " The paper first introduces key notions in language modeling and probabilistic parsing, and briefly reviews some previous approaches to using syntactic structure for language modeling",
            " A lexicalized probabilistic topdown parser is then presented, which performs very well, in terms of both the accuracy of returned parses and the efficiency with which they are found, relative to the best broad-coverage statistical parsers",
            "This paper describes the functioning of a broad-coverage probabilistic top-down parser, and its application to the problem of language modeling for speech recognition"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.1055666008163696,
                0.059817679129922065,
                0.17556684056262953,
                0.025706477820388058,
                0.07496673478971269
            ],
            [
                0.1055666008163696,
                1.0,
                0.1231431460008623,
                0.0234514994017299,
                0.03370202361550916,
                0.0
            ],
            [
                0.059817679129922065,
                0.1231431460008623,
                1.0,
                0.0,
                0.0,
                0.09431933278829903
            ],
            [
                0.17556684056262953,
                0.0234514994017299,
                0.0,
                1.0,
                0.022842658362148653,
                0.266685428162317
            ],
            [
                0.025706477820388058,
                0.03370202361550916,
                0.0,
                0.022842658362148653,
                1.0,
                0.19448803060610517
            ],
            [
                0.07496673478971269,
                0.0,
                0.09431933278829903,
                0.266685428162317,
                0.19448803060610517,
                1.0
            ]
        ]
    },
    "N07-1050": {
        "input_sentences": [
            "The experiments show that unrestricted non-projective parsing gives a significant improvement in accuracy, compared to a strictly projective baseline, with up to 35% error reduction, leading to state-of-the-art results for the given data sets.",
            "Incremental Non-Projective Dependency Parsing",
            "Moreover, by restricting the class of permissible structures to limited degrees of non-projectivity, the parsing time can be reduced by up to 50% without a significant decrease in accuracy.",
            "Using data from five different languages, we evaluate an incremental deterministic parser that derives non-projective depenstructures in supported by SVM classifiers for predicting the next parser action.",
            "Abstract",
            "An open issue in data-driven dependency parsing is how to handle non-projective dependencies, which seem to be required by linguistically adequate representations, but which pose problems in parsing with respect to both accuracy and efficiency."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.19560960416167844,
                0.11150164598030594,
                0.07736782028398498,
                0.0,
                0.14531360531602283
            ],
            [
                0.19560960416167844,
                1.0,
                0.11311588004763544,
                0.20082219713707805,
                0.0,
                0.3208848098088128
            ],
            [
                0.11150164598030594,
                0.11311588004763544,
                1.0,
                0.01742879032958039,
                0.0,
                0.09915044379040928
            ],
            [
                0.07736782028398498,
                0.20082219713707805,
                0.01742879032958039,
                1.0,
                0.0,
                0.06358639054604527
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.14531360531602283,
                0.3208848098088128,
                0.09915044379040928,
                0.06358639054604527,
                0.0,
                1.0
            ]
        ]
    },
    "P12-1053": {
        "input_sentences": [
            "It can be effectively constructed and the maximal rank of the nononly increases by Thus, simple context-free tree grammars strongly lexicalize tree adjoining grammars and themselves.",
            "A more powerful model, the simple context-free tree grammar, admits such a normal form.",
            "Linguist., 2012) that finitely ambiguous tree adjoining grammars cannot be transformed into a normal form (preserving the generated tree language), in which each production contains a lexical symbol.",
            "Abstract",
            "Strong Lexicalization of Tree Adjoining Grammars",
            "it was shown Tree-adjoining grammars are not closed unstrong Comput."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.25706564664688,
                0.1513151486920576,
                0.0,
                0.2562760422343445,
                0.19806227657571074
            ],
            [
                0.25706564664688,
                1.0,
                0.17426826981755877,
                0.0,
                0.05519139536088405,
                0.04265452719365379
            ],
            [
                0.1513151486920576,
                0.17426826981755877,
                1.0,
                0.0,
                0.18362100553732805,
                0.14191101933199168
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.2562760422343445,
                0.05519139536088405,
                0.18362100553732805,
                0.0,
                1.0,
                0.2517783560447331
            ],
            [
                0.19806227657571074,
                0.04265452719365379,
                0.14191101933199168,
                0.0,
                0.2517783560447331,
                1.0
            ]
        ]
    },
    "W05-0602": {
        "input_sentences": [
            "A compositional-semantics procedure is then used to map the augmented parse tree into a final meaning representation.",
            "It first usesan integrated statistical parser to pro duce a semantically augmented parse tree, in which each non-terminal node has both a syntactic and a semantic label.",
            "A Statistical Semantic Parser That Integrates Syntax And Semantics",
            "We evaluate the system in two domains, a natural-language database interface and an interpreter for coaching instructions in robotic soccer.",
            "Abstract",
            "We present experimentalresults demonstrating that SCISSOR produces more accurate semantic representa tions than several previous approaches.",
            "We introduce a learning semantic parser,SCISSOR, that maps natural-language sentences to a detailed, formal, meaning representation language."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.18519879129409944,
                0.11044697523775737,
                0.0,
                0.0,
                0.0,
                0.12951252565990962
            ],
            [
                0.18519879129409944,
                1.0,
                0.20620154470123164,
                0.0,
                0.0,
                0.03238272028101808,
                0.06790432215118136
            ],
            [
                0.11044697523775737,
                0.20620154470123164,
                1.0,
                0.0,
                0.0,
                0.0579362340329072,
                0.12148827108582502
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.18225564670997887
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.03238272028101808,
                0.0579362340329072,
                0.0,
                0.0,
                1.0,
                0.09564738235256108
            ],
            [
                0.12951252565990962,
                0.06790432215118136,
                0.12148827108582502,
                0.18225564670997887,
                0.0,
                0.09564738235256108,
                1.0
            ]
        ]
    },
    "P13-1126": {
        "input_sentences": [
            "This paper proposes a new approach to domain adaptation in statistical machine translation (SMT) based on a vector space model (VSM).",
            "Thus, we obtain a decoding feature whose value represents the phrase pair\u2019s closeness to the dev.",
            "This profile might, for instance, be a vector with a dimensionality equal to the number of training subcorpora; each entry in the vector reflects the contribution of a particular subcorpus to all the phrase pairs that can be extracted from the dev set.",
            "Abstract",
            "The general idea is first to create a vector profile for the in-domain development (\u201cdev\u201d) set.",
            "Vector Space Model for Adaptation in Statistical Machine Translation",
            "This is a simple, computationally cheap form of instance weighting for phrase pairs.",
            "Then, for each phrase pair extracted from the training data, we create a vector with features defined in the same way, and calculate its similarity score with the vector representing the dev set.",
            "Experiments on large scale NIST evaluation data show improvements over strong baselines: +1.8 BLEU on Arabic to English and +1.4 BLEU on Chinese to English over a non-adapted baseline, and significant improvements in most circumstances over baselines with linear mixture model adaptation.",
            "An informal analysis suggests that VSM adaptation may help in making a good choice among words with the same meaning, on the basis of style and genre."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.05249965673926595,
                0.0,
                0.12330983538159682,
                0.6020794368639759,
                0.0,
                0.05626738634331536,
                0.05066760173939263,
                0.09355898246472096
            ],
            [
                0.0,
                1.0,
                0.08070980994936608,
                0.0,
                0.06216665349451435,
                0.0,
                0.06046518082528341,
                0.15798863050399087,
                0.0,
                0.0
            ],
            [
                0.05249965673926595,
                0.08070980994936608,
                1.0,
                0.0,
                0.24110016494348596,
                0.0871972260217332,
                0.18255152532875965,
                0.2971124592169028,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.12330983538159682,
                0.06216665349451435,
                0.24110016494348596,
                0.0,
                1.0,
                0.0671635794852781,
                0.0,
                0.2584031395802582,
                0.0,
                0.0
            ],
            [
                0.6020794368639759,
                0.0,
                0.0871972260217332,
                0.0,
                0.0671635794852781,
                1.0,
                0.0,
                0.09345508731604048,
                0.08415434681393985,
                0.05857638918075465
            ],
            [
                0.0,
                0.06046518082528341,
                0.18255152532875965,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0454408460865352,
                0.0,
                0.0
            ],
            [
                0.05626738634331536,
                0.15798863050399087,
                0.2971124592169028,
                0.0,
                0.2584031395802582,
                0.09345508731604048,
                0.0454408460865352,
                1.0,
                0.034449902594650764,
                0.0
            ],
            [
                0.05066760173939263,
                0.0,
                0.0,
                0.0,
                0.0,
                0.08415434681393985,
                0.0,
                0.034449902594650764,
                1.0,
                0.021072560990227845
            ],
            [
                0.09355898246472096,
                0.0,
                0.0,
                0.0,
                0.0,
                0.05857638918075465,
                0.0,
                0.0,
                0.021072560990227845,
                1.0
            ]
        ]
    },
    "P13-2073": {
        "input_sentences": [
            "Although pivoting is a robust technique, it introduces some low quality translations.",
            "One common solution is to pivot through a third language for which there exist parallel corpora with the source and target languages.",
            "We show positive results (0.6 BLEU points) on Persian-Arabic SMT as a case study.",
            "An important challenge to statistical machine translation (SMT) is the lack of parallel data for many language pairs.",
            "Abstract",
            "In this paper, we present two language-independent features to improve the quality of phrase-pivot based SMT.",
            "The features, source connectivity strength and target connectivity strength reflect the quality of projected alignments between the source and target phrases in the pivot phrase table.",
            "Language Independent Connectivity Strength Features for Phrase Pivot Statistical Machine Translation"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.07428813551794945,
                0.047988814491602215,
                0.0
            ],
            [
                0.0,
                1.0,
                0.0,
                0.13286065876893433,
                0.0,
                0.10371270638964286,
                0.2675773871890108,
                0.11609226842955357
            ],
            [
                0.0,
                0.0,
                1.0,
                0.06061650072003941,
                0.0,
                0.06499006365859618,
                0.0,
                0.0
            ],
            [
                0.0,
                0.13286065876893433,
                0.06061650072003941,
                1.0,
                0.0,
                0.11355005877486495,
                0.0,
                0.3447612208851409
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.07428813551794945,
                0.10371270638964286,
                0.06499006365859618,
                0.11355005877486495,
                0.0,
                1.0,
                0.16756985182876785,
                0.3760183457789695
            ],
            [
                0.047988814491602215,
                0.2675773871890108,
                0.0,
                0.0,
                0.0,
                0.16756985182876785,
                1.0,
                0.40515841097516675
            ],
            [
                0.0,
                0.11609226842955357,
                0.0,
                0.3447612208851409,
                0.0,
                0.3760183457789695,
                0.40515841097516675,
                1.0
            ]
        ]
    },
    "N06-1037": {
        "input_sentences": [
            "It also shows that our method significantly outperforms the previous two dependency tree kernels on the 5 ACE relation major types.",
            "This paper proposes to use a convolution kernel over parse trees to model syntactic structure information for relation extraction.",
            "Exploring Syntactic Features For Relation Extraction Using A Convolution Tree Kernel",
            "Our study reveals that the syntactic structure features embedded in a parse tree are very effective for relation extraction and these features can be well captured by the convolution tree kernel.",
            "Abstract",
            "Evaluation on the ACE 2003 corpus shows that the convolution kernel over parse trees can achieve comparable performance with the previous best-reported feature-based methods on the 24 ACE relation subtypes."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.028405861902009347,
                0.1053847275547428,
                0.10975301996478112,
                0.0,
                0.21593527758551817
            ],
            [
                0.028405861902009347,
                1.0,
                0.28883772217176423,
                0.2920669372368839,
                0.0,
                0.16362586876355223
            ],
            [
                0.1053847275547428,
                0.28883772217176423,
                1.0,
                0.5269466286923327,
                0.0,
                0.09800488039611684
            ],
            [
                0.10975301996478112,
                0.2920669372368839,
                0.5269466286923327,
                1.0,
                0.0,
                0.09275538126828374
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.21593527758551817,
                0.16362586876355223,
                0.09800488039611684,
                0.09275538126828374,
                0.0,
                1.0
            ]
        ]
    },
    "W12-3407": {
        "input_sentences": [
            "Abstract",
            "The information in figure 1 has been simplified due to space reasons, as typically each word contains many morphosyntactic features (case, number, type of subordinated sentence, ...), which are relevant for parsing.",
            "First, subsection 2.1 will describe the Basque Dependency Treebank, and then subsection 2.2 will explain the main details of the analyzers that have been employed.",
            "The first one is to mark the beginning of the phrase (B-VP if it is a verb phrase and B-NP whether it's a noun phrase) and the other one to mark the continuation of the phrase (I-NP or I-VP, meaning that the word is inside an NP or VP).",
            "2 f-score = 2 * precision * recall / (precision + recall) (ncmod = non-clausal modifier, ncobj = non-clausal object, ncpred = non-clausal predicate, ncsubj = non-clausal subject, nciobj = non-clausal indirect object) Table 2 shows how the addition of the rule-based parsers\u2019 tags performs in accord with this behavior, as MaltParser gets f-score improvements for the local relations.",
            "MaltParser (Nivre, 2006) is a representative of local, greedy, transition-based dependency parsing models, where the parser obtains deterministically a dependency tree in a single pass over the input using two data structures: a stack of partially analyzed items and the remaining input sequence.",
            "In the rest of this paper, section 2 will first present the corpus and the different parsers we will combine, followed by the experimental results in section 3, and the main conclusions of the work.",
            "We have presented a preliminary effort to integrate different syntactic analyzers, with the objective of getting the best from each system.",
            "To determine the best action at each step, the parser uses history-based feature models and discriminative machine learning.",
            "For all those reasons, the relation between the input dependency tags and the obtained results seems to be intricate, and we think that it deserves new experiments in order to determine their nature.",
            "This subsection will present the four types of analyzers that have been used.",
            "This means that there is room for improvement in the first-stage knowledge-based parsers, which will have, at least in theory, a positive effect on the second-phase statistical parsers, allowing us to test whether knowledge-based and machine learningbased systems can be successfully combined.",
            "For that reason, we performed a matching process trying to link the multiword units given by the morphological analysis module and the treebank, obtaining a correct match for 99% of the sentences.",
            "For that reason, MaltParser, seems to mostly benefit of the local nature of the stacked features, while MST does not get a significant improvement, except for some local dependency relations, such as ncobj and ncsubj.",
            "We use the freely available version of MSTParser1.",
            "The results show a modest improvement over the baseline, although they also present interesting lines for further research.",
            "In this paper we will experiment the use of the stacking technique, giving the tags obtained by the rulebased syntactic partial parsers as input to the statistical parsers.",
            "The rule-based chunker (RBC henceforth, Aranzabe et al., 2009) uses 560 rules, where 479 of the rules deal with noun phrases and the rest with verb phrases.",
            "The last tag marks words that are outside a chunk.",
            "Most of the experiments on combined parsers have relied on different types of statistical parsers (Sagae and Lavie, 2006, Martins et al., 2008, McDonald and Nivre, 2011), trained on an automatically annotated treebank.",
            "This section will describe the main resources that have been used in the experiments.",
            "This algorithm finds the highest scoring directed spanning tree in a dependency graph forming a valid dependency tree.",
            "As the analyzers are applied after morphological processing, the errors can be propagated and augmented.",
            "For that reason, the results can serve as an upper bound on the real results.",
            "As could be expected, the gold tags gave a noticeable improvement to the parser\u2019s results, reaching 95% LAS.",
            "Combining Rule-Based and Statistical Syntactic Analyzers",
            "The evaluation of the chunker on the BDT gave a result of 87% precision and 85% recall over all chunks.",
            "Finally, we must also take into account that the rule-based analyzers were developed mainly having linguistic principles in mind, such as coverage of diverse linguistic phenomena or the treatment of specific syntactic constructions (Aranzabe et al., 2004), instead of performanceoriented measures, such as precision and recall.",
            "The table shows modest gains, suggesting that the rule-based analyzers help the statistical ones, giving slight increases over the baseline, which are statistically significant when applying MaltParser to the output of the rule-based dependency parser and a combination of the chunker and rule-based parsers.",
            "The first step consisted in applying the complete set of text processing tools for Basque, including: properties, such as case, number, tense, or different types of subordination for verbs.",
            "We performed an additional test using the partial dependency analyzer\u2019s gold dependency relations as input to MaltParser.",
            "The last two lines of the sentence in figure 1 do not properly correspond to the treebank, but are the result of the rule-based partial syntactic analyzers (see subsection 2.2).",
            "Our work will make use the second version of the Basque dependency Treebank (BDT II, Aduriz et al., 2003), containing 150,000 tokens (11,225 sentences).",
            "This means that the result of this analysis is on the one hand a partial analysis and, on the other hand, it does not define a dependency tree, and can also be seen as a set of constraints on the shape of the tree.",
            "These tags contain errors of the CG-based syntactic taggers.",
            "If only categorial (POS) ambiguity is taken into account, there is an average of 1.55 interpretations per wordform, which rises to 2.65 when the full morphosyntactic information is taken into account, giving an overall 64% of ambiguous word-forms. can pose an important problem, as determining the correct interpretation for each word-form requires in many cases the inspection of local contexts, and in some others, as the agreement of verbs with subject, object or indirect object, it could also suppose the examination of elements which can be far from each other, added to the free constituent order of the main sentence elements in Basque.",
            "The rule-based analyzers are based on the Contraint Grammar (CG) formalism (Karlsson et al., 1995), based on the assignment of morphosyntactic tags to words using a formalism that has the capabilities of finite state automata or regular expressions, by means of a set of rules that examine mainly local contexts of words to determine the correct tag assignment.",
            "Although the potential gain is in theory high, the experiments have shown very modest improvements, which seem to happen in the set of local dependency relations.",
            "We will experiment the effect of using the output of the knowledge-based analyzers as input to the data-driven parsers in a stacked learning scheme.",
            "The experiments have been performed on the Basque Dependency Treebank (Aduriz et al., 2003).",
            "For evaluation, we divided the treebank in three sets, corresponding to training, development, and test (80%, 10%, and 10%, respectively).",
            "For example, this analyzer assigns tags of the form &NCSUBJ> (see figure 1), meaning that the corresponding wordform is a non-clausal syntactic subject and that its head is situated to its right (the \u201c>\u201d or \u201c<\u201d symbols mark the direction of the head).",
            "As table 1 shows, the parser type is relevant, as MaltParser seems to be sensitive when using the stacked features, while the partial parsers do not seem to give any significant improvement to MST.",
            "Consequently, the morphological analyzer for Basque (Aduriz et al. 2000) gives a high ambiguity.",
            "The MST Parser can be considered a representative of global, exhaustive graph-based parsing (McDonald et al., 2005, 2006).",
            "The table shows the differences in f-score2 corresponding to five local dependency relations, (determination of verbal modifiers, such as subject, object and indirect object).",
            "As the CG formalism only allows the assignment of tags, the rules only aim at marking the name of the dependency relation together with the direction of the head (left or right).",
            "However, when examining the scores for the output dependency relations, we noticed that the gold partial dependency tags are beneficial for some relations, although negative for some others.",
            "Looking with more detail at the errors made by the different versions of the parsers, we observe significant differences in the results for different dependency relations, seeing that the statistical parsers behave in a different manner regarding to each relation, as shown in table 2.",
            "The erroneous assignment of incorrect part of speech or morphological features can difficult the work of the parser.",
            "For example the non-clausal modifier (ncmod) relation\u2019s f-score increases 3.25 points, while the dependency relation for clausal subordinate sentences functioning as indirect object decreases 0.46 points, which is surprising in principle.",
            "We have performed three experiments for each statistical parser, trying with the chunks provided by the chunker, the partial dependency parser, and both.",
            "In our work we will study the use of two partial rule-based syntactic analyzers together with two data-driven parsers: set of predefined tags to each word, where each tag gives both the name of a dependency relation (e.g. subject) together with the direction of its head (left or right).",
            "Figure 1 shows how the two last lines of the example sentence contain the tags assigned by the rule-based chunker (B-NP, I-NP, B-VP and I-VP) and the rule-based partial dependency analyzer (&NCSUBJ, &<NCMOD, &<AUXMOD, &CCOMP_OBJ and &MAINV) .",
            "In this paper we present a set of preliminary experiments on the combination of two knowledge-based partial syntactic analyzers with two state of the art data-driven statistical parsers.",
            "As it was successfully done on part of speech (POS) tagging, where the use of rule-based POS taggers (Tapanainen and Voutilainen, 1994) or a combination of a rulebased POS tagger with a statistical one (Aduriz et al., 1997, Ezeiza et al., 1998) outperformed purely statistical taggers, we think that exploring the combination of knowledge-based and data-driven systems in syntactic processing can be an interesting line of research.",
            "In the following experiments we will make use of the second order non-projective algorithm.",
            "Table 1 shows the results of using the output of the knowledge-based analyzers as input to the statistical parsers.",
            "The two most successful approaches have been stacking (Martins et al., 2008) and voting (Sagae and Lavie, 2006, Nivre and McDonald, 2008, McDonald and Nivre, 2011).",
            "Yeh (2000) used the output of several baseline diverse parsers to increase the performance of a second transformation-based parser.",
            "Figure 1 presents an example of a syntactically annotated sentence.",
            "The general idea will be to apply a stacked scheme where the output of the rule-based partial parsers will be given as input to MaltParser and MST, two state of the art statistical parsers.",
            "This paper presents the results of a set of preliminary experiments combining two knowledge-based partial dependency analyzers with two statistical parsers, applied to the Basque Dependency Treebank.",
            "This is in contrast to the local but richer contexts used by transition-based parsers.",
            "In our experiments, we will use the StackLazy algorithm with the liblinear classifier.",
            "The learning procedure is global since model parameters are set relative to classifying the entire dependency graph, and not just over single arc attachments.",
            "Regarding the data-driven parsers, they are trained using two kinds of tags as input: syntactic analyzers (two last lines of the example in figure 1).",
            "As both the chunker and the partial dependency analyzer are based on a set of local rules in the CG formalism, we could expect that the stacked parsers could benefit mostly on the local dependency relations.",
            "Morphologically rich languages present new challenges, as the use of state of the art parsers for more configurational and non-inflected languages like English does not reach similar performance levels in languages like Basque, Greek or Turkish (Nivre et al., 2007a).",
            "Several variants of the parser have been implemented, and we will use one of its standard versions (MaltParser version 1.4).",
            "In the last years, many attempts have been performed trying to combine different parsers (Surdeanu and Manning, 2010), with significant improvements over the best individual parser\u2019s baseline.",
            "The learning configuration can include any kind of information (such as word-form, lemma, category, subcategory or morphological features).",
            "The experiments were performed on the development set, leaving the best system for the final test.",
            "We must take into account that this evaluation was performed on the gold POS tags, rather than on automatically assigned POS tasks, as in the present experiment.",
            "The system was evaluated on the BDT, obtaining f-scores between 90% for the auxmod dependency relation between the auxiliary and the main verb and 52% for the subject dependency relation, giving a (macro) average of 65%.",
            "Although not shown in Table 2, we also inspected the results on the long distance relations, where we did not observe noticeable improvements with respect to the baseline on any parser.",
            "Regarding the data-driven parsers, we have made use of MaltParser (Nivre et al., 2007b) and MST Parser (McDonald et al., 2006), two state of the art dependency parsers representing two dominant approaches in data-driven dependency parsing, and that have been successfully applied to typologically different languages and treebanks (McDonald and Nivre, 2007).",
            "As each type of syntactic information can have an important influence on the results on specific relations, their study can shed light on novel schemes of parser combination.",
            "When performing this task, we found the problem of matching the treebank tokens with those obtained from the analyzers, as there were divergences on the treatment of multiword units, mostly coming from Named Entities, verb compounds and complex postpositions (formed with morphemes appearing at two different words).",
            "McDonald and Nivre (2007) examined the types of errors made by the two data-driven parsers used in this work, showing how the greedy algorithm of MaltParser performed better with local dependency relations, while the graph-based algorithm of MST was more accurate for global relations.",
            "Each word contains its form, lemma, category or coarse part of speech (CPOS), POS, morphosyntactic features such as case, number of subordinate relations, and the dependency relation (headword + dependency).",
            "To learn arc scores, it uses large-margin structured learning algorithms, which optimize the parameters of the model to maximize the score margin between the correct dependency graph and all incorrect dependency graphs for every sentence in a training set.",
            "The chunker delimits the chunks with three tags, using a standard IOB marking style (see figure 1).",
            "The analyzers are a rulebased chunker, a rule-based shallow dependency parser and two state of the art data-driven dependency parsers, MaltParser and MST.",
            "The rule-based dependency analyzer (RBDA, Aranzabe et al., 2004) uses a set of 505 CG rules that try to assign dependency relations to wordforms.",
            "We can point out some avenues for further research: schemes, such as voting, trying to get the best from each type of parser."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                1.0,
                0.0,
                0.024026534986732077,
                0.0,
                0.03943057659026706,
                0.0,
                0.0,
                0.0,
                0.07484958773097639,
                0.0,
                0.0,
                0.0,
                0.04815076106591727,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.10699304597654437,
                0.0,
                0.10967487923431232,
                0.0,
                0.0,
                0.0,
                0.11514864273278817,
                0.03322784548611779,
                0.0,
                0.0,
                0.0,
                0.0,
                0.03513365226126543,
                0.2003136810844977,
                0.0,
                0.06201113015526177,
                0.0,
                0.0,
                0.0,
                0.0,
                0.06060814683806853,
                0.0,
                0.0,
                0.04291553194748022,
                0.06642556143280656,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.1413806153263591,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.05193482937790414,
                0.0,
                0.0,
                0.0,
                0.0,
                0.16045067347317066,
                0.0,
                0.0,
                0.0,
                0.0,
                0.03534848539909246,
                0.11168911538573899,
                0.0,
                0.0,
                0.31184231891320163,
                0.03343967605423698,
                0.0526778954713561,
                0.0,
                0.0,
                0.07121387034569454
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.028680169843705607,
                0.05958597940179076,
                0.037946268293257965,
                0.0,
                0.021225735454201422,
                0.3718216696063581,
                0.0,
                0.041337116125857554,
                0.021019234066526695,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0414611578476195,
                0.11412076180007465,
                0.0385717282675089,
                0.04633780939843355,
                0.0,
                0.0,
                0.06652470277669104,
                0.0,
                0.02113323115154247,
                0.0382945408335924,
                0.04357258613534137,
                0.05392412190376143,
                0.29118868234038625,
                0.10125624189643684,
                0.015973590401194056,
                0.0,
                0.05279973902601383,
                0.018803457650810436,
                0.02283595963723368,
                0.03846712746607064,
                0.19138125073618797,
                0.04468949843753353,
                0.0,
                0.0,
                0.06171692648135421,
                0.0,
                0.019739779815653336,
                0.021557500838577014,
                0.04497752056040993,
                0.01629787356452923,
                0.0,
                0.014092401780238746,
                0.02755822329546134,
                0.04788434509417075,
                0.0150587837776803,
                0.03722124356583917,
                0.0,
                0.0,
                0.04838657286385875,
                0.0,
                0.0,
                0.0,
                0.0,
                0.1908009604658386,
                0.0,
                0.0,
                0.01936314321433945,
                0.03811365661675679,
                0.04373791722319365,
                0.030177485976211275,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.08876789633248985,
                0.0,
                0.02571102562101421,
                0.0,
                0.057623725184948314,
                0.015714750164625264,
                0.03666189150989827,
                0.029194819044733835,
                0.0,
                0.08780698975745406,
                0.038963847101126124,
                0.0
            ],
            [
                0.0,
                0.024026534986732077,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.05562957281777155,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.023959474948896633,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.09849383471629984,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.02411278415722953,
                0.35803927379652467,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.02816966697215738,
                0.0,
                0.0,
                0.026543870156487823,
                0.0,
                0.0,
                0.0,
                0.022807658481081232,
                0.0,
                0.023594131755257066,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.02792665859021938,
                0.008336597903897047,
                0.0,
                0.008568387898266748,
                0.013664369181976898,
                0.0,
                0.026533898907315803,
                0.0,
                0.12391152271464789,
                0.0,
                0.0,
                0.034811723368721355,
                0.016958379187411596,
                0.0,
                0.015651016723265986,
                0.0,
                0.0,
                0.0,
                0.0,
                0.015180020037222429,
                0.0459581845151896,
                0.13527878453851805,
                0.09112948208895652,
                0.09647738574720398,
                0.0,
                0.03851617157831185,
                0.026727521572407043,
                0.0,
                0.0,
                0.0354586826466981,
                0.07575788210893404,
                0.04003073384212867,
                0.06238555813946591,
                0.02080628629109306,
                0.0,
                0.0,
                0.2602832822125582,
                0.07516560843037699,
                0.0,
                0.008989163790726814,
                0.21388711704992106,
                0.013877947868269779,
                0.04489922009742759,
                0.04128466260914046,
                0.0,
                0.41455739125180197,
                0.0,
                0.060145423322406306,
                0.098032286853431,
                0.020132406570374538,
                0.015841381893940208,
                0.1519007967289927,
                0.08896798336671315,
                0.0,
                0.01906829707402151,
                0.0,
                0.05572542738526803,
                0.019095335975480163,
                0.04872896783928347,
                0.0,
                0.0,
                0.02662034700686726,
                0.06804346228845805,
                0.07412403778514752,
                0.021327265915358086,
                0.033567407755783894,
                0.0,
                0.0,
                0.013921563383818124,
                0.018018468352358943,
                0.06050820388746659,
                0.02106027052612263,
                0.01373688575085492,
                0.0,
                0.05882415991945388,
                0.012398630215202345,
                0.04112699205954334,
                0.01599411540811404,
                0.056055884182811495,
                0.034119633369343136,
                0.0
            ],
            [
                0.0,
                0.03943057659026706,
                0.028680169843705607,
                0.0,
                0.02792665859021938,
                1.0,
                0.0,
                0.0,
                0.09377335023771355,
                0.09012334447421859,
                0.0,
                0.021086692140404338,
                0.0,
                0.10818331782040433,
                0.0,
                0.0,
                0.06906166384086909,
                0.010551558741266554,
                0.0,
                0.0649504028463785,
                0.0,
                0.1378864363416293,
                0.0,
                0.0,
                0.023212808007295617,
                0.02859533202995954,
                0.0,
                0.009084020467897231,
                0.08186301845066339,
                0.0,
                0.22207393588222,
                0.01662995093829878,
                0.02094743135575908,
                0.09486159659314346,
                0.022752788237043114,
                0.012442959055622429,
                0.05874090020350566,
                0.05818257353074323,
                0.1642136484481718,
                0.039592083781619075,
                0.0,
                0.0,
                0.0880128392282774,
                0.0,
                0.18925562623870318,
                0.05029397532881875,
                0.026105258108174784,
                0.054465950950775596,
                0.01973606306233215,
                0.02604515284000492,
                0.01706532629139019,
                0.08762983983358885,
                0.06184159562245124,
                0.038379729630346186,
                0.04999650111574535,
                0.029659681163616374,
                0.0,
                0.1623638037343891,
                0.09034862191474657,
                0.037457185978186584,
                0.0,
                0.10199429666266605,
                0.07012488428097471,
                0.14022987000137502,
                0.0,
                0.07590241728503368,
                0.146321727682257,
                0.12606466886477646,
                0.021189549056388382,
                0.06370087586994574,
                0.019416789347735178,
                0.0,
                0.0,
                0.0,
                0.0416111344982887,
                0.020498367793126637,
                0.1936069881301794,
                0.019993168474563817,
                0.0,
                0.16294421285454128,
                0.044396061851804676,
                0.03535374031948972,
                0.03770164411518182,
                0.1668856339871395,
                0.06021413340263207,
                0.025495607206304578
            ],
            [
                0.0,
                0.0,
                0.05958597940179076,
                0.0,
                0.008336597903897047,
                0.0,
                1.0,
                0.04855974347437785,
                0.0,
                0.03723536294532794,
                0.09169109882549814,
                0.03075491544031112,
                0.0,
                0.0,
                0.0,
                0.11986413314473537,
                0.1074684436821206,
                0.05607783010009917,
                0.0,
                0.06963379904829718,
                0.3468838759853325,
                0.0,
                0.0,
                0.09245053401025695,
                0.041365506747934065,
                0.0,
                0.0,
                0.0,
                0.014615267354781476,
                0.03461866103855976,
                0.0,
                0.0,
                0.04352042613717719,
                0.0,
                0.0,
                0.02341639934842727,
                0.0,
                0.0,
                0.024116153368363157,
                0.0,
                0.0,
                0.0,
                0.02281001916957183,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.15774744434154933,
                0.06656358109736413,
                0.0,
                0.0,
                0.06540772234875038,
                0.0,
                0.1448758666961397,
                0.0,
                0.0,
                0.08488569557724056,
                0.0,
                0.022101684571526427,
                0.0,
                0.0400716118569038,
                0.1248218828055438,
                0.02901479499449704,
                0.0,
                0.0,
                0.023894552282583692,
                0.02133355941994148,
                0.039550780108699064,
                0.0,
                0.12862949023571235,
                0.0,
                0.0,
                0.049937234977327986,
                0.04322568897973829,
                0.03652834120722135,
                0.05068001350520504,
                0.03562806986501691,
                0.029396165758163742,
                0.05486662882006975,
                0.0,
                0.0,
                0.0,
                0.024087922276649253,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.037946268293257965,
                0.0,
                0.0,
                0.0,
                0.04855974347437785,
                1.0,
                0.07009113238410652,
                0.0,
                0.06361811377070684,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0462535222657456,
                0.0,
                0.0,
                0.045582704477069594,
                0.0,
                0.0,
                0.04771286488238532,
                0.0,
                0.0,
                0.1554009772901934,
                0.0,
                0.04936699657679571,
                0.02400426867336751,
                0.04486558475338539,
                0.0,
                0.09037526213691092,
                0.0,
                0.0,
                0.06914649304475641,
                0.0,
                0.019361442542536366,
                0.0,
                0.039608623692603095,
                0.0,
                0.0,
                0.03368161759583642,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.12617680160183803,
                0.0,
                0.0,
                0.0,
                0.06809511724776843,
                0.0,
                0.18310822786843803,
                0.02185185338153187,
                0.0,
                0.04982242456314797,
                0.0,
                0.0,
                0.0,
                0.0,
                0.12755789073722318,
                0.0,
                0.0,
                0.0,
                0.08903308454047117,
                0.0,
                0.0,
                0.0,
                0.11521229897775749,
                0.0,
                0.0941902732877012,
                0.0,
                0.0,
                0.0,
                0.033175442243204005,
                0.04128232267749398,
                0.06175010529026468,
                0.0,
                0.0,
                0.0,
                0.0,
                0.03956225665093407,
                0.0,
                0.08444582717640788
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.008568387898266748,
                0.09377335023771355,
                0.0,
                0.07009113238410652,
                1.0,
                0.07521393982588966,
                0.0,
                0.095623591078691,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.06577070915113498,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.03479717789873706,
                0.04286585472154955,
                0.0,
                0.013617407948139716,
                0.06717393575774844,
                0.07060065574300627,
                0.0,
                0.024929140889175423,
                0.0,
                0.0,
                0.03410758490432718,
                0.0,
                0.07916954256122481,
                0.0,
                0.09583989598474481,
                0.0,
                0.0,
                0.0,
                0.03450554965203611,
                0.0,
                0.05589199042178538,
                0.0,
                0.0,
                0.0,
                0.0,
                0.03904300662326613,
                0.0,
                0.08133542291131245,
                0.01878337867682075,
                0.03019710969661948,
                0.023983878960038167,
                0.02155753420625652,
                0.0,
                0.031178370083339575,
                0.0,
                0.056150223775571974,
                0.0,
                0.020592879616889884,
                0.022748409393396157,
                0.02982151966155441,
                0.0,
                0.05565277183851258,
                0.0,
                0.02192671572600757,
                0.0,
                0.04184333181860327,
                0.08579671785120528,
                0.06290331403773002,
                0.08302750546671797,
                0.0,
                0.0,
                0.030728094184339496,
                0.018970899538298527,
                0.029970774752893458,
                0.0,
                0.01575625367831856,
                0.0,
                0.08817777126616948,
                0.0,
                0.06119634101849953,
                0.08122259816289233,
                0.11265711229336782
            ],
            [
                0.0,
                0.07484958773097639,
                0.021225735454201422,
                0.0,
                0.013664369181976898,
                0.09012334447421859,
                0.03723536294532794,
                0.0,
                0.07521393982588966,
                1.0,
                0.0,
                0.0,
                0.0,
                0.10311957694401044,
                0.0,
                0.05837128537037522,
                0.16711375008158272,
                0.0,
                0.0,
                0.03299812999481409,
                0.0673265257315512,
                0.034568434065883155,
                0.0,
                0.10428530191330504,
                0.08436426525305805,
                0.0,
                0.0,
                0.0,
                0.0134270978293536,
                0.0,
                0.10888814666569031,
                0.0,
                0.01550285925171978,
                0.014315718568520415,
                0.05439280265691814,
                0.032565551990231846,
                0.061603771452359596,
                0.06312732478165518,
                0.055527835668240974,
                0.09038094926238144,
                0.0,
                0.026495018017331555,
                0.0,
                0.0,
                0.0,
                0.017691021576735112,
                0.10576329971265451,
                0.0762678717437782,
                0.08615005775529205,
                0.0,
                0.08058154556533521,
                0.0761814673004347,
                0.09191043272956714,
                0.03757415971572339,
                0.04468795653806222,
                0.04310632533541221,
                0.14270199084993535,
                0.13138059445422404,
                0.0,
                0.0,
                0.0,
                0.04613276927220659,
                0.1279498021192038,
                0.0,
                0.05891816201872889,
                0.0173534754489334,
                0.09418273073882419,
                0.0391984330394297,
                0.04828065288500973,
                0.0,
                0.0,
                0.0,
                0.053966916376008665,
                0.03457778109054249,
                0.11364062848686347,
                0.04120440332734767,
                0.02304252191610868,
                0.04018888654606796,
                0.05165313782354007,
                0.01408374292072547,
                0.07705156130963071,
                0.026164738334097222,
                0.039725496775848676,
                0.04425931884285688,
                0.034919855551378436,
                0.0
            ],
            [
                0.0,
                0.0,
                0.3718216696063581,
                0.0,
                0.0,
                0.0,
                0.09169109882549814,
                0.06361811377070684,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.1437377501415755,
                0.0,
                0.0,
                0.0,
                0.10331086965789617,
                0.19132705096819275,
                0.0,
                0.07768679669401486,
                0.0,
                0.0,
                0.11153075915404127,
                0.0,
                0.03543052753833895,
                0.03908410750042523,
                0.10168555446099041,
                0.0,
                0.22760160795157844,
                0.0,
                0.0,
                0.0,
                0.0,
                0.03152458889678134,
                0.0,
                0.06449135057645619,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.04887163680537758,
                0.0,
                0.17896326076557528,
                0.0,
                0.0,
                0.08112161316201115,
                0.0,
                0.12028096024009033,
                0.0,
                0.0,
                0.0591880737167926,
                0.1579032309421129,
                0.0,
                0.0,
                0.06389874556632737,
                0.0,
                0.05867239894995628,
                0.0,
                0.0,
                0.0,
                0.0,
                0.1053754101195176,
                0.0,
                0.0,
                0.0,
                0.0,
                0.038511913033728765,
                0.17534225747008292,
                0.0,
                0.0,
                0.0,
                0.06441585506914754,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.026533898907315803,
                0.021086692140404338,
                0.03075491544031112,
                0.0,
                0.095623591078691,
                0.0,
                0.0,
                1.0,
                0.0,
                0.04430054648266495,
                0.0,
                0.06217058171896686,
                0.10428131782944162,
                0.023197661980925578,
                0.0,
                0.13354560996783033,
                0.0,
                0.0,
                0.0,
                0.0,
                0.049697861554587386,
                0.11904003223716862,
                0.0,
                0.019971270729692653,
                0.11026408693014154,
                0.0,
                0.0626054004962954,
                0.03656104184088774,
                0.040166122462736834,
                0.04150681317891563,
                0.050022134510066714,
                0.0,
                0.08470935951956454,
                0.06800224328837066,
                0.24602008211218246,
                0.0,
                0.044207457673741915,
                0.0,
                0.08749829270886476,
                0.0,
                0.033162325381397434,
                0.0,
                0.0,
                0.0,
                0.07468911575454212,
                0.0,
                0.0,
                0.03620871194908724,
                0.05816686602732014,
                0.04428703724689406,
                0.1982488400242882,
                0.16140631960365948,
                0.061737956301343315,
                0.25771793266505894,
                0.0,
                0.12295335189324877,
                0.0,
                0.12432496624662186,
                0.18803654663837716,
                0.09234889892441485,
                0.0,
                0.0,
                0.040034014966426675,
                0.067900901003913,
                0.019679823794240603,
                0.0,
                0.03223745235105988,
                0.0,
                0.06707640215070428,
                0.0,
                0.0,
                0.0,
                0.0754273869111088,
                0.0,
                0.0,
                0.04879270724229204,
                0.0,
                0.0,
                0.0,
                0.07666754495585239,
                0.028647621436856726,
                0.0
            ],
            [
                0.0,
                0.0,
                0.041337116125857554,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.061017713936960614,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.030829097358248278,
                0.0,
                0.0,
                0.07011855493341865,
                0.0764936932958258,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.050245802783371596,
                0.043396016379588655,
                0.08040759908513957,
                0.10628175380464996,
                0.0,
                0.024143992341214483,
                0.03134741182554706,
                0.0,
                0.0,
                0.11799380607940875,
                0.03322958088352346,
                0.0,
                0.0,
                0.05798175637807719,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.06229585238890096,
                0.04090948974590364,
                0.12284462758452072,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.06832785226959351,
                0.039599854284351206,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.08792253426443754,
                0.051531998037889826,
                0.05383413646689863,
                0.04030026224233222,
                0.05715788546336642,
                0.0,
                0.0,
                0.0,
                0.17310413633014576,
                0.029285603907317003,
                0.0,
                0.0378666341594286,
                0.0,
                0.0,
                0.0,
                0.06718372764644817
            ],
            [
                0.0,
                0.04815076106591727,
                0.021019234066526695,
                0.0,
                0.12391152271464789,
                0.10818331782040433,
                0.0,
                0.0,
                0.0,
                0.10311957694401044,
                0.0,
                0.04430054648266495,
                0.061017713936960614,
                1.0,
                0.0,
                0.08289961144328568,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.034232123947454056,
                0.0,
                0.09130004559525354,
                0.06626821397716791,
                0.0,
                0.0,
                0.0,
                0.08311798454983374,
                0.0,
                0.1425913664300189,
                0.0,
                0.015352034704070362,
                0.06952253468447697,
                0.0,
                0.03647697629346305,
                0.04735997186637549,
                0.1477542238319275,
                0.06947564368054991,
                0.029016399858246562,
                0.0,
                0.051304391810690464,
                0.3565356544084206,
                0.0,
                0.053842862939454436,
                0.12772118586685002,
                0.019132122770996934,
                0.11474236740742133,
                0.08738024357690327,
                0.06824579175336305,
                0.012506902493783719,
                0.02445771963027404,
                0.01662619914181003,
                0.059989272589012745,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.144752656071594,
                0.040271730793646904,
                0.11656681902362821,
                0.0,
                0.01718464658696458,
                0.0,
                0.3949088195432376,
                0.04171960107478713,
                0.05245639424361138,
                0.0554312925364697,
                0.056453870873675156,
                0.0,
                0.0,
                0.030496129575230138,
                0.03464090205570275,
                0.07729327848794544,
                0.033787148220784706,
                0.0,
                0.19441239679359032,
                0.11031693865183653,
                0.025910186269892173,
                0.0,
                0.14846238920645985,
                0.06699049142726805,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.06938054581921967,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.14599949589355038,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.05711968522014201,
                0.0,
                0.0,
                0.03277790404937506,
                0.08106830856982448,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.09615906005339142,
                0.0,
                0.0,
                0.0,
                0.036712445224505445,
                0.23931939696676083,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.03919647214042388,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.11986413314473537,
                0.0,
                0.0,
                0.05837128537037522,
                0.1437377501415755,
                0.06217058171896686,
                0.0,
                0.08289961144328568,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.14492826379266974,
                0.15784543117356964,
                0.0,
                0.0,
                0.0,
                0.13193944672072447,
                0.0,
                0.0,
                0.10803486956565231,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.11104001822836909,
                0.0,
                0.0,
                0.0,
                0.0,
                0.09222019573068417,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.044819546103271726,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0654322750598785,
                0.08659262965670726,
                0.11217986677308436,
                0.0,
                0.08551542018665982,
                0.0,
                0.08935642105390958,
                0.0,
                0.0,
                0.06239388982344334,
                0.0,
                0.0,
                0.0,
                0.10643042629061492,
                0.0,
                0.043587576739912114,
                0.0,
                0.07779126841640797,
                0.0,
                0.0,
                0.07828312558008348,
                0.0,
                0.1393874322160236,
                0.0,
                0.05585164394234836,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.1259341289646825
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.034811723368721355,
                0.06906166384086909,
                0.1074684436821206,
                0.0462535222657456,
                0.0,
                0.16711375008158272,
                0.0,
                0.10428131782944162,
                0.0,
                0.0,
                0.06938054581921967,
                0.0,
                1.0,
                0.0,
                0.0,
                0.11685033498083647,
                0.0,
                0.0,
                0.0,
                0.0,
                0.040420236143421856,
                0.16217678098536437,
                0.0,
                0.025759749814152112,
                0.11398251820118402,
                0.0,
                0.11348332208141833,
                0.09193719124410715,
                0.03669653926524782,
                0.028768543892974122,
                0.12283268443039175,
                0.03119734960356781,
                0.02071448399872349,
                0.0,
                0.2105859128192589,
                0.0,
                0.0,
                0.05983244157554917,
                0.0972799236505798,
                0.0,
                0.0,
                0.0,
                0.03695317454430729,
                0.07905191824939693,
                0.1078172207575075,
                0.0,
                0.0,
                0.10190150958267497,
                0.18532748676335162,
                0.052934253791497944,
                0.27043823741166984,
                0.12430049398423146,
                0.056404980084154926,
                0.20722656919158586,
                0.07143345475298836,
                0.05345476702277214,
                0.0,
                0.22231875450357289,
                0.213474624138537,
                0.07017470101091114,
                0.06690468769989219,
                0.0,
                0.20521766517505732,
                0.09098313404030212,
                0.05395219877723875,
                0.06015221897840899,
                0.046536265447519105,
                0.0,
                0.0,
                0.11818574097007659,
                0.05758899610868465,
                0.0,
                0.08793362431872583,
                0.03852051874372558,
                0.055375045914809434,
                0.03707692979689155,
                0.0,
                0.0,
                0.042587949167121296,
                0.15088014279204495,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.05562957281777155,
                0.016958379187411596,
                0.010551558741266554,
                0.05607783010009917,
                0.0,
                0.06577070915113498,
                0.0,
                0.0,
                0.023197661980925578,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.044108821076968736,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.08483922847465657,
                0.0400784764965221,
                0.09618570379816627,
                0.1142026893237685,
                0.0,
                0.0,
                0.0493392489969509,
                0.04319702849958888,
                0.0,
                0.02503054946371427,
                0.0,
                0.12291818660688245,
                0.0,
                0.018190210121214658,
                0.08164535032609178,
                0.0,
                0.0,
                0.0,
                0.06149356152052946,
                0.07291126091561552,
                0.0,
                0.09094079860819126,
                0.0,
                0.0,
                0.0,
                0.0,
                0.046005936689142074,
                0.03717568133052223,
                0.08490476987964878,
                0.017601060594730305,
                0.08293492719937447,
                0.0,
                0.022880885197767573,
                0.04149727163820327,
                0.01667074679149634,
                0.0,
                0.04075700881545991,
                0.016694385959587107,
                0.021885132737057684,
                0.0,
                0.0,
                0.0,
                0.14485428836034162,
                0.030068268078348163,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.03992517719912814,
                0.0,
                0.06420547718009688,
                0.0,
                0.034305464914723374,
                0.011563049338270421,
                0.0,
                0.03392131370428358,
                0.041475921898311056,
                0.09022164289219037,
                0.2654296022027722,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.1883632571174377,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.09733799352057808,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.07670445653929217,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0414611578476195,
                0.0,
                0.015651016723265986,
                0.0649504028463785,
                0.06963379904829718,
                0.045582704477069594,
                0.0,
                0.03299812999481409,
                0.10331086965789617,
                0.13354560996783033,
                0.030829097358248278,
                0.0,
                0.0,
                0.0,
                0.11685033498083647,
                0.044108821076968736,
                0.0,
                1.0,
                0.05602685316071424,
                0.0,
                0.0,
                0.0,
                0.0,
                0.06294356203147926,
                0.0,
                0.03797405135138399,
                0.04949603517589472,
                0.07773063605983335,
                0.0,
                0.04352623631493549,
                0.07864830121424843,
                0.0,
                0.0,
                0.0,
                0.033787709096407305,
                0.035501430152640866,
                0.04527534181451392,
                0.1994789642399768,
                0.03332929404236285,
                0.0,
                0.04282322304571056,
                0.06885174292389211,
                0.1695766390287808,
                0.0,
                0.0,
                0.0,
                0.17508169827848918,
                0.0,
                0.0,
                0.08341573958948426,
                0.03430971815011161,
                0.0,
                0.11621431377158663,
                0.09177095849400595,
                0.04133520720555199,
                0.10273224784648194,
                0.5689333770841702,
                0.04149340520305149,
                0.10694782458652954,
                0.10546817270006272,
                0.14994650686922323,
                0.054471985684799246,
                0.04902969782050625,
                0.0,
                0.1265911181741167,
                0.04005133737974944,
                0.08181813618366786,
                0.0,
                0.07299048775469665,
                0.0,
                0.04490943898384221,
                0.0721586821192029,
                0.0,
                0.0,
                0.28981796398908005,
                0.0,
                0.05343774455581727,
                0.14084444620727654,
                0.0,
                0.0,
                0.0,
                0.04522234114282219,
                0.05447155878372832,
                0.0
            ],
            [
                0.0,
                0.0,
                0.11412076180007465,
                0.0,
                0.0,
                0.0,
                0.3468838759853325,
                0.0,
                0.0,
                0.0673265257315512,
                0.19132705096819275,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.05602685316071424,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.04484775376834672,
                0.0,
                0.07243404250647777,
                0.0,
                0.10370560677631642,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.08741272752697264,
                0.0,
                0.0,
                0.07587477167354245,
                0.0,
                0.08433677581065835,
                0.0,
                0.0,
                0.10916984165691547,
                0.0,
                0.0,
                0.07196627249228975,
                0.14331670353027498,
                0.10003594786859957,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.09162932868651535,
                0.0,
                0.08278706845510997,
                0.0,
                0.0,
                0.0,
                0.0,
                0.07572163869551385,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0385717282675089,
                0.0,
                0.0,
                0.1378864363416293,
                0.0,
                0.0,
                0.0,
                0.034568434065883155,
                0.0,
                0.0,
                0.0,
                0.034232123947454056,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.024399925741681247,
                0.0,
                0.08782133634958916,
                0.0,
                0.028172030868707027,
                0.22914244595652672,
                0.0,
                0.0,
                0.0,
                0.03719086044175807,
                0.0,
                0.05324707299473037,
                0.0,
                0.0,
                0.0,
                0.0,
                0.058152744979812876,
                0.032148392620119766,
                0.03510875031734477,
                0.07325081655211513,
                0.026542871456452215,
                0.0,
                0.022951019191831613,
                0.04488158382156195,
                0.030510209524744942,
                0.02452487807804525,
                0.0,
                0.0,
                0.07553392095644607,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.07390137300523915,
                0.0,
                0.08959445397905559,
                0.08146456975481445,
                0.0,
                0.07123198680070938,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.05596247796011594,
                0.0,
                0.04187322017010889,
                0.0,
                0.0,
                0.15540159418629768,
                0.0597079042149101,
                0.08518766597049136,
                0.0,
                0.08042870521001415,
                0.06345689092256268,
                0.0
            ],
            [
                0.0,
                0.0,
                0.04633780939843355,
                0.0,
                0.0,
                0.0,
                0.0,
                0.04771286488238532,
                0.0,
                0.0,
                0.07768679669401486,
                0.0,
                0.07011855493341865,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0836468063313897,
                0.0,
                0.026572494419455594,
                0.029312638015921048,
                0.08534382454363935,
                0.0,
                0.04864578190520694,
                0.0,
                0.0,
                0.14922219884709503,
                0.0,
                0.023643084671231693,
                0.0,
                0.04836778259769535,
                0.0,
                0.0,
                0.0,
                0.0,
                0.09804792450060812,
                0.0,
                0.0,
                0.0,
                0.0,
                0.07149223826595646,
                0.10534311847851174,
                0.0,
                0.0,
                0.03665317415540348,
                0.0,
                0.04680123355704976,
                0.05277274549342628,
                0.0,
                0.06084029120684765,
                0.0,
                0.0,
                0.0,
                0.0,
                0.15576639005890974,
                0.0,
                0.0,
                0.0,
                0.04792333555107574,
                0.0,
                0.0,
                0.0,
                0.0,
                0.08714129699759991,
                0.0,
                0.0,
                0.0,
                0.0,
                0.06310670277729977,
                0.0,
                0.028883498645735764,
                0.06893430965770413,
                0.0,
                0.0,
                0.0,
                0.04831116182216548,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.09245053401025695,
                0.0,
                0.0,
                0.10428530191330504,
                0.0,
                0.0,
                0.0764936932958258,
                0.09130004559525354,
                0.0,
                0.14492826379266974,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.11585262016484336,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.08007395875111499,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.15278062416859253,
                0.0,
                0.0,
                0.0,
                0.0,
                0.11147202938048739,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.10230514193672646,
                0.0,
                0.09978374664742752,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.015180020037222429,
                0.023212808007295617,
                0.041365506747934065,
                0.0,
                0.03479717789873706,
                0.08436426525305805,
                0.0,
                0.049697861554587386,
                0.0,
                0.06626821397716791,
                0.0,
                0.15784543117356964,
                0.040420236143421856,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.11585262016484336,
                1.0,
                0.0,
                0.10694209725471276,
                0.0,
                0.02425199674296518,
                0.0,
                0.09365004284627113,
                0.0,
                0.0,
                0.0,
                0.060426048448820276,
                0.0,
                0.021465424764960075,
                0.0,
                0.0,
                0.0,
                0.0,
                0.02943384352642868,
                0.11156893781442442,
                0.0,
                0.03650599567861308,
                0.0,
                0.03829279976542728,
                0.11805948194697392,
                0.035827806907914206,
                0.042827299624622846,
                0.0,
                0.08921896207251652,
                0.03327721247757157,
                0.02674906503436972,
                0.0,
                0.0,
                0.0,
                0.06835923672759246,
                0.0,
                0.03667466145033218,
                0.0,
                0.0,
                0.04987636937860063,
                0.0,
                0.0,
                0.0,
                0.04350932917857552,
                0.0,
                0.0,
                0.04589904989591514,
                0.031927962191351175,
                0.0,
                0.0,
                0.11352631131599557,
                0.0,
                0.17223623202267607,
                0.02080967806898277,
                0.0775223651343809,
                0.0,
                0.0,
                0.0,
                0.0,
                0.04413184604536232,
                0.03997054575994314,
                0.0,
                0.04192365526298419
            ],
            [
                0.0,
                0.0,
                0.06652470277669104,
                0.0,
                0.0459581845151896,
                0.02859533202995954,
                0.0,
                0.1554009772901934,
                0.04286585472154955,
                0.0,
                0.11153075915404127,
                0.11904003223716862,
                0.0,
                0.0,
                0.0,
                0.0,
                0.16217678098536437,
                0.08483922847465657,
                0.0,
                0.06294356203147926,
                0.0,
                0.0,
                0.0836468063313897,
                0.0,
                0.0,
                1.0,
                0.0,
                0.15958628014584098,
                0.3371854946115583,
                0.0,
                0.0,
                0.29215169853808876,
                0.0,
                0.0,
                0.18905695206906306,
                0.0,
                0.14712476787322484,
                0.0,
                0.11873554351645323,
                0.0,
                0.0,
                0.0590482200327269,
                0.0,
                0.0,
                0.044970908611578514,
                0.0,
                0.0,
                0.0,
                0.05807771046548427,
                0.0,
                0.0,
                0.09820413118066787,
                0.22012776168713016,
                0.1619679636053114,
                0.2853734536023934,
                0.1941784769027003,
                0.0,
                0.2601655703334998,
                0.0,
                0.045178684152688456,
                0.0,
                0.18364357095442288,
                0.3730648950674266,
                0.059309970449046893,
                0.0,
                0.0,
                0.1560864810361126,
                0.04360853761019821,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.07237323640964405,
                0.0414664868172099,
                0.031336529816537534,
                0.0,
                0.0,
                0.0,
                0.20215017875868577,
                0.1047709938327148,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.13527878453851805,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0400784764965221,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.10694209725471276,
                0.0,
                1.0,
                0.10749667368363035,
                0.038062321017622296,
                0.0,
                0.0,
                0.0983961020181901,
                0.06845690518832764,
                0.06321477688957719,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.07534473215322043,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.17907284423696418,
                0.0,
                0.03825723865749298,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.05555866802701218,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.08558097588832127,
                0.06799328855050626,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.16144028002007085,
                0.06273181380027293,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.02113323115154247,
                0.0,
                0.09112948208895652,
                0.009084020467897231,
                0.0,
                0.04936699657679571,
                0.013617407948139716,
                0.0,
                0.03543052753833895,
                0.019971270729692653,
                0.0,
                0.0,
                0.0,
                0.0,
                0.025759749814152112,
                0.09618570379816627,
                0.0,
                0.03797405135138399,
                0.0,
                0.0,
                0.026572494419455594,
                0.0,
                0.0,
                0.15958628014584098,
                0.10749667368363035,
                1.0,
                0.09015510152555865,
                0.0,
                0.0,
                0.09280927413154065,
                0.0371890732606113,
                0.0,
                0.06005865644064929,
                0.04167490871008084,
                0.1037220762249517,
                0.0,
                0.03771930699878954,
                0.0702899023411807,
                0.0,
                0.01875813992326458,
                0.0,
                0.052940876812039114,
                0.06277057283558699,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.06992907410983203,
                0.05145316357903344,
                0.0635768196362703,
                0.08356996822071526,
                0.0,
                0.04744591334720787,
                0.035725723010862104,
                0.07248125914055037,
                0.0,
                0.035088417869667696,
                0.0346175588390564,
                0.01884129147180545,
                0.0,
                0.0,
                0.04958476394009215,
                0.013853339692333945,
                0.02588629503522522,
                0.0,
                0.0,
                0.0,
                0.0,
                0.04841474597651399,
                0.0,
                0.0,
                0.055275612177950025,
                0.07509900316428414,
                0.051049382353182,
                0.009954830318041305,
                0.0,
                0.0,
                0.0,
                0.06421804648076974,
                0.16876767277812874,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0382945408335924,
                0.0,
                0.09647738574720398,
                0.08186301845066339,
                0.014615267354781476,
                0.02400426867336751,
                0.06717393575774844,
                0.0134270978293536,
                0.03908410750042523,
                0.11026408693014154,
                0.0,
                0.08311798454983374,
                0.0,
                0.13193944672072447,
                0.11398251820118402,
                0.1142026893237685,
                0.0,
                0.04949603517589472,
                0.0,
                0.024399925741681247,
                0.029312638015921048,
                0.0,
                0.02425199674296518,
                0.3371854946115583,
                0.038062321017622296,
                0.09015510152555865,
                1.0,
                0.0492053372291647,
                0.06966481025403112,
                0.1650453035091452,
                0.010942601964693151,
                0.01010466570007129,
                0.07131414855687246,
                0.020540409971460227,
                0.130882716360301,
                0.0708430056769719,
                0.140813083913229,
                0.02068226917263199,
                0.0,
                0.0,
                0.2026636799559118,
                0.0,
                0.07047270947155745,
                0.08237261854877764,
                0.013636967884599314,
                0.06979983468684053,
                0.1163615337132786,
                0.02721113971421758,
                0.04879980097152704,
                0.15222551519448396,
                0.15075837736650763,
                0.2313645591936905,
                0.17493389265702255,
                0.15761614005252092,
                0.0,
                0.32604773552408345,
                0.0,
                0.17543571710254144,
                0.0,
                0.23851854782124932,
                0.14455641327380062,
                0.08545418667562268,
                0.0,
                0.012248848516165667,
                0.043135011962277765,
                0.1251711200341275,
                0.009352192393636662,
                0.06655263049762919,
                0.11462631215056307,
                0.0,
                0.0,
                0.0,
                0.05965372233512475,
                0.09856206272477243,
                0.06640796749295927,
                0.06570910137216417,
                0.014531243584475077,
                0.0758128562479994,
                0.0231917902196936,
                0.01846822656721296,
                0.03938946765933925,
                0.3114335440188437,
                0.1347937536022642,
                0.026636992074930567
            ],
            [
                0.0,
                0.10699304597654437,
                0.04357258613534137,
                0.0,
                0.0,
                0.0,
                0.03461866103855976,
                0.04486558475338539,
                0.07060065574300627,
                0.0,
                0.10168555446099041,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.07773063605983335,
                0.0,
                0.0,
                0.08534382454363935,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0492053372291647,
                1.0,
                0.0,
                0.0,
                0.03182455899100191,
                0.02314734047357215,
                0.0,
                0.04769150292941624,
                0.017511338109759536,
                0.03309160429732102,
                0.0,
                0.06015060197528294,
                0.0,
                0.0,
                0.0,
                0.04530416892438609,
                0.0,
                0.0,
                0.0,
                0.0,
                0.08995253296361445,
                0.0,
                0.0,
                0.0,
                0.027147309006263144,
                0.0,
                0.03466350673643413,
                0.030808967612943425,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.07461927774942952,
                0.0,
                0.0,
                0.028059143709315917,
                0.0,
                0.03169032246796871,
                0.02215220362265793,
                0.0,
                0.03628744932997851,
                0.0,
                0.04186100046331344,
                0.0,
                0.0,
                0.0,
                0.023651059656601914,
                0.0,
                0.027159866833797317,
                0.04024416190227157,
                0.1050675024534704,
                0.021153115846837614,
                0.0,
                0.0,
                0.028231268373532164,
                0.0
            ],
            [
                0.0,
                0.0,
                0.05392412190376143,
                0.0,
                0.03851617157831185,
                0.22207393588222,
                0.0,
                0.0,
                0.0,
                0.10888814666569031,
                0.0,
                0.0626054004962954,
                0.050245802783371596,
                0.1425913664300189,
                0.0,
                0.0,
                0.11348332208141833,
                0.0,
                0.0,
                0.0,
                0.0,
                0.08782133634958916,
                0.0,
                0.0,
                0.09365004284627113,
                0.0,
                0.0,
                0.0,
                0.06966481025403112,
                0.0,
                1.0,
                0.05305790701868484,
                0.03938511689973596,
                0.07045633893775129,
                0.0,
                0.0,
                0.034478554102938846,
                0.10072488850405682,
                0.1410688353337396,
                0.16772455132675942,
                0.0756134934382899,
                0.05482714205860478,
                0.17209953278677617,
                0.08147874114979549,
                0.0,
                0.08706825343063063,
                0.049082802794604787,
                0.3356929970787832,
                0.07188668765046406,
                0.0,
                0.032086028091160394,
                0.2001822647444484,
                0.08263152333966477,
                0.11624744770135549,
                0.051046059929070756,
                0.0,
                0.0,
                0.17744598906472317,
                0.0,
                0.0,
                0.0,
                0.15116834464974355,
                0.15173228970508018,
                0.0,
                0.0,
                0.044086619640639556,
                0.13977256695287038,
                0.2652787585741322,
                0.0,
                0.06728753742575573,
                0.0562760376508231,
                0.0,
                0.19715035574719517,
                0.14758685769328506,
                0.07823677131158921,
                0.044435021261853426,
                0.08904645506448436,
                0.04333988321533345,
                0.0,
                0.18497825549186275,
                0.12259064549961268,
                0.066471691525233,
                0.07088619294510488,
                0.17103750452635796,
                0.19474928024198038,
                0.0
            ],
            [
                0.0,
                0.10967487923431232,
                0.29118868234038625,
                0.0,
                0.026727521572407043,
                0.01662995093829878,
                0.0,
                0.09037526213691092,
                0.024929140889175423,
                0.0,
                0.22760160795157844,
                0.03656104184088774,
                0.043396016379588655,
                0.0,
                0.0,
                0.10803486956565231,
                0.09193719124410715,
                0.0493392489969509,
                0.0,
                0.04352623631493549,
                0.0,
                0.0,
                0.04864578190520694,
                0.0,
                0.0,
                0.29215169853808876,
                0.0983961020181901,
                0.09280927413154065,
                0.1650453035091452,
                0.0,
                0.05305790701868484,
                1.0,
                0.0426264865999298,
                0.09690241995274572,
                0.10994828925779992,
                0.02839907900942417,
                0.08556213542045685,
                0.0,
                0.06905204881839068,
                0.08056698695501355,
                0.046915372622660774,
                0.08113665728350765,
                0.04601373206284602,
                0.0,
                0.02615335968394163,
                0.0,
                0.0,
                0.044255020194566265,
                0.0,
                0.0,
                0.0,
                0.0542310786931423,
                0.16488381872591645,
                0.2674560342142936,
                0.1634618280965841,
                0.06836853835332737,
                0.0,
                0.08685837003287654,
                0.0,
                0.02627419398833847,
                0.18831273069604404,
                0.10465315150940796,
                0.16393107290879175,
                0.03449240937948276,
                0.0,
                0.0,
                0.249657590963697,
                0.06839638617404942,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.04208950501002392,
                0.06049382144524374,
                0.018224126681920305,
                0.0,
                0.044540170495286024,
                0.07016462844381442,
                0.11756280890192651,
                0.06093080106114496,
                0.0
            ],
            [
                0.0,
                0.0,
                0.10125624189643684,
                0.0,
                0.0,
                0.02094743135575908,
                0.04352042613717719,
                0.0,
                0.0,
                0.01550285925171978,
                0.0,
                0.040166122462736834,
                0.08040759908513957,
                0.015352034704070362,
                0.14599949589355038,
                0.0,
                0.03669653926524782,
                0.04319702849958888,
                0.0,
                0.07864830121424843,
                0.0,
                0.028172030868707027,
                0.0,
                0.0,
                0.0,
                0.0,
                0.06845690518832764,
                0.0371890732606113,
                0.010942601964693151,
                0.03182455899100191,
                0.03938511689973596,
                0.0426264865999298,
                1.0,
                0.011666795917091128,
                0.0,
                0.01703744826223436,
                0.03308926870265894,
                0.016678935290504262,
                0.0,
                0.41945496433797064,
                0.03264032974508299,
                0.0,
                0.0,
                0.17525152480958048,
                0.06175251263643545,
                0.014417546511041551,
                0.01574517415617457,
                0.032850695432621535,
                0.011903645954619157,
                0.06119117694719292,
                0.050476865656133144,
                0.02012798368748331,
                0.08722280133637006,
                0.010998639171357846,
                0.0,
                0.10360296299061457,
                0.197513502147482,
                0.0,
                0.045502290426898497,
                0.05772989172125203,
                0.0,
                0.0,
                0.11357200280610233,
                0.0,
                0.05086014647611904,
                0.014142458553226666,
                0.0,
                0.03194531356228346,
                0.07442911368860272,
                0.12658005992932592,
                0.0,
                0.0,
                0.0,
                0.0,
                0.07408868778654391,
                0.0,
                0.10991263014737164,
                0.0,
                0.07355119851262912,
                0.047823319755149,
                0.026777123704671033,
                0.021323320999006818,
                0.0,
                0.03606975352983943,
                0.08180398030343006,
                0.0
            ],
            [
                0.0,
                0.0,
                0.015973590401194056,
                0.0,
                0.0,
                0.09486159659314346,
                0.0,
                0.0,
                0.0,
                0.014315718568520415,
                0.0,
                0.04150681317891563,
                0.10628175380464996,
                0.06952253468447697,
                0.0,
                0.0,
                0.028768543892974122,
                0.0,
                0.0,
                0.0,
                0.0,
                0.22914244595652672,
                0.0,
                0.0,
                0.0,
                0.0,
                0.06321477688957719,
                0.0,
                0.01010466570007129,
                0.02314734047357215,
                0.07045633893775129,
                0.09690241995274572,
                0.011666795917091128,
                1.0,
                0.0,
                0.0,
                0.04790856867145094,
                0.04580598970067242,
                0.0,
                0.022051045475106883,
                0.0,
                0.0,
                0.029561616228169958,
                0.0,
                0.0,
                0.013313514297546625,
                0.01453947806480481,
                0.05876686205182084,
                0.010992117173916183,
                0.0,
                0.009504634516703211,
                0.05342753871440818,
                0.061262385607661195,
                0.02919468881023331,
                0.062090584750866845,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0259662563751412,
                0.08949669028783026,
                0.0,
                0.0,
                0.03883996787253569,
                0.0,
                0.08626398674403453,
                0.031704857425377424,
                0.0,
                0.0,
                0.0,
                0.03846149227677423,
                0.0,
                0.023175567725953878,
                0.0,
                0.01734082702070053,
                0.0,
                0.0,
                0.010598829011922644,
                0.024726649504219867,
                0.039125758255192995,
                0.0,
                0.03330769066433956,
                0.052217828787877035,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0354586826466981,
                0.022752788237043114,
                0.0,
                0.06914649304475641,
                0.03410758490432718,
                0.05439280265691814,
                0.0,
                0.050022134510066714,
                0.0,
                0.0,
                0.0,
                0.0,
                0.12283268443039175,
                0.02503054946371427,
                0.0,
                0.0,
                0.0,
                0.0,
                0.14922219884709503,
                0.0,
                0.060426048448820276,
                0.18905695206906306,
                0.0,
                0.06005865644064929,
                0.07131414855687246,
                0.0,
                0.0,
                0.10994828925779992,
                0.0,
                0.0,
                1.0,
                0.0,
                0.14345066249644362,
                0.0,
                0.03922434675520138,
                0.0,
                0.0,
                0.0894462367965095,
                0.0,
                0.0,
                0.03578253819171031,
                0.0,
                0.15329279392932277,
                0.057629414187285656,
                0.08166685275988228,
                0.0,
                0.0,
                0.0,
                0.13085008093202452,
                0.18314775324641588,
                0.10577927547304103,
                0.20276616775440431,
                0.0,
                0.04933905485877145,
                0.0,
                0.035947861429879345,
                0.0,
                0.032587759219034104,
                0.03599883560335056,
                0.04719187021709005,
                0.0,
                0.0,
                0.13222010088725733,
                0.13416493867896476,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.05541659770218853,
                0.0,
                0.0,
                0.0,
                0.05758607454995932,
                0.0,
                0.10367879521868427,
                0.0,
                0.0,
                0.06366666118864758,
                0.039178429559629184,
                0.11952060109179194,
                0.0
            ],
            [
                0.0,
                0.11514864273278817,
                0.05279973902601383,
                0.023959474948896633,
                0.07575788210893404,
                0.012442959055622429,
                0.02341639934842727,
                0.0,
                0.0,
                0.032565551990231846,
                0.0,
                0.0,
                0.024143992341214483,
                0.03647697629346305,
                0.0,
                0.0,
                0.03119734960356781,
                0.0,
                0.0,
                0.0,
                0.04484775376834672,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.04167490871008084,
                0.020540409971460227,
                0.04769150292941624,
                0.0,
                0.02839907900942417,
                0.01703744826223436,
                0.0,
                0.0,
                1.0,
                0.06216097824890855,
                0.01981486945931084,
                0.0,
                0.032201947225282565,
                0.0,
                0.07077902997399702,
                0.0,
                0.06755102786273973,
                0.0,
                0.1749913144692058,
                0.0,
                0.0,
                0.0,
                0.0,
                0.05796206289158036,
                0.0,
                0.06419362674530697,
                0.01720015358617742,
                0.0,
                0.04421630241559504,
                0.040793337061553483,
                0.0,
                0.0,
                0.0,
                0.03660892351179485,
                0.0,
                0.022346468824926285,
                0.07144121325912926,
                0.0,
                0.0,
                0.0,
                0.03795159625289616,
                0.01185930096383193,
                0.0,
                0.0,
                0.11000687140291691,
                0.0,
                0.12565347262372736,
                0.12497762377142682,
                0.0,
                0.0,
                0.0635537225485412,
                0.025956687082853667,
                0.013635762544877842,
                0.11727043724876425,
                0.03668622499886484,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.03322784548611779,
                0.018803457650810436,
                0.0,
                0.04003073384212867,
                0.05874090020350566,
                0.0,
                0.019361442542536366,
                0.07916954256122481,
                0.061603771452359596,
                0.03152458889678134,
                0.08470935951956454,
                0.03134741182554706,
                0.04735997186637549,
                0.0,
                0.0,
                0.02071448399872349,
                0.12291818660688245,
                0.1883632571174377,
                0.033787709096407305,
                0.0,
                0.0,
                0.023643084671231693,
                0.0,
                0.021465424764960075,
                0.14712476787322484,
                0.0,
                0.1037220762249517,
                0.130882716360301,
                0.017511338109759536,
                0.034478554102938846,
                0.08556213542045685,
                0.03308926870265894,
                0.04790856867145094,
                0.14345066249644362,
                0.06216097824890855,
                1.0,
                0.04872799511959162,
                0.09304196380890922,
                0.06254099018150024,
                0.0,
                0.015084198879633807,
                0.029901046602691512,
                0.04710455907066972,
                0.08127300115810061,
                0.02223857001065956,
                0.2610553556342015,
                0.020471963436987817,
                0.0,
                0.10540544180766163,
                0.0,
                0.0,
                0.13770980120999182,
                0.09343981256957902,
                0.11900698109347708,
                0.08776597971773803,
                0.0,
                0.11703451902425523,
                0.031787241376494316,
                0.038309775409417005,
                0.0,
                0.08483116309724127,
                0.07923008053325162,
                0.14304843410927126,
                0.0,
                0.019503348183231746,
                0.07306715817142,
                0.26607376114944936,
                0.040888804421297345,
                0.0,
                0.0,
                0.0,
                0.029096742074255267,
                0.01968589439890159,
                0.0,
                0.0,
                0.06824636501121471,
                0.0,
                0.07053520275280464,
                0.044276190157042906,
                0.03262984715755798,
                0.04068710380257355,
                0.054387489927227965,
                0.12159196083733374,
                0.17141904805597158,
                0.0
            ],
            [
                0.0,
                0.0,
                0.02283595963723368,
                0.0,
                0.06238555813946591,
                0.05818257353074323,
                0.0,
                0.0,
                0.0,
                0.06312732478165518,
                0.0,
                0.06800224328837066,
                0.0,
                0.1477542238319275,
                0.0,
                0.11104001822836909,
                0.0,
                0.0,
                0.0,
                0.035501430152640866,
                0.07243404250647777,
                0.03719086044175807,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0708430056769719,
                0.03309160429732102,
                0.10072488850405682,
                0.0,
                0.016678935290504262,
                0.04580598970067242,
                0.0,
                0.01981486945931084,
                0.04872799511959162,
                1.0,
                0.0,
                0.09723741793465497,
                0.0,
                0.0,
                0.0,
                0.10623090640642972,
                0.0,
                0.09673555937601726,
                0.02078574233439138,
                0.12465973129674043,
                0.10652164666860113,
                0.0,
                0.013587893813395131,
                0.08196073658468273,
                0.05372147863645953,
                0.01451967933648643,
                0.09360891761075768,
                0.0,
                0.053440020040969406,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.13253936827438506,
                0.06332093657264654,
                0.0633878045197896,
                0.05552589720732896,
                0.0,
                0.21643893559252625,
                0.0,
                0.0,
                0.06634739878425136,
                0.0,
                0.11304577385286504,
                0.0,
                0.033131958180190775,
                0.18606149880592357,
                0.024790570934595087,
                0.036707424760818945,
                0.0,
                0.10541359665934807,
                0.06848076156479324,
                0.05593446519230646,
                0.0,
                0.047616913950883945,
                0.10986262721353655,
                0.0
            ],
            [
                0.0,
                0.0,
                0.03846712746607064,
                0.0,
                0.02080628629109306,
                0.1642136484481718,
                0.024116153368363157,
                0.039608623692603095,
                0.09583989598474481,
                0.055527835668240974,
                0.06449135057645619,
                0.24602008211218246,
                0.0,
                0.06947564368054991,
                0.0,
                0.0,
                0.2105859128192589,
                0.018190210121214658,
                0.0,
                0.04527534181451392,
                0.0,
                0.0,
                0.04836778259769535,
                0.0,
                0.0,
                0.11873554351645323,
                0.0,
                0.03771930699878954,
                0.140813083913229,
                0.0,
                0.1410688353337396,
                0.06905204881839068,
                0.0,
                0.0,
                0.03922434675520138,
                0.0,
                0.09304196380890922,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.16842435798925898,
                0.0,
                0.026003899327946015,
                0.0,
                0.0,
                0.06822642064432727,
                0.04177533187292635,
                0.0,
                0.0,
                0.0,
                0.17094798455136592,
                0.034727228710784076,
                0.29084851361683567,
                0.1118695280968525,
                0.0,
                0.47759454134137413,
                0.0,
                0.12389575608912659,
                0.0,
                0.3561729505167161,
                0.1609219223622877,
                0.07241444751109764,
                0.0,
                0.06400170597259078,
                0.32342487793342967,
                0.1255280685311244,
                0.015431733174665096,
                0.0,
                0.025278669571123194,
                0.0723399621752234,
                0.0,
                0.08812548310105732,
                0.0,
                0.0,
                0.16320875801555723,
                0.0,
                0.023977508615440846,
                0.11787426035619741,
                0.0,
                0.04824935197092149,
                0.06499521494282025,
                0.22532006941113916,
                0.02246374026132117,
                0.0
            ],
            [
                0.0,
                0.0,
                0.19138125073618797,
                0.0,
                0.0,
                0.039592083781619075,
                0.0,
                0.0,
                0.0,
                0.09038094926238144,
                0.0,
                0.0,
                0.11799380607940875,
                0.029016399858246562,
                0.0,
                0.0,
                0.0,
                0.08164535032609178,
                0.0,
                0.1994789642399768,
                0.10370560677631642,
                0.05324707299473037,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0702899023411807,
                0.02068226917263199,
                0.06015060197528294,
                0.16772455132675942,
                0.08056698695501355,
                0.41945496433797064,
                0.022051045475106883,
                0.0,
                0.032201947225282565,
                0.06254099018150024,
                0.09723741793465497,
                0.0,
                1.0,
                0.061692464721776356,
                0.0,
                0.0,
                0.3312374169069556,
                0.1167164896021995,
                0.027250152999480342,
                0.02975946042071931,
                0.06209007031762972,
                0.022498708311195433,
                0.0,
                0.019454123005826697,
                0.21269180213082556,
                0.025861569112328602,
                0.020788183341461406,
                0.06883455811832549,
                0.16304899953813873,
                0.07651139592259563,
                0.0,
                0.08600245367755,
                0.0,
                0.0,
                0.0,
                0.27994760255185686,
                0.0,
                0.0907538845337181,
                0.02673021786814372,
                0.0,
                0.06037883640756232,
                0.10397510276165747,
                0.0,
                0.06824160071350564,
                0.0,
                0.18307319858722282,
                0.07481955656853269,
                0.04743584242805371,
                0.0,
                0.16855813085185287,
                0.0,
                0.04783675721649899,
                0.07606398858694066,
                0.05061060266249032,
                0.04030254102076004,
                0.0,
                0.06817431118317673,
                0.1546151404836984,
                0.0
            ],
            [
                0.0,
                0.0,
                0.04468949843753353,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.044207457673741915,
                0.03322958088352346,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.03332929404236285,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.07534473215322043,
                0.0,
                0.0,
                0.0,
                0.0756134934382899,
                0.046915372622660774,
                0.03264032974508299,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.061692464721776356,
                1.0,
                0.05200350542504922,
                0.0,
                0.0,
                0.0,
                0.06195076244926812,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.04281134709008092,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.18491036054767848,
                0.06786807336201589,
                0.0,
                0.0,
                0.0,
                0.0,
                0.027856065799319926,
                0.0,
                0.0,
                0.052500963098769476,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.03513365226126543,
                0.0,
                0.09849383471629984,
                0.2602832822125582,
                0.0,
                0.0,
                0.03368161759583642,
                0.0,
                0.026495018017331555,
                0.0,
                0.0,
                0.0,
                0.051304391810690464,
                0.0,
                0.0,
                0.05983244157554917,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.02943384352642868,
                0.0590482200327269,
                0.0,
                0.01875813992326458,
                0.0,
                0.0,
                0.05482714205860478,
                0.08113665728350765,
                0.0,
                0.0,
                0.0894462367965095,
                0.07077902997399702,
                0.015084198879633807,
                0.0,
                0.0,
                0.0,
                0.05200350542504922,
                1.0,
                0.0,
                0.050074830972771205,
                0.0,
                0.09405922580852698,
                0.2624434623500735,
                0.02807158838369203,
                0.0,
                0.0,
                0.13942917561219328,
                0.0,
                0.292038211376339,
                0.14788037021381115,
                0.03303807590610499,
                0.014847878707223601,
                0.058906698034624054,
                0.0,
                0.0,
                0.0,
                0.13133416173019807,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.1647734670410053,
                0.04447035790816026,
                0.026676379008080005,
                0.0,
                0.0,
                0.053419552038597454,
                0.0,
                0.026993713926450034,
                0.03493755454661981,
                0.0,
                0.0,
                0.02805047742018701,
                0.0,
                0.0,
                0.04474273516798173,
                0.0,
                0.07777345751273111,
                0.0,
                0.03961634060496744,
                0.0
            ],
            [
                0.0,
                0.2003136810844977,
                0.0,
                0.0,
                0.07516560843037699,
                0.0880128392282774,
                0.02281001916957183,
                0.0,
                0.03450554965203611,
                0.0,
                0.0,
                0.08749829270886476,
                0.0,
                0.3565356544084206,
                0.0,
                0.09222019573068417,
                0.0972799236505798,
                0.0,
                0.0,
                0.04282322304571056,
                0.0,
                0.0,
                0.0,
                0.0,
                0.11156893781442442,
                0.0,
                0.0,
                0.0,
                0.2026636799559118,
                0.0,
                0.17209953278677617,
                0.04601373206284602,
                0.0,
                0.029561616228169958,
                0.0,
                0.0,
                0.029901046602691512,
                0.0,
                0.16842435798925898,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.09609657972964744,
                0.10907018667976667,
                0.0,
                0.04161895254313242,
                0.13375082239266095,
                0.11838718762354714,
                0.0,
                0.13947201884690044,
                0.05737935724892242,
                0.07107965060467263,
                0.07326581563098605,
                0.0,
                0.0,
                0.2864580427918123,
                0.0,
                0.06383148486328492,
                0.0,
                0.24883159000308736,
                0.06949171029806189,
                0.03605461555386118,
                0.0,
                0.0,
                0.09029996279967142,
                0.1353509485099125,
                0.014595948373574292,
                0.10386856022443597,
                0.11723350737144915,
                0.06280110281683064,
                0.0,
                0.0,
                0.0,
                0.08872720381387872,
                0.11240201556319773,
                0.10255206596847186,
                0.0,
                0.09312736379396523,
                0.052600461897553935,
                0.0,
                0.061475065120503346,
                0.18596575523480294,
                0.0,
                0.13077602959499074
            ],
            [
                0.0,
                0.0,
                0.06171692648135421,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.05798175637807719,
                0.0,
                0.0,
                0.0,
                0.0,
                0.06149356152052946,
                0.0,
                0.06885174292389211,
                0.0,
                0.0,
                0.09804792450060812,
                0.0,
                0.0,
                0.0,
                0.0,
                0.052940876812039114,
                0.0,
                0.04530416892438609,
                0.08147874114979549,
                0.0,
                0.17525152480958048,
                0.0,
                0.0,
                0.06755102786273973,
                0.04710455907066972,
                0.10623090640642972,
                0.0,
                0.3312374169069556,
                0.0,
                0.050074830972771205,
                0.0,
                1.0,
                0.08790840635929521,
                0.0,
                0.0,
                0.0,
                0.0,
                0.08710931133032968,
                0.0,
                0.0,
                0.0871484868584699,
                0.04550730552987517,
                0.0,
                0.12280507884299088,
                0.0,
                0.0,
                0.0647752401700064,
                0.1053954294299423,
                0.0,
                0.0,
                0.05912316882722407,
                0.0,
                0.0,
                0.0,
                0.0,
                0.06608750054789847,
                0.07831186163989133,
                0.0,
                0.0,
                0.07205803738799564,
                0.0,
                0.0,
                0.0,
                0.0,
                0.10022165410850399,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.1348145301046768,
                0.0
            ],
            [
                0.0,
                0.06201113015526177,
                0.0,
                0.0,
                0.008989163790726814,
                0.18925562623870318,
                0.0,
                0.0,
                0.05589199042178538,
                0.0,
                0.0,
                0.033162325381397434,
                0.0,
                0.053842862939454436,
                0.0,
                0.0,
                0.0,
                0.07291126091561552,
                0.0,
                0.1695766390287808,
                0.0,
                0.058152744979812876,
                0.0,
                0.0,
                0.03650599567861308,
                0.044970908611578514,
                0.0,
                0.06277057283558699,
                0.07047270947155745,
                0.0,
                0.0,
                0.02615335968394163,
                0.06175251263643545,
                0.0,
                0.03578253819171031,
                0.0,
                0.08127300115810061,
                0.0,
                0.026003899327946015,
                0.1167164896021995,
                0.0,
                0.0,
                0.09609657972964744,
                0.08790840635929521,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.04096032831216309,
                0.0,
                0.08532963810913832,
                0.01970579173981401,
                0.031680027595898975,
                0.025161677887197576,
                0.09937124423406447,
                0.0,
                0.03270947566037831,
                0.2096434726080988,
                0.05890764568521474,
                0.0,
                0.07421591653027437,
                0.023865536953236142,
                0.031285993107328755,
                0.0,
                0.1303690434983827,
                0.0,
                0.02300349160122154,
                0.04298423222517714,
                0.04389817171363616,
                0.030536125909376453,
                0.0,
                0.0,
                0.0,
                0.0,
                0.03223708763882909,
                0.30361409489266744,
                0.031442577808975844,
                0.0,
                0.2099746383534514,
                0.0,
                0.04401562861963608,
                0.0,
                0.12745373011797298,
                0.09004072060847837,
                0.0400960765369035
            ],
            [
                0.0,
                0.0,
                0.019739779815653336,
                0.0,
                0.21388711704992106,
                0.05029397532881875,
                0.0,
                0.0,
                0.0,
                0.017691021576735112,
                0.0,
                0.0,
                0.0,
                0.12772118586685002,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.032148392620119766,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.08237261854877764,
                0.0,
                0.08706825343063063,
                0.0,
                0.014417546511041551,
                0.013313514297546625,
                0.0,
                0.1749913144692058,
                0.02223857001065956,
                0.09673555937601726,
                0.0,
                0.027250152999480342,
                0.06195076244926812,
                0.09405922580852698,
                0.10907018667976667,
                0.0,
                0.0,
                1.0,
                0.017967538194313168,
                0.10775792595393896,
                0.1363644715738116,
                0.0,
                0.1346756229057693,
                0.022968962559080063,
                0.06099627271428401,
                0.049030346721144626,
                0.0,
                0.0,
                0.0,
                0.1450519426669525,
                0.0,
                0.0,
                0.0,
                0.0,
                0.037820364726221335,
                0.05473566101540061,
                0.0,
                0.016138606133927206,
                0.0,
                0.15111157755396218,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.07026023840828007,
                0.07921998243631617,
                0.02142937803040025,
                0.031730502851160414,
                0.0,
                0.09112125002353051,
                0.05919589876543631,
                0.024333016623319412,
                0.0,
                0.04116084508044019,
                0.06291273727345664,
                0.0
            ],
            [
                0.0,
                0.0,
                0.021557500838577014,
                0.0,
                0.013877947868269779,
                0.026105258108174784,
                0.0,
                0.0,
                0.0,
                0.10576329971265451,
                0.0,
                0.0,
                0.0,
                0.019132122770996934,
                0.0,
                0.0,
                0.03695317454430729,
                0.09094079860819126,
                0.0,
                0.0,
                0.0,
                0.03510875031734477,
                0.0,
                0.0,
                0.03829279976542728,
                0.0,
                0.0,
                0.0,
                0.013636967884599314,
                0.0,
                0.049082802794604787,
                0.0,
                0.01574517415617457,
                0.01453947806480481,
                0.15329279392932277,
                0.0,
                0.2610553556342015,
                0.02078574233439138,
                0.0,
                0.02975946042071931,
                0.0,
                0.2624434623500735,
                0.0,
                0.0,
                0.0,
                0.017967538194313168,
                1.0,
                0.07745996423165355,
                0.05474194940776309,
                0.09401792700408024,
                0.08184106222593558,
                0.025084040159149272,
                0.3693566044425419,
                0.03816145647006079,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0413030212046375,
                0.0,
                0.0,
                0.017624716107001066,
                0.03977729941350885,
                0.24359059253753804,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.03511824343914338,
                0.11541686973287248,
                0.0,
                0.02340268428395575,
                0.0,
                0.0,
                0.014303876559610363,
                0.07825590312901248,
                0.026573701994707637,
                0.14152450283718773,
                0.044951106882888996,
                0.1477717053870621,
                0.0
            ],
            [
                0.0,
                0.0,
                0.04497752056040993,
                0.0,
                0.04489922009742759,
                0.054465950950775596,
                0.0,
                0.0,
                0.0,
                0.0762678717437782,
                0.0,
                0.0,
                0.0,
                0.11474236740742133,
                0.0,
                0.0,
                0.07905191824939693,
                0.0,
                0.0,
                0.0,
                0.0,
                0.07325081655211513,
                0.0,
                0.0,
                0.11805948194697392,
                0.0,
                0.0,
                0.0,
                0.06979983468684053,
                0.0,
                0.3356929970787832,
                0.044255020194566265,
                0.032850695432621535,
                0.05876686205182084,
                0.057629414187285656,
                0.0,
                0.020471963436987817,
                0.12465973129674043,
                0.06822642064432727,
                0.06209007031762972,
                0.0,
                0.02807158838369203,
                0.04161895254313242,
                0.0,
                0.0,
                0.10775792595393896,
                0.07745996423165355,
                1.0,
                0.08896882686505656,
                0.0,
                0.02676260525387232,
                0.10138674312548984,
                0.10065912905222481,
                0.08091235379573072,
                0.04257696053141566,
                0.0,
                0.0,
                0.08581983868327134,
                0.0,
                0.06252733615898161,
                0.0,
                0.09323995774655582,
                0.12655824404647895,
                0.0,
                0.0,
                0.03677216747014886,
                0.041495633366904955,
                0.19983687792333626,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.10827209430260162,
                0.12894816193091654,
                0.07412553090708206,
                0.048827307090569164,
                0.07229864556282935,
                0.0,
                0.14172762754979343,
                0.13487915157508734,
                0.10955721074532629,
                0.042089338950433444,
                0.09378588683250076,
                0.1433480495048222,
                0.0
            ],
            [
                0.0,
                0.0,
                0.01629787356452923,
                0.0,
                0.04128466260914046,
                0.01973606306233215,
                0.15774744434154933,
                0.12617680160183803,
                0.0,
                0.08615005775529205,
                0.0,
                0.07468911575454212,
                0.0,
                0.08738024357690327,
                0.0,
                0.044819546103271726,
                0.1078172207575075,
                0.0,
                0.0,
                0.17508169827848918,
                0.0,
                0.026542871456452215,
                0.07149223826595646,
                0.08007395875111499,
                0.035827806907914206,
                0.05807771046548427,
                0.0,
                0.0,
                0.1163615337132786,
                0.08995253296361445,
                0.07188668765046406,
                0.0,
                0.011903645954619157,
                0.010992117173916183,
                0.08166685275988228,
                0.0,
                0.0,
                0.10652164666860113,
                0.04177533187292635,
                0.022498708311195433,
                0.0,
                0.0,
                0.13375082239266095,
                0.0,
                0.0,
                0.1363644715738116,
                0.05474194940776309,
                0.08896882686505656,
                1.0,
                0.0,
                0.06187337273150779,
                0.05640045654919199,
                0.0792292597164415,
                0.010362599241843368,
                0.07291736693316771,
                0.02920768145447306,
                0.0,
                0.1996038942341812,
                0.0,
                0.038285757841360096,
                0.0,
                0.09731495644200326,
                0.13486016177150909,
                0.050261029261413494,
                0.0,
                0.013324614799903026,
                0.10719695514792807,
                0.0952625439951691,
                0.020347114427177255,
                0.08729981722108125,
                0.17836306077375685,
                0.0,
                0.0,
                0.0,
                0.08725731077110616,
                0.21709631166928828,
                0.16219236595131378,
                0.057056301098555355,
                0.07638249112002939,
                0.11563797167390598,
                0.08280856233511528,
                0.020090215396220825,
                0.0,
                0.0757103054009197,
                0.05194302303555383,
                0.0
            ],
            [
                0.0,
                0.06060814683806853,
                0.0,
                0.0,
                0.0,
                0.02604515284000492,
                0.06656358109736413,
                0.0,
                0.03904300662326613,
                0.0,
                0.0,
                0.0,
                0.06229585238890096,
                0.06824579175336305,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.10534311847851174,
                0.0,
                0.042827299624622846,
                0.0,
                0.0,
                0.0,
                0.02721113971421758,
                0.0,
                0.0,
                0.0,
                0.06119117694719292,
                0.0,
                0.0,
                0.0,
                0.10540544180766163,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.11838718762354714,
                0.08710931133032968,
                0.04096032831216309,
                0.0,
                0.09401792700408024,
                0.0,
                0.0,
                1.0,
                0.0,
                0.10010514465440656,
                0.06626982763242599,
                0.0,
                0.0,
                0.04688520986402533,
                0.0,
                0.0,
                0.0,
                0.04114957408552755,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.05149948982365257,
                0.035823699350905056,
                0.14847887653462624,
                0.0,
                0.0,
                0.0,
                0.03781919615309096,
                0.023348801475789174,
                0.03688711061740545,
                0.0,
                0.05558979741400191,
                0.13946346013391914,
                0.07295837934154607,
                0.0,
                0.04484761055573021,
                0.0,
                0.047039031580880734
            ],
            [
                0.0,
                0.0,
                0.014092401780238746,
                0.0,
                0.41455739125180197,
                0.01706532629139019,
                0.0,
                0.0,
                0.0,
                0.08058154556533521,
                0.0,
                0.0,
                0.04090948974590364,
                0.012506902493783719,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.022951019191831613,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.04879980097152704,
                0.0,
                0.032086028091160394,
                0.0,
                0.050476865656133144,
                0.009504634516703211,
                0.0,
                0.05796206289158036,
                0.0,
                0.013587893813395131,
                0.0,
                0.019454123005826697,
                0.0,
                0.13942917561219328,
                0.0,
                0.0,
                0.0,
                0.1346756229057693,
                0.08184106222593558,
                0.02676260525387232,
                0.06187337273150779,
                0.0,
                1.0,
                0.01639774363648867,
                0.07112152764399013,
                0.07231594629042615,
                0.0,
                0.0,
                0.05009811996264711,
                0.0,
                0.0,
                0.0,
                0.060391028018345574,
                0.0,
                0.027000289779039767,
                0.0,
                0.0,
                0.011521492333565845,
                0.046152110910846075,
                0.026025014244587048,
                0.02268734253157944,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.13045262504797064,
                0.0,
                0.015298620750852913,
                0.0,
                0.0,
                0.009350618933167309,
                0.12929958606690042,
                0.05128159616625581,
                0.0,
                0.029385087974879636,
                0.023184338446115803,
                0.0
            ],
            [
                0.0,
                0.0,
                0.02755822329546134,
                0.0,
                0.0,
                0.08762983983358885,
                0.0,
                0.0,
                0.08133542291131245,
                0.0761814673004347,
                0.0,
                0.03620871194908724,
                0.12284462758452072,
                0.02445771963027404,
                0.0,
                0.0,
                0.10190150958267497,
                0.046005936689142074,
                0.0,
                0.08341573958948426,
                0.08741272752697264,
                0.04488158382156195,
                0.0,
                0.0,
                0.08921896207251652,
                0.09820413118066787,
                0.17907284423696418,
                0.0,
                0.15222551519448396,
                0.0,
                0.2001822647444484,
                0.0542310786931423,
                0.02012798368748331,
                0.05342753871440818,
                0.0,
                0.0,
                0.0,
                0.08196073658468273,
                0.0,
                0.21269180213082556,
                0.0,
                0.0,
                0.13947201884690044,
                0.0,
                0.08532963810913832,
                0.022968962559080063,
                0.025084040159149272,
                0.10138674312548984,
                0.05640045654919199,
                0.10010514465440656,
                0.01639774363648867,
                1.0,
                0.0626600669126588,
                0.09428309100845278,
                0.1651411168248263,
                0.049387535390929015,
                0.06449091820961751,
                0.0714285243010549,
                0.0,
                0.08572387990407233,
                0.0,
                0.09197548310687544,
                0.20943437023995104,
                0.0,
                0.07649581182115923,
                0.022530712888883753,
                0.0,
                0.16236806489997538,
                0.0,
                0.10728509781384266,
                0.21221666546309448,
                0.0,
                0.15431111318902097,
                0.06306487870150207,
                0.03998333839480332,
                0.0787859486068496,
                0.0785578701034523,
                0.07684420339326963,
                0.0,
                0.06411380170896842,
                0.042659321496998054,
                0.03397072874267087,
                0.18531670739343745,
                0.2229009950081997,
                0.04533784842492507,
                0.2031270988690062
            ],
            [
                0.0,
                0.04291553194748022,
                0.04788434509417075,
                0.02411278415722953,
                0.060145423322406306,
                0.06184159562245124,
                0.06540772234875038,
                0.06809511724776843,
                0.01878337867682075,
                0.09191043272956714,
                0.04887163680537758,
                0.05816686602732014,
                0.0,
                0.01662619914181003,
                0.05711968522014201,
                0.0,
                0.18532748676335162,
                0.03717568133052223,
                0.09733799352057808,
                0.03430971815011161,
                0.0,
                0.030510209524744942,
                0.03665317415540348,
                0.0,
                0.03327721247757157,
                0.22012776168713016,
                0.0,
                0.06992907410983203,
                0.15075837736650763,
                0.027147309006263144,
                0.08263152333966477,
                0.16488381872591645,
                0.08722280133637006,
                0.061262385607661195,
                0.13085008093202452,
                0.06419362674530697,
                0.13770980120999182,
                0.05372147863645953,
                0.17094798455136592,
                0.025861569112328602,
                0.0,
                0.292038211376339,
                0.05737935724892242,
                0.0871484868584699,
                0.01970579173981401,
                0.06099627271428401,
                0.3693566044425419,
                0.10065912905222481,
                0.0792292597164415,
                0.06626982763242599,
                0.07112152764399013,
                0.0626600669126588,
                1.0,
                0.1264639560911616,
                0.2755834749795815,
                0.11156186853304692,
                0.04643714847170894,
                0.09564631019909874,
                0.0,
                0.04180098390922647,
                0.0,
                0.11874786016094618,
                0.17474774139258692,
                0.054875770883862175,
                0.05508135826903661,
                0.04555169570486479,
                0.22078931724742623,
                0.14151903296007398,
                0.03272363096623739,
                0.049522179059997735,
                0.01915621160295708,
                0.05031587965393618,
                0.045107817758661996,
                0.030518459238349147,
                0.13979915800980006,
                0.0,
                0.16646956063829066,
                0.10358895173432868,
                0.018170189987918046,
                0.14111776714189708,
                0.1101491376067381,
                0.04588687200029596,
                0.03506184942585879,
                0.24642362839350387,
                0.10715089030972987,
                0.0
            ],
            [
                0.0,
                0.06642556143280656,
                0.0150587837776803,
                0.35803927379652467,
                0.098032286853431,
                0.038379729630346186,
                0.0,
                0.0,
                0.03019710969661948,
                0.03757415971572339,
                0.0,
                0.04428703724689406,
                0.0,
                0.059989272589012745,
                0.0,
                0.0654322750598785,
                0.052934253791497944,
                0.08490476987964878,
                0.0,
                0.0,
                0.0,
                0.02452487807804525,
                0.0,
                0.0,
                0.02674906503436972,
                0.1619679636053114,
                0.03825723865749298,
                0.05145316357903344,
                0.2313645591936905,
                0.0,
                0.11624744770135549,
                0.2674560342142936,
                0.010998639171357846,
                0.02919468881023331,
                0.18314775324641588,
                0.01720015358617742,
                0.09343981256957902,
                0.01451967933648643,
                0.034727228710784076,
                0.020788183341461406,
                0.0,
                0.14788037021381115,
                0.07107965060467263,
                0.04550730552987517,
                0.031680027595898975,
                0.049030346721144626,
                0.03816145647006079,
                0.08091235379573072,
                0.010362599241843368,
                0.0,
                0.07231594629042615,
                0.09428309100845278,
                0.1264639560911616,
                1.0,
                0.0621125931600004,
                0.05582893217219073,
                0.0,
                0.10114842006633722,
                0.0,
                0.03182639632802686,
                0.17858559593529877,
                0.10228904483582786,
                0.08776484431619762,
                0.04178126612398472,
                0.0,
                0.012311575028371774,
                0.17333232401129192,
                0.15985796506210612,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.08605000648241062,
                0.07072417743153052,
                0.0,
                0.01634771883291594,
                0.0,
                0.0,
                0.03206704195469645,
                0.023310555678371384,
                0.0455389511180862,
                0.11027061128779954,
                0.16429518806215493,
                0.13458353101418885,
                0.0
            ],
            [
                0.0,
                0.0,
                0.03722124356583917,
                0.0,
                0.020132406570374538,
                0.04999650111574535,
                0.1448758666961397,
                0.18310822786843803,
                0.023983878960038167,
                0.04468795653806222,
                0.17896326076557528,
                0.1982488400242882,
                0.0,
                0.0,
                0.0,
                0.08659262965670726,
                0.27043823741166984,
                0.017601060594730305,
                0.0,
                0.11621431377158663,
                0.07587477167354245,
                0.0,
                0.04680123355704976,
                0.0,
                0.0,
                0.2853734536023934,
                0.0,
                0.0635768196362703,
                0.17493389265702255,
                0.03466350673643413,
                0.051046059929070756,
                0.1634618280965841,
                0.0,
                0.062090584750866845,
                0.10577927547304103,
                0.0,
                0.11900698109347708,
                0.09360891761075768,
                0.29084851361683567,
                0.06883455811832549,
                0.0,
                0.03303807590610499,
                0.07326581563098605,
                0.0,
                0.025161677887197576,
                0.0,
                0.0,
                0.04257696053141566,
                0.07291736693316771,
                0.0,
                0.0,
                0.1651411168248263,
                0.2755834749795815,
                0.0621125931600004,
                1.0,
                0.24830875280795417,
                0.05597850373290252,
                0.2754123239084038,
                0.0,
                0.05337430266081827,
                0.0,
                0.2796711288157397,
                0.5063145404114048,
                0.07006906847602905,
                0.06639882337639876,
                0.0386066693987075,
                0.23778080917729869,
                0.13652566261478782,
                0.12413443570411073,
                0.0,
                0.024459937071127907,
                0.0,
                0.1184156231371179,
                0.0634818191770468,
                0.0,
                0.0,
                0.2367761576801271,
                0.11205560851466372,
                0.023200918474209523,
                0.11405651640432546,
                0.0,
                0.029104642633135093,
                0.0,
                0.36948145602737686,
                0.06057967476391525,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.015841381893940208,
                0.029659681163616374,
                0.0,
                0.02185185338153187,
                0.02155753420625652,
                0.04310632533541221,
                0.0,
                0.16140631960365948,
                0.0,
                0.0,
                0.03277790404937506,
                0.11217986677308436,
                0.12430049398423146,
                0.08293492719937447,
                0.0,
                0.09177095849400595,
                0.0,
                0.0,
                0.05277274549342628,
                0.0,
                0.0,
                0.1941784769027003,
                0.0,
                0.08356996822071526,
                0.15761614005252092,
                0.030808967612943425,
                0.0,
                0.06836853835332737,
                0.10360296299061457,
                0.0,
                0.20276616775440431,
                0.04421630241559504,
                0.08776597971773803,
                0.0,
                0.1118695280968525,
                0.16304899953813873,
                0.0,
                0.014847878707223601,
                0.0,
                0.12280507884299088,
                0.09937124423406447,
                0.0,
                0.0,
                0.0,
                0.02920768145447306,
                0.04688520986402533,
                0.0,
                0.049387535390929015,
                0.11156186853304692,
                0.05582893217219073,
                0.24830875280795417,
                1.0,
                0.026647772848641678,
                0.12793732389778328,
                0.056556908538171344,
                0.022720672090684346,
                0.0,
                0.07488008753517159,
                0.09334582317622438,
                0.029827393505456563,
                0.03160821824023429,
                0.0,
                0.07591125922857209,
                0.021931034557070614,
                0.05304790472671509,
                0.028418105374505443,
                0.0,
                0.0,
                0.0,
                0.2054685772068824,
                0.0,
                0.0,
                0.17981539919433775,
                0.08252092975207975,
                0.0,
                0.050380387885975805,
                0.11956863692690237,
                0.0,
                0.0,
                0.14392987913399155,
                0.10241930416326184,
                0.04589594470116847
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.1519007967289927,
                0.0,
                0.0,
                0.0,
                0.0,
                0.14270199084993535,
                0.0,
                0.061737956301343315,
                0.0,
                0.0,
                0.08106830856982448,
                0.0,
                0.056404980084154926,
                0.0,
                0.0,
                0.04133520720555199,
                0.08433677581065835,
                0.07553392095644607,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.197513502147482,
                0.0,
                0.0,
                0.040793337061553483,
                0.0,
                0.053440020040969406,
                0.0,
                0.07651139592259563,
                0.0,
                0.058906698034624054,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.05009811996264711,
                0.06449091820961751,
                0.04643714847170894,
                0.0,
                0.05597850373290252,
                0.026647772848641678,
                1.0,
                0.0,
                0.0,
                0.08873461797748766,
                0.0,
                0.0,
                0.05309491105536313,
                0.0,
                0.2754988942974337,
                0.0,
                0.0,
                0.0,
                0.07265124331481516,
                0.070285388962023,
                0.0,
                0.0,
                0.06760182080007539,
                0.0,
                0.0,
                0.0,
                0.031865938849925994,
                0.0,
                0.0,
                0.1230949973050573,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.04838657286385875,
                0.0,
                0.08896798336671315,
                0.1623638037343891,
                0.08488569557724056,
                0.04982242456314797,
                0.031178370083339575,
                0.13138059445422404,
                0.08112161316201115,
                0.25771793266505894,
                0.0,
                0.0,
                0.0,
                0.08551542018665982,
                0.20722656919158586,
                0.022880885197767573,
                0.0,
                0.10273224784648194,
                0.0,
                0.0,
                0.06084029120684765,
                0.15278062416859253,
                0.06835923672759246,
                0.2601655703334998,
                0.0,
                0.04744591334720787,
                0.32604773552408345,
                0.0,
                0.17744598906472317,
                0.08685837003287654,
                0.0,
                0.0,
                0.04933905485877145,
                0.0,
                0.11703451902425523,
                0.0,
                0.47759454134137413,
                0.0,
                0.0,
                0.0,
                0.2864580427918123,
                0.0,
                0.03270947566037831,
                0.1450519426669525,
                0.0,
                0.08581983868327134,
                0.1996038942341812,
                0.0,
                0.0,
                0.0714285243010549,
                0.09564631019909874,
                0.10114842006633722,
                0.2754123239084038,
                0.12793732389778328,
                0.0,
                1.0,
                0.0,
                0.15584452035876867,
                0.0,
                0.29520803201573936,
                0.32699960063206907,
                0.0910878241163797,
                0.0,
                0.0,
                0.2507338878161528,
                0.06697367700128566,
                0.01941108501876478,
                0.0,
                0.03179723227796048,
                0.0,
                0.0,
                0.0,
                0.0,
                0.1339130229498377,
                0.04144894454731392,
                0.05887774267799902,
                0.030160543407826784,
                0.04812641609387834,
                0.0,
                0.0,
                0.08175540807945282,
                0.1260677820188321,
                0.02825642247157489,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.09034862191474657,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.07143345475298836,
                0.04149727163820327,
                0.0,
                0.5689333770841702,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.035725723010862104,
                0.0,
                0.0,
                0.0,
                0.0,
                0.045502290426898497,
                0.0,
                0.0,
                0.0,
                0.031787241376494316,
                0.0,
                0.0,
                0.08600245367755,
                0.0,
                0.0,
                0.0,
                0.0647752401700064,
                0.2096434726080988,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.056556908538171344,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.08078254940534839,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.3556665944875052,
                0.0,
                0.0,
                0.13392501257490388,
                0.0,
                0.0,
                0.0,
                0.0,
                0.05124646309318392,
                0.08130265016616128
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.01906829707402151,
                0.037457185978186584,
                0.022101684571526427,
                0.0,
                0.056150223775571974,
                0.0,
                0.12028096024009033,
                0.12295335189324877,
                0.0,
                0.0,
                0.0,
                0.08935642105390958,
                0.05345476702277214,
                0.01667074679149634,
                0.0,
                0.04149340520305149,
                0.10916984165691547,
                0.0,
                0.0,
                0.0,
                0.03667466145033218,
                0.045178684152688456,
                0.0,
                0.07248125914055037,
                0.17543571710254144,
                0.0,
                0.0,
                0.02627419398833847,
                0.05772989172125203,
                0.0,
                0.035947861429879345,
                0.0,
                0.038309775409417005,
                0.0,
                0.12389575608912659,
                0.0,
                0.0,
                0.0,
                0.06383148486328492,
                0.1053954294299423,
                0.05890764568521474,
                0.0,
                0.0,
                0.06252733615898161,
                0.038285757841360096,
                0.04114957408552755,
                0.0,
                0.08572387990407233,
                0.04180098390922647,
                0.03182639632802686,
                0.05337430266081827,
                0.022720672090684346,
                0.08873461797748766,
                0.15584452035876867,
                0.0,
                1.0,
                0.0,
                0.12705705866848893,
                0.05062485889119061,
                0.156463978980435,
                0.0,
                0.0,
                0.028770008249152237,
                0.04879624198686287,
                0.06567748476078213,
                0.04410099097308936,
                0.11359297779959403,
                0.0,
                0.0,
                0.0,
                0.0,
                0.09546290069320655,
                0.05019369425331707,
                0.03158784947058665,
                0.0,
                0.08266802538279286,
                0.0,
                0.0,
                0.0,
                0.09350102634553882,
                0.020587300717855615,
                0.04028132927597526
            ],
            [
                0.0,
                0.1413806153263591,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.10694782458652954,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.18831273069604404,
                0.0,
                0.0,
                0.0,
                0.03660892351179485,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.13133416173019807,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.060391028018345574,
                0.0,
                0.0,
                0.17858559593529877,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.13737405998109198,
                0.0,
                0.0,
                0.0,
                0.1941391469986114,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.057416217417583425,
                0.09044840908681252,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.05572542738526803,
                0.10199429666266605,
                0.0400716118569038,
                0.0,
                0.020592879616889884,
                0.04613276927220659,
                0.0,
                0.12432496624662186,
                0.06832785226959351,
                0.144752656071594,
                0.0,
                0.0,
                0.22231875450357289,
                0.04075700881545991,
                0.0,
                0.10546817270006272,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.18364357095442288,
                0.0,
                0.035088417869667696,
                0.23851854782124932,
                0.0,
                0.15116834464974355,
                0.10465315150940796,
                0.0,
                0.0259662563751412,
                0.032587759219034104,
                0.0,
                0.08483116309724127,
                0.0,
                0.3561729505167161,
                0.0,
                0.0,
                0.0,
                0.24883159000308736,
                0.0,
                0.07421591653027437,
                0.0,
                0.0,
                0.09323995774655582,
                0.09731495644200326,
                0.0,
                0.0,
                0.09197548310687544,
                0.11874786016094618,
                0.10228904483582786,
                0.2796711288157397,
                0.07488008753517159,
                0.0,
                0.29520803201573936,
                0.0,
                0.12705705866848893,
                0.0,
                1.0,
                0.14577376072733106,
                0.09183180082230767,
                0.0,
                0.0,
                0.10539827998240892,
                0.16312439955011043,
                0.08905543568283608,
                0.05125699545432685,
                0.042003258970886456,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.17568691122677274,
                0.0,
                0.0,
                0.11358780230063296,
                0.0,
                0.0,
                0.0,
                0.3486637269733553,
                0.05033228609003731,
                0.0
            ],
            [
                0.0,
                0.0,
                0.1908009604658386,
                0.0,
                0.019095335975480163,
                0.07012488428097471,
                0.1248218828055438,
                0.12755789073722318,
                0.022748409393396157,
                0.1279498021192038,
                0.0591880737167926,
                0.18803654663837716,
                0.039599854284351206,
                0.040271730793646904,
                0.0,
                0.06239388982344334,
                0.213474624138537,
                0.016694385959587107,
                0.0,
                0.14994650686922323,
                0.07196627249228975,
                0.07390137300523915,
                0.15576639005890974,
                0.11147202938048739,
                0.04987636937860063,
                0.3730648950674266,
                0.0,
                0.0346175588390564,
                0.14455641327380062,
                0.07461927774942952,
                0.15173228970508018,
                0.16393107290879175,
                0.11357200280610233,
                0.08949669028783026,
                0.03599883560335056,
                0.022346468824926285,
                0.07923008053325162,
                0.13253936827438506,
                0.1609219223622877,
                0.27994760255185686,
                0.04281134709008092,
                0.0,
                0.06949171029806189,
                0.05912316882722407,
                0.023865536953236142,
                0.037820364726221335,
                0.0413030212046375,
                0.12655824404647895,
                0.13486016177150909,
                0.0,
                0.027000289779039767,
                0.20943437023995104,
                0.17474774139258692,
                0.08776484431619762,
                0.5063145404114048,
                0.09334582317622438,
                0.05309491105536313,
                0.32699960063206907,
                0.0,
                0.05062485889119061,
                0.13737405998109198,
                0.14577376072733106,
                1.0,
                0.06645963558115293,
                0.0629784539824795,
                0.07371669243562144,
                0.06532267028920259,
                0.21329239976359432,
                0.043071971485155645,
                0.0,
                0.023199944561004382,
                0.0,
                0.1123157383418093,
                0.0,
                0.06583599225144784,
                0.0440439675969864,
                0.1275827755144144,
                0.04295846739319645,
                0.05520199120078586,
                0.06522269098715058,
                0.07024222769485934,
                0.08354110505450918,
                0.0,
                0.18660058492802764,
                0.13211171602859423,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.04872896783928347,
                0.14022987000137502,
                0.02901479499449704,
                0.0,
                0.02982151966155441,
                0.0,
                0.1579032309421129,
                0.09234889892441485,
                0.0,
                0.11656681902362821,
                0.0,
                0.0,
                0.07017470101091114,
                0.021885132737057684,
                0.0,
                0.054471985684799246,
                0.14331670353027498,
                0.0,
                0.0,
                0.0,
                0.0,
                0.059309970449046893,
                0.0,
                0.01884129147180545,
                0.08545418667562268,
                0.0,
                0.0,
                0.03449240937948276,
                0.0,
                0.0,
                0.04719187021709005,
                0.07144121325912926,
                0.14304843410927126,
                0.06332093657264654,
                0.07241444751109764,
                0.0,
                0.0,
                0.0,
                0.03605461555386118,
                0.0,
                0.031285993107328755,
                0.05473566101540061,
                0.0,
                0.0,
                0.050261029261413494,
                0.0,
                0.0,
                0.0,
                0.054875770883862175,
                0.04178126612398472,
                0.07006906847602905,
                0.029827393505456563,
                0.0,
                0.0910878241163797,
                0.0,
                0.156463978980435,
                0.0,
                0.09183180082230767,
                0.06645963558115293,
                1.0,
                0.0,
                0.0,
                0.03776888085782185,
                0.18533820657395997,
                0.018566334673425448,
                0.0,
                0.03041344961348419,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.039645129346543524,
                0.0,
                0.0,
                0.15210028887466367,
                0.0,
                0.0,
                0.0,
                0.0723296769891213,
                0.027026732188015667,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.05891816201872889,
                0.0,
                0.0,
                0.0,
                0.0,
                0.09615906005339142,
                0.0,
                0.06690468769989219,
                0.0,
                0.0,
                0.04902969782050625,
                0.10003594786859957,
                0.08959445397905559,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.05086014647611904,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0633878045197896,
                0.0,
                0.0907538845337181,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.07649581182115923,
                0.05508135826903661,
                0.0,
                0.06639882337639876,
                0.03160821824023429,
                0.2754988942974337,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0629784539824795,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.03540235455692413,
                0.08336891514461477,
                0.0,
                0.0,
                0.08018580454819928,
                0.0,
                0.0,
                0.0,
                0.03779773849467359,
                0.0,
                0.0,
                0.14600895771661573,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.01936314321433945,
                0.0,
                0.0,
                0.07590241728503368,
                0.0,
                0.0,
                0.05565277183851258,
                0.0173534754489334,
                0.0,
                0.0,
                0.0,
                0.01718464658696458,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.08146456975481445,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.012248848516165667,
                0.028059143709315917,
                0.044086619640639556,
                0.0,
                0.014142458553226666,
                0.03883996787253569,
                0.0,
                0.0,
                0.019503348183231746,
                0.05552589720732896,
                0.06400170597259078,
                0.02673021786814372,
                0.0,
                0.0,
                0.0,
                0.0,
                0.1303690434983827,
                0.016138606133927206,
                0.017624716107001066,
                0.03677216747014886,
                0.013324614799903026,
                0.0,
                0.011521492333565845,
                0.022530712888883753,
                0.04555169570486479,
                0.012311575028371774,
                0.0386066693987075,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.07371669243562144,
                0.0,
                0.0,
                1.0,
                0.0,
                0.07105397706472757,
                0.0,
                0.0,
                0.0,
                0.056660619292255424,
                0.04662291723323013,
                0.0,
                0.02809336070854321,
                0.0,
                0.021020503757991187,
                0.0,
                0.0,
                0.10369134264886028,
                0.029973577857936973,
                0.2831983131345959,
                0.0,
                0.04037549281495995,
                0.06329831126043763,
                0.0
            ],
            [
                0.0,
                0.05193482937790414,
                0.03811365661675679,
                0.0,
                0.02662034700686726,
                0.146321727682257,
                0.023894552282583692,
                0.08903308454047117,
                0.0,
                0.09418273073882419,
                0.06389874556632737,
                0.040034014966426675,
                0.0,
                0.0,
                0.0,
                0.10643042629061492,
                0.20521766517505732,
                0.0,
                0.0,
                0.1265911181741167,
                0.0,
                0.0,
                0.04792333555107574,
                0.0,
                0.04350932917857552,
                0.1560864810361126,
                0.0,
                0.04958476394009215,
                0.043135011962277765,
                0.0,
                0.13977256695287038,
                0.249657590963697,
                0.0,
                0.0,
                0.13222010088725733,
                0.0,
                0.07306715817142,
                0.0,
                0.32342487793342967,
                0.0,
                0.0,
                0.1647734670410053,
                0.09029996279967142,
                0.0,
                0.0,
                0.0,
                0.03977729941350885,
                0.041495633366904955,
                0.10719695514792807,
                0.0,
                0.046152110910846075,
                0.0,
                0.22078931724742623,
                0.17333232401129192,
                0.23778080917729869,
                0.07591125922857209,
                0.0,
                0.2507338878161528,
                0.0,
                0.028770008249152237,
                0.1941391469986114,
                0.10539827998240892,
                0.06532267028920259,
                0.03776888085782185,
                0.0,
                0.0,
                1.0,
                0.027770131209193468,
                0.015289932416694676,
                0.0,
                0.025046386232298105,
                0.0,
                0.0,
                0.039902311226314956,
                0.0,
                0.0,
                0.2136154119112201,
                0.04146442698165689,
                0.023757181523374884,
                0.09883764752633056,
                0.0,
                0.0,
                0.17936329060768852,
                0.19503948591364834,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.04373791722319365,
                0.0,
                0.06804346228845805,
                0.12606466886477646,
                0.02133355941994148,
                0.0,
                0.02192671572600757,
                0.0391984330394297,
                0.0,
                0.067900901003913,
                0.0,
                0.3949088195432376,
                0.0,
                0.0,
                0.09098313404030212,
                0.14485428836034162,
                0.0,
                0.04005133737974944,
                0.0,
                0.07123198680070938,
                0.0,
                0.0,
                0.0,
                0.04360853761019821,
                0.05555866802701218,
                0.013853339692333945,
                0.1251711200341275,
                0.03169032246796871,
                0.2652787585741322,
                0.06839638617404942,
                0.03194531356228346,
                0.08626398674403453,
                0.13416493867896476,
                0.03795159625289616,
                0.26607376114944936,
                0.21643893559252625,
                0.1255280685311244,
                0.06037883640756232,
                0.0,
                0.04447035790816026,
                0.1353509485099125,
                0.06608750054789847,
                0.02300349160122154,
                0.15111157755396218,
                0.24359059253753804,
                0.19983687792333626,
                0.0952625439951691,
                0.0,
                0.026025014244587048,
                0.16236806489997538,
                0.14151903296007398,
                0.15985796506210612,
                0.13652566261478782,
                0.021931034557070614,
                0.0,
                0.06697367700128566,
                0.0,
                0.04879624198686287,
                0.0,
                0.16312439955011043,
                0.21329239976359432,
                0.18533820657395997,
                0.0,
                0.07105397706472757,
                0.027770131209193468,
                1.0,
                0.013651173618189044,
                0.0,
                0.022361941024147094,
                0.0,
                0.052656463676328626,
                0.0,
                0.06345793508781324,
                0.03604129679163543,
                0.07663127248613097,
                0.03515302906402837,
                0.0,
                0.18134508227402676,
                0.09943341339464491,
                0.08052352277863091,
                0.05749587253054675,
                0.20152614534433974,
                0.32727356682625797,
                0.0
            ],
            [
                0.0,
                0.0,
                0.030177485976211275,
                0.0,
                0.07412403778514752,
                0.021189549056388382,
                0.039550780108699064,
                0.0,
                0.0,
                0.04828065288500973,
                0.05867239894995628,
                0.019679823794240603,
                0.0,
                0.04171960107478713,
                0.036712445224505445,
                0.043587576739912114,
                0.05395219877723875,
                0.030068268078348163,
                0.0,
                0.08181813618366786,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.02588629503522522,
                0.009352192393636662,
                0.02215220362265793,
                0.0,
                0.0,
                0.07442911368860272,
                0.031704857425377424,
                0.0,
                0.01185930096383193,
                0.040888804421297345,
                0.0,
                0.015431733174665096,
                0.10397510276165747,
                0.0,
                0.026676379008080005,
                0.014595948373574292,
                0.07831186163989133,
                0.04298423222517714,
                0.0,
                0.0,
                0.0,
                0.020347114427177255,
                0.0,
                0.02268734253157944,
                0.0,
                0.03272363096623739,
                0.0,
                0.12413443570411073,
                0.05304790472671509,
                0.07265124331481516,
                0.01941108501876478,
                0.08078254940534839,
                0.06567748476078213,
                0.0,
                0.08905543568283608,
                0.043071971485155645,
                0.018566334673425448,
                0.03540235455692413,
                0.0,
                0.015289932416694676,
                0.013651173618189044,
                1.0,
                0.031829312068708863,
                0.01231224168116746,
                0.0,
                0.0,
                0.03195443626020457,
                0.0,
                0.0,
                0.2448934786396095,
                0.0,
                0.0,
                0.03303037212785088,
                0.0,
                0.0,
                0.0,
                0.09165267184084747,
                0.037132378335313285,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.021327265915358086,
                0.06370087586994574,
                0.0,
                0.0,
                0.04184333181860327,
                0.0,
                0.0,
                0.0,
                0.0,
                0.05245639424361138,
                0.23931939696676083,
                0.0,
                0.06015221897840899,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.04589904989591514,
                0.0,
                0.0,
                0.0,
                0.06655263049762919,
                0.0,
                0.06728753742575573,
                0.0,
                0.12658005992932592,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.10386856022443597,
                0.0,
                0.04389817171363616,
                0.0,
                0.0,
                0.0,
                0.08729981722108125,
                0.05149948982365257,
                0.0,
                0.10728509781384266,
                0.049522179059997735,
                0.0,
                0.0,
                0.028418105374505443,
                0.070285388962023,
                0.0,
                0.0,
                0.04410099097308936,
                0.0,
                0.05125699545432685,
                0.0,
                0.0,
                0.08336891514461477,
                0.0,
                0.0,
                0.0,
                0.031829312068708863,
                1.0,
                0.038393122573110026,
                0.0,
                0.0,
                0.0,
                0.0,
                0.04053174462244444,
                0.09108911469629587,
                0.039532806074259776,
                0.0,
                0.03921832391543736,
                0.0,
                0.0,
                0.13308091415185197,
                0.10968766782148391,
                0.0,
                0.05041286460996164
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.033567407755783894,
                0.019416789347735178,
                0.12862949023571235,
                0.11521229897775749,
                0.08579671785120528,
                0.0,
                0.0,
                0.03223745235105988,
                0.08792253426443754,
                0.0554312925364697,
                0.0,
                0.07779126841640797,
                0.046536265447519105,
                0.0,
                0.0,
                0.07299048775469665,
                0.0,
                0.0,
                0.0,
                0.0,
                0.031927962191351175,
                0.0,
                0.0,
                0.0,
                0.11462631215056307,
                0.03628744932997851,
                0.0562760376508231,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.06634739878425136,
                0.025278669571123194,
                0.06824160071350564,
                0.0,
                0.0,
                0.11723350737144915,
                0.0,
                0.030536125909376453,
                0.0,
                0.0,
                0.0,
                0.17836306077375685,
                0.035823699350905056,
                0.0,
                0.21221666546309448,
                0.01915621160295708,
                0.0,
                0.024459937071127907,
                0.0,
                0.0,
                0.03179723227796048,
                0.0,
                0.11359297779959403,
                0.0,
                0.042003258970886456,
                0.023199944561004382,
                0.03041344961348419,
                0.0,
                0.0,
                0.025046386232298105,
                0.022361941024147094,
                0.01231224168116746,
                0.038393122573110026,
                1.0,
                0.0,
                0.136476462254703,
                0.04513688606121916,
                0.0,
                0.1436055041054798,
                0.07052968347818016,
                0.027499522114711922,
                0.030813204307840392,
                0.04886930776363938,
                0.0,
                0.0,
                0.0,
                0.05868319151517581,
                0.0,
                0.1786146859246206
            ],
            [
                0.0,
                0.16045067347317066,
                0.0,
                0.02816966697215738,
                0.0,
                0.0,
                0.0,
                0.0,
                0.06290331403773002,
                0.0,
                0.0,
                0.0,
                0.051531998037889826,
                0.056453870873675156,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.08714129699759991,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.11000687140291691,
                0.0,
                0.0,
                0.0723399621752234,
                0.0,
                0.0,
                0.053419552038597454,
                0.06280110281683064,
                0.07205803738799564,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.14847887653462624,
                0.0,
                0.0,
                0.05031587965393618,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.056660619292255424,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.06547438460370054,
                0.0,
                0.0,
                0.30913963787668525,
                0.04271508269315827,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0941902732877012,
                0.08302750546671797,
                0.053966916376008665,
                0.0,
                0.06707640215070428,
                0.05383413646689863,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.04490943898384221,
                0.09162932868651535,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.04186100046331344,
                0.19715035574719517,
                0.0,
                0.0,
                0.03846149227677423,
                0.0,
                0.0,
                0.029096742074255267,
                0.11304577385286504,
                0.0,
                0.18307319858722282,
                0.18491036054767848,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.15431111318902097,
                0.045107817758661996,
                0.0,
                0.1184156231371179,
                0.0,
                0.06760182080007539,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.1123157383418093,
                0.0,
                0.08018580454819928,
                0.04662291723323013,
                0.0,
                0.052656463676328626,
                0.0,
                0.0,
                0.136476462254703,
                0.0,
                1.0,
                0.06610699222641317,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0480389725060703,
                0.0,
                0.03514789972099554,
                0.0,
                0.0,
                0.04690891861861408,
                0.10003157516571347
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.013921563383818124,
                0.0,
                0.049937234977327986,
                0.0,
                0.0,
                0.03457778109054249,
                0.1053754101195176,
                0.0,
                0.04030026224233222,
                0.0,
                0.0,
                0.07828312558008348,
                0.11818574097007659,
                0.0,
                0.0,
                0.0721586821192029,
                0.0,
                0.0,
                0.0,
                0.0,
                0.11352631131599557,
                0.0,
                0.08558097588832127,
                0.04841474597651399,
                0.0,
                0.0,
                0.14758685769328506,
                0.0,
                0.0,
                0.0,
                0.05541659770218853,
                0.12565347262372736,
                0.01968589439890159,
                0.0,
                0.08812548310105732,
                0.07481955656853269,
                0.06786807336201589,
                0.026993713926450034,
                0.0,
                0.0,
                0.0,
                0.0,
                0.03511824343914338,
                0.10827209430260162,
                0.0,
                0.0,
                0.0,
                0.06306487870150207,
                0.030518459238349147,
                0.08605000648241062,
                0.0634818191770468,
                0.2054685772068824,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.039902311226314956,
                0.0,
                0.03195443626020457,
                0.0,
                0.04513688606121916,
                0.0,
                0.06610699222641317,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.03596199952119993,
                0.11678455934761472,
                0.0,
                0.04047322009186438,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.08876789633248985,
                0.026543870156487823,
                0.018018468352358943,
                0.0416111344982887,
                0.04322568897973829,
                0.0,
                0.0,
                0.11364062848686347,
                0.0,
                0.0,
                0.05715788546336642,
                0.030496129575230138,
                0.0,
                0.0,
                0.05758899610868465,
                0.03992517719912814,
                0.0,
                0.0,
                0.08278706845510997,
                0.05596247796011594,
                0.0,
                0.0,
                0.0,
                0.0,
                0.06799328855050626,
                0.0,
                0.05965372233512475,
                0.0,
                0.07823677131158921,
                0.0,
                0.07408868778654391,
                0.023175567725953878,
                0.0,
                0.12497762377142682,
                0.0,
                0.033131958180190775,
                0.0,
                0.04743584242805371,
                0.0,
                0.03493755454661981,
                0.0,
                0.0,
                0.0,
                0.07026023840828007,
                0.11541686973287248,
                0.12894816193091654,
                0.08725731077110616,
                0.0,
                0.13045262504797064,
                0.03998333839480332,
                0.13979915800980006,
                0.07072417743153052,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.06583599225144784,
                0.0,
                0.0,
                0.02809336070854321,
                0.0,
                0.06345793508781324,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.037303298796180974,
                0.0,
                0.03736162945357738,
                0.02280002476522079,
                0.12473797029291521,
                0.08369999517131749,
                0.0,
                0.07165095041772884,
                0.056531390543753925,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.06050820388746659,
                0.020498367793126637,
                0.03652834120722135,
                0.0,
                0.030728094184339496,
                0.04120440332734767,
                0.0,
                0.0,
                0.0,
                0.03464090205570275,
                0.0,
                0.1393874322160236,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.10230514193672646,
                0.17223623202267607,
                0.0,
                0.0,
                0.0,
                0.09856206272477243,
                0.0,
                0.044435021261853426,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.18606149880592357,
                0.0,
                0.0,
                0.0,
                0.0,
                0.08872720381387872,
                0.0,
                0.03223708763882909,
                0.07921998243631617,
                0.0,
                0.07412553090708206,
                0.21709631166928828,
                0.03781919615309096,
                0.0,
                0.0787859486068496,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.1339130229498377,
                0.0,
                0.09546290069320655,
                0.0,
                0.0,
                0.0440439675969864,
                0.0,
                0.0,
                0.0,
                0.0,
                0.03604129679163543,
                0.0,
                0.04053174462244444,
                0.1436055041054798,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.01837625308323336,
                0.1019283552379045,
                0.0,
                0.051797617321322,
                0.030210448890563367,
                0.0,
                0.0,
                0.035296503017722074,
                0.03210732624394159,
                0.03702122141116259
            ],
            [
                0.0,
                0.03534848539909246,
                0.02571102562101421,
                0.0,
                0.02106027052612263,
                0.1936069881301794,
                0.05068001350520504,
                0.033175442243204005,
                0.018970899538298527,
                0.02304252191610868,
                0.0,
                0.0754273869111088,
                0.0,
                0.07729327848794544,
                0.03919647214042388,
                0.0,
                0.08793362431872583,
                0.06420547718009688,
                0.0,
                0.28981796398908005,
                0.0,
                0.04187322017010889,
                0.06310670277729977,
                0.0,
                0.02080967806898277,
                0.0,
                0.0,
                0.055275612177950025,
                0.06640796749295927,
                0.023651059656601914,
                0.08904645506448436,
                0.0,
                0.10991263014737164,
                0.01734082702070053,
                0.0,
                0.0,
                0.06824636501121471,
                0.024790570934595087,
                0.16320875801555723,
                0.16855813085185287,
                0.0,
                0.0,
                0.11240201556319773,
                0.10022165410850399,
                0.30361409489266744,
                0.02142937803040025,
                0.02340268428395575,
                0.048827307090569164,
                0.16219236595131378,
                0.023348801475789174,
                0.015298620750852913,
                0.0785578701034523,
                0.16646956063829066,
                0.01634771883291594,
                0.2367761576801271,
                0.17981539919433775,
                0.031865938849925994,
                0.04144894454731392,
                0.3556665944875052,
                0.05019369425331707,
                0.0,
                0.17568691122677274,
                0.1275827755144144,
                0.039645129346543524,
                0.03779773849467359,
                0.021020503757991187,
                0.2136154119112201,
                0.07663127248613097,
                0.2448934786396095,
                0.09108911469629587,
                0.07052968347818016,
                0.0,
                0.0,
                0.0,
                0.037303298796180974,
                0.01837625308323336,
                1.0,
                0.01792335504622476,
                0.020083112667104285,
                0.30330453768771887,
                0.039799913667331294,
                0.03169370781646804,
                0.0,
                0.38381312074514484,
                0.12158853914368115,
                0.022856148121747518
            ],
            [
                0.0,
                0.11168911538573899,
                0.0,
                0.0,
                0.01373688575085492,
                0.019993168474563817,
                0.03562806986501691,
                0.04128232267749398,
                0.029970774752893458,
                0.04018888654606796,
                0.0,
                0.0,
                0.0,
                0.033787148220784706,
                0.0,
                0.05585164394234836,
                0.03852051874372558,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.09978374664742752,
                0.0775223651343809,
                0.07237323640964405,
                0.0,
                0.07509900316428414,
                0.06570910137216417,
                0.0,
                0.04333988321533345,
                0.04208950501002392,
                0.0,
                0.0,
                0.05758607454995932,
                0.0635537225485412,
                0.0,
                0.036707424760818945,
                0.0,
                0.0,
                0.0,
                0.02805047742018701,
                0.10255206596847186,
                0.0,
                0.031442577808975844,
                0.031730502851160414,
                0.0,
                0.07229864556282935,
                0.057056301098555355,
                0.03688711061740545,
                0.0,
                0.07684420339326963,
                0.10358895173432868,
                0.0,
                0.11205560851466372,
                0.08252092975207975,
                0.0,
                0.05887774267799902,
                0.0,
                0.03158784947058665,
                0.0,
                0.0,
                0.04295846739319645,
                0.0,
                0.0,
                0.0,
                0.04146442698165689,
                0.03515302906402837,
                0.0,
                0.039532806074259776,
                0.027499522114711922,
                0.06547438460370054,
                0.0,
                0.0,
                0.0,
                0.1019283552379045,
                0.01792335504622476,
                1.0,
                0.0,
                0.050521021972950705,
                0.029465887257802192,
                0.0,
                0.0,
                0.03442659135196579,
                0.031316014491561364,
                0.2129551139687464
            ],
            [
                0.0,
                0.0,
                0.057623725184948314,
                0.022807658481081232,
                0.0,
                0.0,
                0.029396165758163742,
                0.06175010529026468,
                0.0,
                0.05165313782354007,
                0.038511913033728765,
                0.0,
                0.17310413633014576,
                0.0,
                0.0,
                0.0,
                0.055375045914809434,
                0.034305464914723374,
                0.07670445653929217,
                0.05343774455581727,
                0.0,
                0.0,
                0.028883498645735764,
                0.0,
                0.0,
                0.0414664868172099,
                0.0,
                0.051049382353182,
                0.014531243584475077,
                0.027159866833797317,
                0.0,
                0.06049382144524374,
                0.07355119851262912,
                0.0,
                0.0,
                0.025956687082853667,
                0.07053520275280464,
                0.0,
                0.023977508615440846,
                0.04783675721649899,
                0.027856065799319926,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.07638249112002939,
                0.0,
                0.0,
                0.0,
                0.018170189987918046,
                0.0,
                0.023200918474209523,
                0.0,
                0.0,
                0.030160543407826784,
                0.0,
                0.0,
                0.0,
                0.0,
                0.05520199120078586,
                0.0,
                0.0,
                0.0,
                0.023757181523374884,
                0.0,
                0.0,
                0.0,
                0.030813204307840392,
                0.0,
                0.0,
                0.0,
                0.03736162945357738,
                0.0,
                0.020083112667104285,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.023949439825428853,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.015714750164625264,
                0.0,
                0.05882415991945388,
                0.16294421285454128,
                0.05486662882006975,
                0.0,
                0.01575625367831856,
                0.01408374292072547,
                0.17534225747008292,
                0.04879270724229204,
                0.029285603907317003,
                0.19441239679359032,
                0.0,
                0.0,
                0.03707692979689155,
                0.011563049338270421,
                0.0,
                0.14084444620727654,
                0.07572163869551385,
                0.15540159418629768,
                0.06893430965770413,
                0.0,
                0.0,
                0.031336529816537534,
                0.0,
                0.009954830318041305,
                0.0758128562479994,
                0.04024416190227157,
                0.18497825549186275,
                0.018224126681920305,
                0.047823319755149,
                0.010598829011922644,
                0.10367879521868427,
                0.013635762544877842,
                0.044276190157042906,
                0.10541359665934807,
                0.11787426035619741,
                0.07606398858694066,
                0.0,
                0.0,
                0.09312736379396523,
                0.0,
                0.2099746383534514,
                0.09112125002353051,
                0.014303876559610363,
                0.14172762754979343,
                0.11563797167390598,
                0.05558979741400191,
                0.009350618933167309,
                0.06411380170896842,
                0.14111776714189708,
                0.03206704195469645,
                0.11405651640432546,
                0.050380387885975805,
                0.1230949973050573,
                0.04812641609387834,
                0.13392501257490388,
                0.08266802538279286,
                0.0,
                0.11358780230063296,
                0.06522269098715058,
                0.15210028887466367,
                0.14600895771661573,
                0.10369134264886028,
                0.09883764752633056,
                0.18134508227402676,
                0.03303037212785088,
                0.03921832391543736,
                0.04886930776363938,
                0.0,
                0.0480389725060703,
                0.03596199952119993,
                0.02280002476522079,
                0.051797617321322,
                0.30330453768771887,
                0.050521021972950705,
                0.0,
                1.0,
                0.06992520653624075,
                0.05004227909297866,
                0.0,
                0.22873219951008641,
                0.08859534791153502,
                0.0
            ],
            [
                0.0,
                0.31184231891320163,
                0.03666189150989827,
                0.023594131755257066,
                0.012398630215202345,
                0.044396061851804676,
                0.0,
                0.0,
                0.0,
                0.07705156130963071,
                0.0,
                0.0,
                0.0,
                0.11031693865183653,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0597079042149101,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0231917902196936,
                0.1050675024534704,
                0.12259064549961268,
                0.0,
                0.026777123704671033,
                0.024726649504219867,
                0.0,
                0.11727043724876425,
                0.03262984715755798,
                0.06848076156479324,
                0.0,
                0.05061060266249032,
                0.0,
                0.04474273516798173,
                0.052600461897553935,
                0.0,
                0.0,
                0.05919589876543631,
                0.07825590312901248,
                0.13487915157508734,
                0.08280856233511528,
                0.13946346013391914,
                0.12929958606690042,
                0.042659321496998054,
                0.1101491376067381,
                0.023310555678371384,
                0.0,
                0.11956863692690237,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.07024222769485934,
                0.0,
                0.0,
                0.029973577857936973,
                0.0,
                0.09943341339464491,
                0.0,
                0.0,
                0.0,
                0.30913963787668525,
                0.0,
                0.11678455934761472,
                0.12473797029291521,
                0.030210448890563367,
                0.039799913667331294,
                0.029465887257802192,
                0.0,
                0.06992520653624075,
                1.0,
                0.0451927237225448,
                0.0,
                0.076446366215199,
                0.08858008250556373,
                0.0
            ],
            [
                0.0,
                0.03343967605423698,
                0.029194819044733835,
                0.0,
                0.04112699205954334,
                0.03535374031948972,
                0.0,
                0.0,
                0.08817777126616948,
                0.026164738334097222,
                0.0,
                0.0,
                0.0378666341594286,
                0.025910186269892173,
                0.0,
                0.0,
                0.0,
                0.03392131370428358,
                0.0,
                0.0,
                0.0,
                0.08518766597049136,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.01846822656721296,
                0.021153115846837614,
                0.066471691525233,
                0.044540170495286024,
                0.021323320999006818,
                0.039125758255192995,
                0.0,
                0.03668622499886484,
                0.04068710380257355,
                0.05593446519230646,
                0.04824935197092149,
                0.04030254102076004,
                0.052500963098769476,
                0.0,
                0.0,
                0.0,
                0.04401562861963608,
                0.024333016623319412,
                0.026573701994707637,
                0.10955721074532629,
                0.020090215396220825,
                0.07295837934154607,
                0.05128159616625581,
                0.03397072874267087,
                0.04588687200029596,
                0.0455389511180862,
                0.029104642633135093,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.057416217417583425,
                0.0,
                0.08354110505450918,
                0.0,
                0.0,
                0.2831983131345959,
                0.0,
                0.08052352277863091,
                0.0,
                0.0,
                0.0,
                0.04271508269315827,
                0.03514789972099554,
                0.0,
                0.08369999517131749,
                0.0,
                0.03169370781646804,
                0.0,
                0.0,
                0.05004227909297866,
                0.0451927237225448,
                1.0,
                0.0,
                0.06087623241363909,
                0.11362488152176414,
                0.0
            ],
            [
                0.0,
                0.0526778954713561,
                0.0,
                0.0,
                0.01599411540811404,
                0.03770164411518182,
                0.0,
                0.0,
                0.0,
                0.039725496775848676,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.042587949167121296,
                0.041475921898311056,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.04413184604536232,
                0.0,
                0.16144028002007085,
                0.0,
                0.03938946765933925,
                0.0,
                0.07088619294510488,
                0.07016462844381442,
                0.0,
                0.0,
                0.06366666118864758,
                0.0,
                0.054387489927227965,
                0.0,
                0.06499521494282025,
                0.0,
                0.0,
                0.07777345751273111,
                0.061475065120503346,
                0.0,
                0.0,
                0.0,
                0.14152450283718773,
                0.042089338950433444,
                0.0,
                0.0,
                0.0,
                0.18531670739343745,
                0.03506184942585879,
                0.11027061128779954,
                0.0,
                0.0,
                0.0,
                0.08175540807945282,
                0.0,
                0.0,
                0.09044840908681252,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.17936329060768852,
                0.05749587253054675,
                0.0,
                0.13308091415185197,
                0.0,
                0.0,
                0.0,
                0.04047322009186438,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.06491912959678728,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.08780698975745406,
                0.0,
                0.056055884182811495,
                0.1668856339871395,
                0.024087922276649253,
                0.03956225665093407,
                0.06119634101849953,
                0.04425931884285688,
                0.06441585506914754,
                0.07666754495585239,
                0.0,
                0.14846238920645985,
                0.0,
                0.0,
                0.15088014279204495,
                0.09022164289219037,
                0.0,
                0.04522234114282219,
                0.0,
                0.08042870521001415,
                0.04831116182216548,
                0.0,
                0.03997054575994314,
                0.20215017875868577,
                0.06273181380027293,
                0.06421804648076974,
                0.3114335440188437,
                0.0,
                0.17103750452635796,
                0.11756280890192651,
                0.03606975352983943,
                0.03330769066433956,
                0.039178429559629184,
                0.0,
                0.12159196083733374,
                0.047616913950883945,
                0.22532006941113916,
                0.06817431118317673,
                0.0,
                0.0,
                0.18596575523480294,
                0.0,
                0.12745373011797298,
                0.04116084508044019,
                0.044951106882888996,
                0.09378588683250076,
                0.0757103054009197,
                0.04484761055573021,
                0.029385087974879636,
                0.2229009950081997,
                0.24642362839350387,
                0.16429518806215493,
                0.36948145602737686,
                0.14392987913399155,
                0.0,
                0.1260677820188321,
                0.0,
                0.09350102634553882,
                0.0,
                0.3486637269733553,
                0.18660058492802764,
                0.0723296769891213,
                0.0,
                0.04037549281495995,
                0.19503948591364834,
                0.20152614534433974,
                0.09165267184084747,
                0.10968766782148391,
                0.05868319151517581,
                0.0,
                0.0,
                0.0,
                0.07165095041772884,
                0.035296503017722074,
                0.38381312074514484,
                0.03442659135196579,
                0.023949439825428853,
                0.22873219951008641,
                0.076446366215199,
                0.06087623241363909,
                0.06491912959678728,
                1.0,
                0.1417580165299906,
                0.04390133818350825
            ],
            [
                0.0,
                0.0,
                0.038963847101126124,
                0.0,
                0.034119633369343136,
                0.06021413340263207,
                0.0,
                0.0,
                0.08122259816289233,
                0.034919855551378436,
                0.0,
                0.028647621436856726,
                0.0,
                0.06699049142726805,
                0.0,
                0.0,
                0.0,
                0.2654296022027722,
                0.0,
                0.05447155878372832,
                0.0,
                0.06345689092256268,
                0.0,
                0.0,
                0.0,
                0.1047709938327148,
                0.0,
                0.16876767277812874,
                0.1347937536022642,
                0.028231268373532164,
                0.19474928024198038,
                0.06093080106114496,
                0.08180398030343006,
                0.052217828787877035,
                0.11952060109179194,
                0.0,
                0.17141904805597158,
                0.10986262721353655,
                0.02246374026132117,
                0.1546151404836984,
                0.0,
                0.03961634060496744,
                0.0,
                0.1348145301046768,
                0.09004072060847837,
                0.06291273727345664,
                0.1477717053870621,
                0.1433480495048222,
                0.05194302303555383,
                0.0,
                0.023184338446115803,
                0.04533784842492507,
                0.10715089030972987,
                0.13458353101418885,
                0.06057967476391525,
                0.10241930416326184,
                0.0,
                0.02825642247157489,
                0.05124646309318392,
                0.020587300717855615,
                0.0,
                0.05033228609003731,
                0.13211171602859423,
                0.027026732188015667,
                0.0,
                0.06329831126043763,
                0.0,
                0.32727356682625797,
                0.037132378335313285,
                0.0,
                0.0,
                0.0,
                0.04690891861861408,
                0.0,
                0.056531390543753925,
                0.03210732624394159,
                0.12158853914368115,
                0.031316014491561364,
                0.0,
                0.08859534791153502,
                0.08858008250556373,
                0.11362488152176414,
                0.0,
                0.1417580165299906,
                1.0,
                0.0
            ],
            [
                0.0,
                0.07121387034569454,
                0.0,
                0.0,
                0.0,
                0.025495607206304578,
                0.0,
                0.08444582717640788,
                0.11265711229336782,
                0.0,
                0.0,
                0.0,
                0.06718372764644817,
                0.0,
                0.0,
                0.1259341289646825,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.04192365526298419,
                0.0,
                0.0,
                0.0,
                0.026636992074930567,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.13077602959499074,
                0.0,
                0.0400960765369035,
                0.0,
                0.0,
                0.0,
                0.0,
                0.047039031580880734,
                0.0,
                0.2031270988690062,
                0.0,
                0.0,
                0.0,
                0.04589594470116847,
                0.0,
                0.0,
                0.08130265016616128,
                0.04028132927597526,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.05041286460996164,
                0.1786146859246206,
                0.0,
                0.10003157516571347,
                0.0,
                0.0,
                0.03702122141116259,
                0.022856148121747518,
                0.2129551139687464,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.04390133818350825,
                0.0,
                1.0
            ]
        ]
    },
    "P87-1015": {
        "input_sentences": [
            "We consider the structural descriptions produced by various grammatical formalisms in terms of the complexity of the paths and the relationship between paths in the sets of structural descriptions that each system can generate.",
            "In considering the relationship between formalisms, we show that it is useful to abstract away from the details of the formalism, and examine the nature of their derivation process as reflected by properties their trees. find that several of the formalisms considered can be seen as being closely related since they have derivation tree sets with the same structure as those produced by Context-Free Grammars On the basis of this observation, we describe a class of formalisms which we call Linear Context- Free Rewriting Systems, and show they are recognizable in polynomial time and generate only semilinear languages.",
            "Abstract",
            "CHARACTERIZING STRUCTURAL DESCRIPTIONS PRODUCED BY VARIOUS GRAMMATICAL FORMALISMS*"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.1270909128320098,
                0.0,
                0.5495946540701895
            ],
            [
                0.1270909128320098,
                1.0,
                0.11432201079877596,
                0.11393957122021557
            ],
            [
                0.0,
                0.11432201079877596,
                1.0,
                0.0
            ],
            [
                0.5495946540701895,
                0.11393957122021557,
                0.0,
                1.0
            ]
        ]
    },
    "D09-1034": {
        "input_sentences": [
            "We also present an approximation to entropy measures that would otherwise be intractable to calculate for a grammar of that size.",
            "In this paper, we present novel methods for calculating separate lexical and syntactic surprisal measures from a single incremental parser using a lexicalized PCFG.",
            "Empirical results demonstrate the utility of our methods in predicting human reading times.",
            "Abstract",
            "A number of recent publications have made use of the incremental output of stochastic parsers to derive measures of high utility for psycholinguistic modeling, following the work of Hale (2001; 2003; 2006).",
            "Deriving lexical and syntactic expectation-based measures for psycholinguistic modeling via incremental top-down parsing"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.1051122885769276,
                0.0,
                0.0,
                0.031432848950392236,
                0.048422658993676065
            ],
            [
                0.1051122885769276,
                1.0,
                0.06330384934181253,
                0.0,
                0.053509202714855576,
                0.21579382168927755
            ],
            [
                0.0,
                0.06330384934181253,
                1.0,
                0.0,
                0.05509758013196887,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.031432848950392236,
                0.053509202714855576,
                0.05509758013196887,
                0.0,
                1.0,
                0.18781981674304835
            ],
            [
                0.048422658993676065,
                0.21579382168927755,
                0.0,
                0.0,
                0.18781981674304835,
                1.0
            ]
        ]
    },
    "W05-0638": {
        "input_sentences": [
            "Exploiting Full Parsing Information To Label Semantic Roles Using An Ensemble Of ME And SVM Via Integer Linear Programming",
            "The experimental results show that full parsing information not only increases the F-score of argument classification models by 0.7%, but also effectively removes all labeling inconsistencies, which increases the F-score by 0.64%.",
            "Our system achieves an F-score of 76.53% in the development set and 76.38% in Test WSJ.",
            "In this paper, we propose a method that exploits full parsing information by representing it as features of argument classification models and as constraints in integer linear learning programs.",
            "In addition, to take advantage of SVM-based and Maximum Entropy-based argument classification models, we incorporate their scoring matrices, and use the combined matrix in the above-mentioned integer linear programs.",
            "Abstract",
            "The ensemble of SVM and ME also boosts the F-score by 0.77%."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.08420401873412922,
                0.0,
                0.18991033400291968,
                0.11507728502249547,
                0.0,
                0.20443180164813776
            ],
            [
                0.08420401873412922,
                1.0,
                0.07532851983153278,
                0.18276823787870936,
                0.08859959186045825,
                0.0,
                0.1328962085466801
            ],
            [
                0.0,
                0.07532851983153278,
                1.0,
                0.0,
                0.0,
                0.0,
                0.07720885213126388
            ],
            [
                0.18991033400291968,
                0.18276823787870936,
                0.0,
                1.0,
                0.21210273347579547,
                0.0,
                0.0
            ],
            [
                0.11507728502249547,
                0.08859959186045825,
                0.0,
                0.21210273347579547,
                1.0,
                0.0,
                0.060540795634403906
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.20443180164813776,
                0.1328962085466801,
                0.07720885213126388,
                0.0,
                0.060540795634403906,
                0.0,
                1.0
            ]
        ]
    },
    "W12-3145": {
        "input_sentences": [
            "KenLM: Faster and smaller model queries.",
            "Kriya - The SFU System for Translation Task at WMT-12",
            "models for morpheme segmentation and morphology Transactions on Speech and Language 4(1):3:1\u20133:34, February.",
            "In of the Sixth on Statistical Machine pages 187\u2013197.",
            "2011.",
            "Abstract",
            "Kenneth Heafield."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P04-1036": {
        "input_sentences": [
            "Furthermore, we demonstrate that our method discovers appropriate predominant senses for words from two domainspecific corpora.",
            "This is a very promising result given that our method does not require any hand-tagged text, such as SemCor.",
            "We present work on the use of a thesaurus acquired from raw textual corpora and the WordNet similarity package to find predominant noun senses automatically.",
            "The acquired predominant senses give a of 64% on the nouns of the 2 English all-words task.",
            "Whilst there are a few hand-tagged corpora available for some languages, one would expect the frequency distribution of the senses of words, particularly topical words, to depend on the genre and domain of the text under consideration.",
            "word sense disambiguation the heuristic of choosing the most common sense is extremely powerful because the distribution of the senses of a word is often skewed.",
            "Abstract",
            "The problem with using the predominant, or first sense heuristic, aside from the fact that it does not take surrounding context into account, is that it assumes some quantity of handtagged data.",
            "Finding Predominant Word Senses in Untagged Text"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.09053623944518177,
                0.11738372283221297,
                0.1739064811577693,
                0.17015623956699327,
                0.02714543376969908,
                0.0,
                0.03357547080922753,
                0.11334467476973316
            ],
            [
                0.09053623944518177,
                1.0,
                0.0,
                0.0,
                0.166334844301741,
                0.0,
                0.0,
                0.06708029646431188,
                0.09477258186856681
            ],
            [
                0.11738372283221297,
                0.0,
                1.0,
                0.15196435058548835,
                0.055338235223308795,
                0.020589660753194645,
                0.0,
                0.02546680813634491,
                0.08597130631579723
            ],
            [
                0.1739064811577693,
                0.0,
                0.15196435058548835,
                1.0,
                0.13659685139695746,
                0.03050402017781022,
                0.0,
                0.03772961772257243,
                0.12736831820616012
            ],
            [
                0.17015623956699327,
                0.166334844301741,
                0.055338235223308795,
                0.13659685139695746,
                1.0,
                0.06585353943284725,
                0.0,
                0.0,
                0.10102359633544657
            ],
            [
                0.02714543376969908,
                0.0,
                0.020589660753194645,
                0.03050402017781022,
                0.06585353943284725,
                1.0,
                0.0,
                0.15923972414038476,
                0.23598590670624442
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.03357547080922753,
                0.06708029646431188,
                0.02546680813634491,
                0.03772961772257243,
                0.0,
                0.15923972414038476,
                0.0,
                1.0,
                0.046491337042759866
            ],
            [
                0.11334467476973316,
                0.09477258186856681,
                0.08597130631579723,
                0.12736831820616012,
                0.10102359633544657,
                0.23598590670624442,
                0.0,
                0.046491337042759866,
                1.0
            ]
        ]
    },
    "N10-1091": {
        "input_sentences": [
            "In this paper we implemented such a study for English dependency parsing and find several non-obvious facts: (a) the diversity of base parsers is more important than complex models for learning (e.g., stacking, supervised meta-classification), (b) approximate, linear-time re-parsing algorithms guarantee well-formed dependency trees without significant performance loss, and (c) the simplest scoring model for re-parsing (unweighted voting) performs essentially as well as other more complex models.",
            "Ensemble Models for Dependency Parsing: Cheap and Good?",
            "This study proves that fast and accurate ensemble parsers can be built with minimal effort.",
            "Abstract",
            "Previous work on dependency parsing used various kinds of combination models but a systematic analysis and comparison of these approaches is lacking."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.23695864045898832,
                0.06965186617093432,
                0.0,
                0.1348202309282242
            ],
            [
                0.23695864045898832,
                1.0,
                0.1154592683573037,
                0.0,
                0.19155977633761764
            ],
            [
                0.06965186617093432,
                0.1154592683573037,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.1348202309282242,
                0.19155977633761764,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "E12-1055": {
        "input_sentences": [
            "While techniques for domain adaptation of monolingual data can be borrowed for parallel data, we explore conceptual differences between translation model and language model domain adaptation and their effect on performance, such as the fact that translation models typically consist of several features that have different characteristics and can be optimized separately.",
            "We investigate the problem of domain adaptation for parallel data in Statistical Machine Translation (SMT).",
            "Abstract",
            "We also explore adapting multiple (4\u201310) data sets with no priori between in-domain and out-of-domain data except for an in-domain development set.",
            "Perplexity Minimization for Translation Model Domain Adaptation in Statistical Machine Translation"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.2945289385797102,
                0.0,
                0.23622621602994864,
                0.3454358556531734
            ],
            [
                0.2945289385797102,
                1.0,
                0.0,
                0.20498516549659912,
                0.45167164871701415
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.23622621602994864,
                0.20498516549659912,
                0.0,
                1.0,
                0.1063816407227266
            ],
            [
                0.3454358556531734,
                0.45167164871701415,
                0.0,
                0.1063816407227266,
                1.0
            ]
        ]
    },
    "D11-1033": {
        "input_sentences": [
            "Domain Adaptation via Pseudo In-Domain Data Selection",
            "We explore efficient domain adaptation for the task of statistical machine translation based on extracting sentences from a large generaldomain parallel corpus that are most relevant to the target domain.",
            "These sentences may be selected with simple cross-entropy based methods, of which we present three.",
            "As these sentences are not themselves identical the in-domain data, we call them These subcorpora \u2013 1% the size of the original \u2013 can then used to train small domain-adapted Statistical Machine Translation (SMT) systems which outperform systems trained on the entire corpus.",
            "Abstract",
            "Performance is further improved when we use these domain-adapted models in combination with a true in-domain model.",
            "The results show that more training data is not always better, and that best results are attained via proper domain-relevant data selection, as well as combining inand general-domain systems during decoding."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.24208947464787134,
                0.0,
                0.18841525306491508,
                0.0,
                0.19459783421153595,
                0.33293437582417496
            ],
            [
                0.24208947464787134,
                1.0,
                0.11680298438476507,
                0.2640549383396075,
                0.0,
                0.10282733369436077,
                0.11400493666980072
            ],
            [
                0.0,
                0.11680298438476507,
                1.0,
                0.042648512479109335,
                0.0,
                0.0,
                0.0
            ],
            [
                0.18841525306491508,
                0.2640549383396075,
                0.042648512479109335,
                1.0,
                0.0,
                0.14154554387108487,
                0.18880486957267412
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.19459783421153595,
                0.10282733369436077,
                0.0,
                0.14154554387108487,
                0.0,
                1.0,
                0.09164014171882383
            ],
            [
                0.33293437582417496,
                0.11400493666980072,
                0.0,
                0.18880486957267412,
                0.0,
                0.09164014171882383,
                1.0
            ]
        ]
    },
    "P10-1021": {
        "input_sentences": [
            "There is evidence that the language processor is highly predictive, such that prior context allows upcoming linguistic material to be anticipated.",
            "Syntactic and Semantic Factors in Processing Difficulty: An Integrated Measure",
            "In this paper we analyze reading times in terms of a single predictive measure which integrates a model of semantic composition with an incremental parser and a language model.",
            "Abstract",
            "The analysis of reading times can provide insights into the processes that underlie language comprehension, with longer reading times indicating greater cognitive load.",
            "Previous work has investigated the contributions of semantic and syntactic contexts in isolation, essentially treating them as independent factors."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.08718515898893452,
                0.0,
                0.03495598015310731,
                0.0
            ],
            [
                0.0,
                1.0,
                0.12418459724075503,
                0.0,
                0.0,
                0.23649199891508643
            ],
            [
                0.08718515898893452,
                0.12418459724075503,
                1.0,
                0.0,
                0.19510826997764252,
                0.03682765627129264
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.03495598015310731,
                0.0,
                0.19510826997764252,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.23649199891508643,
                0.03682765627129264,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "E12-1014": {
        "input_sentences": [
            "We propose a novel algorithm to estimate reordering probabilities from monolingual data.",
            "In this paper, we examine an idealization where a phrase-table is given.",
            "We examine the degradation in translation performance when bilingually estimated translation probabilities are removed and show that 80%+ of the loss can be recovered with monolingually estimated features alone.",
            "Our method only requires monolingual corpora in source and target languages, a small bilingual dictionary, and a small bitext for tuning feature weights.",
            "Abstract",
            "Toward Statistical Machine Translation without Parallel Corpora",
            "We further show that our monolingual features add 1.5 BLEU points when combined with standard bilingually estimated phrase table features.",
            "We extend existing research on bilingual lexicon induction estimate and phrasal translation probabilities for MT-scale phrasetables.",
            "We estimate the parameters of a phrasebased statistical machine translation sysfrom instead of a corpus.",
            "We report translation results for an end-to-end translation system using these monolingual features alone."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.05809759734699289,
                0.04288830595653827,
                0.0,
                0.0,
                0.05264664227575046,
                0.1293315058454423,
                0.07975355605902552,
                0.055746195413241315
            ],
            [
                0.0,
                1.0,
                0.08540912957362436,
                0.0,
                0.0,
                0.0,
                0.19582731253279756,
                0.0,
                0.0,
                0.0
            ],
            [
                0.05809759734699289,
                0.08540912957362436,
                1.0,
                0.0,
                0.0,
                0.10098715005979599,
                0.27096574351488645,
                0.10110992372980475,
                0.06988735237217339,
                0.17207120694140696
            ],
            [
                0.04288830595653827,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0966414931581528,
                0.03379212641212303,
                0.054227600147404485,
                0.0,
                0.0357816263482173
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.10098715005979599,
                0.0966414931581528,
                0.0,
                1.0,
                0.0,
                0.05620206680091345,
                0.35341976249772633,
                0.12258847532784996
            ],
            [
                0.05264664227575046,
                0.19582731253279756,
                0.27096574351488645,
                0.03379212641212303,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.15505733912927433
            ],
            [
                0.1293315058454423,
                0.0,
                0.10110992372980475,
                0.054227600147404485,
                0.0,
                0.05620206680091345,
                0.0,
                1.0,
                0.09990459338931931,
                0.06878700447932598
            ],
            [
                0.07975355605902552,
                0.0,
                0.06988735237217339,
                0.0,
                0.0,
                0.35341976249772633,
                0.0,
                0.09990459338931931,
                1.0,
                0.08483637737011153
            ],
            [
                0.055746195413241315,
                0.0,
                0.17207120694140696,
                0.0357816263482173,
                0.0,
                0.12258847532784996,
                0.15505733912927433,
                0.06878700447932598,
                0.08483637737011153,
                1.0
            ]
        ]
    },
    "P14-2022": {
        "input_sentences": [
            "Our key contribution avoids this behavior by placing hypotheses into equivalence classes, masking the parts of state that matter least to the score.",
            "Translation hypotheses keep track of state, such as context for the language model and coverage of words in the source sentence.",
            "Since our algorithm and cube pruning are both approximate, improvement can be used to increase speed or accuracy.",
            "For example, cube pruning will repeatedly query the language model with hypotheses that differ only in source coverage, despite the fact that source coverage is irrelevant to the language model.",
            "Faster Phrase-Based Decoding by Refining Feature State",
            "Abstract",
            "When tuned to attain the same accuracy, our algorithm is 4.0\u20137.7 times as fast as the Moses decoder with cube pruning.",
            "Most features depend upon only part of the state, but traditional algorithms, including cube pruning, handle state atomically.",
            "We contribute a faster decoding algorithm for phrase-based machine translation.",
            "Moreover, we exploit shared words in hypotheses to iteratively refine language model scores rather than handling language model state atomically."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.08243488714040108,
                0.0,
                0.02959052229184539,
                0.044849411280149194,
                0.0,
                0.0,
                0.06843564522550513,
                0.0,
                0.06464992465058736
            ],
            [
                0.08243488714040108,
                1.0,
                0.0,
                0.46138657260303184,
                0.05518653483924493,
                0.0,
                0.0,
                0.0842090455968853,
                0.10428871099692637,
                0.37517343373561235
            ],
            [
                0.0,
                0.0,
                1.0,
                0.07599351270006177,
                0.0,
                0.0,
                0.28167016008259727,
                0.108960456311272,
                0.08330165133408066,
                0.0
            ],
            [
                0.02959052229184539,
                0.46138657260303184,
                0.07599351270006177,
                1.0,
                0.0,
                0.0,
                0.07117895626170508,
                0.06770679807129608,
                0.0,
                0.31755830977340893
            ],
            [
                0.044849411280149194,
                0.05518653483924493,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.10262103531705506,
                0.5083641748235931,
                0.04328028390464829
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.28167016008259727,
                0.07117895626170508,
                0.0,
                0.0,
                1.0,
                0.1020572846085736,
                0.07802408898031522,
                0.0
            ],
            [
                0.06843564522550513,
                0.0842090455968853,
                0.108960456311272,
                0.06770679807129608,
                0.10262103531705506,
                0.0,
                0.1020572846085736,
                1.0,
                0.0,
                0.13371285454060983
            ],
            [
                0.0,
                0.10428871099692637,
                0.08330165133408066,
                0.0,
                0.5083641748235931,
                0.0,
                0.07802408898031522,
                0.0,
                1.0,
                0.0
            ],
            [
                0.06464992465058736,
                0.37517343373561235,
                0.0,
                0.31755830977340893,
                0.04328028390464829,
                0.0,
                0.0,
                0.13371285454060983,
                0.0,
                1.0
            ]
        ]
    },
    "N07-2041": {
        "input_sentences": [
            "Simultaneous Identification of Biomedical Named-Entity and Functional Relation Using Statistical Parsing Techniques",
            "We build a parser that derives both syntactic and domain-dependent semantic information achieves an F-score of the relation extraction task.",
            "In this paper we propose a statistical parsing technique that simultaneously identifies biomedical named-entities (NEs) and extracts subcellular localization relations for bacterial proteins from the text in MEDLINE articles.",
            "Abstract",
            "We then propose a semi-supervised approach that incorporates noisy automatically labeled data to improve the F-score of our parser to Our key contributions are: learning from noisy data, and building an annotated corpus that can benefit relation extraction research."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.04414918680480012,
                0.20254546380526303,
                0.0,
                0.02920634101925007
            ],
            [
                0.04414918680480012,
                1.0,
                0.0,
                0.0,
                0.1393288514500273
            ],
            [
                0.20254546380526303,
                0.0,
                1.0,
                0.0,
                0.029848124972362357
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.02920634101925007,
                0.1393288514500273,
                0.029848124972362357,
                0.0,
                1.0
            ]
        ]
    },
    "P13-2009": {
        "input_sentences": [
            "Semantic Parsing as Machine Translation",
            "Abstract",
            "These results support the use of machine translation methods as an informative baseline in semantic parsing evaluations, and suggest that research in semantic parsing could benefit from advances in machine translation.",
            "Semantic parsing is the problem of deriving a structured meaning representation from a natural language utterance.",
            "In experiments on the multilingual GeoQuery corpus we find that our parser is competitive with the state of the art, and in some cases achieves higher accuracy than recently proposed purpose-built systems.",
            "Here we approach it as a straightforward machine translation task, and demonstrate that standard machine translation components can be adapted into a semantic parser."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.6278953457208092,
                0.2090808208031968,
                0.0,
                0.492531983760786
            ],
            [
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.6278953457208092,
                0.0,
                1.0,
                0.1312808742618138,
                0.0,
                0.30925854022203475
            ],
            [
                0.2090808208031968,
                0.0,
                0.1312808742618138,
                1.0,
                0.0,
                0.03439206357473867
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.04782158888714564
            ],
            [
                0.492531983760786,
                0.0,
                0.30925854022203475,
                0.03439206357473867,
                0.04782158888714564,
                1.0
            ]
        ]
    },
    "W11-2147": {
        "input_sentences": [
            "Experiments with word alignment normalization and clause reordering for SMT between English and German",
            "This paper presents the LIU system for theWMT 2011 shared task for translation be tween German and English.",
            "This resulted in small improvements for both transla tion directions.",
            "Abstract",
            "For German?English trans lation we tried to make the German text moresimilar to the English text by normalizing Ger man morphology and performing rule-basedclause reordering of the German text.",
            "For English?German we attempted to improve the trans lation tables with a combination of standard statistical word alignments and phrase-basedword alignments."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.08511166447052676,
                0.0,
                0.0,
                0.18108639939966426,
                0.13511291021442176
            ],
            [
                0.08511166447052676,
                1.0,
                0.0,
                0.0,
                0.11166764614270029,
                0.058894410506489026
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.18108639939966426,
                0.11166764614270029,
                0.0,
                0.0,
                1.0,
                0.15994853463670436
            ],
            [
                0.13511291021442176,
                0.058894410506489026,
                0.0,
                0.0,
                0.15994853463670436,
                1.0
            ]
        ]
    },
    "P14-1008": {
        "input_sentences": [
            "An inference engine is built to achieve inference on abstract denotations.",
            "Dependency-based Compositional Semantics (DCS) is a framework of natural language semantics with easy-to-process structures as well as strict semantics.",
            "Logical Inference on Dependency-based Compositional Semantics",
            "Furthermore, we propose a way to generate on-the-fly knowledge in logical inference, by combining our framework with the idea of tree transformation.",
            "Abstract",
            "Experiments on FraCaS and PASCAL RTE datasets show promising results.",
            "In this paper, we equip the DCS framework logical inference, by defining abdenotations an abstraction of the computing process of denotations in original DCS."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.16384903801955142,
                0.09262915304899486,
                0.34185671375630083,
                0.0,
                0.16853021732190604
            ],
            [
                0.0,
                1.0,
                0.5567940748249751,
                0.03833032425807289,
                0.0,
                0.0,
                0.18664162173463486
            ],
            [
                0.16384903801955142,
                0.5567940748249751,
                1.0,
                0.1371606569752501,
                0.0,
                0.0,
                0.1308004230871749
            ],
            [
                0.09262915304899486,
                0.03833032425807289,
                0.1371606569752501,
                1.0,
                0.0,
                0.0,
                0.11610920203212544
            ],
            [
                0.34185671375630083,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.16853021732190604,
                0.18664162173463486,
                0.1308004230871749,
                0.11610920203212544,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "C10-1132": {
        "input_sentences": [
            "However, generative and discriminative charac ter-based approaches are significantly different and complement each other.",
            "A Character-Based Joint Model for Chinese Word Segmentation",
            "The character-based tagging approach is a dominant technique for Chinese word segmentation, and both discrimi native and generative models can be adopted in that framework.",
            "A simple joint model combining the character-based generative model and the discriminative one is thus proposed in this paper to take advantage of both approaches.",
            "Abstract",
            "In addition, closed tests also show that the proposed joint model outperforms all the existing approaches reported in the literature and achieves the best F score in four out of five corpora.",
            "Experiments on the Sec ond SIGHAN Bakeoff show that this joint approach achieves 21% relative error reduction over the discriminative model and 14% over the generative one."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.07575302454249241,
                0.08416511614504105,
                0.22812656788067626,
                0.0,
                0.05443763717064354,
                0.09407030086744737
            ],
            [
                0.07575302454249241,
                1.0,
                0.4418483685751145,
                0.35269730693171986,
                0.0,
                0.11084308790608627,
                0.1092158259028051
            ],
            [
                0.08416511614504105,
                0.4418483685751145,
                1.0,
                0.12236485086530556,
                0.0,
                0.0,
                0.08541863149823394
            ],
            [
                0.22812656788067626,
                0.35269730693171986,
                0.12236485086530556,
                1.0,
                0.0,
                0.2203095077461532,
                0.1882460107930919
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.05443763717064354,
                0.11084308790608627,
                0.0,
                0.2203095077461532,
                0.0,
                1.0,
                0.11287109795264282
            ],
            [
                0.09407030086744737,
                0.1092158259028051,
                0.08541863149823394,
                0.1882460107930919,
                0.0,
                0.11287109795264282,
                1.0
            ]
        ]
    },
    "P11-1089": {
        "input_sentences": [
            "Most previous studies of morphological disambiguation and dependency parsing have been pursued independently.",
            "However, in morphologically-rich languages, there is often considerable interaction between morphology and syntax, such that neither can be disambiguated without the other.",
            "Morphological taggers operate on n-grams and do not take into account syntactic relations; parsers use the \u201cpipeline\u201d approach, assuming that morphological information has been separately obtained.",
            "Abstract",
            "In this paper, we propose a discriminative model that jointly infers morphological properties and syntactic structures.",
            "In evaluations on various highly-inflected languages, this joint model outperforms both a baseline tagger in morphological disambiguation, and a pipeline parser in head selection.",
            "A Discriminative Model for Joint Morphological Disambiguation and Dependency Parsing"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.06146631431547778,
                0.0,
                0.04099668308569163,
                0.0874849300030467,
                0.4343191438837163
            ],
            [
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.06797082519286661,
                0.0
            ],
            [
                0.06146631431547778,
                0.0,
                1.0,
                0.0,
                0.11662169883760831,
                0.09119580144195362,
                0.07584398866170822
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.04099668308569163,
                0.0,
                0.11662169883760831,
                0.0,
                1.0,
                0.07603054101664981,
                0.25774957268890963
            ],
            [
                0.0874849300030467,
                0.06797082519286661,
                0.09119580144195362,
                0.0,
                0.07603054101664981,
                1.0,
                0.2699461492378048
            ],
            [
                0.4343191438837163,
                0.0,
                0.07584398866170822,
                0.0,
                0.25774957268890963,
                0.2699461492378048,
                1.0
            ]
        ]
    },
    "W06-0508": {
        "input_sentences": [
            "We suggest that the use of knowledge intensive strategies to process the input text and corpusbased techniques to deal with unpredicted cases and ambiguity problems allows to accurately discover the relevant relations between pairs of entities in that text.",
            "We present an approach for extracting relations from texts that exploits linguistic and empirical strategies, by means of a pipeline method involving a parser, partof-speech tagger, named entity recognition system, pattern-based classification and word sense disambiguation models, and resources such as ontology, knowledge base and lexical databases.",
            "A Hybrid Approach For Extracting Semantic Relations From Texts",
            "The relations extracted can be used for various tasks, including semantic web annotation and ontology learning.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.060604959832066416,
                0.03298161578994914,
                0.02105734948027468,
                0.0
            ],
            [
                0.060604959832066416,
                1.0,
                0.20853750836104765,
                0.05679091410242427,
                0.0
            ],
            [
                0.03298161578994914,
                0.20853750836104765,
                1.0,
                0.15766849504641986,
                0.0
            ],
            [
                0.02105734948027468,
                0.05679091410242427,
                0.15766849504641986,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "C10-1061": {
        "input_sentences": [
            "LCFRS, an extension of CFG, can de scribe discontinuities both in constituencyand dependency structures in a straight forward way and is therefore a naturalcandidate to be used for data-driven parsing.",
            "Our experiments show that data driven LCFRS parsing is feasible with a reasonable speed and yields output of competitive quality.",
            "We evaluate our parser with a gram mar extracted from the German NeGratreebank.",
            "Data-Driven Parsing with Probabilistic Linear Context-Free Rewriting Systems",
            "Abstract",
            "This paper presents a first efficient imple mentation of a weighted deductive CYKparser for Probabilistic Linear ContextFree Rewriting Systems (PLCFRS), to gether with context-summary estimatesfor parse items used to speed up parsing."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.17269492005076345,
                0.0,
                0.14890442587851024,
                0.0,
                0.06189493390543048
            ],
            [
                0.17269492005076345,
                1.0,
                0.0,
                0.1770821183870285,
                0.0,
                0.07360752340794291
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.14890442587851024,
                0.1770821183870285,
                0.0,
                1.0,
                0.0,
                0.34817942678338043
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.06189493390543048,
                0.07360752340794291,
                0.0,
                0.34817942678338043,
                0.0,
                1.0
            ]
        ]
    },
    "P12-1025": {
        "input_sentences": [
            "We address the issue of consuming heterogeneous annotation data for Chinese word segmentation and part-of-speech tagging.",
            "Evaluation on the CTB and PPD data shows that our novel model achieves a relative error reduction of 11% over the best reported result in the literature.",
            "Abstract",
            "Reducing Approximation and Estimation Errors for Chinese Lexical Processing with Heterogeneous Annotations",
            "We empirically analyze the diversity between two representative corpora, i.e.",
            "Penn Chinese Treebank (CTB) and PKU\u2019s People\u2019s Daily (PPD), on manually mapped data, and show that their linguistic annotations are systematically different and highly compatible.",
            "The analysis is further exploited to improve processing accuracy by (1) integrating systems that are respectively trained on heterogeneous annotations to reduce the approximation error, and (2) re-training models with high quality automatically converted data to reduce the estimation error."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.03258799068615554,
                0.0,
                0.1281430780068903,
                0.0,
                0.07499997031336665,
                0.05857000283268841
            ],
            [
                0.03258799068615554,
                1.0,
                0.0,
                0.0,
                0.0,
                0.12034280190422095,
                0.0939797471782157
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.1281430780068903,
                0.0,
                0.0,
                1.0,
                0.0,
                0.10217274596606582,
                0.24360192128030228
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.07499997031336665,
                0.12034280190422095,
                0.0,
                0.10217274596606582,
                0.0,
                1.0,
                0.04669981487672907
            ],
            [
                0.05857000283268841,
                0.0939797471782157,
                0.0,
                0.24360192128030228,
                0.0,
                0.04669981487672907,
                1.0
            ]
        ]
    },
    "P14-1012": {
        "input_sentences": [
            "In this paper, instead of designing new features based on intuition, linguistic knowledge and domain, we learn some new and effective features using the deep autoencoder (DAE) paradigm for phrase-based translation model.",
            "Moreover, to learn high dimensional feature representation, we introduce a natural horizontal composition of more DAEs for large hidden layers feature learning.",
            "Learning New Semi-Supervised Deep Auto-encoder Features for Statistical Machine Translation",
            "On two Chinese- English tasks, our semi-supervised DAE features obtain statistically significant improvements of 1.34/2.45 (IWSLT) and 0.82/1.52 (NIST) BLEU points over the unsupervised DBN features and the baseline features, respectively.",
            "Using the unsupervised pre-trained deep belief net (DBN) to initialize DAE\u2019s parameters and using the input original phrase features as a teacher for semi-supervised fine-tuning, we learn new semi-supervised DAE features, which are more effective and stable than the unsupervised DBN features.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.02574867849607202,
                0.22019775509791184,
                0.11677201091876027,
                0.2940683240518942,
                0.0
            ],
            [
                0.02574867849607202,
                1.0,
                0.06063555241201858,
                0.0,
                0.021158239610106842,
                0.0
            ],
            [
                0.22019775509791184,
                0.06063555241201858,
                1.0,
                0.15239067623315636,
                0.2527860993187766,
                0.0
            ],
            [
                0.11677201091876027,
                0.0,
                0.15239067623315636,
                1.0,
                0.3234130452737731,
                0.0
            ],
            [
                0.2940683240518942,
                0.021158239610106842,
                0.2527860993187766,
                0.3234130452737731,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P14-2110": {
        "input_sentences": [
            "We experiment on two code-switching corpora (English-Spanish Twitter data and English-Chinese Weibo data) and show that csLDA improves perplexity over LDA, and learns semantically coherent aligned topics as judged by human annotators.",
            "Learning Polylingual Topic Models from Code-Switched Social Media Documents",
            "Abstract",
            "Code-switched documents are in social media, providing evidence polylingual topic models to infer aligned topics across languages.",
            "We Code-Switched LDA (csLDA), which infers language specific topic distributions based on code-switched documents to facilitate multi-lingual corpus analysis."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.027165330410330014,
                0.0,
                0.10281634697550306,
                0.09736607104978132
            ],
            [
                0.027165330410330014,
                1.0,
                0.0,
                0.6010305842810572,
                0.2709087889152935
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.10281634697550306,
                0.6010305842810572,
                0.0,
                1.0,
                0.20098700095588087
            ],
            [
                0.09736607104978132,
                0.2709087889152935,
                0.0,
                0.20098700095588087,
                1.0
            ]
        ]
    },
    "D11-1140": {
        "input_sentences": [
            "Traditional CCG lexicons list lexical items that pair words and phrases with syntactic and semantic content.",
            "Such lexicons can be inefficient when words appear repeatedly with closely related lexical content.",
            "Lexical Generalization in CCG Grammar Induction for Semantic Parsing",
            "Abstract",
            "We also present an algorithm for learning factored CCG lexicons, along with a probabilistic parse-selection model.",
            "Evaluations on benchmark datasets demonstrate that the approach learns highly accurate parsers, whose generalization performance benefits greatly from the lexical factoring.",
            "In this paper, we introduce factored lexicons, which both model word meaning model systematic variation in word usage.",
            "We consider the problem of learning factored probabilistic CCG grammars for semantic parsing from data containing sentences paired with logical-form meaning representations."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.2722118249564969,
                0.20186730136910477,
                0.0,
                0.0975823788215377,
                0.03542273717527521,
                0.036291903543245733,
                0.08106266378629477
            ],
            [
                0.2722118249564969,
                1.0,
                0.06883966994409761,
                0.0,
                0.054920794080956015,
                0.03987287208369899,
                0.04085123124431552,
                0.0
            ],
            [
                0.20186730136910477,
                0.06883966994409761,
                1.0,
                0.0,
                0.06778814092685465,
                0.1351901237640606,
                0.0,
                0.19813707668932257
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0975823788215377,
                0.054920794080956015,
                0.06778814092685465,
                0.0,
                1.0,
                0.0,
                0.2331056339823224,
                0.22629771110222813
            ],
            [
                0.03542273717527521,
                0.03987287208369899,
                0.1351901237640606,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.036291903543245733,
                0.04085123124431552,
                0.0,
                0.0,
                0.2331056339823224,
                0.0,
                1.0,
                0.08853166620263712
            ],
            [
                0.08106266378629477,
                0.0,
                0.19813707668932257,
                0.0,
                0.22629771110222813,
                0.0,
                0.08853166620263712,
                1.0
            ]
        ]
    },
    "P01-1018": {
        "input_sentences": [
            "We then introduce a formalism which, under these constraints, maximally squeezes strong generative power out of context-free grammar.",
            "We consider the question \u201cHow much strong generative power can be squeezed out of a formal system without increasing its weak generative power?\u201d and propose some theoretical and practical constraints on this problem.",
            "Constraints On Strong Generative Power",
            "Abstract",
            "Finally, we generalize this result to formalisms beyond CFG."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.238435587667789,
                0.45167210392589197,
                0.0,
                0.0
            ],
            [
                0.238435587667789,
                1.0,
                0.5278953151973058,
                0.0,
                0.0
            ],
            [
                0.45167210392589197,
                0.5278953151973058,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "D12-1046": {
        "input_sentences": [
            "Our experimental results on Chinese Tree Bank 5 corpus show that our approach outperforms the state-of-the-art pipeline system.",
            "Joint Chinese Word Segmentation, POS Tagging and Parsing",
            "In this paper, we propose a novel decoding algorithm for discriminative joint Chinese word segmentation, part-of-speech (POS) tagging, and parsing.",
            "Abstract",
            "As far as we know, this is the first work on joint Chinese word segmentation, POS tagging and parsing.",
            "In our approach, we train the three individual models separately during training, and incorporate them together in a unified framework during decoding.",
            "We extend the CYK parsing algorithm so that it can deal with word segmentation and POS tagging features.",
            "Previous work often used a pipeline method \u2013 Chinese word segmentation followed by POS tagging and parsing, which suffers from error propagation and is unable to leverage information in later modules for earlier components."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.06504648937122004,
                0.03402779671301544,
                0.0,
                0.04467568320231189,
                0.07346275597559679,
                0.0,
                0.07847014245258696
            ],
            [
                0.06504648937122004,
                1.0,
                0.5231304109099408,
                0.0,
                0.6868269699744741,
                0.0,
                0.4046957571361989,
                0.2925797076760502
            ],
            [
                0.03402779671301544,
                0.5231304109099408,
                1.0,
                0.0,
                0.35930007502677624,
                0.07712809208227743,
                0.3061132021602685,
                0.15305734270048255
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.04467568320231189,
                0.6868269699744741,
                0.35930007502677624,
                0.0,
                1.0,
                0.0,
                0.27795596063538114,
                0.27562480238442166
            ],
            [
                0.07346275597559679,
                0.0,
                0.07712809208227743,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.4046957571361989,
                0.3061132021602685,
                0.0,
                0.27795596063538114,
                0.0,
                1.0,
                0.15116885944367803
            ],
            [
                0.07847014245258696,
                0.2925797076760502,
                0.15305734270048255,
                0.0,
                0.27562480238442166,
                0.0,
                0.15116885944367803,
                1.0
            ]
        ]
    },
    "P12-2058": {
        "input_sentences": [
            "Empirically, we show a gain in running time of a standard machine translation system, at a small loss in accuracy.",
            "We propose a novel heuristic algorithm for Cube Pruning running in linear time in the beam size.",
            "Heuristic Cube Pruning in Linear Time",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.11735318906753682,
                0.07970385532520921,
                0.0
            ],
            [
                0.11735318906753682,
                1.0,
                0.5829495577403239,
                0.0
            ],
            [
                0.07970385532520921,
                0.5829495577403239,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "W10-2803": {
        "input_sentences": [
            "In this paper, we argue in favor of reconsidering models for word meaning, using as a basis results from cognitive science on human concept representation.",
            "Or move away from dictionary senses completely, and only model similarities between individual word usages.",
            "We argue that distributional models provide a flexible framework for experimenting with alternative models of word meanings, and discuss example models.",
            "What Is Word Meaning Really? (And How Can Distributional Models Help Us Describe It?)",
            "Abstract",
            "More specifically, we argue for a more flexible representation of word meaning than the assignment of a single best-fitting dictionary sense to each occurrence: Either use dictionary senses, but view them as having fuzzy boundaries, and assume that an occurrence can activate multiple senses to different degrees."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.027054790482824227,
                0.16927729964015928,
                0.17592902027816007,
                0.0,
                0.10183003747836954
            ],
            [
                0.027054790482824227,
                1.0,
                0.025996861320902783,
                0.04822899442360328,
                0.0,
                0.20247494703184624
            ],
            [
                0.16927729964015928,
                0.025996861320902783,
                1.0,
                0.328497957585426,
                0.0,
                0.07308005537275572
            ],
            [
                0.17592902027816007,
                0.04822899442360328,
                0.328497957585426,
                1.0,
                0.0,
                0.07111284201925301
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.10183003747836954,
                0.20247494703184624,
                0.07308005537275572,
                0.07111284201925301,
                0.0,
                1.0
            ]
        ]
    },
    "P12-1048": {
        "input_sentences": [
            "Experimental result on the NIST Chinese-English translation task shows that our approach significantly outperforms the baseline system.",
            "Translation Model Adaptation for Statistical Machine Translation with Monolingual Topic Information",
            "Our method establishes the relationship between the out-of-domain bilingual corpus and the in-domain monolingual corpora via topic mapping and phrase-topic distribution probability estimation from in-domain monolingual corpora.",
            "To adapt a translation model trained from the data in one domain to another, previous works paid more attention to the studies of parallel corpus while ignoring the in-domain monolingual corpora which can be obtained more easily.",
            "Abstract",
            "In this paper, we propose a novel approach for translation model adaptation by utilizing in-domain monolingual topic information instead of the in-domain bilingual corpora, which incorporates the topic information into translation probability estimation."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.08609740509151238,
                0.0,
                0.026294011852850914,
                0.0,
                0.09610318849859109
            ],
            [
                0.08609740509151238,
                1.0,
                0.1580639537598134,
                0.15464952414259261,
                0.0,
                0.4910074286227581
            ],
            [
                0.0,
                0.1580639537598134,
                1.0,
                0.3025960197614599,
                0.0,
                0.4598706143748725
            ],
            [
                0.026294011852850914,
                0.15464952414259261,
                0.3025960197614599,
                1.0,
                0.0,
                0.22610492540165664
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.09610318849859109,
                0.4910074286227581,
                0.4598706143748725,
                0.22610492540165664,
                0.0,
                1.0
            ]
        ]
    },
    "P04-1040": {
        "input_sentences": [
            "This general framework allows us to accurately recover both grammatical and semantic information as well as non-local dependencies.",
            "The method is based on graph rewriting using memorybased learning, applied to dependency structures.",
            "Enriching The Output Of A Parser Using Memory-Based Learning",
            "We describe a method for enriching the output of a parser with information available in a corpus.",
            "Abstract",
            "Our method is largely independent of the choice of parser and corpus, and shows state of the art performance.",
            "It also facilitates dependency-based evaluation of phrase structure parsers."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0,
                0.09656833309698316,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                1.0,
                0.30340464999334765,
                0.08118116778770522,
                0.0,
                0.06008135830031526,
                0.16864483466736604
            ],
            [
                0.0,
                0.30340464999334765,
                1.0,
                0.39502492913917886,
                0.0,
                0.07822435913783136,
                0.092697354594617
            ],
            [
                0.09656833309698316,
                0.08118116778770522,
                0.39502492913917886,
                1.0,
                0.0,
                0.2635135090062682,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.06008135830031526,
                0.07822435913783136,
                0.2635135090062682,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.16864483466736604,
                0.092697354594617,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P14-1004": {
        "input_sentences": [
            "We apply them to two real, non-trivial datasets: human-computer spoken dialogues in bus query service, and humanhuman text-based chats from a live technical support service.",
            "A key challenge for computational conversation models is to discover latent structure in task-oriented dialogue, since it provides a basis for analysing, evaluating, and building conversational systems.",
            "Quantitatively, we show our models achieve superior performance on held-out log likelihood evaluation and an ordering task.",
            "Abstract",
            "Discovering Latent Structure in Task-Oriented Dialogues",
            "We propose three new unsupervised models to discover latent structures in task-oriented dialogues.",
            "We show that our models extract meaningful state representations and dialogue structures consistent with human annotations.",
            "Our methods synthesize hidden Markov models (for underlying state) and topic models (to connect words to states)."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0,
                0.0,
                0.05923014338976621,
                0.04388735063308135,
                0.05348625668600657,
                0.0
            ],
            [
                0.0,
                1.0,
                0.05965442056546082,
                0.0,
                0.2909596822379525,
                0.24717278593566977,
                0.09256223704197122,
                0.04934709865991644
            ],
            [
                0.0,
                0.05965442056546082,
                1.0,
                0.0,
                0.06729510311490569,
                0.08893251063531543,
                0.03545501934274752,
                0.0610453238236123
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.05923014338976621,
                0.2909596822379525,
                0.06729510311490569,
                0.0,
                1.0,
                0.3975815264407624,
                0.0,
                0.0
            ],
            [
                0.04388735063308135,
                0.24717278593566977,
                0.08893251063531543,
                0.0,
                0.3975815264407624,
                1.0,
                0.1379913181979644,
                0.07356640689484631
            ],
            [
                0.05348625668600657,
                0.09256223704197122,
                0.03545501934274752,
                0.0,
                0.0,
                0.1379913181979644,
                1.0,
                0.14118523681561343
            ],
            [
                0.0,
                0.04934709865991644,
                0.0610453238236123,
                0.0,
                0.0,
                0.07356640689484631,
                0.14118523681561343,
                1.0
            ]
        ]
    },
    "D10-1004": {
        "input_sentences": [
            "Dependency Parsing.",
            "Experiments show state-of-the-art performance for 14 languages.",
            "We present a unified view of two state-of-theart non-projective dependency parsers, both approximate: the loopy belief propagation parser of Smith and Eisner (2008) and the relaxed linear program of Martins et al. (2009).",
            "Abstract",
            "The algorithm does not require a learning rate parameter and provides a single framework for a wide family of convex loss functions, including CRFs and structured SVMs.",
            "Turbo Parsers: Dependency Parsing by Approximate Variational Inference",
            "We also propose a new aggressive online algorithm to learn the model parameters, which makes use of the underlying variational representation.",
            "By representing the model assumptions with a factor graph, we shed light on the optimization problems tackled in each method."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0993181415487934,
                0.0,
                0.0,
                0.47936917005257945,
                0.0,
                0.0
            ],
            [
                0.0,
                1.0,
                0.06182975195968488,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0993181415487934,
                0.06182975195968488,
                1.0,
                0.0,
                0.0,
                0.17548624043009434,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0479769525272371,
                0.0
            ],
            [
                0.47936917005257945,
                0.0,
                0.17548624043009434,
                0.0,
                0.0,
                1.0,
                0.0874143468588967,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0479769525272371,
                0.0874143468588967,
                1.0,
                0.06170329354045935
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.06170329354045935,
                1.0
            ]
        ]
    },
    "P12-3029": {
        "input_sentences": [
            "The corpus will facilitate the study of linguistic trends, especially those related to the evolution of syntax.",
            "We present a new edition of the Google Books Ngram Corpus, which describes how often words and phrases were used over a period of five centuries, in eight languages; it reflects 6% of all books ever published.",
            "Syntactic Annotations",
            "The annotations are produced automatically with statistical models that are specifically adapted to historical text.",
            "Abstract",
            "This new edition introduces syntactic annotations: words are tagged with their part-of-speech, and headmodifier relationships are recorded.",
            "Syntactic Annotations for the Google Books NGram Corpus"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.04356400827207836,
                0.0,
                0.0,
                0.0,
                0.0,
                0.09290010954000999
            ],
            [
                0.04356400827207836,
                1.0,
                0.0,
                0.0,
                0.0,
                0.17435659896525577,
                0.44260900789491836
            ],
            [
                0.0,
                0.0,
                1.0,
                0.1395151599136691,
                0.0,
                0.3140843925315073,
                0.5056276579754371
            ],
            [
                0.0,
                0.0,
                0.1395151599136691,
                1.0,
                0.0,
                0.04381953425042085,
                0.0705427235592171
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.17435659896525577,
                0.3140843925315073,
                0.04381953425042085,
                0.0,
                1.0,
                0.15880975580234385
            ],
            [
                0.09290010954000999,
                0.44260900789491836,
                0.5056276579754371,
                0.0705427235592171,
                0.0,
                0.15880975580234385,
                1.0
            ]
        ]
    },
    "P01-1005": {
        "input_sentences": [
            "In this paper, we evaluate the performance of different learning methods on a prototypical natural language disambiguation task, confusion set disambiguation, when trained on orders of magnitude more labeled data than has previously been used.",
            "Scaling To Very Very Large Corpora For Natural Language Disambiguation",
            "Yet for most core natural language tasks, algorithms continue to be optimized, tested and compared after training on corpora consisting of only one million words or less.",
            "Since this will often not be the case, we examine methods for effectively exploiting very large corpora when labeled data comes at a cost.",
            "Abstract",
            "The amount of readily available on-line text has reached hundreds of billions of words and continues to grow.",
            "We are fortunate that for this particular application, correctly labeled training data is free."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.27417964510203574,
                0.06619883766617657,
                0.12895294113936098,
                0.0,
                0.0,
                0.08820780697614163
            ],
            [
                0.27417964510203574,
                1.0,
                0.22213486395330623,
                0.20283993350103185,
                0.0,
                0.0,
                0.0
            ],
            [
                0.06619883766617657,
                0.22213486395330623,
                1.0,
                0.048974342442728476,
                0.0,
                0.06420135936680478,
                0.07722891258559583
            ],
            [
                0.12895294113936098,
                0.20283993350103185,
                0.048974342442728476,
                1.0,
                0.0,
                0.0,
                0.13051345000212472
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.06420135936680478,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.08820780697614163,
                0.0,
                0.07722891258559583,
                0.13051345000212472,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "D12-1108": {
        "input_sentences": [
            "Document-Wide Decoding for Phrase-Based Statistical Machine Translation",
            "Research into models with a more varied, non-local dependency structure is to some extent stifled by the difficulty of decoding such models effectively, as can be seen by the problems some researchers encountered when they attempted to solve discourse-level problems.",
            "Moreover, by optionally initialising the state with the output of a traditional DP decoder, we can ensure that the final hypothesis is no worse than what would have been found by DP search alone.",
            "In this paper, we present a method for decoding complete documents in phrase-based SMT.",
            "Abstract",
            "The initial state is improved by the application of a series of operations using a hill climbing strategy to find a (local) maximum of the score function.",
            "This setup gives us complete freedom to define scoring functions over the entire document.",
            "Consider, for instance, the work on cache-based language models by Tiedemann (2010) and Gong et al. (2011), where error propagation was a serious issue, or the works on pronominal anaphora by Le Nagard and Koehn (2010), who implemented cross-sentence dependencies with an ad-hoc two-pass decoding strategy, and Hardmeier and Federico (2010) with the use of an external decoder driver to manage backward-only dependencies between sentences.",
            "any obvious way, especially if joint optimisation of a number of interdependent decisions over an entire document is required.",
            "We start by describing the decoding algorithm and the state operations used by our decoder, then we present empirical results demonstrating the effectiveness of our approach and its usability with a document-level semantic language model, and finally we discuss some related work.",
            "Our decoder uses a local search approach whose state consists of a complete translation of an entire document at any time."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.031551593108568345,
                0.0,
                0.2627012606866291,
                0.0,
                0.0,
                0.05595984018539598,
                0.055917127742587926,
                0.04861950024379003,
                0.0684896844287762,
                0.160218325128874
            ],
            [
                0.031551593108568345,
                1.0,
                0.0,
                0.028709532234520857,
                0.0,
                0.03293938111348858,
                0.0,
                0.054187262639238135,
                0.0,
                0.05054702404657115,
                0.04073825580318462
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.03460179608402873,
                0.0,
                0.017585750118296037,
                0.0,
                0.054631258490876515,
                0.15486952111172586
            ],
            [
                0.2627012606866291,
                0.028709532234520857,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0782269304313678,
                0.05088030185555635,
                0.0,
                0.09305561477744735,
                0.07499795507710831
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.03293938111348858,
                0.03460179608402873,
                0.0,
                0.0,
                1.0,
                0.0,
                0.029759292854723635,
                0.0,
                0.07477710090092136,
                0.1007418316939907
            ],
            [
                0.05595984018539598,
                0.0,
                0.0,
                0.0782269304313678,
                0.0,
                0.0,
                1.0,
                0.0,
                0.10809945230517368,
                0.030019826323731166,
                0.1915373979875412
            ],
            [
                0.055917127742587926,
                0.054187262639238135,
                0.017585750118296037,
                0.05088030185555635,
                0.0,
                0.029759292854723635,
                0.0,
                1.0,
                0.0,
                0.0733240122733401,
                0.022734281403781507
            ],
            [
                0.04861950024379003,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.10809945230517368,
                0.0,
                1.0,
                0.026082078655508472,
                0.10363742796933971
            ],
            [
                0.0684896844287762,
                0.05054702404657115,
                0.054631258490876515,
                0.09305561477744735,
                0.0,
                0.07477710090092136,
                0.030019826323731166,
                0.0733240122733401,
                0.026082078655508472,
                1.0,
                0.15657510791408627
            ],
            [
                0.160218325128874,
                0.04073825580318462,
                0.15486952111172586,
                0.07499795507710831,
                0.0,
                0.1007418316939907,
                0.1915373979875412,
                0.022734281403781507,
                0.10363742796933971,
                0.15657510791408627,
                1.0
            ]
        ]
    },
    "P08-1108": {
        "input_sentences": [
            "By letting one model generate features for the other, we consistently improve accuracy for both models, resulting in a significant improvement of the state of the art when evaluated on data sets from the CoNLL-X shared task.",
            "In this paper, we show how these results can be exploited to improve parsing accuracy by integrating a graph-based and a transition-based model.",
            "Integrating Graph-Based and Transition-Based Dependency Parsers",
            "Abstract",
            "Previous studies of data-driven dependency parsing have shown that the distribution of parsing errors are correlated with theoretical properties of the models used for learning and inference."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.1474842203425601,
                0.0,
                0.0,
                0.0770228660473026
            ],
            [
                0.1474842203425601,
                1.0,
                0.5737493065249883,
                0.0,
                0.10037449631626544
            ],
            [
                0.0,
                0.5737493065249883,
                1.0,
                0.0,
                0.06420805446928936
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0770228660473026,
                0.10037449631626544,
                0.06420805446928936,
                0.0,
                1.0
            ]
        ]
    },
    "P12-1002": {
        "input_sentences": [
            "Joint Feature Selection in Distributed",
            "We deploy local features for SCFG-based SMT that can be read off from rules at runtime, and present a learnalgorithm that applies regularization for joint feature selection over distributed stochastic learning processes.",
            "Joint Feature Selection in Distributed Stochastic Learning for Large-Scale Discriminative Training in SMT",
            "With a few exceptions, discriminative training in statistical machine translation (SMT) has been content with tuning weights for large feature sets on small development data.",
            "Abstract",
            "The goal of this paper is to show that this common wisdom can also be brought to bear upon SMT.",
            "Evidence from machine learning indicates that increasing the training sample size results in better prediction.",
            "We present experiments on learning on 1.5 million training sentences, and show significant improvements over tuning discriminative models on small development sets."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.3490307235705317,
                0.5682100808558768,
                0.0828651766996907,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.3490307235705317,
                1.0,
                0.3499002739010843,
                0.05784498516458603,
                0.0,
                0.03950394419794238,
                0.03241829305784823,
                0.08339811445297106
            ],
            [
                0.5682100808558768,
                0.3499002739010843,
                1.0,
                0.28475841948144387,
                0.0,
                0.06431107008922929,
                0.10555174473565836,
                0.163144928797828
            ],
            [
                0.0828651766996907,
                0.05784498516458603,
                0.28475841948144387,
                1.0,
                0.0,
                0.045979522110779145,
                0.10364889306734455,
                0.3282319825873785
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.03950394419794238,
                0.06431107008922929,
                0.045979522110779145,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.03241829305784823,
                0.10555174473565836,
                0.10364889306734455,
                0.0,
                0.0,
                1.0,
                0.07921622026249882
            ],
            [
                0.0,
                0.08339811445297106,
                0.163144928797828,
                0.3282319825873785,
                0.0,
                0.0,
                0.07921622026249882,
                1.0
            ]
        ]
    },
    "N03-1004": {
        "input_sentences": [
            "Experiments evaluating the effectiveness of our answer resolution algorithm show a 35.0% relative improvement over our baseline system in the number of questions correctly answered, and a 32.8% improvement according to the average precision metric.",
            "Motivated by the success of ensemble methods in machine learning and other areas of natural language processing, we developed a multistrategy and multi-source approach to question answering which is based on combining the results from different answering agents searching for answers in multiple corpora.",
            "Abstract",
            "The answering agents adopt fundamentally different strategies, one utilizing primarily knowledge-based mechanisms and the other adopting statistical techniques.",
            "We present our multi-level answer resolution algorithm that combines results from the answering agents at the question, passage, and/or answer levels.",
            "In Question Answering Two Heads Are Better Than One"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0,
                0.0,
                0.17159657145966087,
                0.0
            ],
            [
                0.0,
                1.0,
                0.0,
                0.14771340475586495,
                0.17933520755468646,
                0.143370409848274
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.14771340475586495,
                0.0,
                1.0,
                0.06967436021150795,
                0.059943963221527216
            ],
            [
                0.17159657145966087,
                0.17933520755468646,
                0.0,
                0.06967436021150795,
                1.0,
                0.14448998865541002
            ],
            [
                0.0,
                0.143370409848274,
                0.0,
                0.059943963221527216,
                0.14448998865541002,
                1.0
            ]
        ]
    },
    "P12-1110": {
        "input_sentences": [
            "Based on an extension of the incremental joint model for POS tagging and dependency parsing (Hatori et al., 2011), we propose an efficient character-based decoding method that can combine features from state-of-the-art segmentation, POS tagging, and dependency parsing models.",
            "In experiments using the Chinese Treebank (CTB), we show that the accuracies of the three tasks can be improved significantly over the baseline models, particularly by 0.6% for POS tagging and 2.4% for dependency parsing.",
            "We also perform comparison experiments with the partially joint models.",
            "Incremental Joint Approach to Word Segmentation, POS Tagging, and Dependency Parsing in Chinese",
            "We propose the first joint model for word segmentation, POS tagging, and dependency parsing for Chinese.",
            "Abstract",
            "We also describe our method to align comparable states in the beam, and how we can combine features of different characteristics in our incremental framework."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.2009158371971305,
                0.08192054908030298,
                0.38861248215739824,
                0.4713068031027406,
                0.0,
                0.16484859775437616
            ],
            [
                0.2009158371971305,
                1.0,
                0.15957780855687148,
                0.25619454333975755,
                0.25940425183925747,
                0.0,
                0.0
            ],
            [
                0.08192054908030298,
                0.15957780855687148,
                1.0,
                0.07861249131360082,
                0.07959738028994993,
                0.0,
                0.0
            ],
            [
                0.38861248215739824,
                0.25619454333975755,
                0.07861249131360082,
                1.0,
                0.713853515039751,
                0.0,
                0.07208193990263688
            ],
            [
                0.4713068031027406,
                0.25940425183925747,
                0.07959738028994993,
                0.713853515039751,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.16484859775437616,
                0.0,
                0.0,
                0.07208193990263688,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "D10-1069": {
        "input_sentences": [
            "We show that dependency parsers have more difficulty parsing questions than constituency parsers.",
            "We propose an in which a deterministic parser is trained on the output of a more accurate, but slower, latent variable constituency parser (converted to dependencies).",
            "It is well known that parsing accuracies drop significantly on out-of-domain data.",
            "With 100K unlabeled and 2K labeled questions, uptraining is able to improve parsing accuracy to 84%, closing the gap between in-domain and out-of-domain performance.",
            "Uptraining for Accurate Deterministic Question Parsing",
            "Abstract",
            "What is less known is that some parsers suffer more from domain shifts than others.",
            "In particular, deterministic shift-reduce dependency parsers, which are of highest interest for practical applications because of their linear running time, drop to 60% labeled accuracy on a question test set.",
            "Uptraining with 100K unlabeled questions achieves results comparable to having 2K labeled questions for training."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.081069988809532,
                0.07703672993080614,
                0.1128994041125147,
                0.10452252834828252,
                0.0,
                0.23523647988396765,
                0.18751862651045043,
                0.14220799333631212
            ],
            [
                0.081069988809532,
                1.0,
                0.0,
                0.0,
                0.19594642272910429,
                0.0,
                0.0,
                0.03555714047215734,
                0.0
            ],
            [
                0.07703672993080614,
                0.0,
                1.0,
                0.17885594357363918,
                0.10603652525928609,
                0.0,
                0.27715932799702686,
                0.07573162177362662,
                0.0
            ],
            [
                0.1128994041125147,
                0.0,
                0.17885594357363918,
                1.0,
                0.15539938580840199,
                0.0,
                0.153330173092272,
                0.08544255131593806,
                0.3693055559681606
            ],
            [
                0.10452252834828252,
                0.19594642272910429,
                0.10603652525928609,
                0.15539938580840199,
                1.0,
                0.0,
                0.0,
                0.18043006358932037,
                0.09787046705527558
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.23523647988396765,
                0.0,
                0.27715932799702686,
                0.153330173092272,
                0.0,
                0.0,
                1.0,
                0.06823874876393454,
                0.0
            ],
            [
                0.18751862651045043,
                0.03555714047215734,
                0.07573162177362662,
                0.08544255131593806,
                0.18043006358932037,
                0.0,
                0.06823874876393454,
                1.0,
                0.041252511235869996
            ],
            [
                0.14220799333631212,
                0.0,
                0.0,
                0.3693055559681606,
                0.09787046705527558,
                0.0,
                0.0,
                0.041252511235869996,
                1.0
            ]
        ]
    },
    "P11-2084": {
        "input_sentences": [
            "A topic model outputs a set of multinomial distributions over words for each topic.",
            "The best results, obtained by combining knowledge from wordtopic distributions with similarity measures in the original space, are also reported.",
            "Experiments on a document-aligned English-Italian Wikipedia corpus confirm that the developed methods which only use knowledge from word-topic distributions outperform methods based on similarity measures in the original word-document space.",
            "Identifying Word Translations from Comparable Corpora Using Latent Topic Models",
            "In this paper, we investigate the value of bilingual topic models, i.e., a bilingual Latent Dirichlet Allocation model for finding translations of terms in comparable corpora without using any linguistic resources.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.05965387012604221,
                0.09080648405217641,
                0.11165659277290771,
                0.12645668377664235,
                0.0
            ],
            [
                0.05965387012604221,
                1.0,
                0.24068803520448948,
                0.0,
                0.0,
                0.0
            ],
            [
                0.09080648405217641,
                0.24068803520448948,
                1.0,
                0.135495862538359,
                0.016279278290296052,
                0.0
            ],
            [
                0.11165659277290771,
                0.0,
                0.135495862538359,
                1.0,
                0.41934776010745384,
                0.0
            ],
            [
                0.12645668377664235,
                0.0,
                0.016279278290296052,
                0.41934776010745384,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "N09-2064": {
        "input_sentences": [
            "We present results on WSJ section 23 and also on the English side of a Chinese-English parallel corpus.",
            "Combining Constituent Parsers",
            "First, we propose a method of parse hybridization that recomproductions of conthereby preserving the structure of the output of the individual parsers to a greater extent.",
            "We propose three ways to improve upon existing methods for parser combination.",
            "the output of multiple parsers via parse selection or parse hybridization improves f-score over the best individual parser (Henderson and Brill, 1999; Sagae and Lavie, 2006).",
            "Third, we extend these parser combination from multiple outputs to muloutputs.",
            "Abstract",
            "Second, we propose an efficient lineartime algorithm for computing expected f-score using Minimum Bayes Risk parse selection."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                1.0,
                0.100772350706149,
                0.0,
                0.084035351827084,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.100772350706149,
                1.0,
                0.06676172584383447,
                0.2871434783593358,
                0.0,
                0.0,
                0.09072618419485903
            ],
            [
                0.0,
                0.0,
                0.06676172584383447,
                1.0,
                0.05567345686149227,
                0.2302363325336128,
                0.0,
                0.06182111235853505
            ],
            [
                0.0,
                0.084035351827084,
                0.2871434783593358,
                0.05567345686149227,
                1.0,
                0.14088356302044505,
                0.0,
                0.17726253592461566
            ],
            [
                0.0,
                0.0,
                0.0,
                0.2302363325336128,
                0.14088356302044505,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.09072618419485903,
                0.06182111235853505,
                0.17726253592461566,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "W03-1022": {
        "input_sentences": [
            "We show how information contained in the dictionary can be used as additional training data that improves accuracy in learning new nouns.",
            "Supersense Tagging Of Unknown Nouns In WordNet",
            "We present a new framework for classifying common nouns that extends namedentity classification.",
            "This framework has a number of practical advantages.",
            "Abstract",
            "We used a fixed set 26 semantic labels, which we called su- These are the labels used by lexicographers developing WordNet.",
            "We also define a more realistic evaluation procedure than cross-validation."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.07453519673902247,
                0.12876555366634165,
                0.0,
                0.0,
                0.10630026831943039,
                0.0
            ],
            [
                0.07453519673902247,
                1.0,
                0.08757924767229369,
                0.0,
                0.0,
                0.08562761556760151,
                0.0
            ],
            [
                0.12876555366634165,
                0.08757924767229369,
                1.0,
                0.12778629794308544,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.12778629794308544,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.10630026831943039,
                0.08562761556760151,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "D11-1022": {
        "input_sentences": [
            "We show how first-order logical constraints can be handled efficiently, even though the corresponding subproblems are no longer combinatorial, and report experiments in dependency parsing, with state-of-the-art results.",
            "Dual Decomposition with Many Overlapping Components",
            "Dual decomposition has been recently proposed as a way of combining complementary models, with a boost in predictive power.",
            "However, in cases where lightweight decomare not readily available due to the presence of rich features or logical constraints), the original subgradient algorithm is inefficient.",
            "Abstract",
            "We sidestep that difficulty by adopting an augmented Lagrangian method that accelerates model consensus by regularizing towards the averaged votes."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0,
                0.09397985590619753,
                0.0,
                0.0
            ],
            [
                0.0,
                1.0,
                0.2286244614433553,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.2286244614433553,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.09397985590619753,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "D07-1092": {
        "input_sentences": [
            "In particular, they drastically impact machine transla tion quality.",
            "In this study we show that ana logical learning offers as well an elegant andeffective solution to the problem of identify ing potential translations of unknown words.",
            "Translating Unknown Words by Analogical Learning",
            "Unknown words are a well-known hindranceto natural language applications.",
            "Abstract",
            "Recently, Stroppa and Yvon (2005) have shown how analogical learning alone deals nicely with morphology in differentlanguages.",
            "An easy way out commercial translation systems usually offer their users is the possibility to add unknown wordsand their translations into a dedicated lex icon."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                1.0,
                0.2186221507627906,
                0.10066864315790312,
                0.0,
                0.04360881361234533,
                0.07612390105321662
            ],
            [
                0.0,
                0.2186221507627906,
                1.0,
                0.20757333367366154,
                0.0,
                0.21299018550199683,
                0.05574469000438112
            ],
            [
                0.0,
                0.10066864315790312,
                0.20757333367366154,
                1.0,
                0.0,
                0.0,
                0.04030484466348048
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.04360881361234533,
                0.21299018550199683,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.07612390105321662,
                0.05574469000438112,
                0.04030484466348048,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "W06-3114": {
        "input_sentences": [
            "We evaluated machine translation performance for six European language pairs that participated in a shared task: translating French, German, Spanish texts to English and back",
            " Evaluation was done automatically using the BLEU score and manually on fluency and adequacy"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0
            ],
            [
                0.0,
                1.0
            ]
        ]
    },
    "D09-1161": {
        "input_sentences": [
            "The proposed framework leverages on the strengths of previous system combination and re-ranking techniques in parsing by integrating them into a linear model.",
            "Our experiments are carried out on both the Chinese and English Penn Treebank syntactic parsing task by combining two stateof-the-art parsing models, a head-driven lexicalized model and a latent-annotation-based un-lexicalized model.",
            "As a result, it is able to fully utilize both the logarithm of the probability of each k-best parse tree from each individual parser and any additional useful features.",
            "Abstract",
            "Experimental results show that our F-Scores of 85.45 on Chinese and 92.62 on English outperform the previously best-reported systems by 1.21 and 0.52, respectively.",
            "For feature weight tuning, we compare the simulated-annealing algorithm and the perceptron algorithm.",
            "In this paper, we propose a linear model-based general framework to combine k-best parse outputs from multiple parsers.",
            "K-Best Combination of Syntactic Parsers"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.15337456676110311,
                0.0,
                0.0,
                0.0,
                0.0,
                0.1856362919841347,
                0.13794309047552905
            ],
            [
                0.15337456676110311,
                1.0,
                0.0,
                0.0,
                0.07107738255780964,
                0.0,
                0.10886951279464328,
                0.08919846677445885
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.027935574270317457,
                0.0,
                0.09443731540768514,
                0.07011542360467947
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.07107738255780964,
                0.027935574270317457,
                0.0,
                1.0,
                0.0,
                0.03130257991692562,
                0.06384113401695046
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.1856362919841347,
                0.10886951279464328,
                0.09443731540768514,
                0.0,
                0.03130257991692562,
                0.0,
                1.0,
                0.21581748242594959
            ],
            [
                0.13794309047552905,
                0.08919846677445885,
                0.07011542360467947,
                0.0,
                0.06384113401695046,
                0.0,
                0.21581748242594959,
                1.0
            ]
        ]
    },
    "W12-3401": {
        "input_sentences": [
            "A distributional thesaurus is created from a large text corpus and used for distributional clustering and WordNet automatic sense ranking.",
            "We obtain improvements in parsing accuracy with some lexical generalization configurations in experiments run on the French Treebank and two out-of-domain treebanks, with slightly better performance for the probabilistic lexical generalization approach compared to the standard single-mapping approach.",
            "Probabilistic lexical information is introduced into parser feature vectors by modifying the weights of lexical features.",
            "Abstract",
            "The standard approach for lexical generalization in parsing is to map a word to a single generalized class, either replacing the word with the class or adding a new feature for the class.",
            "We use a richer framework that allows for probabilistic generalization, with a word represented as a probability distribution over a space of generalized classes: lemmas, clusters, or synsets.",
            "Probabilistic Lexical Generalization for French Dependency Parsing",
            "This paper investigates the impact on French dependency parsing of lexical generalization methods beyond lemmatization and morphological analysis."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                1.0,
                0.11564072190110067,
                0.0,
                0.21102351400982255,
                0.05847378571868955,
                0.33776268755276084,
                0.15290416103196583
            ],
            [
                0.0,
                0.11564072190110067,
                1.0,
                0.0,
                0.09651174109939835,
                0.03496231996318872,
                0.20681308013441216,
                0.06766825531076781
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.21102351400982255,
                0.09651174109939835,
                0.0,
                1.0,
                0.1428683436312548,
                0.14028191663997502,
                0.07518980893318498
            ],
            [
                0.0,
                0.05847378571868955,
                0.03496231996318872,
                0.0,
                0.1428683436312548,
                1.0,
                0.11700916333218743,
                0.027551959470116648
            ],
            [
                0.0,
                0.33776268755276084,
                0.20681308013441216,
                0.0,
                0.14028191663997502,
                0.11700916333218743,
                1.0,
                0.4549621569122109
            ],
            [
                0.0,
                0.15290416103196583,
                0.06766825531076781,
                0.0,
                0.07518980893318498,
                0.027551959470116648,
                0.4549621569122109,
                1.0
            ]
        ]
    },
    "W11-1310": {
        "input_sentences": [
            "We propose an exemplar-based model which is designed to handle polysemy.",
            "Most models represent each word as a single prototype-based vector without addressing polysemy.",
            "Exemplar-Based Word-Space Model for Compositionality Detection: Shared Task System Description",
            "In this paper, we highlight the problems of polysemy in word space models of compositionality detection.",
            "This model is tested for compositionality detection and it is found to outperform existing prototype-based models.",
            "We have participated in the shared task (Biemann and Giesbrecht, 2011) and our best performing exemplar-model is ranked first in two types of evaluations and second in two other evaluations.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.15767928124582833,
                0.23929062456439046,
                0.09256765269503545,
                0.14242575501716828,
                0.1035278478154242,
                0.0
            ],
            [
                0.15767928124582833,
                1.0,
                0.14244395413538447,
                0.23636084851403488,
                0.25107584531250565,
                0.0,
                0.0
            ],
            [
                0.23929062456439046,
                0.14244395413538447,
                1.0,
                0.36532528554236937,
                0.29935522118777713,
                0.23950191783717967,
                0.0
            ],
            [
                0.09256765269503545,
                0.23636084851403488,
                0.36532528554236937,
                1.0,
                0.24836383725981231,
                0.0,
                0.0
            ],
            [
                0.14242575501716828,
                0.25107584531250565,
                0.29935522118777713,
                0.24836383725981231,
                1.0,
                0.039795697721812656,
                0.0
            ],
            [
                0.1035278478154242,
                0.0,
                0.23950191783717967,
                0.0,
                0.039795697721812656,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "A00-2030": {
        "input_sentences": [
            "In this paper we report adapting a lexic al ized, probabilistic context-free parser to information extraction and evaluate this new technique on MUC-7 template elements and template relations.",
            "A Novel Use of Statistical Parsing to Extract Information from Text",
            "Abstract",
            "Since 1995, a few statistical parsing algorithms have demonstrated a breakthrough in parsing accuracy, as measured against the UPenn TREEBANK as a gold standard."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.05519964129862864,
                0.0,
                0.0
            ],
            [
                0.05519964129862864,
                1.0,
                0.0,
                0.21268347212012056
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.21268347212012056,
                0.0,
                1.0
            ]
        ]
    },
    "W12-3134": {
        "input_sentences": [
            "The main con",
            "We present Joshua 4.0, the newest version of our open-source decoder for parsing-based statistical machine translation.",
            "Abstract",
            "Joshua 4.0: Packing, PRO, and Paraphrases"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                1.0,
                0.0,
                0.09581273984464105
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.09581273984464105,
                0.0,
                1.0
            ]
        ]
    },
    "W04-1506": {
        "input_sentences": [
            "We present the Dependency Parser, for the linguistic processing of Basque, which can serve as a representative of agglutinative languages that are also characterized by the free order of its constituents.",
            "The Dependency syntactic model is applied to establish the dependency-based grammatical relations between the components within the clause.",
            "This scheme was used both to the manual tagging of the corpus and to develop the parser.",
            "Abstract",
            "Previous to the completion of the grammar for the dependency parsing, the design of the Dependency Structure-based Scheme had to be accomplished; we concentrated on issues that must be resolved by any practical system that uses such models.",
            "Such a deep analysis is used to improve the output of the shallow parsing where syntactic structure ambiguity is not fully and explicitly resolved.",
            "Towards A Dependency Parser For Basque",
            "The manually tagged corpus has been used to evaluate the accuracy of the parser.",
            "We have evaluated the application of the grammar to corpus, measuring the linking of the verb with its dependents, with satisfactory results."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.07473384469558378,
                0.05203995729482315,
                0.0,
                0.06143018863703928,
                0.0,
                0.3519702992057696,
                0.050665725353673724,
                0.0
            ],
            [
                0.07473384469558378,
                1.0,
                0.0,
                0.0,
                0.19490563731238153,
                0.06646766158434347,
                0.2123299746149681,
                0.0,
                0.0
            ],
            [
                0.05203995729482315,
                0.0,
                1.0,
                0.0,
                0.08076941908715798,
                0.06997941984624487,
                0.14785326322207504,
                0.2800714983916237,
                0.07765188176513191
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.06143018863703928,
                0.19490563731238153,
                0.08076941908715798,
                0.0,
                1.0,
                0.16390650070343799,
                0.17453230791250895,
                0.0,
                0.06062567271503728
            ],
            [
                0.0,
                0.06646766158434347,
                0.06997941984624487,
                0.0,
                0.16390650070343799,
                1.0,
                0.0,
                0.06813145610886143,
                0.0
            ],
            [
                0.3519702992057696,
                0.2123299746149681,
                0.14785326322207504,
                0.0,
                0.17453230791250895,
                0.0,
                1.0,
                0.1439488657651009,
                0.0
            ],
            [
                0.050665725353673724,
                0.0,
                0.2800714983916237,
                0.0,
                0.0,
                0.06813145610886143,
                0.1439488657651009,
                1.0,
                0.07560130944034218
            ],
            [
                0.0,
                0.0,
                0.07765188176513191,
                0.0,
                0.06062567271503728,
                0.0,
                0.0,
                0.07560130944034218,
                1.0
            ]
        ]
    },
    "P04-1006": {
        "input_sentences": [
            "We present a technique that improves the efficiency of word-lattice parsing as used in speech recognition language modeling.",
            "Our technique applies a probabilistic parser iteratively where on each iteration it focuses on a different subset of the wordlattice.",
            "Attention Shifting For Parsing Speech",
            "This attention-shifting technique provides a six-times increase in speed (measured as the number of parser analyses evaluated) while performing equivalently when used as the first-stage of a multi-stage parsing-based language model.",
            "Abstract",
            "The parser\u2019s attention is shifted towards word-lattice subsets for which there are few or no syntactic analyses posited."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.052451732967176284,
                0.24856154671058772,
                0.16620583337924102,
                0.0,
                0.1667820723808189
            ],
            [
                0.052451732967176284,
                1.0,
                0.0,
                0.0705518201881785,
                0.0,
                0.060629692183762206
            ],
            [
                0.24856154671058772,
                0.0,
                1.0,
                0.23673571205965177,
                0.0,
                0.11956851162506964
            ],
            [
                0.16620583337924102,
                0.0705518201881785,
                0.23673571205965177,
                1.0,
                0.0,
                0.1360358069787404
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.1667820723808189,
                0.060629692183762206,
                0.11956851162506964,
                0.1360358069787404,
                0.0,
                1.0
            ]
        ]
    },
    "P10-1155": {
        "input_sentences": [
            "All Words Domain Adapted WSD: Finding a Middle Ground between Supervision and Unsupervision",
            "Finally, our approach is not restricted to any specific set of target words, a departure from a commonly observed practice in domain specific WSD.",
            "Many supervised WSD systems have been built, but the effort of creatthe training corpus sense corpora has always been a matter of concern.",
            "Therefore, attempts have been made to develop unsupervised and knowledge based techniques for WSD which do not need sense marked corpora.",
            "Our research reported here proposes to stick to the supervised approach, but with far less demand on annotation.",
            "We show that if we have ANY sense marked corpora, be it from mixed domain or a specific domain, a small amount of annotation in ANY other domain can deliver the goods almost as if exhaustive sense marking were available in that domain.",
            "Accuracy figures close to self domain training lend credence to the viability of our approach.",
            "We have tested our approach across Tourism and Health domain corpora, using also the well known mixed domain SemCor corpus.",
            "Abstract",
            "Our contribution thus lies in finding a convenient middle ground between pure supervised and pure unsupervised WSD.",
            "In spite of decades of research on word sense disambiguation (WSD), all-words general purpose WSD has remained a distant goal.",
            "However such approaches have not proved effective, since they typically do not better Wordnet first sense baseline accuracy."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.14048847388665534,
                0.041111598687947774,
                0.042459120802652274,
                0.0,
                0.14504778654429226,
                0.051892857916963187,
                0.09501268680501822,
                0.0,
                0.30171018549577344,
                0.1374731167388025,
                0.0
            ],
            [
                0.14048847388665534,
                1.0,
                0.0293961470890394,
                0.03035966978223983,
                0.04748555841485989,
                0.20403717898389143,
                0.08223287197614779,
                0.10925030967815741,
                0.0,
                0.027096527476643813,
                0.09829780620103273,
                0.0
            ],
            [
                0.041111598687947774,
                0.0293961470890394,
                1.0,
                0.13033900878380153,
                0.06916927035065583,
                0.0978627986892229,
                0.08424098743137524,
                0.12560239102484771,
                0.0,
                0.089378628086321,
                0.0968517526162548,
                0.04408040859559624
            ],
            [
                0.042459120802652274,
                0.03035966978223983,
                0.13033900878380153,
                1.0,
                0.0,
                0.16186626878986732,
                0.0,
                0.05007142579923426,
                0.0,
                0.1090498763343432,
                0.10002627957855831,
                0.04552523991579468
            ],
            [
                0.0,
                0.04748555841485989,
                0.06916927035065583,
                0.0,
                1.0,
                0.06518266607397166,
                0.058641417306959445,
                0.053684445606215055,
                0.0,
                0.06375825474403,
                0.07778257710835895,
                0.0
            ],
            [
                0.14504778654429226,
                0.20403717898389143,
                0.0978627986892229,
                0.16186626878986732,
                0.06518266607397166,
                1.0,
                0.12807962900907519,
                0.3268671179029049,
                0.0,
                0.0,
                0.053400312515239357,
                0.06482859309149283
            ],
            [
                0.051892857916963187,
                0.08223287197614779,
                0.08424098743137524,
                0.0,
                0.058641417306959445,
                0.12807962900907519,
                1.0,
                0.1349166612884673,
                0.0,
                0.0,
                0.0,
                0.08974028504522838
            ],
            [
                0.09501268680501822,
                0.10925030967815741,
                0.12560239102484771,
                0.05007142579923426,
                0.053684445606215055,
                0.3268671179029049,
                0.1349166612884673,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.30171018549577344,
                0.027096527476643813,
                0.089378628086321,
                0.1090498763343432,
                0.06375825474403,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.055805920451512316,
                0.0
            ],
            [
                0.1374731167388025,
                0.09829780620103273,
                0.0968517526162548,
                0.10002627957855831,
                0.07778257710835895,
                0.053400312515239357,
                0.0,
                0.0,
                0.0,
                0.055805920451512316,
                1.0,
                0.03868003063301379
            ],
            [
                0.0,
                0.0,
                0.04408040859559624,
                0.04552523991579468,
                0.0,
                0.06482859309149283,
                0.08974028504522838,
                0.0,
                0.0,
                0.0,
                0.03868003063301379,
                1.0
            ]
        ]
    },
    "N12-1007": {
        "input_sentences": [
            "Standard entity clustering systems commonly rely on mention (string) matching, syntactic features, and linguistic resources like English WordNet.",
            "Our approach extends standard clustering algorithms with cross-lingual mention and context similarity measures.",
            "When co-referent text mentions appear in different languages, these techniques cannot be easily applied.",
            "On an Arabic-English corpus that contains seven different text genres, our best model yields a 24.3% F1 gain over the baseline.",
            "Consequently, we develop new methods for clustering text mentions across documents and languages simultaneously, producing cross-lingual entity clusters.",
            "Entity Clustering Across Languages",
            "Abstract",
            "Crucially, we do not assume a pre-existing entity list (knowledge base), so entity characteristics are unknown."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.1596108733100837,
                0.0,
                0.05045978588648968,
                0.06234765327247069,
                0.18714583513156666,
                0.0,
                0.06619334939289764
            ],
            [
                0.1596108733100837,
                1.0,
                0.0,
                0.0,
                0.17215896679745854,
                0.1149917206030925,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                1.0,
                0.12029029721638025,
                0.1852345935021228,
                0.16632280815500608,
                0.0,
                0.0
            ],
            [
                0.05045978588648968,
                0.0,
                0.12029029721638025,
                1.0,
                0.04052766516095265,
                0.0,
                0.0,
                0.0
            ],
            [
                0.06234765327247069,
                0.17215896679745854,
                0.1852345935021228,
                0.04052766516095265,
                1.0,
                0.3331500977760966,
                0.0,
                0.07139725761794005
            ],
            [
                0.18714583513156666,
                0.1149917206030925,
                0.16632280815500608,
                0.0,
                0.3331500977760966,
                1.0,
                0.0,
                0.21430958025990043
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.06619334939289764,
                0.0,
                0.0,
                0.0,
                0.07139725761794005,
                0.21430958025990043,
                0.0,
                1.0
            ]
        ]
    },
    "D07-1026": {
        "input_sentences": [
            "We demonstrate the effectiveness of our technique largelysurpassing both the random and most fre quent baselines and outperforming current state-of-the-art unsupervised approaches ona benchmark ontology available in the liter ature.",
            "Instance Based Lexical Entailment",
            "The approach is fully unsupervised and based on kernel methods.",
            "Instance Based Lexical Entailment for Ontology Population",
            "Abstract",
            "In this paper we propose an instance based method for lexical entailment and apply it to automatic ontology population from text."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.06854846473934505,
                0.06385737633495707,
                0.0,
                0.03662634384627384
            ],
            [
                0.0,
                1.0,
                0.11736533237485014,
                0.7800429793267447,
                0.0,
                0.44740520227188313
            ],
            [
                0.06854846473934505,
                0.11736533237485014,
                1.0,
                0.09155000353535173,
                0.0,
                0.052509860270876604
            ],
            [
                0.06385737633495707,
                0.7800429793267447,
                0.09155000353535173,
                1.0,
                0.0,
                0.5735648087725097
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.03662634384627384,
                0.44740520227188313,
                0.052509860270876604,
                0.5735648087725097,
                0.0,
                1.0
            ]
        ]
    },
    "P05-1061": {
        "input_sentences": [
            "Simple Algorithms For Complex Relation Extraction With Applications To Biomedical IE",
            "We present here a simple two-stage method for extracting complex relations between named entities in text.",
            "complex relation is any relation in which some of the arguments may be be unspecified.",
            "Abstract",
            "We evaluate the new method against a standard baseline for extracting genomic variation relations from biomedical text.",
            "The first stage creates a graph from pairs of entities that are likely to be related, and the second stage scores maximal cliques in that graph as potential complex relation instances."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.16946911700792627,
                0.27879292819665347,
                0.0,
                0.09659496656536723,
                0.08565944892116031
            ],
            [
                0.16946911700792627,
                1.0,
                0.06411348975645113,
                0.0,
                0.33086182423769284,
                0.20906479552219825
            ],
            [
                0.27879292819665347,
                0.06411348975645113,
                1.0,
                0.0,
                0.0,
                0.14870531685831168
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.09659496656536723,
                0.33086182423769284,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.08565944892116031,
                0.20906479552219825,
                0.14870531685831168,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P11-2067": {
        "input_sentences": [
            "Speculations as to cause have suggested the parser, the data, or other factors.",
            "An early work proposing this idea showed improved translation performance, but subsequent work has had mixed results.",
            "Clause Restructuring For SMT Not Absolutely Helpful",
            "Abstract",
            "There are a number of systems that use a syntax-based reordering step prior to phrasebased statistical MT.",
            "We systematically investigate possible factors to give an initial answer to the question: Under what conditions does this use of syntax help PSMT?"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.08144334807210837
            ],
            [
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.12061682783202671
            ],
            [
                0.08144334807210837,
                0.0,
                0.0,
                0.0,
                0.12061682783202671,
                1.0
            ]
        ]
    },
    "N10-1035": {
        "input_sentences": [
            "The use of well-nested linear context-free rewriting systems has been empirically motivated for modeling of the syntax of languages with discontinuous constituents or relatively free word order.",
            "Abstract",
            "Our result is obtained through a linear space construction of a binary normal form for the grammar at hand.",
            "We present a chart-based parsing algorithm that asymptotically improves the known running time upper bound for this class of rewriting systems.",
            "Linear Context-Free Rewriting Systems",
            "Efficient Parsing of Well-Nested Linear Context-Free Rewriting Systems"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.029593285568207332,
                0.04948867524055049,
                0.45178353923139836,
                0.3899263656413529
            ],
            [
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.029593285568207332,
                0.0,
                1.0,
                0.0,
                0.08108827925146052,
                0.05512248833033561
            ],
            [
                0.04948867524055049,
                0.0,
                0.0,
                1.0,
                0.13560344654673268,
                0.1802383229236981
            ],
            [
                0.45178353923139836,
                0.0,
                0.08108827925146052,
                0.13560344654673268,
                1.0,
                0.6797836732901541
            ],
            [
                0.3899263656413529,
                0.0,
                0.05512248833033561,
                0.1802383229236981,
                0.6797836732901541,
                1.0
            ]
        ]
    },
    "D07-1122": {
        "input_sentences": [
            "The parser first identifies dependencies using a deterministic parsing method and then labels those dependencies as a sequence labeling problem.",
            "A Two-Stage Parser for Multilingual Dependency Parsing",
            "Then we present evaluation results and error analyses focusing on Chinese.",
            "We describe the features used ineach stage.",
            "For four languages with different values of ROOT, we design some spe cial features for the ROOT labeler.",
            "We present a two-stage multilingual de pendency parsing system submitted to the Multilingual Track of CoNLL-2007.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.17844733462538206,
                0.0,
                0.0,
                0.0,
                0.045083185753217195,
                0.0
            ],
            [
                0.17844733462538206,
                1.0,
                0.0,
                0.15314452174471074,
                0.0,
                0.42163781359175756,
                0.0
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.08665635549866692,
                0.0
            ],
            [
                0.0,
                0.15314452174471074,
                0.0,
                1.0,
                0.112795770076881,
                0.09164609671121099,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.112795770076881,
                1.0,
                0.0,
                0.0
            ],
            [
                0.045083185753217195,
                0.42163781359175756,
                0.08665635549866692,
                0.09164609671121099,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P14-1078": {
        "input_sentences": [
            "Our approach integrates domain specific parsing and typing systems, and can utilize labeled as well as unlabeled examples.",
            "In this paper, we present a manifold model for medical relation extraction.",
            "Abstract",
            "Medical Relation Extraction with Manifold Models",
            "Relation Extraction with Manifold Models",
            "Our model is built upon a medical corpus containing 80M sentences (11 gigabyte text) and designed to accurately and efficiently detect the key medical relations that can facilitate clinical decision making.",
            "Effectiveness of our model is demonstrated both theoretically with a proof to show that the solution is a closed-form solution and experimentally with positive results in experiments.",
            "To provide users with more flexibility, we also take label weight into consideration."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                1.0,
                0.0,
                0.582553259980236,
                0.4846129411178613,
                0.16086053220160193,
                0.06388398970868361,
                0.0
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.582553259980236,
                0.0,
                1.0,
                0.9015750672636621,
                0.13781649408064703,
                0.0,
                0.0
            ],
            [
                0.0,
                0.4846129411178613,
                0.0,
                0.9015750672636621,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.16086053220160193,
                0.0,
                0.13781649408064703,
                0.0,
                1.0,
                0.030226480888060292,
                0.0
            ],
            [
                0.0,
                0.06388398970868361,
                0.0,
                0.0,
                0.0,
                0.030226480888060292,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "C10-1135": {
        "input_sentences": [
            "As tokenization is usually ambiguous for many natural languages such as Chineseand Korean, tokenization errors might po tentially introduce translation mistakes fortranslation systems that rely on 1-best tokenizations.",
            "By integrat ing tokenization and translation features in a discriminative framework, our jointdecoder outperforms the baseline trans lation systems using 1-best tokenizationsand lattices significantly on both ChineseEnglish and Korean-Chinese tasks.",
            "Abstract",
            "Taking a sequence of atomic units that can be combined to form words in different ways as input, our joint decoder produces a tokenization on the source side and a translation on thetarget side simultaneously.",
            "While using lattices to offer more alternatives to translation systems have elegantly alleviated this prob lem, we take a further step to tokenize and translate jointly.",
            "Interestingly, as a tokenizer, our joint de coder achieves significant improvements over monolingual Chinese tokenizers.",
            "Joint Tokenization and Translation"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.1663014165171296,
                0.0,
                0.06391502530143615,
                0.05574790285309895,
                0.0,
                0.23722522559572537
            ],
            [
                0.1663014165171296,
                1.0,
                0.0,
                0.038646829246552925,
                0.14431951133332674,
                0.05266814465095064,
                0.14344049373891105
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.06391502530143615,
                0.038646829246552925,
                0.0,
                1.0,
                0.02075227549774136,
                0.04128717113877712,
                0.2694276088933261
            ],
            [
                0.05574790285309895,
                0.14431951133332674,
                0.0,
                0.02075227549774136,
                1.0,
                0.0,
                0.0770235670463815
            ],
            [
                0.0,
                0.05266814465095064,
                0.0,
                0.04128717113877712,
                0.0,
                1.0,
                0.1532403130783967
            ],
            [
                0.23722522559572537,
                0.14344049373891105,
                0.0,
                0.2694276088933261,
                0.0770235670463815,
                0.1532403130783967,
                1.0
            ]
        ]
    },
    "D07-1030": {
        "input_sentences": [
            "This paper proposes a method using the ex isting Rule-based Machine Translation (RBMT) system as a black box to produce synthetic bilingual corpus, which will be used as training data for the Statistical Ma chine Translation (SMT) system.",
            "With the synthetic bilingual corpus, we can build an SMT system even if there is no real bilingual corpus.",
            "We use the existing RBMT system to translate the monolingual corpus into synthetic bilingual corpus.",
            "In our experi ments using BLEU as a metric, the system achieves a relative improvement of 11.7% over the best RBMT system that is used to produce the synthetic bilingual corpora.",
            "Using RBMT Systems to Produce Bilingual Corpus for SMT",
            "Abstract",
            "We also interpolate the model trained on a real bilingual corpus and the models trained on the synthetic bilingual corpora.",
            "The interpolated model achieves an abso lute improvement of 0.0245 BLEU score (13.1% relative) as compared with the in dividual model trained on the real bilingual corpus."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.1797506077706563,
                0.12289097241642061,
                0.1682720035135714,
                0.276262219830118,
                0.0,
                0.07145588475044208,
                0.02423705167464986
            ],
            [
                0.1797506077706563,
                1.0,
                0.345328104725285,
                0.1046839129335441,
                0.37685661536350357,
                0.0,
                0.36786819078708854,
                0.17821371169492073
            ],
            [
                0.12289097241642061,
                0.345328104725285,
                1.0,
                0.11269863862022626,
                0.24472821928760635,
                0.0,
                0.17524589575995328,
                0.07345877166237355
            ],
            [
                0.1682720035135714,
                0.1046839129335441,
                0.11269863862022626,
                1.0,
                0.26644653477996894,
                0.0,
                0.14882191892398924,
                0.23013415814701876
            ],
            [
                0.276262219830118,
                0.37685661536350357,
                0.24472821928760635,
                0.26644653477996894,
                1.0,
                0.0,
                0.12316760494894012,
                0.062079790067758406
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.07145588475044208,
                0.36786819078708854,
                0.17524589575995328,
                0.14882191892398924,
                0.12316760494894012,
                0.0,
                1.0,
                0.3576808029038223
            ],
            [
                0.02423705167464986,
                0.17821371169492073,
                0.07345877166237355,
                0.23013415814701876,
                0.062079790067758406,
                0.0,
                0.3576808029038223,
                1.0
            ]
        ]
    },
    "P11-1061": {
        "input_sentences": [
            "Our method does not assume any knowledge about the target language (in particular no tagging dictionary is assumed), making it applicable to a wide array of resource-poor languages.",
            "We describe a novel approach for inducing unsupervised part-of-speech taggers for languages that have no labeled training data, but have translated text in a resource-rich language.",
            "Abstract",
            "We use graph-based label propagation for cross-lingual knowledge transfer and use the projected labels as features in an unsupervised model (Berg- Kirkpatrick et al., 2010).",
            "Across eight European languages, our approach results in an average absolute improvement of 10.4% over a state-of-the-art baseline, and 16.7% over vanilla hidden Markov models induced with the Expectation Maximization algorithm.",
            "Unsupervised Part-of-Speech Tagging with Bilingual Graph-Based Projections"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.13169363614263954,
                0.0,
                0.03813501822591,
                0.028120434072375446,
                0.07593843807864022
            ],
            [
                0.13169363614263954,
                1.0,
                0.0,
                0.029767875056616735,
                0.07399922069329141,
                0.14243875773907877
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.03813501822591,
                0.029767875056616735,
                0.0,
                1.0,
                0.0,
                0.17722115273305802
            ],
            [
                0.028120434072375446,
                0.07399922069329141,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.07593843807864022,
                0.14243875773907877,
                0.0,
                0.17722115273305802,
                0.0,
                1.0
            ]
        ]
    },
    "W06-2932": {
        "input_sentences": [
            "The first stage based on the unlabeled dependency parsing models described by McDonald and Pereira (2006) augmented with morphological features for a subset of the languages.",
            "The second stage takes the output from the first and labels all the edges in the dependency graph with appropriate syntactic categories using a globally trained sequence classifier over components of the graph.",
            "present a two-stage multilingual pendency parser and evaluate it on 13 diverse languages.",
            "Multilingual Dependency Analysis with a Two-Stage Discriminative Parser",
            "Abstract",
            "We report results on the CoNLL-X shared task (Buchholz et al., 2006) data sets and present an error analysis."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.052771583978781796,
                0.10634825651019743,
                0.11673273974410864,
                0.0,
                0.05134397122608517
            ],
            [
                0.052771583978781796,
                1.0,
                0.03056413098443932,
                0.0976442128844634,
                0.0,
                0.0
            ],
            [
                0.10634825651019743,
                0.03056413098443932,
                1.0,
                0.32594717748762453,
                0.0,
                0.07023371956586016
            ],
            [
                0.11673273974410864,
                0.0976442128844634,
                0.32594717748762453,
                1.0,
                0.0,
                0.09500267527973784
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.05134397122608517,
                0.0,
                0.07023371956586016,
                0.09500267527973784,
                0.0,
                1.0
            ]
        ]
    },
    "D12-1129": {
        "input_sentences": [
            "A New Minimally-Supervised Framework for Domain Word Sense Disambiguation",
            "We present a new minimally-supervised framework for performing domain-driven Word Sense Disambiguation (WSD).",
            "The acquired glosses are then used as the sense inventory for fullyunsupervised domain WSD.",
            "Our experiments, on new and gold-standard datasets, show that our wide-coverage framework enables highperformance results on dozens of domains at a coarse and fine-grained level.",
            "Abstract",
            "Glossaries for several domains are iteratively acquired from the Web by means of a bootstrapping technique."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.7459445501008777,
                0.17788609254768248,
                0.11296325392873985,
                0.0,
                0.0
            ],
            [
                0.7459445501008777,
                1.0,
                0.22577332827780336,
                0.08426432362980504,
                0.0,
                0.0
            ],
            [
                0.17788609254768248,
                0.22577332827780336,
                1.0,
                0.0,
                0.0,
                0.09882405606522016
            ],
            [
                0.11296325392873985,
                0.08426432362980504,
                0.0,
                1.0,
                0.0,
                0.0627563784199212
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.09882405606522016,
                0.0627563784199212,
                0.0,
                1.0
            ]
        ]
    },
    "D11-1039": {
        "input_sentences": [
            "Experiments on DARPA Communicator conversational logs demonstrate effective learning, despite requiring no explicit meaning annotations.",
            "In this paper, we present an approach for using conversational interactions of this type to induce semantic parsers.",
            "Bootstrapping Semantic Parsers from Conversations",
            "Instead, we model meaning with latent variables, and introduce a loss function to measure how well potential meanings match the conversation.",
            "When something goes wrong, a system can ask for clarification, rewording, or otherwise redirect the interaction to achieve its goals.",
            "This loss drives the overall learning approach, which induces a weighted CCG grammar that could be used to automatically bootstrap the semantic analysis component in a complete dialog system.",
            "Abstract",
            "We demonstrate learning without any explicit annotation of the meanings of user utterances.",
            "Conversations provide rich opportunities for interactive, continuous learning."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0721147399967092,
                0.0,
                0.06097585719412181,
                0.0,
                0.03196455353824917,
                0.0,
                0.23335430744010724,
                0.050624512432095356
            ],
            [
                0.0721147399967092,
                1.0,
                0.2468899149563858,
                0.0,
                0.0,
                0.10839636743737886,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.2468899149563858,
                1.0,
                0.0,
                0.0,
                0.07982919461584698,
                0.0,
                0.0,
                0.16724133387954587
            ],
            [
                0.06097585719412181,
                0.0,
                0.0,
                1.0,
                0.0,
                0.05219501452842094,
                0.0,
                0.08682102967552979,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.03196455353824917,
                0.10839636743737886,
                0.07982919461584698,
                0.05219501452842094,
                0.0,
                1.0,
                0.0,
                0.04551302071038251,
                0.043334317605004016
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.23335430744010724,
                0.0,
                0.0,
                0.08682102967552979,
                0.0,
                0.04551302071038251,
                0.0,
                1.0,
                0.07208217314901301
            ],
            [
                0.050624512432095356,
                0.0,
                0.16724133387954587,
                0.0,
                0.0,
                0.043334317605004016,
                0.0,
                0.07208217314901301,
                1.0
            ]
        ]
    },
    "P11-1060": {
        "input_sentences": [
            "Learning Dependency-Based Compositional Semantics",
            "Compositional question answering begins by mapping questions to logical forms, but training a semantic parser to perform this mapping typically requires the costly annotation of the target logical forms.",
            "In tackling this challenging learning problem, we introduce a new semantic representation which highlights a parallel between dependency syntax and efficient evaluation of logical forms.",
            "Abstract",
            "On two stansemantic parsing benchmarks our system obtains the highest published accuracies, despite requiring no annotated logical forms.",
            "In this paper, we learn to map questions to answers via latent logical forms, which are induced automatically from question-answer pairs."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.07596271981172245,
                0.18113882241046905,
                0.0,
                0.0,
                0.0
            ],
            [
                0.07596271981172245,
                1.0,
                0.12715772395210728,
                0.0,
                0.09743181104032199,
                0.18750850537280417
            ],
            [
                0.18113882241046905,
                0.12715772395210728,
                1.0,
                0.0,
                0.05808337155681907,
                0.05716975546285532
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.09743181104032199,
                0.05808337155681907,
                0.0,
                1.0,
                0.06472779823155181
            ],
            [
                0.0,
                0.18750850537280417,
                0.05716975546285532,
                0.0,
                0.06472779823155181,
                1.0
            ]
        ]
    },
    "W07-1712": {
        "input_sentences": [
            "We show that it is feasible to boost performance by considering several heuristics and patterns acquired from the Web data.",
            "In this paper, we discuss named entity recognition for Ukrainian language, which is a Slavonic language with a rich morphology.",
            "Named Entity Recognition for Ukrainian: A Resource-Light Approach",
            "The approach we follow uses a restricted number of features.",
            "Abstract",
            "Kruislaan 419, 1098VA the katrenko@science.uva.nl Pieter HCSL, University of Kruislaan 419, 1098VA the pitera@science.uva.nl Abstract Named entity recognition (NER) is a subtask of information extraction (IE) which can be used further on for different purposes."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                1.0,
                0.2894979496097446,
                0.0,
                0.0,
                0.06987810201070326
            ],
            [
                0.0,
                0.2894979496097446,
                1.0,
                0.12909823740658932,
                0.0,
                0.1065040256857209
            ],
            [
                0.0,
                0.0,
                0.12909823740658932,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.13283122300642156
            ],
            [
                0.0,
                0.06987810201070326,
                0.1065040256857209,
                0.0,
                0.13283122300642156,
                1.0
            ]
        ]
    },
    "D10-1025": {
        "input_sentences": [
            "The OPCA method is shown to perform best.",
            "The largest differences in performance are observed on the task of retrieval when the documents are only comparable and not parallel.",
            "We use discriminative training to create a projection of documents from multiple languages into a single translingual vector space.",
            "We evaluate these algorithms on two tasks: parallel document retrieval for Wikipedia and Europarl documents, and cross-lingual text classification on Reuters.",
            "Each model is then made discriminative by encouraging comparable document pairs to have similar vector representations.",
            "We explore two variants to create these projections: Oriented Principal Component Analysis (OPCA) and Coupled Probabilistic Latent Semantic Analysis (CPLSA).",
            "Both of these variants start with a basic model of documents (PCA and PLSA).",
            "Abstract",
            "The two discriminative variants, OPCA and CPLSA, significantly outperform their corresponding baselines.",
            "Translingual Document Representations from Discriminative Projections",
            "Representing documents by vectors that are independent of language enhances machine translation and multilingual text categorization."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.06756570824571763,
                0.0,
                0.0,
                0.10526845390267081,
                0.0,
                0.0
            ],
            [
                0.0,
                1.0,
                0.04228082204552288,
                0.1910467552660308,
                0.10087795228428624,
                0.0,
                0.056213235916515183,
                0.0,
                0.0,
                0.0,
                0.04209733192635548
            ],
            [
                0.0,
                0.04228082204552288,
                1.0,
                0.033385554740046675,
                0.14180952921521559,
                0.058992359502842685,
                0.04884859070110403,
                0.0,
                0.05677266826327667,
                0.2085528481298521,
                0.036582048753306146
            ],
            [
                0.0,
                0.1910467552660308,
                0.033385554740046675,
                1.0,
                0.06160668289426111,
                0.0,
                0.04438679226211262,
                0.0,
                0.0,
                0.09060215665712985,
                0.09926870018873032
            ],
            [
                0.0,
                0.10087795228428624,
                0.14180952921521559,
                0.06160668289426111,
                1.0,
                0.0,
                0.11654801310615485,
                0.0,
                0.068192016813507,
                0.3702668234152687,
                0.0
            ],
            [
                0.06756570824571763,
                0.0,
                0.058992359502842685,
                0.0,
                0.0,
                1.0,
                0.06066068689751535,
                0.0,
                0.18921267671878295,
                0.10420791482068457,
                0.0
            ],
            [
                0.0,
                0.056213235916515183,
                0.04884859070110403,
                0.04438679226211262,
                0.11654801310615485,
                0.06066068689751535,
                1.0,
                0.0,
                0.09451032022268739,
                0.0,
                0.04863659780940353
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.10526845390267081,
                0.0,
                0.05677266826327667,
                0.0,
                0.068192016813507,
                0.18921267671878295,
                0.09451032022268739,
                0.0,
                1.0,
                0.10028690881973341,
                0.0
            ],
            [
                0.0,
                0.0,
                0.2085528481298521,
                0.09060215665712985,
                0.3702668234152687,
                0.10420791482068457,
                0.0,
                0.0,
                0.10028690881973341,
                1.0,
                0.0
            ],
            [
                0.0,
                0.04209733192635548,
                0.036582048753306146,
                0.09926870018873032,
                0.0,
                0.0,
                0.04863659780940353,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "D07-1066": {
        "input_sentences": [
            "(2006), the question whether or not Ger man is harder to parse than English remains undecided.",
            "This claim is based on the assumption that PARSEVAL metrics fully re flect parse quality across treebank encodingschemes.",
            "Wealso provide extensive past-parsing crosstreebank conversion.",
            "The results of the ex periments show that, contrary to Ku?bler etal.",
            "Recent studies focussed on the question whether less-configurational languages like German are harder to parse than English, or whether the lower parsing scores are an artefact of treebank encoding schemes and data structures, as claimed by Ku?bler et al(2006).",
            "We use thePARSEVAL metric, the Leaf-Ancestor metric as well as a dependency-based evaluation, and present novel approaches measur ing the effect of controlled error insertion on treebank trees and parser output.",
            "In this paper we present new ex periments to test this claim.",
            "Treebank Annotation Schemes and Parser Evaluation for German",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.06473802515255109,
                0.0,
                0.0,
                0.2637650298807632,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.06473802515255109,
                1.0,
                0.0,
                0.0,
                0.06625371965465406,
                0.0784500094968681,
                0.09623780061216919,
                0.066464093158657,
                0.0
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.058198427407869645,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.12465329568975456,
                0.0,
                0.24374324412260565,
                0.0,
                0.0
            ],
            [
                0.2637650298807632,
                0.06625371965465406,
                0.058198427407869645,
                0.12465329568975456,
                1.0,
                0.01885621617416949,
                0.0,
                0.1889149960733471,
                0.0
            ],
            [
                0.0,
                0.0784500094968681,
                0.0,
                0.0,
                0.01885621617416949,
                1.0,
                0.062475020798521644,
                0.18936472146247565,
                0.0
            ],
            [
                0.0,
                0.09623780061216919,
                0.0,
                0.24374324412260565,
                0.0,
                0.062475020798521644,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.066464093158657,
                0.0,
                0.0,
                0.1889149960733471,
                0.18936472146247565,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "W06-3119": {
        "input_sentences": [
            "We present translation results on the shared task \u201dExploiting Parallel Texts for Statistical Machine Translation\u201d generated by a chart parsing decoder operating on phrase tables augmented and generalized with target language syntactic categories.",
            "Our translation system is available open-source under the GNU General",
            "Syntax Augmented Machine Translation Via Chart Parsing",
            "We use a target language parser to generate parse trees for each sentence on the target side of the bilingual training corpus, matching them with phrase table lattices built for the corresponding source sentence.",
            "Abstract",
            "We present results on the French-to-English task for this workshop, representing significant improvements over the workshop\u2019s baseline system.",
            "Considering phrases that correspond to syntactic categories in the parse trees we develop techniques to augment (declare a syntactically motivated category for a phrase pair) and generalize (form mixed terminal and nonterminal phrases) the phrase table into a synchronous bilingual grammar."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.09856495701393254,
                0.40671681986063757,
                0.12697448880933024,
                0.0,
                0.13274058189231178,
                0.10210544908686836
            ],
            [
                0.09856495701393254,
                1.0,
                0.10704579644111178,
                0.06695902729809794,
                0.0,
                0.0,
                0.0
            ],
            [
                0.40671681986063757,
                0.10704579644111178,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.12697448880933024,
                0.06695902729809794,
                0.0,
                1.0,
                0.0,
                0.0,
                0.15992627412049565
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.13274058189231178,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.10210544908686836,
                0.0,
                0.0,
                0.15992627412049565,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "D07-1119": {
        "input_sentences": [
            "We describe our experiments using the DeSR parser in the multilingual and do main adaptation tracks of the CoNLL 2007 shared task.",
            "For the multi lingual track we adopted a second order averaged perceptron and performed feature selection to tune a feature model for each language.",
            "Abstract",
            "DeSR implements an incre mental deterministic Shift/Reduce parsing algorithm, using specific rules to handle non-projective dependencies.",
            "For the domain adaptation track we applied a tree revision method which learns how to correct the mistakes made by the base parser on the adaptation domain.",
            "Multilingual Dependency Parsing and Domain Adaptation using DeSR"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0,
                0.08012477440813684,
                0.13960924640846678,
                0.31965760336780896
            ],
            [
                0.0,
                1.0,
                0.0,
                0.0,
                0.04408892510324349,
                0.0
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.08012477440813684,
                0.0,
                0.0,
                1.0,
                0.0,
                0.20201771013882105
            ],
            [
                0.13960924640846678,
                0.04408892510324349,
                0.0,
                0.0,
                1.0,
                0.29216706617197713
            ],
            [
                0.31965760336780896,
                0.0,
                0.0,
                0.20201771013882105,
                0.29216706617197713,
                1.0
            ]
        ]
    },
    "C02-1154": {
        "input_sentences": [
            "The algorithm makes use of competing evidence to boost the learning of several categories of names simultaneously.",
            "Unsupervised Learning Of Generalized Names",
            "Examples of these are names of diseases and infectious agents, such as bacteria and viruses.",
            "Nomen uses a novel form of bootstrap ping to grow sets of textual instances and of their contextual patterns.",
            "We also investigate the relative merits of several evaluation strategies.",
            "We present results of the algorithm on a large corpus.",
            "Abstract",
            "These names exhibitcertain properties that make their identi ca tion more complex than that of regular propernames.",
            "We present an algorithm, Nomen, for learning generalized names in text."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.18741332523381704,
                0.045915272386412034,
                0.0,
                0.0,
                0.0901573640536203,
                0.0,
                0.03782472488960719,
                0.2284038592293916
            ],
            [
                0.18741332523381704,
                1.0,
                0.08279044279147635,
                0.0,
                0.0,
                0.0,
                0.0,
                0.06820226820658229,
                0.4625460326198179
            ],
            [
                0.045915272386412034,
                0.08279044279147635,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.043590455220157406,
                0.06241079796383836
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0976750065781454
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0901573640536203,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.2846511994536956
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.03782472488960719,
                0.06820226820658229,
                0.043590455220157406,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.05141363952403883
            ],
            [
                0.2284038592293916,
                0.4625460326198179,
                0.06241079796383836,
                0.0976750065781454,
                0.0,
                0.2846511994536956,
                0.0,
                0.05141363952403883,
                1.0
            ]
        ]
    },
    "W11-0131": {
        "input_sentences": [
            "As such, syntax and semantics are fully interactive; composition of semantic vectors necessarily produces a hypothetical syntactic parse.",
            "Evaluations show that using relationally-clustered headwords as a semantic space in this framework improves on a syntax-only model in perplexity and parsing accuracy.",
            "Distributed models of semantics assume that word meanings can be discovered from \u201cthe company they keep.\u201d Many such approaches learn semantics from large corpora, with each document considered to be unstructured bags of words, ignoring syntax and compositionality within a docu- In contrast, this paper proposes a semantic framework, in which semantic vectors are defined and composed in syntactic context.",
            "Structured Composition of Semantic Vectors",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.07178879245877602,
                0.20646509079773384,
                0.30100717674366195,
                0.0
            ],
            [
                0.07178879245877602,
                1.0,
                0.08829086321297627,
                0.0579399888553989,
                0.0
            ],
            [
                0.20646509079773384,
                0.08829086321297627,
                1.0,
                0.12501026304708251,
                0.0
            ],
            [
                0.30100717674366195,
                0.0579399888553989,
                0.12501026304708251,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "A97-1014": {
        "input_sentences": [
            "An Annotation Scheme for Free Word Order Languages",
            "Since the requirements for such a formalism differ from those posited for configurational languages, several features have been added, influencing the architecture of the scheme.",
            "The resulting scheme reflects a stratificational notion of language, and makes only minimal assumpabout the interrelation of the particu- \u2022lar representational strata.",
            "Abstract",
            "We describe an annotation scheme and a tool developed for creating linguistically annotated corpora for non-configurational languages."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.11876052256333934,
                0.041384884321766735,
                0.0,
                0.22387863664261495
            ],
            [
                0.11876052256333934,
                1.0,
                0.02834292804578929,
                0.0,
                0.1533259351413394
            ],
            [
                0.041384884321766735,
                0.02834292804578929,
                1.0,
                0.0,
                0.02888333946430978
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.22387863664261495,
                0.1533259351413394,
                0.02888333946430978,
                0.0,
                1.0
            ]
        ]
    },
    "W10-1403": {
        "input_sentences": [
            "In this paper we explore two strategies to incorporate local morphosyntactic features in Hindi dependency parsing.",
            "All the experiments were done with two data-driven parsers, MaltParser and MSTParser, on a part of multi-layered and multi-representational Hindi Treebank which is under development.",
            "Two Methods to Incorporate &rsquo;Local Morphosyntactic&rsquo; Features in Hindi Dependency Parsing",
            "Further, we compare the results of various experiments based on various criterions and do some error analysis.",
            "We first explore which information provided by the shallow parser is most beneficial and show that local morphosyntactic features in the form of chunk type, head/non-head information, chunk boundary information, distance to the end of the chunk and suffix concatenation are very crucial in Hindi dependency parsing.",
            "Abstract",
            "We then investigate the best way to incorporate this information during dependency parsing.",
            "This paper is also the first attempt at complete sentence level parsing for Hindi.",
            "These features are obtained using a shallow parser."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0379396527227308,
                0.465709796506648,
                0.0,
                0.23642929717533284,
                0.0,
                0.24555712935614807,
                0.2529941150676302,
                0.09104714588958873
            ],
            [
                0.0379396527227308,
                1.0,
                0.031366288776516156,
                0.05814854226158433,
                0.015085016480587571,
                0.0,
                0.0,
                0.038545423416096354,
                0.0
            ],
            [
                0.465709796506648,
                0.031366288776516156,
                1.0,
                0.0,
                0.15326801746335666,
                0.0,
                0.20301229130393805,
                0.10133611381097317,
                0.07527246206287576
            ],
            [
                0.0,
                0.05814854226158433,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.23642929717533284,
                0.015085016480587571,
                0.15326801746335666,
                0.0,
                1.0,
                0.0,
                0.2182776060511059,
                0.04873566515340281,
                0.1588802972196077
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.24555712935614807,
                0.0,
                0.20301229130393805,
                0.0,
                0.2182776060511059,
                0.0,
                1.0,
                0.06455318738222236,
                0.0
            ],
            [
                0.2529941150676302,
                0.038545423416096354,
                0.10133611381097317,
                0.0,
                0.04873566515340281,
                0.0,
                0.06455318738222236,
                1.0,
                0.0
            ],
            [
                0.09104714588958873,
                0.0,
                0.07527246206287576,
                0.0,
                0.1588802972196077,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "W06-2207": {
        "input_sentences": [
            "We show that the combination of the two methods always outperforms the decision list learner alone.",
            "In this paper we present a hybrid approach for the acquisition of syntacticosemantic patterns from raw text.",
            "A Hybrid Approach For The Acquisition Of Information Extraction Patterns",
            "Abstract",
            "Our approach co-trains a decision list learner whose feature space covers the set of all syntactico-semantic patterns with an Expectation Maximization clustering algorithm that uses the text words as attributes.",
            "Furthermore, using a modular architecture we investigate several algorithms for pattern ranking, the most important component of the decision list learner."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0,
                0.0,
                0.16520927315758088,
                0.20182005259661406
            ],
            [
                0.0,
                1.0,
                0.4204070902332055,
                0.0,
                0.14947085335172045,
                0.0
            ],
            [
                0.0,
                0.4204070902332055,
                1.0,
                0.0,
                0.11184679172329436,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.16520927315758088,
                0.14947085335172045,
                0.11184679172329436,
                0.0,
                1.0,
                0.10290813642323277
            ],
            [
                0.20182005259661406,
                0.0,
                0.0,
                0.0,
                0.10290813642323277,
                1.0
            ]
        ]
    },
    "W09-0402": {
        "input_sentences": [
            "We explored novel automatic evaluation measures for machine translation output oriented to the syntactic structure of the the on the detailed tags as well as the precision, recall and F-measure obtained We also introduced Fbased on both word and grams.",
            "Abstract",
            "Syntax-Oriented Evaluation Measures for Machine Translation Output"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.38191611176970136
            ],
            [
                0.0,
                1.0,
                0.0
            ],
            [
                0.38191611176970136,
                0.0,
                1.0
            ]
        ]
    },
    "C04-1180": {
        "input_sentences": [
            "Unlike the dependency structures returned by the parser itself, these can be used directly for semantic in terpretation.",
            "Abstract",
            "We demonstrate that well-formed semantic representations can be produced for over 97% of the sentences in unseen WSJ text.We believe this is a major step towards wide coverage semantic interpretation, one of the key objectives of the field of NLP.",
            "This paper shows how to construct semantic representations from the derivations producedby a wide-coverage CCG parser.",
            "Wide-Coverage Semantic Representations From A CCG Parser"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.052796769408046736,
                0.09864755256878013,
                0.16536459085404295
            ],
            [
                0.0,
                1.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.052796769408046736,
                0.0,
                1.0,
                0.16474399971835543,
                0.2761632032390249
            ],
            [
                0.09864755256878013,
                0.0,
                0.16474399971835543,
                1.0,
                0.5965458025766242
            ],
            [
                0.16536459085404295,
                0.0,
                0.2761632032390249,
                0.5965458025766242,
                1.0
            ]
        ]
    },
    "D12-1133": {
        "input_sentences": [
            "Most current dependency parsers presuppose that input words have been morphologically disambiguated using a part-of-speech tagger before parsing begins.",
            "A Transition-Based System for Joint Part-of-Speech Tagging and Labeled Non-Projective Dependency Parsing",
            "We present a transitionbased system for joint part-of-speech tagging and labeled dependency parsing with nonprojective trees.",
            "Abstract",
            "Experimental evaluation on Chinese, Czech, English and German shows consistent improvements in both tagging and parsing accuracy when compared to a pipeline system, which lead to improved state-of-theart results for all languages."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.13741352649104216,
                0.13741352649104216,
                0.0,
                0.021879298147270645
            ],
            [
                0.13741352649104216,
                1.0,
                0.4256812239687888,
                0.0,
                0.06699485318218065
            ],
            [
                0.13741352649104216,
                0.4256812239687888,
                1.0,
                0.0,
                0.06699485318218065
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.021879298147270645,
                0.06699485318218065,
                0.06699485318218065,
                0.0,
                1.0
            ]
        ]
    },
    "P14-1126": {
        "input_sentences": [
            "We present a novel approach for inducing unsupervised dependency parsers for languages that have no labeled training data, but have translated text in a resourcerich language.",
            "We perform experiments on three Data sets \u2014 Version 1.0 and version 2.0 of Google Universal Dependency Treebanks and Treebanks from CoNLL shared-tasks, across ten languages.",
            "We obtain stateof-the art performance of all the three data sets when compared with previously studied unsupervised and projected parsing systems.",
            "Our method can be used as a purely monolingual dependency parser, requiring no human translations for the test data, thus making it applicable to a wide range of resource-poor languages.",
            "We train probabilistic parsing models for resource-poor languages by transferring cross-lingual knowledge from resource-rich language with entropy regularization.",
            "Unsupervised Dependency Parsing with Transferring Distribution via Parallel Guidance and Entropy Regularization",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0790319716211499,
                0.07555106302228452,
                0.08230290353824653,
                0.0810808779084621,
                0.09897449708224025,
                0.0
            ],
            [
                0.0790319716211499,
                1.0,
                0.07826987106732412,
                0.07045360772938294,
                0.024649700453862968,
                0.03641518043396105,
                0.0
            ],
            [
                0.07555106302228452,
                0.07826987106732412,
                1.0,
                0.02894756796202898,
                0.04030828824742507,
                0.11909545045072263,
                0.0
            ],
            [
                0.08230290353824653,
                0.07045360772938294,
                0.02894756796202898,
                1.0,
                0.16550058152222671,
                0.037922311959405625,
                0.0
            ],
            [
                0.0810808779084621,
                0.024649700453862968,
                0.04030828824742507,
                0.16550058152222671,
                1.0,
                0.2696270710081269,
                0.0
            ],
            [
                0.09897449708224025,
                0.03641518043396105,
                0.11909545045072263,
                0.037922311959405625,
                0.2696270710081269,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "P12-3012": {
        "input_sentences": [
            "Our aim is to provide the research community with easy-to-use tools to perform multilingual lexical semantic analysis and foster further research in this direction.",
            "Multilingual WSD with Just a Few Lines of Code: the BabelNet API",
            "Abstract",
            "In this paper we present an API for programmatic access to BabelNet \u2013 a wide-coverage multilingual lexical knowledge base \u2013 and multilingual knowledge-rich Word Sense Disambiguation (WSD)."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.04431832591036525,
                0.0,
                0.08205924893266756
            ],
            [
                0.04431832591036525,
                1.0,
                0.0,
                0.26691664308354
            ],
            [
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.08205924893266756,
                0.26691664308354,
                0.0,
                1.0
            ]
        ]
    },
    "W11-2205": {
        "input_sentences": [
            "However, this advantage makes them difficult to evaluate against a manually labeled gold standard.",
            "Finally, bearing the issue of evaluation in mind, we propose directions for future work in unsupervised natural language processing.",
            "The primary advantage of these methods is that they do not require annotated data to learn a model.",
            "The development of unsupervised learning methods for natural language processing tasks has become an important and popular area of research.",
            "Evaluating unsupervised learning for natural language processing tasks",
            "Inwe argue that the rarely used evaluation is more appropriate and more informative, as it takes into account the way these methods are likely to be applied.",
            "Abstract",
            "Using unsupervised part-of-speech tagging as our case study, we discuss the reasons that render this evaluation paradigm unsuitable for the evaluation of unsupervised learning methods."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.0949493278376059,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                1.0,
                0.0,
                0.20750098405686662,
                0.29702317925409344,
                0.04675253793303023,
                0.0,
                0.1493404202953002
            ],
            [
                0.0949493278376059,
                0.0,
                1.0,
                0.05144133324060719,
                0.0,
                0.043681114170067224,
                0.0,
                0.03944312244655625
            ],
            [
                0.0,
                0.20750098405686662,
                0.05144133324060719,
                1.0,
                0.5321279871639477,
                0.0397051220859764,
                0.0,
                0.15419701440686304
            ],
            [
                0.0,
                0.29702317925409344,
                0.0,
                0.5321279871639477,
                1.0,
                0.0,
                0.0,
                0.1694013622336534
            ],
            [
                0.0,
                0.04675253793303023,
                0.043681114170067224,
                0.0397051220859764,
                0.0,
                1.0,
                0.0,
                0.10964966235679999
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.0,
                0.1493404202953002,
                0.03944312244655625,
                0.15419701440686304,
                0.1694013622336534,
                0.10964966235679999,
                0.0,
                1.0
            ]
        ]
    },
    "W12-3154": {
        "input_sentences": [
            "Nevertheless, it is frequently necessary to supplement scarce in-domain training data with out-of-domain data.",
            "In statistical machine translation (SMT), it is known that performance declines when the training data is in a different domain from the test data.",
            "In this paper, we first try to relate the effect of the outof-domain data on translation performance to measures of corpus similarity, then we separately analyse the effect of adding the outof-domain data at different parts of the training pipeline (alignment, phrase extraction, and phrase scoring).",
            "Abstract",
            "Analysing the Effect of Out-of-Domain Data on SMT Systems",
            "Through experiments in 2 domains and 8 language pairs it is shown that the out-of-domain data improves coverage and translation of rare words, but may degrade the translation quality for more common words."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.2627754996307716,
                0.1864208420340233,
                0.0,
                0.20807764281407393,
                0.09800991081612427
            ],
            [
                0.2627754996307716,
                1.0,
                0.23592917823834067,
                0.0,
                0.2435002723112735,
                0.13717798640858053
            ],
            [
                0.1864208420340233,
                0.23592917823834067,
                1.0,
                0.0,
                0.22569597381032994,
                0.08916195734702939
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.20807764281407393,
                0.2435002723112735,
                0.22569597381032994,
                0.0,
                1.0,
                0.06389687180626558
            ],
            [
                0.09800991081612427,
                0.13717798640858053,
                0.08916195734702939,
                0.0,
                0.06389687180626558,
                1.0
            ]
        ]
    },
    "P11-1144": {
        "input_sentences": [
            "Semi-Supervised Frame-Semantic Parsing for Unknown Predicates",
            "The label-propagated graph is used within a frame-semantic parser and, for unknown predicates, results in over 15% absolute improvement in frame identification accuracy and over 13% absolute improvement full frame-semantic parsing on a blind test set, over a state-of-the-art supervised baseline.",
            "We construct a large graph where vertices correspond to potential predicates and use label propagation to learn possible semantic frames for new ones.",
            "Abstract",
            "We describe a new approach to disambiguating semantic frames evoked by lexical predicates previously unseen in a lexicon or annotated data.",
            "Our approach makes use of large amounts of unlabeled data in a graph-based semi-supervised learning framework."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.43459329487293835,
                0.1009856292122636,
                0.0,
                0.11094747514805589,
                0.18216870770731633
            ],
            [
                0.43459329487293835,
                1.0,
                0.10884874081238126,
                0.0,
                0.05719698508414797,
                0.052110541572472364
            ],
            [
                0.1009856292122636,
                0.10884874081238126,
                1.0,
                0.0,
                0.1794183706830721,
                0.16031095416988947
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.11094747514805589,
                0.05719698508414797,
                0.1794183706830721,
                0.0,
                1.0,
                0.12984789715901676
            ],
            [
                0.18216870770731633,
                0.052110541572472364,
                0.16031095416988947,
                0.0,
                0.12984789715901676,
                1.0
            ]
        ]
    },
    "W09-1116": {
        "input_sentences": [
            "Indeed, broad-coverage models of noun gender have proved to be the most important source of world knowledge in automatic pronoun resolution systems.",
            "pronouns like reflect the gender and number of the entities to which they refer.",
            "While this provides useful statistics for frequent nouns, many infrequent nouns cannot be classified using this method.",
            "Our model collectively classifies all occurrences of a noun in a document using a wide variety of contextual, morphological, and categorical gender features.",
            "Rather than using co-occurrence information directly, we use it to automatically annotate training examples for a large-scale discriminative gender model.",
            "Glen Glenda or Glendale: Unsupervised and Semi-supervised Learning of English Noun Gender",
            "Previous approaches predict gender by counting the co-occurrence of nouns with pronouns of each gender class.",
            "Pronoun resolution systems can use this fact to filter noun candidates that do not agree with the pronoun gender.",
            "Abstract",
            "By leveraging large volumes of unlabeled data, our full semi-supervised system reduces error by 50% over the existing stateof-the-art in gender classification."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.02357553063868095,
                0.0,
                0.053498619847910704,
                0.016812030216499116,
                0.06495386857852567,
                0.040671390092173694,
                0.32956313574590307,
                0.0,
                0.015690144539261035
            ],
            [
                0.02357553063868095,
                1.0,
                0.0,
                0.023468572342174046,
                0.023738440378366282,
                0.028493717557065677,
                0.16272757579023037,
                0.02601463091151459,
                0.0,
                0.022154347564024138
            ],
            [
                0.0,
                0.0,
                1.0,
                0.04959575453494641,
                0.050166062293112254,
                0.0,
                0.15855504694422126,
                0.0,
                0.0,
                0.0
            ],
            [
                0.053498619847910704,
                0.023468572342174046,
                0.04959575453494641,
                1.0,
                0.12508602478379263,
                0.064659183583258,
                0.04048687069927022,
                0.05903353230723692,
                0.0,
                0.015618960939723595
            ],
            [
                0.016812030216499116,
                0.023738440378366282,
                0.050166062293112254,
                0.12508602478379263,
                1.0,
                0.020319255922231983,
                0.1160432383547007,
                0.08658340821460599,
                0.0,
                0.0737353885737864
            ],
            [
                0.06495386857852567,
                0.028493717557065677,
                0.0,
                0.064659183583258,
                0.020319255922231983,
                1.0,
                0.04915601348281999,
                0.07167392934829447,
                0.0,
                0.15804874937949223
            ],
            [
                0.040671390092173694,
                0.16272757579023037,
                0.15855504694422126,
                0.04048687069927022,
                0.1160432383547007,
                0.04915601348281999,
                1.0,
                0.04487921048827463,
                0.0,
                0.03821963228838854
            ],
            [
                0.32956313574590307,
                0.02601463091151459,
                0.0,
                0.05903353230723692,
                0.08658340821460599,
                0.07167392934829447,
                0.04487921048827463,
                1.0,
                0.0,
                0.01731343083610139
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.015690144539261035,
                0.022154347564024138,
                0.0,
                0.015618960939723595,
                0.0737353885737864,
                0.15804874937949223,
                0.03821963228838854,
                0.01731343083610139,
                0.0,
                1.0
            ]
        ]
    },
    "W11-1002": {
        "input_sentences": [
            "We then show that the correlation of HMEANT, the human variant of MEANT, can be greatly improved by introducing a simple length-based weighting scheme that approximates the degree of contribution of each semantic frame to the overall sentence.",
            "Our analysis finds that both properly structured and flattened representations fail to adequately account for the contribution of each semantic frame to the overall sentence.",
            "Structured vs. Flat Semantic Role Representations for Machine Translation Evaluation",
            "The new results also show that, without flattening the structure of semantic frames, weighting the degree of each frame\u2019s contribution gives HMEANT higher correlations than the previously bestperforming flattened model, as well as HTER.",
            "Abstract",
            "We argue that failing to capture the degree of contribution of each semantic frame in a sentence explains puzzling results in recent work on the MEANT family of semantic MT evaluation metrics, which have disturbingly indicated that dissociating semantic roles and fillers from their predicates actually improves correlation with human adequacy judgments even though, intuitively, properly segregating event frames should more accurately reflect the preservation of meaning."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.17486544036665372,
                0.025152254367455818,
                0.1874922012398039,
                0.0,
                0.19321923791399032
            ],
            [
                0.17486544036665372,
                1.0,
                0.190221559874242,
                0.1359873954875992,
                0.0,
                0.1411871713804671
            ],
            [
                0.025152254367455818,
                0.190221559874242,
                1.0,
                0.025280780290011757,
                0.0,
                0.09051603843706328
            ],
            [
                0.1874922012398039,
                0.1359873954875992,
                0.025280780290011757,
                1.0,
                0.0,
                0.14413695986351563
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0
            ],
            [
                0.19321923791399032,
                0.1411871713804671,
                0.09051603843706328,
                0.14413695986351563,
                0.0,
                1.0
            ]
        ]
    },
    "W06-2905": {
        "input_sentences": [
            "The statistical grammar formalism used is that of stochastic tree substitution grammars (STSGs), such as used in Data-Oriented Parsing.",
            "We present an algorithm for calculating the expected frequencies of arbitrary subtrees given the parameters of an STSG, and a method for estimating the parameters of an STSG given observed frequencies in a tree bank.",
            "What Are The Productive Units Of Natural Language Grammar? A DOP Approach To The Automatic Identification Of Constructions",
            "We report quantitative results on the ATIS corpus of phrase-structure annotated sentences, and give examples of the MWEs extracted from this corpus.",
            "Abstract",
            "We explore a novel computational approach to identifying \u201cconstructions\u201d or \u201cmulti-word expressions\u201d (MWEs) in an annotated corpus.",
            "In this MWEs have no special status, but emerge in a general procedure for finding the best statistical grammar to describe the training corpus."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.035798190747123836,
                0.04533977086933603,
                0.0,
                0.0,
                0.0,
                0.10021779528629218
            ],
            [
                0.035798190747123836,
                1.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            [
                0.04533977086933603,
                0.0,
                1.0,
                0.0,
                0.0,
                0.14569063270283414,
                0.052894650434400246
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.19833589326414044,
                0.135358725180165
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.14569063270283414,
                0.19833589326414044,
                0.0,
                1.0,
                0.0993309340086693
            ],
            [
                0.10021779528629218,
                0.0,
                0.052894650434400246,
                0.135358725180165,
                0.0,
                0.0993309340086693,
                1.0
            ]
        ]
    },
    "D10-1044": {
        "input_sentences": [
            "We describe a new approach to SMT adaptation that weights out-of-domain phrase pairs according to their relevance to the target domain, determined by both how similar to it they appear to be, and whether they belong to general language or not.",
            "This extends previous work on discriminative weighting by using a finer granularity, focusing on the properties of instances rather than corpus components, and using a simpler training procedure.",
            "Discriminative Instance Weighting for Domain Adaptation in Statistical Machine Translation",
            "We incorporate instance weighting into a mixture-model framework, and find that it yields consistent improvements over a wide range of baselines.",
            "Instance Weighting",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.0,
                0.1946613010370093,
                0.0,
                0.0,
                0.0
            ],
            [
                0.0,
                1.0,
                0.09977178919585633,
                0.025189489816718418,
                0.09092684698416184,
                0.0
            ],
            [
                0.1946613010370093,
                0.09977178919585633,
                1.0,
                0.10444092661534825,
                0.3770018457037177,
                0.0
            ],
            [
                0.0,
                0.025189489816718418,
                0.10444092661534825,
                1.0,
                0.27703027930910296,
                0.0
            ],
            [
                0.0,
                0.09092684698416184,
                0.3770018457037177,
                0.27703027930910296,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    },
    "I08-2105": {
        "input_sentences": [
            "We show that allowing only grammatically related words to influence each other?s senses leads to disambiguation results on a par with thebest graph-based systems, while greatly reducing the computation load.",
            "Unsupervised All-words Word Sense Disambiguation with Grammatical Dependencies",
            "We present experiments that analyze the necessity of using a highly interconnectedword/sense graph for unsupervised all words word sense disambiguation.",
            "We also com pare two methods for computing selectional preferences between the senses of every two grammatically related words: one using a Lesk-based measure on WordNet, the other using dependency relations from the British National Corpus.",
            "Abstract",
            "The best configurationuses the syntactically-constrained graph, se lectional preferences computed from thecorpus and a PageRank tie-breaking algo rithm.",
            "We especially note good performancewhen disambiguating verbs with grammati cally constrained links."
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.10197983895350819,
                0.10195790328289572,
                0.18210114516311482,
                0.0,
                0.034723532683839264,
                0.0
            ],
            [
                0.10197983895350819,
                1.0,
                0.4680972495705001,
                0.03854504022279221,
                0.0,
                0.0,
                0.0
            ],
            [
                0.10195790328289572,
                0.4680972495705001,
                1.0,
                0.11366951427249579,
                0.0,
                0.0386697558212047,
                0.0
            ],
            [
                0.18210114516311482,
                0.03854504022279221,
                0.11366951427249579,
                1.0,
                0.0,
                0.0417937807873519,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                1.0,
                0.0,
                0.0
            ],
            [
                0.034723532683839264,
                0.0,
                0.0386697558212047,
                0.0417937807873519,
                0.0,
                1.0,
                0.05941377442654629
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                0.05941377442654629,
                1.0
            ]
        ]
    },
    "N10-1002": {
        "input_sentences": [
            "The general approach of mining features from partial analyses is applicable to a range of lexical acquisition tasks, and is particularly suited to domain-specific lexical tuning and lexical acquisition using lowcoverage grammars.",
            "Chart Mining-based Lexical Acquisition with Precision Grammars",
            "In this paper, we present an innovative chart mining technique for improving parse coverage based on partial parse outputs from precision grammars.",
            "As an illustration of the functionality of our proposed technique, we develop a lexical acquisition model for English verb particle constructions which operates over unlexicalised features mined from a partial parsing chart.",
            "The proposed technique is shown to outperform a state-of-the-art parser over the target task, despite being based on relatively simplistic features.",
            "Abstract"
        ],
        "adjacency_matrix": [
            [
                1.0,
                0.38731385335087853,
                0.08494730407269302,
                0.1850236018269932,
                0.029949632730777723,
                0.0
            ],
            [
                0.38731385335087853,
                1.0,
                0.37349882133570905,
                0.19358924138690117,
                0.07311767500725397,
                0.0
            ],
            [
                0.08494730407269302,
                0.37349882133570905,
                1.0,
                0.09907054969946234,
                0.07483688870124812,
                0.0
            ],
            [
                0.1850236018269932,
                0.19358924138690117,
                0.09907054969946234,
                1.0,
                0.11886132395716846,
                0.0
            ],
            [
                0.029949632730777723,
                0.07311767500725397,
                0.07483688870124812,
                0.11886132395716846,
                1.0,
                0.0
            ],
            [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ]
    }
}